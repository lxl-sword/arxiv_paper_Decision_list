<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-07-10</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-07-10</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07105v1' target='_blank'>4KAgent: Agentic Any Image to 4K Super-Resolution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yushen Zuo, Qi Zheng, Mingyang Wu, Xinrui Jiang, Renjie Li, Jian Wang, Yide Zhang, Gengchen Mai, Lihong V. Wang, James Zou, Xiaoyu Wang, Ming-Hsuan Yang, Zhengzhong Tu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 17:59:19</h6>
<p class='card-text'>We present 4KAgent, a unified agentic super-resolution generalist system
designed to universally upscale any image to 4K resolution (and even higher, if
applied iteratively). Our system can transform images from extremely low
resolutions with severe degradations, for example, highly distorted inputs at
256x256, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three
core components: (1) Profiling, a module that customizes the 4KAgent pipeline
based on bespoke use cases; (2) A Perception Agent, which leverages
vision-language models alongside image quality assessment experts to analyze
the input image and make a tailored restoration plan; and (3) A Restoration
Agent, which executes the plan, following a recursive execution-reflection
paradigm, guided by a quality-driven mixture-of-expert policy to select the
optimal output for each step. Additionally, 4KAgent embeds a specialized face
restoration pipeline, significantly enhancing facial details in portrait and
selfie photos. We rigorously evaluate our 4KAgent across 11 distinct task
categories encompassing a total of 26 diverse benchmarks, setting new
state-of-the-art on a broad spectrum of imaging domains. Our evaluations cover
natural images, portrait photos, AI-generated content, satellite imagery,
fluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and
X-ray, demonstrating superior performance in terms of both perceptual (e.g.,
NIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic
paradigm for low-level vision tasks, we aim to catalyze broader interest and
innovation within vision-centric autonomous agents across diverse research
communities. We will release all the code, models, and results at:
https://4kagent.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07096v1' target='_blank'>Search for GeV-PeV neutrinos from nova T Coronae Borealis with IceCube</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jessie Thwaites, Justin Vandenbroucke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 17:52:05</h6>
<p class='card-text'>The widely anticipated outburst of recurrent nova T Coronae Borealis (T CrB),
which is near the end of its 80-year cycle, provides an excellent opportunity
to search for neutrinos from novae. Novae are an energetic class of transients,
which have been studied for hundreds of years. Because many of them are located
nearby, novae provide an excellent astrophysical laboratory to study
shock-powered emission in our own backyard. Several recent novae have
previously been detected in GeV gamma rays, and the 2021 outburst of RS
Ophiuchi was detected up to TeV energies, with evidence for a hadronic origin
of the observed emission. Previous searches for GeV-TeV neutrinos from novae,
predicted to occur alongside their gamma-ray emission, have been performed
using data from the IceCube Neutrino Observatory. However, no significant
neutrino signals from novae have yet been observed. We present plans for
follow-up of T CrB in real time with IceCube, using datasets spanning GeV to
PeV neutrino energies. Due to its closer distance and higher optical flux,
which has been well measured in two historical eruptions, the expected neutrino
signal from T CrB is several times stronger than that from RS Ophiuchi.
Furthermore, T CrB is located in the Northern sky at a declination where
IceCube's sensitivity is an additional factor of a few better than at the
location of RS Ophiuchi, which is beneficial to this search.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07086v1' target='_blank'>Lifetime study of the ColdADC for the Deep Underground Neutrino
  Experiment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenjie Wu, Benjamin Jargowsky, Yiwen Xiao, Alejandro Yankelevich, Jianming Bian, Cheng-Ju Lin, Tarun Prakash, David Christian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 17:47:21</h6>
<p class='card-text'>ColdADC is a custom ASIC digitizer implemented in 65 nm CMOS technology using
specialized techniques for long-term reliability in cryogenic environments.
ColdADC was developed for use in the DUNE Far Detector complex, which will
consist of four liquid argon time projection chambers. Each contains 17
kilotons liquid argon as the target material in order to measure neutrino
oscillations. Approximately 40,000 ColdADC ASICs will be installed for DUNE in
the first two large detectors and will be operated at cryogenic temperatures
during the experiment without replacement. The lifetime of the ColdADC is a
critical parameter affecting the data quality and physics sensitivity of the
experiment. A measurement of the lifetime of the ColdADC was carried out, and
the results shown in this paper assure orders of magnitude longer lifetime of
the ColdADC than the planned operation time of the detectors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07007v1' target='_blank'>Robust signal decompositions on the circle</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aral Kose, Daniel Liberzon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 16:36:03</h6>
<p class='card-text'>We consider the problem of decomposing a piecewise constant function on the
circle into a sum of indicator functions of closed circular disks in the plane,
whose number and location are not a priori known. This represents a situation
where an agent moving on the circle is able to sense its proximity to some
landmarks, and the goal is to estimate the number of these landmarks and their
possible locations -- which can in turn enable control tasks such as motion
planning and obstacle avoidance. Moreover, the exact values of the function at
its discontinuities (which correspond to disk boundaries for the individual
indicator functions) are not assumed to be known to the agent. We introduce
suitable notions of robustness and degrees of freedom to single out those
decompositions that are more desirable, or more likely, given this non-precise
data collected by the agent. We provide a characterization of robust
decompositions and give a procedure for generating all such decompositions.
When the given function admits a robust decomposition, we compute the number of
possible robust decompositions and derive bounds for the number of
decompositions maximizing the degrees of freedom.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06994v1' target='_blank'>Cross-Modality Masked Learning for Survival Prediction in ICI Treated
  NSCLC Patients</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qilong Xing, Zikai Song, Bingxin Gong, Lian Yang, Junqing Yu, Wei Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 16:19:31</h6>
<p class='card-text'>Accurate prognosis of non-small cell lung cancer (NSCLC) patients undergoing
immunotherapy is essential for personalized treatment planning, enabling
informed patient decisions, and improving both treatment outcomes and quality
of life. However, the lack of large, relevant datasets and effective
multi-modal feature fusion strategies pose significant challenges in this
domain. To address these challenges, we present a large-scale dataset and
introduce a novel framework for multi-modal feature fusion aimed at enhancing
the accuracy of survival prediction. The dataset comprises 3D CT images and
corresponding clinical records from NSCLC patients treated with immune
checkpoint inhibitors (ICI), along with progression-free survival (PFS) and
overall survival (OS) data. We further propose a cross-modality masked learning
approach for medical feature fusion, consisting of two distinct branches, each
tailored to its respective modality: a Slice-Depth Transformer for extracting
3D features from CT images and a graph-based Transformer for learning node
features and relationships among clinical variables in tabular data. The fusion
process is guided by a masked modality learning strategy, wherein the model
utilizes the intact modality to reconstruct missing components. This mechanism
improves the integration of modality-specific features, fostering more
effective inter-modality relationships and feature interactions. Our approach
demonstrates superior performance in multi-modal integration for NSCLC survival
prediction, surpassing existing methods and setting a new benchmark for
prognostic models in this context.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06960v1' target='_blank'>Bounomodes: the grazing ox algorithm for exploration of clustered
  anomalies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Samuel Matloob, Ayan Dutta, O. Patrick Kreidl, Swapnonel Roy, Ladislau Bölöni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 15:46:22</h6>
<p class='card-text'>A common class of algorithms for informative path planning (IPP) follows
boustrophedon ("as the ox turns") patterns, which aim to achieve uniform area
coverage. However, IPP is often applied in scenarios where anomalies, such as
plant diseases, pollution, or hurricane damage, appear in clusters. In such
cases, prioritizing the exploration of anomalous regions over uniform coverage
is beneficial. This work introduces a class of algorithms referred to as
bounom\=odes ("as the ox grazes"), which alternates between uniform
boustrophedon sampling and targeted exploration of detected anomaly clusters.
While uniform sampling can be designed using geometric principles, close
exploration of clusters depends on the spatial distribution of anomalies and
must be learned. In our implementation, the close exploration behavior is
learned using deep reinforcement learning algorithms. Experimental evaluations
demonstrate that the proposed approach outperforms several established
baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06958v1' target='_blank'>A hybrid dosimetry approach for remote audits in Ir-192 HDR interstitial
  brachytherapy: Development and pilot implementation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eleftherios P Pappas, Vasiliki Peppa, Alexandra Drakopoulou, Eleni Velissariou, Zoi Thrapsanioti, Georgios Kollias, Efi Koutsouveli, Pantelis Karaiskos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 15:40:15</h6>
<p class='card-text'>Purpose: This work presents the development and pilot implementation of a
comprehensive remote dosimetry audit for Ir-192 High Dose Rate interstitial
brachytherapy, integrating experimental and computational dosimetry procedures
into a unified workflow. TG43 and Model Based Dose Calculations Algorithms
(MBDCAs) are both considered. Methods: A compact, water-equivalent phantom was
designed to hold two catheters, ten Optically Stimulated Luminescent Dosimeters
(OSLDs) and two radiochromic films, enabling point and 2D dose measurements. A
user-selected treatment plan was created using a clinical Treatment Planning
System (TPS), tailored to the optimal dose range of the dosimeters. A
computational dosimetry audit test was also performed via Monte Carlo (MC)
simulations, enabling independent 3D dose calculations for the same plan and
phantom geometry. All dosimetry results were compared to TPS calculations (TG43
and an MBDCA) using the Gamma Index (GI) test, dose difference maps, and
dose-volume histogram comparisons, wherever applicable. The protocol was
designed to minimize clinical workload. Results: This study was completed
within ten days of phantom delivery to the clinic. If necessary, measurements
were corrected using appropriate correction factors determined through side
studies. GI passing criteria were adapted to the uncertainty of each dosimetry
system. Excellent agreement was found between MBDCA and experimental or MC
results. Within the volume of interest, TG43 systematically overestimated dose
compared to MC (median difference: 2.16%), attributed to missing scatter and
phantom material. Conclusion: Despite the labor-intensive workflow, this
protocol supports remote Ir-192 audits with acceptable uncertainties. Combining
experimental and computational methods enhances the robustness of the audit.
This hybrid approach shows clear advantages for rigorous dosimetry auditing
programs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06899v1' target='_blank'>VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual
  Grounding Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziang Ye, Yang Zhang, Wentao Shi, Xiaoyu You, Fuli Feng, Tat-Seng Chua</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 14:36:00</h6>
<p class='card-text'>Graphical User Interface (GUI) agents powered by Large Vision-Language Models
(LVLMs) have emerged as a revolutionary approach to automating human-machine
interactions, capable of autonomously operating personal devices (e.g., mobile
phones) or applications within the device to perform complex real-world tasks
in a human-like manner. However, their close integration with personal devices
raises significant security concerns, with many threats, including backdoor
attacks, remaining largely unexplored. This work reveals that the visual
grounding of GUI agent-mapping textual plans to GUI elements-can introduce
vulnerabilities, enabling new types of backdoor attacks. With backdoor attack
targeting visual grounding, the agent's behavior can be compromised even when
given correct task-solving plans. To validate this vulnerability, we propose
VisualTrap, a method that can hijack the grounding by misleading the agent to
locate textual plans to trigger locations instead of the intended targets.
VisualTrap uses the common method of injecting poisoned data for attacks, and
does so during the pre-training of visual grounding to ensure practical
feasibility of attacking. Empirical results show that VisualTrap can
effectively hijack visual grounding with as little as 5% poisoned data and
highly stealthy visual triggers (invisible to the human eye); and the attack
can be generalized to downstream tasks, even after clean fine-tuning. Moreover,
the injected trigger can remain effective across different GUI environments,
e.g., being trained on mobile/web and generalizing to desktop environments.
These findings underscore the urgent need for further research on backdoor
attack risks in GUI agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06883v1' target='_blank'>Manifolds in Power Systems Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lucca Rodrigues Pinto, Wilson de Souza Junior, Jaime Laelson Jacob, Luis Alfonso Gallego Pareja, Taufik Abrão</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 14:19:13</h6>
<p class='card-text'>Manifold optimization (MO) is a powerful mathematical framework that can be
applied to solving complex optimization problems with objective functions (OFs)
and constraints on complex geometric structures, which is particularly useful
in advanced power systems. We explore the application of MO techniques, which
offer a robust framework for solving complex, non-convex optimization problems
in electrical power distribution systems (EPDS) and electrical power
transmission systems (EPTS), particularly for power flow analysis. This paper
introduces the principles of MO and demonstrates its advantages over
conventional methods by applying it to power flow optimization. For EPDS, a
cost function derived from a backward-forward sweep (BFS) algorithm is
optimized using the Manopt toolbox, yielding high accuracy and competitive
computational times on 14-bus, 33-bus, and 69-bus systems when compared to
established solvers. Similarly, for EPTS, MO applied via Manopt to 3-bus and
4-bus systems effectively solves power flow equations, matching traditional
methods such as Newton-Raphson in performance. The study highlights that tools
such as Manopt can mitigate implementation complexities, positioning MO as an
efficient and accessible tool for power system analysis and potentially broader
planning applications. The paper provides a comprehensive tutorial on MO,
detailing its theoretical foundations, practical methodologies, and specific
applications in power systems, particularly in power flow optimization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06647v1' target='_blank'>ClipGS: Clippable Gaussian Splatting for Interactive Cinematic
  Visualization of Volumetric Medical Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chengkun Li, Yuqi Tong, Kai Chen, Zhenya Yang, Ruiyang Li, Shi Qiu, Jason Ying-Kuen Chan, Pheng-Ann Heng, Qi Dou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 08:24:28</h6>
<p class='card-text'>The visualization of volumetric medical data is crucial for enhancing
diagnostic accuracy and improving surgical planning and education. Cinematic
rendering techniques significantly enrich this process by providing
high-quality visualizations that convey intricate anatomical details, thereby
facilitating better understanding and decision-making in medical contexts.
However, the high computing cost and low rendering speed limit the requirement
of interactive visualization in practical applications. In this paper, we
introduce ClipGS, an innovative Gaussian splatting framework with the clipping
plane supported, for interactive cinematic visualization of volumetric medical
data. To address the challenges posed by dynamic interactions, we propose a
learnable truncation scheme that automatically adjusts the visibility of
Gaussian primitives in response to the clipping plane. Besides, we also design
an adaptive adjustment model to dynamically adjust the deformation of Gaussians
and refine the rendering performance. We validate our method on five volumetric
medical data (including CT and anatomical slice data), and reach an average
36.635 PSNR rendering quality with 156 FPS and 16.1 MB model size,
outperforming state-of-the-art methods in rendering quality and efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06643v1' target='_blank'>Learning from Sparse Point Labels for Dense Carcinosis Localization in
  Advanced Ovarian Cancer Assessment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Farahdiba Zarin, Riccardo Oliva, Vinkle Srivastav, Armine Vardazaryan, Andrea Rosati, Alice Zampolini Faustini, Giovanni Scambia, Anna Fagotti, Pietro Mascagni, Nicolas Padoy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 08:14:46</h6>
<p class='card-text'>Learning from sparse labels is a challenge commonplace in the medical domain.
This is due to numerous factors, such as annotation cost, and is especially
true for newly introduced tasks. When dense pixel-level annotations are needed,
this becomes even more unfeasible. However, being able to learn from just a few
annotations at the pixel-level, while extremely difficult and underutilized,
can drive progress in studies where perfect annotations are not immediately
available. This work tackles the challenge of learning the dense prediction
task of keypoint localization from a few point annotations in the context of 2d
carcinosis keypoint localization from laparoscopic video frames for diagnostic
planning of advanced ovarian cancer patients. To enable this, we formulate the
problem as a sparse heatmap regression from a few point annotations per image
and propose a new loss function, called Crag and Tail loss, for efficient
learning. Our proposed loss function effectively leverages positive sparse
labels while minimizing the impact of false negatives or missed annotations.
Through an extensive ablation study, we demonstrate the effectiveness of our
approach in achieving accurate dense localization of carcinosis keypoints,
highlighting its potential to advance research in scenarios where dense
annotations are challenging to obtain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06625v1' target='_blank'>Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shizhe Cai, Jayadeep Jacob, Zeya Yin, Fabio Ramos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 07:53:53</h6>
<p class='card-text'>Deep reinforcement learning has shown remarkable success in continuous
control tasks, yet often requires extensive training data, struggles with
complex, long-horizon planning, and fails to maintain safety constraints during
operation. Meanwhile, Model Predictive Control (MPC) offers explainability and
constraint satisfaction, but typically yields only locally optimal solutions
and demands careful cost function design. This paper introduces the Q-guided
STein variational model predictive Actor-Critic (Q-STAC), a novel framework
that bridges these approaches by integrating Bayesian MPC with actor-critic
reinforcement learning through constrained Stein Variational Gradient Descent
(SVGD). Our method optimizes control sequences directly using learned Q-values
as objectives, eliminating the need for explicit cost function design while
leveraging known system dynamics to enhance sample efficiency and ensure
control signals remain within safe boundaries. Extensive experiments on 2D
navigation and robotic manipulation tasks demonstrate that Q-STAC achieves
superior sample efficiency, robustness, and optimality compared to
state-of-the-art algorithms, while maintaining the high expressiveness of
policy distributions. Experiment videos are available on our website:
https://sites.google.com/view/q-stac</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06605v1' target='_blank'>Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step
  Episodic Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyu Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 07:24:18</h6>
<p class='card-text'>Classical sampling-based motion planners like the RRTs suffer from
inefficiencies, particularly in cluttered or high-dimensional spaces, due to
their reliance on undirected, random sampling. This paper introduces the
Episodic RRT, a novel hybrid planning framework that replaces the primitive of
a random point with a learned, multi-step "exploratory episode" generated by a
Deep Reinforcement Learning agent. By making the DRL agent the engine of
exploration, ERRT transforms the search process from a diffuse, volumetric
expansion into a directed, branch-like growth. This paradigm shift yields key
advantages: it counters the curse of dimensionality with focused exploration,
minimizes expensive collision checks by proactively proposing locally valid
paths, and improves connectivity by generating inherently connected path
segments. We demonstrate through extensive empirical evaluation across 2D, 3D,
and 6D environments that ERRT and its variants consistently and significantly
outperform their classical counterparts. In a challenging 6D robotic arm
scenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to
107x faster, reduces collision checks by over 99.6%, and finds initial paths
that are nearly 50% shorter. Furthermore, its asymptotically optimal variant,
ERRT*, demonstrates vastly superior anytime performance, refining solutions to
near-optimality up to 29x faster than standard RRT* in 3D environments. Code:
https://xinyuwuu.github.io/Episodic_RRT/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06509v1' target='_blank'>Prediction-Augmented Mechanism Design for Weighted Facility Location</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yangguang Shi, Zhenyu Xue</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-09 03:13:52</h6>
<p class='card-text'>Facility location is fundamental in operations research, mechanism design,
and algorithmic game theory, with applications ranging from urban
infrastructure planning to distributed systems. Recent research in this area
has focused on augmenting classic strategyproof mechanisms with predictions to
achieve an improved performance guarantee against the uncertainty under the
strategic environment. Previous work has been devoted to address the trade-off
obstacle of balancing the consistency (near-optimality under accurate
predictions) and robustness (bounded inefficiency under poor predictions)
primarily in the unweighted setting, assuming that all agents have the same
importance. However, this assumption may not be true in some practical
scenarios, leading to research of weighted facility location problems.
  The major contribution of the current work is to provide a prediction
augmented algorithmic framework for balancing the consistency and robustness
over strategic agents with non-uniform weights. In particular, through a
reduction technique that identifies a subset of \emph{representative} instances
and maps the other given locations to the representative ones, we prove that
there exists a \emph{strategyproof} mechanism achieving a bounded consistency
guarantee of $\frac{\sqrt{(1+c)^2W^2_{\min}+(1-c)^2W^2_{\max}}}{(1+c)W_{\min}}$
and a bounded robustness guarantee of
$\frac{\sqrt{(1-c)^2W^2_{\min}+(1+c)^2W^2_{\max}}}{(1-c)W_{\min}}$ in weighted
settings, where $c$ can be viewed as a parameter to make a trade-off between
the consistency and robustness and $W_{\min}$ and $W_{\max}$ denote the minimum
and maximum agents' weight. We also proved that there is no strategyproof
deterministic mechanism that reach $1$-consistency and $O\left( n \cdot
\frac{W_{\max}}{W_{\min}} \right)$-robustness in weighted FLP, even with fully
predictions of all agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06441v1' target='_blank'>VisioPath: Vision-Language Enhanced Model Predictive Control for Safe
  Autonomous Navigation in Mixed Traffic</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shanting Wang, Panagiotis Typaldos, Chenjun Li, Andreas A. Malikopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 22:47:41</h6>
<p class='card-text'>In this paper, we introduce VisioPath, a novel framework combining
vision-language models (VLMs) with model predictive control (MPC) to enable
safe autonomous driving in dynamic traffic environments. The proposed approach
leverages a bird's-eye view video processing pipeline and zero-shot VLM
capabilities to obtain structured information about surrounding vehicles,
including their positions, dimensions, and velocities. Using this rich
perception output, we construct elliptical collision-avoidance potential fields
around other traffic participants, which are seamlessly integrated into a
finite-horizon optimal control problem for trajectory planning. The resulting
trajectory optimization is solved via differential dynamic programming with an
adaptive regularization scheme and is embedded in an event-triggered MPC loop.
To ensure collision-free motion, a safety verification layer is incorporated in
the framework that provides an assessment of potential unsafe trajectories.
Extensive simulations in Simulation of Urban Mobility (SUMO) demonstrate that
VisioPath outperforms conventional MPC baselines across multiple metrics. By
combining modern AI-driven perception with the rigorous foundation of optimal
control, VisioPath represents a significant step forward in safe trajectory
planning for complex traffic systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06421v1' target='_blank'>Never Trust the Manufacturer, Never Trust the Client: A Novel Method for
  Streaming STL Files for Secure Additive</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seyed Ali Ghazi Asgar, Narasimha Reddy, Satish T. S. Bukkapatnam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 21:59:21</h6>
<p class='card-text'>While additive manufacturing has opened interesting avenues to reimagine
manufacturing as a service (MaaS) platform, transmission of design files from
client to manufacturer over networks opens up many cybersecurity challenges.
Securing client's intellectual property (IP) especially from cyber-attacks
emerges as a major challenge. Earlier works introduced streaming, instead of
sharing process plan (G-code) files, as a possible solution. However, executing
client's G-codes on manufacturer's machines exposes them to potential malicious
G-codes. This paper proposes a viable approach when the client and manufacturer
do not trust each other and both the client and manufacturer want to preserve
their IP of designs and manufacturing process respectively. The proposed
approach is based on segmenting and streaming design (STL) files and employing
a novel machine-specific STL to G-code translator at the manufacturer's site in
real-time for printing. This approach secures design and manufacturing process
IPs as demonstrated in a real-world implementation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06373v1' target='_blank'>Digital Wargames to Enhance Military Medical Evacuation Decision-Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jeremy Fischer, Ram Krishnamoorthy, Vishal Kumar, Mahdi Al-Husseini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 20:20:27</h6>
<p class='card-text'>Medical evacuation is one of the United States Army's most storied and
critical mission sets, responsible for efficiently and expediently evacuating
the battlefield ill and injured. Medical evacuation planning involves designing
a robust network of medical platforms and facilities capable of moving and
treating large numbers of casualties. Until now, there has not been a medium to
simulate these networks in a classroom setting and evaluate both offline
planning and online decision-making performance. This work describes the
Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer
simulation developed in Unity that replicates battlefield constraints and
uncertainties. MEWI accurately models patient interactions at casualty
collection points, ambulance exchange points, medical treatment facilities, and
evacuation platforms. Two operational scenarios are introduced: an amphibious
island assault in the Pacific and a Eurasian conflict across a sprawling road
and river network. These scenarios pit students against the clock to save as
many casualties as possible while adhering to doctrinal lessons learned during
didactic training. We visualize performance data collected from two iterations
of the MEWI Pacific scenario executed in the United States Army's Medical
Evacuation Doctrine Course. We consider post-wargame Likert survey data from
student participants and external observer notes to identify key planning
decision points, document medical evacuation lessons learned, and quantify
general utility. Results indicate that MEWI participation substantially
improves uptake of medical evacuation lessons learned and co-operative
decision-making. MEWI is a substantial step forward in the field of
high-fidelity training tools for medical education, and our study findings
offer critical insights into improving medical evacuation education and
operations across the joint force.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06348v1' target='_blank'>Quantum sensing with ultracold simulators in lattice and ensemble
  systems: a review</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Keshav Das Agarwal, Sayan Mondal, Ayan Sahoo, Debraj Rakshit, Aditi Sen De, Ujjwal Sen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 19:19:11</h6>
<p class='card-text'>Sensing of parameters is an important aspect in all disciplines, with
applications ranging from fundamental science to medicine. Quantum sensing and
metrology is an emerging field that lies at the cross-roads of quantum physics,
quantum technology, and the discipline in which the parameter estimation is to
be performed. While miniaturization of devices often requires quantum mechanics
to be utilized for understanding and planning of a parameter estimation,
quantum-enhanced sensing is also possible that uses paradigmatic quantum
characteristics like quantum coherence and quantum entanglement to go beyond
the so-called standard quantum limit. The current review hopes to bring
together the concepts related to quantum sensing as realized in ensemble
systems, like spin ensembles, light-matter systems, and Bose-Einstein
condensates, and lattice systems, like those which can be modelled by the Bose-
and Fermi-Hubbard models, and quantum spin models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06346v1' target='_blank'>Solving the Constrained Random Disambiguation Path Problem via
  Lagrangian Relaxation and Graph Reduction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Li Zhou, Elvan Ceyhan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 19:12:46</h6>
<p class='card-text'>We study a resource-constrained variant of the Random Disambiguation Path
(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,
in which a navigating agent must reach a target in a spatial environment
populated with uncertain obstacles. Each ambiguous obstacle may be
disambiguated at a (possibly) heterogeneous resource cost, subject to a global
disambiguation budget. We formulate this constrained planning problem as a
Weight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs
that incorporate probabilistic blockage and traversal penalties. To solve it,
we propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation
with a two-phase vertex elimination (TPVE) procedure. The method prunes
infeasible and suboptimal paths while provably preserving the optimal solution,
and leverages dual bounds to guide efficient search. We establish correctness,
feasibility guarantees, and surrogate optimality under mild assumptions. Our
analysis also demonstrates that COLOGR frequently achieves zero duality gap and
offers improved computational complexity over prior constrained path-planning
methods. Extensive simulation experiments validate the algorithm's robustness
across varying obstacle densities, sensor accuracies, and risk models,
consistently outperforming greedy baselines and approaching offline-optimal
benchmarks. The proposed framework is broadly applicable to stochastic network
design, mobility planning, and constrained decision-making under uncertainty.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06176v1' target='_blank'>IceCat-2: Updated IceCube Event Catalog of Alert Tracks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Angela Zegarelli, Anna Franckowiak, Giacomo Sommani, Nora Valtonen-Mattila, Tianlu Yuan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 16:55:02</h6>
<p class='card-text'>We present preliminary results for IceCat-2, the second public catalog of
IceCube Alert Tracks, which plans to build and improve upon the first release,
IceCat-1. The initial catalog, last updated in October 2023, included all
real-time alerts issued since 2016, as well as events observed by IceCube since
the start of full-detector data collection in 2011 that would have triggered an
alert if the program had been in place at that time. IceCat-2 plans to expand
on this by incorporating all additional alerts since IceCat-1, and reprocessing
all events with significantly improved reconstruction algorithms. A key
advancement in IceCat-2 will come from an updated reconstruction technique
introduced by the IceCube Collaboration in September 2024. This approach
substantially enhances the angular resolution of muon track alerts, while also
improving statistical coverage. With respect to IceCat-1, the 50%(90%) angular
uncertainty on track alerts is expected to be reduced by a factor of
approximately 5(4). These refined reconstructions will allow us to revisit
possible correlations between past alerts and sources in gamma-ray and X-ray
catalogs. The enhanced precision may uncover new astrophysical associations
with known astrophysical sources, offering deeper insight into potential cosmic
ray accelerators.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06165v1' target='_blank'>OmniPart: Part-Aware 3D Generation with Semantic Decoupling and
  Structural Cohesion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yunhan Yang, Yufan Zhou, Yuan-Chen Guo, Zi-Xin Zou, Yukun Huang, Ying-Tian Liu, Hao Xu, Ding Liang, Yan-Pei Cao, Xihui Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 16:46:15</h6>
<p class='card-text'>The creation of 3D assets with explicit, editable part structures is crucial
for advancing interactive applications, yet most generative methods produce
only monolithic shapes, limiting their utility. We introduce OmniPart, a novel
framework for part-aware 3D object generation designed to achieve high semantic
decoupling among components while maintaining robust structural cohesion.
OmniPart uniquely decouples this complex task into two synergistic stages: (1)
an autoregressive structure planning module generates a controllable,
variable-length sequence of 3D part bounding boxes, critically guided by
flexible 2D part masks that allow for intuitive control over part decomposition
without requiring direct correspondences or semantic labels; and (2) a
spatially-conditioned rectified flow model, efficiently adapted from a
pre-trained holistic 3D generator, synthesizes all 3D parts simultaneously and
consistently within the planned layout. Our approach supports user-defined part
granularity, precise localization, and enables diverse downstream applications.
Extensive experiments demonstrate that OmniPart achieves state-of-the-art
performance, paving the way for more interpretable, editable, and versatile 3D
content.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06129v1' target='_blank'>Learning-Augmented Model-Based Multi-Robot Planning for Time-Critical
  Search and Inspection Under Uncertainty</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhish Khanal, Joseph Prince Mathew, Cameron Nowzari, Gregory J. Stein</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 16:15:22</h6>
<p class='card-text'>In disaster response or surveillance operations, quickly identifying areas
needing urgent attention is critical, but deploying response teams to every
location is inefficient or often impossible. Effective performance in this
domain requires coordinating a multi-robot inspection team to prioritize
inspecting locations more likely to need immediate response, while also
minimizing travel time. This is particularly challenging because robots must
directly observe the locations to determine which ones require additional
attention. This work introduces a multi-robot planning framework for
coordinated time-critical multi-robot search under uncertainty. Our approach
uses a graph neural network to estimate the likelihood of PoIs needing
attention from noisy sensor data and then uses those predictions to guide a
multi-robot model-based planner to determine the cost-effective plan. Simulated
experiments demonstrate that our planner improves performance at least by
16.3\%, 26.7\%, and 26.2\% for 1, 3, and 5 robots, respectively, compared to
non-learned and learned baselines. We also validate our approach on real-world
platforms using quad-copters.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06089v1' target='_blank'>Combining IceCube Muon Tracks and Cascades to measure the Galactic
  Diffuse Neutrino Flux</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonas Hellrung, Julia Becker Tjus, Wolfgang Rhode</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 15:29:49</h6>
<p class='card-text'>The diffuse Galactic neutrino flux is produced by cosmic rays interacting
with the interstellar medium. The measurement of this flux can help to
understand the distribution of cosmic rays in the Galaxy. The first observation
of this neutrino flux was published in 2023 by the IceCube Collaboration. Here,
plans for a new analysis combining different event topologies are presented.
IceCube measures events in two main topologies. Tracks, originating in charged
current $\nu_\mu$ interactions, provide a better angular resolution. In
contrast, cascades, from most other possible interactions, provide a better
energy resolution and are able to observe the Southern sky (and therefore the
Galactic Center) despite the huge background of atmospheric muons. Combining
both event topologies in one analysis exploits all these advantages.
Sensitivities and model discrimination power of a combined measurement using a
forward folding binned likelihood fit are discussed here.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.05979v1' target='_blank'>AURA-CVC: Autonomous Ultrasound-guided Robotic Assistance for Central
  Venous Catheterization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Deepak Raina, Lidia Al-Zogbi, Brian Teixeira, Vivek Singh, Ankur Kapoor, Thorsten Fleiter, Muyinatu A. Lediju Bell, Vinciya Pandian, Axel Krieger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 13:36:56</h6>
<p class='card-text'>Purpose: Central venous catheterization (CVC) is a critical medical procedure
for vascular access, hemodynamic monitoring, and life-saving interventions. Its
success remains challenging due to the need for continuous ultrasound-guided
visualization of a target vessel and approaching needle, which is further
complicated by anatomical variability and operator dependency. Errors in needle
placement can lead to life-threatening complications. While robotic systems
offer a potential solution, achieving full autonomy remains challenging. In
this work, we propose an end-to-end robotic-ultrasound-guided CVC pipeline,
from scan initialization to needle insertion. Methods: We introduce a
deep-learning model to identify clinically relevant anatomical landmarks from a
depth image of the patient's neck, obtained using RGB-D camera, to autonomously
define the scanning region and paths. Then, a robot motion planning framework
is proposed to scan, segment, reconstruct, and localize vessels (veins and
arteries), followed by the identification of the optimal insertion zone.
Finally, a needle guidance module plans the insertion under ultrasound guidance
with operator's feedback. This pipeline was validated on a high-fidelity
commercial phantom across 10 simulated clinical scenarios. Results: The
proposed pipeline achieved 10 out of 10 successful needle placements on the
first attempt. Vessels were reconstructed with a mean error of 2.15
\textit{mm}, and autonomous needle insertion was performed with an error less
than or close to 1 \textit{mm}. Conclusion: To our knowledge, this is the first
robotic CVC system demonstrated on a high-fidelity phantom with integrated
planning, scanning, and insertion. Experimental results show its potential for
clinical translation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.06277v1' target='_blank'>The Prompt War: How AI Decides on a Military Intervention</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maxim Chupilkin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 12:52:08</h6>
<p class='card-text'>Which factors determine AI propensity for military intervention? While the
use of AI in war games and military planning is growing exponentially, the
simple analysis of key drivers embedded in the models has not yet been done.
This paper does a simple conjoint experiment proposing a model to decide on
military intervention in 640 vignettes where each was run for 100 times
allowing to explore AI decision on military intervention systematically. The
analysis finds that largest predictors of AI decision to intervene are high
domestic support and high probability of success. Costs such as international
condemnation, military deaths, civilian deaths, and negative economic effect
are statistically significant, but their effect is around half of domestic
support and probability of victory. Closing window of opportunity only reaches
statistical significance in interaction with other factors. The results are
remarkably consistent across scenarios and across different models (OpenAI GPT,
Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.05910v1' target='_blank'>Low voltage user phase reconfiguration as a planning problem</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sari Kerckhove, Marta Vanin, Reinhilde D'hulst, Dirk Van Hertem</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 11:56:28</h6>
<p class='card-text'>Considerable levels of phase imbalance in low voltage (LV) distribution
networks imply that grid assets are suboptimally utilized and can cause
additional losses, equipment failure and degradation. With the ongoing energy
transition, the installation of additional single-phase distributed energy
resources may further increase the phase imbalance if no countermeasures are
taken.
  Phase reconfiguration is a cost-effective solution to reduce imbalance.
However, dynamic reconfiguration, through real-time phase swapping of loads
using remotely controlled switches, is often impractical because these switches
are too costly for widespread installation at LV users. Approaching phase
reconfiguration as a planning problem, i.e. static reconfiguration, is an
underaddressed but promising alternative. Effective static approaches that
allow appropriate imbalance objectives are currently lacking.
  This paper presents reliable and expressive static phase reconfiguration
methods that grid operators can easily integrate into routine maintenance for
effective phase balancing.
  We present and compare three static methods, an exact mixed-integer nonlinear
formulation (MINLP), a mixed-integer quadratic approximation (MIQP), and a
genetic algorithm (GA), each supporting different imbalance objectives. The
MIQP approach, despite using proxy objectives, efficiently mitigates the
different types of imbalance considered, and outperforms both MINLP and GA in
scalability and consistency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.05884v1' target='_blank'>Comparison of Path Planning Algorithms for Autonomous Vehicle Navigation
  Using Satellite and Airborne LiDAR Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chang Liu, Zhexiong Xue, Tamas Sziranyi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 11:15:21</h6>
<p class='card-text'>Autonomous vehicle navigation in unstructured environments, such as forests
and mountainous regions, presents significant challenges due to irregular
terrain and complex road conditions. This work provides a comparative
evaluation of mainstream and well-established path planning algorithms applied
to weighted pixel-level road networks derived from high-resolution satellite
imagery and airborne LiDAR data. For 2D road-map navigation, where the weights
reflect road conditions and terrain difficulty, A*, Dijkstra, RRT*, and a Novel
Improved Ant Colony Optimization Algorithm (NIACO) are tested on the DeepGlobe
satellite dataset. For 3D road-map path planning, 3D A*, 3D Dijkstra,
RRT-Connect, and NIACO are evaluated using the Hamilton airborne LiDAR dataset,
which provides detailed elevation information. All algorithms are assessed
under identical start and end point conditions, focusing on path cost,
computation time, and memory consumption. Results demonstrate that Dijkstra
consistently offers the most stable and efficient performance in both 2D and 3D
scenarios, particularly when operating on dense, pixel-level geospatial
road-maps. These findings highlight the reliability of Dijkstra-based planning
for static terrain navigation and establish a foundation for future research on
dynamic path planning under complex environmental constraints.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.05791v2' target='_blank'>GTA1: GUI Test-time Scaling Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yan Yang, Dongxu Li, Yutong Dai, Yuhao Yang, Ziyang Luo, Zirui Zhao, Zhiyuan Hu, Junzhe Huang, Amrita Saha, Zeyuan Chen, Ran Xu, Liyuan Pan, Caiming Xiong, Junnan Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 08:52:18</h6>
<p class='card-text'>Graphical user interface (GUI) agents autonomously operate across platforms
(e.g., Linux) to complete tasks by interacting with visual elements.
Specifically, a user instruction is decomposed into a sequence of action
proposals, each corresponding to an interaction with the GUI. After each
action, the agent observes the updated GUI environment to plan the next step.
However, two main challenges arise: i) resolving ambiguity in task planning
(i.e., the action proposal sequence), where selecting an appropriate plan is
non-trivial, as many valid ones may exist; ii) accurately grounding actions in
complex and high-resolution interfaces, i.e., precisely interacting with visual
targets.
  This paper investigates the two aforementioned challenges with our GUI
Test-time Scaling Agent, namely GTA1. First, to select the most appropriate
action proposal, we introduce a test-time scaling method. At each step, we
sample multiple candidate action proposals and leverage a judge model to
evaluate and select the most suitable one. It trades off computation for better
decision quality by concurrent sampling, shortening task execution steps, and
improving overall performance. Second, we propose a model that achieves
improved accuracy when grounding the selected action proposal to its
corresponding visual elements. Our key insight is that reinforcement learning
(RL) facilitates visual grounding through inherent objective alignments,
rewarding successful clicks on interface elements.
  Experimentally, our method establishes state-of-the-art performance across
diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7%
accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When
paired with a planner applying our test-time scaling strategy, it exhibits
state-of-the-art agentic performance (e.g., 45.2% task success rate on
OSWorld). We open-source our code and models here.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.05767v1' target='_blank'>Vers un cadre ontologique pour la gestion des comp{é}tences : {à}
  des fins de formation, de recrutement, de m{é}tier, ou de recherches
  associ{é}es</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ngoc Luyen Le, Marie-Hélène Abel, Bertrand Laforge</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 08:13:30</h6>
<p class='card-text'>The rapid transformation of the labor market, driven by technological
advancements and the digital economy, requires continuous competence
development and constant adaptation. In this context, traditional competence
management systems lack interoperability, adaptability, and semantic
understanding, making it difficult to align individual competencies with labor
market needs and training programs. This paper proposes an ontology-based
framework for competence management, enabling a structured representation of
competencies, occupations, and training programs. By leveraging ontological
models and semantic reasoning, this framework aims to enhance the automation of
competence-to-job matching, the personalization of learning recommendations,
and career planning. This study discusses the design, implementation, and
potential applications of the framework, focusing on competence training
programs, job searching, and finding competent individuals.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.05764v1' target='_blank'>PSAT: Pediatric Segmentation Approaches via Adult Augmentations and
  Transfer Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tristan Kirscher, Sylvain Faisan, Xavier Coubez, Loris Barrier, Philippe Meyer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-08 08:07:36</h6>
<p class='card-text'>Pediatric medical imaging presents unique challenges due to significant
anatomical and developmental differences compared to adults. Direct application
of segmentation models trained on adult data often yields suboptimal
performance, particularly for small or rapidly evolving structures. To address
these challenges, several strategies leveraging the nnU-Net framework have been
proposed, differing along four key axes: (i) the fingerprint dataset (adult,
pediatric, or a combination thereof) from which the Training Plan -including
the network architecture-is derived; (ii) the Learning Set (adult, pediatric,
or mixed), (iii) Data Augmentation parameters, and (iv) the Transfer learning
method (finetuning versus continual learning). In this work, we introduce PSAT
(Pediatric Segmentation Approaches via Adult Augmentations and Transfer
learning), a systematic study that investigates the impact of these axes on
segmentation performance. We benchmark the derived strategies on two pediatric
CT datasets and compare them with state-of-theart methods, including a
commercial radiotherapy solution. PSAT highlights key pitfalls and provides
actionable insights for improving pediatric segmentation. Our experiments
reveal that a training plan based on an adult fingerprint dataset is misaligned
with pediatric anatomy-resulting in significant performance degradation,
especially when segmenting fine structures-and that continual learning
strategies mitigate institutional shifts, thus enhancing generalization across
diverse pediatric datasets. The code is available at
https://github.com/ICANS-Strasbourg/PSAT.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>