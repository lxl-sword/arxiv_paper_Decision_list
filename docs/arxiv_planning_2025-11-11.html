<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-11-11</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-11-11</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07375v1' target='_blank'>Exact Smooth Reformulations for Trajectory Optimization Under Signal
  Temporal Logic Specifications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaohang Han, Joris Verhagen, Jana Tumova</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 18:31:15</h6>
<p class='card-text'>We study motion planning under Signal Temporal Logic (STL), a useful
formalism for specifying spatial-temporal requirements. We pose STL synthesis
as a trajectory optimization problem leveraging the STL robustness semantics.
To obtain a differentiable problem without approximation error, we introduce an
exact reformulation of the max and min operators. The resulting method is
exact, smooth, and sound. We validate it in numerical simulations,
demonstrating its practical performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07292v1' target='_blank'>PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simon Gerstenecker, Andreas Geiger, Katrin Renz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 16:41:47</h6>
<p class='card-text'>Most recent work in autonomous driving has prioritized benchmark performance
and methodological innovation over in-depth analysis of model failures, biases,
and shortcut learning. This has led to incremental improvements without a deep
understanding of the current failures. While it is straightforward to look at
situations where the model fails, it is hard to understand the underlying
reason. This motivates us to conduct a systematic study, where inputs to the
model are perturbed and the predictions observed. We introduce PlanT 2.0, a
lightweight, object-centric planning transformer designed for autonomous
driving research in CARLA. The object-level representation enables controlled
analysis, as the input can be easily perturbed (e.g., by changing the location
or adding or removing certain objects), in contrast to sensor-based models. To
tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0,
we introduce multiple upgrades to PlanT, achieving state-of-the-art performance
on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis
exposes insightful failures, such as a lack of scene understanding caused by
low obstacle diversity, rigid expert behaviors leading to exploitable
shortcuts, and overfitting to a fixed set of expert trajectories. Based on
these findings, we argue for a shift toward data-centric development, with a
focus on richer, more robust, and less biased datasets. We open-source our code
and model at https://github.com/autonomousvision/plant2.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07231v1' target='_blank'>Mapping Reduced Accessibility to WASH Facilities in Rohingya Refugee
  Camps with Sub-Meter Imagery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kyeongjin Ahn, YongHun Suh, Sungwon Han, Jeasurk Yang, Hannes Taubenböck, Meeyoung Cha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 15:48:04</h6>
<p class='card-text'>Access to Water, Sanitation, and Hygiene (WASH) services remains a major
public health concern in refugee camps. This study introduces a remote
sensing-driven framework to quantify WASH accessibility-specifically to water
pumps, latrines, and bathing cubicles-in the Rohingya camps of Cox's Bazar, one
of the world's most densely populated displacement settings. Detecting refugee
shelters in such emergent camps presents substantial challenges, primarily due
to their dense spatial configuration and irregular geometric patterns. Using
sub-meter satellite images, we develop a semi-supervised segmentation framework
that achieves an F1-score of 76.4% in detecting individual refugee shelters.
Applying the framework across multi-year data reveals declining WASH
accessibility, driven by rapid refugee population growth and reduced facility
availability, rising from 25 people per facility in 2022 to 29.4 in 2025.
Gender-disaggregated analysis further shows that women and girls experience
reduced accessibility, in scenarios with inadequate safety-related segregation
in WASH facilities. These findings suggest the importance of demand-responsive
allocation strategies that can identify areas with under-served
populations-such as women and girls-and ensure that limited infrastructure
serves the greatest number of people in settings with fixed or shrinking
budgets. We also discuss the value of high-resolution remote sensing and
machine learning to detect inequality and inform equitable resource planning in
complex humanitarian environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07219v1' target='_blank'>Integrating Epigenetic and Phenotypic Features for Biological Age
  Estimation in Cancer Patients via Multimodal Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuyue Jiang, Wenjing Ma, Shaojun Yu, Chang Su, Runze Yan, Jiaying Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 15:42:14</h6>
<p class='card-text'>Biological age, which may be older or younger than chronological age due to
factors such as genetic predisposition, environmental exposures, serves as a
meaningful biomarker of aging processes and can inform risk stratification,
treatment planning, and survivorship care in cancer patients. We propose
EpiCAge, a multimodal framework that integrates epigenetic and phenotypic data
to improve biological age prediction. Evaluated on eight internal and four
external cancer cohorts, EpiCAge consistently outperforms existing epigenetic
and phenotypic age clocks. Our analyses show that EpiCAge identifies
biologically relevant markers, and its derived age acceleration is
significantly associated with mortality risk. These results highlight EpiCAge
as a promising multimodal machine learning tool for biological age assessment
in oncology.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07155v1' target='_blank'>Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in
  Reinforcement Learning for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thomas Steinecker, Alexander Bienemann, Denis Trescher, Thorsten Luettel, Mirko Maehlisch</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 14:45:24</h6>
<p class='card-text'>Reinforcement learning (RL) has shown promise in robotics, but deploying RL
on real vehicles remains challenging due to the complexity of vehicle dynamics
and the mismatch between simulation and reality. Factors such as tire
characteristics, road surface conditions, aerodynamic disturbances, and vehicle
load make it infeasible to model real-world dynamics accurately, which hinders
direct transfer of RL agents trained in simulation. In this paper, we present a
framework that decouples motion planning from vehicle control through a spatial
and temporal alignment strategy between a virtual vehicle and the real system.
An RL agent is first trained in simulation using a kinematic bicycle model to
output continuous control actions. Its behavior is then distilled into a
trajectory-predicting agent that generates finite-horizon ego-vehicle
trajectories, enabling synchronization between virtual and real vehicles. At
deployment, a Stanley controller governs lateral dynamics, while longitudinal
alignment is maintained through adaptive update mechanisms that compensate for
deviations between virtual and real trajectories. We validate our approach on a
real vehicle and demonstrate that the proposed alignment strategy enables
robust zero-shot transfer of RL-based motion planning from simulation to
reality, successfully decoupling high-level trajectory generation from
low-level vehicle control.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07106v1' target='_blank'>HENet++: Hybrid Encoding and Multi-task Learning for 3D Perception and
  End-to-end Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhongyu Xia, Zhiwei Lin, Yongtao Wang, Ming-Hsuan Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 13:49:59</h6>
<p class='card-text'>Three-dimensional feature extraction is a critical component of autonomous
driving systems, where perception tasks such as 3D object detection,
bird's-eye-view (BEV) semantic segmentation, and occupancy prediction serve as
important constraints on 3D features. While large image encoders,
high-resolution images, and long-term temporal inputs can significantly enhance
feature quality and deliver remarkable performance gains, these techniques are
often incompatible in both training and inference due to computational resource
constraints. Moreover, different tasks favor distinct feature representations,
making it difficult for a single model to perform end-to-end inference across
multiple tasks while maintaining accuracy comparable to that of single-task
models. To alleviate these issues, we present the HENet and HENet++ framework
for multi-task 3D perception and end-to-end autonomous driving. Specifically,
we propose a hybrid image encoding network that uses a large image encoder for
short-term frames and a small one for long-term frames. Furthermore, our
framework simultaneously extracts both dense and sparse features, providing
more suitable representations for different tasks, reducing cumulative errors,
and delivering more comprehensive information to the planning module. The
proposed architecture maintains compatibility with various existing 3D feature
extraction methods and supports multimodal inputs. HENet++ achieves
state-of-the-art end-to-end multi-task 3D perception results on the nuScenes
benchmark, while also attaining the lowest collision rate on the nuScenes
end-to-end autonomous driving benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07098v1' target='_blank'>Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture
  and Focalized Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuanshao Zhu, Xiangyu Zhao, Zijian Zhang, Xuetao Wei, James Jianqiao Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 13:38:26</h6>
<p class='card-text'>Fine-grained urban flow inference is crucial for urban planning and
intelligent transportation systems, enabling precise traffic management and
resource allocation. However, the practical deployment of existing methods is
hindered by two key challenges: the prohibitive computational cost of
over-parameterized models and the suboptimal performance of conventional loss
functions on the highly skewed distribution of urban flows. To address these
challenges, we propose a unified solution that synergizes architectural
efficiency with adaptive optimization. Specifically, we first introduce PLGF, a
lightweight yet powerful architecture that employs a Progressive Local-Global
Fusion strategy to effectively capture both fine-grained details and global
contextual dependencies. Second, we propose DualFocal Loss, a novel function
that integrates dual-space supervision with a difficulty-aware focusing
mechanism, enabling the model to adaptively concentrate on hard-to-predict
regions. Extensive experiments on 4 real-world scenarios validate the
effectiveness and scalability of our method. Notably, while achieving
state-of-the-art performance, PLGF reduces the model size by up to 97% compared
to current high-performing methods. Furthermore, under comparable parameter
budgets, our model yields an accuracy improvement of over 10% against strong
baselines. The implementation is included in the https://github.com/Yasoz/PLGF.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07090v1' target='_blank'>Green AI: A systematic review and meta-analysis of its definitions,
  lifecycle models, hardware and measurement attempts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marcel Rojahn, Marcus Grum</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 13:26:06</h6>
<p class='card-text'>Across the Artificial Intelligence (AI) lifecycle - from hardware to
development, deployment, and reuse - burdens span energy, carbon, water, and
embodied impacts. Cloud provider tools improve transparency but remain
heterogeneous and often omit water and value chain effects, limiting
comparability and reproducibility. Addressing these multi dimensional burdens
requires a lifecycle approach linking phase explicit mapping with system levers
(hardware, placement, energy mix, cooling, scheduling) and calibrated
measurement across facility, system, device, and workload levels. This article
(i) establishes a unified, operational definition of Green AI distinct from
Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle
Assessment (LCA) stages, making energy, carbon, water, and embodied impacts
first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles
with decision gateways; (iv) systematizes hardware and system level strategies
across the edge cloud continuum to reduce embodied burdens; and (v) defines a
calibrated measurement framework combining estimator models with direct
metering to enable reproducible, provider agnostic comparisons. Combining
definition, lifecycle processes, hardware strategies, and calibrated
measurement, this article offers actionable, evidence based guidance for
researchers, practitioners, and policymakers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.07071v1' target='_blank'>Multi-Agent Reinforcement Learning for Deadlock Handling among
  Autonomous Mobile Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marcel Müller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 13:04:44</h6>
<p class='card-text'>This dissertation explores the application of multi-agent reinforcement
learning (MARL) for handling deadlocks in intralogistics systems that rely on
autonomous mobile robots (AMRs). AMRs enhance operational flexibility but also
increase the risk of deadlocks, which degrade system throughput and
reliability. Existing approaches often neglect deadlock handling in the
planning phase and rely on rigid control rules that cannot adapt to dynamic
operational conditions.
  To address these shortcomings, this work develops a structured methodology
for integrating MARL into logistics planning and operational control. It
introduces reference models that explicitly consider deadlock-capable
multi-agent pathfinding (MAPF) problems, enabling systematic evaluation of MARL
strategies. Using grid-based environments and an external simulation software,
the study compares traditional deadlock handling strategies with MARL-based
solutions, focusing on PPO and IMPALA algorithms under different training and
execution modes.
  Findings reveal that MARL-based strategies, particularly when combined with
centralized training and decentralized execution (CTDE), outperform rule-based
methods in complex, congested environments. In simpler environments or those
with ample spatial freedom, rule-based methods remain competitive due to their
lower computational demands. These results highlight that MARL provides a
flexible and scalable solution for deadlock handling in dynamic intralogistics
scenarios, but requires careful tailoring to the operational context.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06990v1' target='_blank'>Koopman-Based Dynamic Environment Prediction for Safe UAV Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vitor Bueno, Ali Azarbahram, Marcello Farina, Lorenzo Fagiano</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 11:42:09</h6>
<p class='card-text'>This paper presents a Koopman-based model predictive control (MPC) framework
for safe UAV navigation in dynamic environments using real-time LiDAR data. By
leveraging the Koopman operator to linearly approximate the dynamics of
surrounding objets, we enable efficient and accurate prediction of the position
of moving obstacles. Embedding this into an MPC formulation ensures robust,
collision-free trajectory planning suitable for real-time execution. The method
is validated through simulation and ROS2-Gazebo implementation, demonstrating
reliable performance under sensor noise, actuation delays, and environmental
uncertainty.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06946v1' target='_blank'>Learning to Focus: Prioritizing Informative Histories with Structured
  Attention Mechanisms in Partially Observable Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel De Dios Allegue, Jinke He, Frans A. Oliehoek</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 10:53:16</h6>
<p class='card-text'>Transformers have shown strong ability to model long-term dependencies and
are increasingly adopted as world models in model-based reinforcement learning
(RL) under partial observability. However, unlike natural language corpora, RL
trajectories are sparse and reward-driven, making standard self-attention
inefficient because it distributes weight uniformly across all past tokens
rather than emphasizing the few transitions critical for control. To address
this, we introduce structured inductive priors into the self-attention
mechanism of the dynamics head: (i) per-head memory-length priors that
constrain attention to task-specific windows, and (ii) distributional priors
that learn smooth Gaussian weightings over past state-action pairs. We
integrate these mechanisms into UniZero, a model-based RL agent with a
Transformer-based world model that supports planning under partial
observability. Experiments on the Atari 100k benchmark show that most
efficiency gains arise from the Gaussian prior, which smoothly allocates
attention to informative transitions, while memory-length priors often truncate
useful signals with overly restrictive cut-offs. In particular, Gaussian
Attention achieves a 77% relative improvement in mean human-normalized scores
over UniZero. These findings suggest that in partially observable RL domains
with non-stationary temporal dependencies, discrete memory windows are
difficult to learn reliably, whereas smooth distributional priors flexibly
adapt across horizons and yield more robust data efficiency. Overall, our
results demonstrate that encoding structured temporal priors directly into
self-attention improves the prioritization of informative histories for
dynamics modeling under partial observability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06921v1' target='_blank'>Analysis of Traffic Congestion in North Campus, Delhi University Using
  Continuous Time Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siddhartha Mahajan, Harsh Raj, Sonam Tanwar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 10:16:48</h6>
<p class='card-text'>This project investigates traffic congestion within North Campus, Delhi
University (DU), using continuous time simulations implemented in UXSim to
model vehicle movement and interaction. The study focuses on several key
intersections, identifies recurring congestion points, and evaluates the
effectiveness of conventional traffic management measures. Implementing signal
timing optimization and modest intersection reconfiguration resulted in
measurable improvements in simulated traffic flow. The results provide
practical insights for local traffic management and illustrate the value of
continuous time simulation methods for informing short-term interventions and
longer-term planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06874v1' target='_blank'>Radio-Coverage-Aware Path Planning for Cooperative Autonomous Vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Giuseppe Baruffa, Luca Rugini, Francesco Binucci, Fabrizio Frescura, Paolo Banelli, Renzo Perfetti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 09:18:42</h6>
<p class='card-text'>Fleets of autonomous vehicles (AV) often are at the core of intelligent
transportation scenarios for smart cities, and may require a wireless Internet
connection to offload computer vision tasks to data centers located either in
the edge or the cloud section of the network. Cooperation among AVs is
successful when the environment is unknown, or changes dynamically, so as to
improve coverage and trip time, and minimize the traveled distance. The AVs,
while mapping the environment with range-based sensors, move across the
wireless coverage areas, with consequences on the achieved access bit rate,
latency, and handover rate. In this paper, we propose to modify the cost of
path planning algorithms such as Dijkstra and A*, so that not only the traveled
distance is considered in the best path solution, but also the radio coverage
experience. To this aim, several radio-related cost-weighting functions are
introduced and tested, to assess the performance of the proposed techniques
with extensive simulations. The proposed mapping algorithm can achieve a
mapping error probability below 2%, while the proposed path-planning algorithms
extend the experienced radio coverage of the AVs, with limited distance
increase with respect to shortest-path existing methods, such as conventional
Dijkstra and A* algorithms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06804v1' target='_blank'>AgentSUMO: An Agentic Framework for Interactive Simulation Scenario
  Generation in SUMO via Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minwoo Jeong, Jeeyun Chang, Yoonjin Yoon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 07:46:12</h6>
<p class='card-text'>The growing complexity of urban mobility systems has made traffic simulation
indispensable for evidence-based transportation planning and policy evaluation.
However, despite the analytical capabilities of platforms such as the
Simulation of Urban MObility (SUMO), their application remains largely confined
to domain experts. Developing realistic simulation scenarios requires expertise
in network construction, origin-destination modeling, and parameter
configuration for policy experimentation, creating substantial barriers for
non-expert users such as policymakers, urban planners, and city officials.
Moreover, the requests expressed by these users are often incomplete and
abstract-typically articulated as high-level objectives, which are not well
aligned with the imperative, sequential workflows employed in existing
language-model-based simulation frameworks. To address these challenges, this
study proposes AgentSUMO, an agentic framework for interactive simulation
scenario generation via large language models. AgentSUMO departs from
imperative, command-driven execution by introducing an adaptive reasoning layer
that interprets user intents, assesses task complexity, infers missing
parameters, and formulates executable simulation plans. The framework is
structured around two complementary components, the Interactive Planning
Protocol, which governs reasoning and user interaction, and the Model Context
Protocol, which manages standardized communication and orchestration among
simulation tools. Through this design, AgentSUMO converts abstract policy
objectives into executable simulation scenarios. Experiments on urban networks
in Seoul and Manhattan demonstrate that the agentic workflow achieves
substantial improvements in traffic flow metrics while maintaining
accessibility for non-expert users, successfully bridging the gap between
policy goals and executable simulation workflows.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06801v1' target='_blank'>Vision-Aided Online A* Path Planning for Efficient and Safe Navigation
  of Service Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Praveen Kumar, Tushar Sandhan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 07:44:22</h6>
<p class='card-text'>The deployment of autonomous service robots in human-centric environments is
hindered by a critical gap in perception and planning. Traditional navigation
systems rely on expensive LiDARs that, while geometrically precise, are seman-
tically unaware, they cannot distinguish a important document on an office
floor from a harmless piece of litter, treating both as physically traversable.
While advanced semantic segmentation exists, no prior work has successfully
integrated this visual intelligence into a real-time path planner that is
efficient enough for low-cost, embedded hardware. This paper presents a frame-
work to bridge this gap, delivering context-aware navigation on an affordable
robotic platform. Our approach centers on a novel, tight integration of a
lightweight perception module with an online A* planner. The perception system
employs a semantic segmentation model to identify user-defined visual
constraints, enabling the robot to navigate based on contextual importance
rather than physical size alone. This adaptability allows an operator to define
what is critical for a given task, be it sensitive papers in an office or
safety lines in a factory, thus resolving the ambiguity of what to avoid. This
semantic perception is seamlessly fused with geometric data. The identified
visual constraints are projected as non-geometric obstacles onto a global map
that is continuously updated from sensor data, enabling robust navigation
through both partially known and unknown environments. We validate our
framework through extensive experiments in high-fidelity simulations and on a
real-world robotic platform. The results demonstrate robust, real-time
performance, proving that a cost- effective robot can safely navigate complex
environments while respecting critical visual cues invisible to traditional
planners.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06797v1' target='_blank'>FedNET: Federated Learning for Proactive Traffic Management and Network
  Capacity Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saroj Kumar Panda, Basabdatta Palit, Sadananda Behera</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 07:36:16</h6>
<p class='card-text'>We propose FedNET, a proactive and privacy-preserving framework for early
identification of high-risk links in large-scale communication networks, that
leverages a distributed multi-step traffic forecasting method. FedNET employs
Federated Learning (FL) to model the temporal evolution of node-level traffic
in a distributed manner, enabling accurate multi-step-ahead predictions (e.g.,
several hours to days) without exposing sensitive network data. Using these
node-level forecasts and known routing information, FedNET estimates the future
link-level utilization by aggregating traffic contributions across all
source-destination pairs. The links are then ranked according to the predicted
load intensity and temporal variability, providing an early warning signal for
potential high-risk links. We compare the federated traffic prediction of
FedNET against a centralized multi-step learning baseline and then
systematically analyze the impact of history and prediction window sizes on
forecast accuracy using the $R^2$ score. Results indicate that FL achieves
accuracy close to centralized training, with shorter prediction horizons
consistently yielding the highest accuracy ($R^2 >0.92$), while longer horizons
providing meaningful forecasts ($R^2 \approx 0.45\text{--}0.55$). We further
validate the efficacy of the FedNET framework in predicting network utilization
on a realistic network topology and demonstrate that it consistently identifies
high-risk links well in advance (i.e., three days ahead) of the critical stress
states emerging, making it a practical tool for anticipatory traffic
engineering and capacity planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06791v1' target='_blank'>Coupling Agent-based Modeling and Life Cycle Assessment to Analyze
  Trade-offs in Resilient Energy Transitions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Beichen Zhang, Mohammed T. Zaki, Hanna Breunig, Newsha K. Ajami</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 07:28:03</h6>
<p class='card-text'>Transitioning to sustainable and resilient energy systems requires navigating
complex and interdependent trade-offs across environmental, social, and
resource dimensions. Neglecting these trade-offs can lead to unintended
consequences across sectors. However, existing assessments often evaluate
emerging energy pathways and their impacts in silos, overlooking critical
interactions such as regional resource competition and cumulative impacts. We
present an integrated modeling framework that couples agent-based modeling and
Life Cycle Assessment (LCA) to simulate how energy transition pathways interact
with regional resource competition, ecological constraints, and community-level
burdens. We apply the model to a case study in Southern California. The results
demonstrate how integrated and multiscale decision making can shape energy
pathway deployment and reveal spatially explicit trade-offs under
scenario-driven constraints. This modeling framework can further support more
adaptive and resilient energy transition planning on spatial and institutional
scales.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06747v1' target='_blank'>Beyond Centrality: Understanding Urban Street Network Typologies Through
  Intersection Patterns</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anu Kuncheria, Joan L. Walker, Jane Macfarlane</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 06:22:05</h6>
<p class='card-text'>The structure of road networks plays a pivotal role in shaping transportation
dynamics. It also provides insights into how drivers experience city streets
and helps uncover each urban environment's unique characteristics and
challenges. Consequently, characterizing cities based on their road network
patterns can facilitate the identification of similarities and differences,
informing collaborative traffic management strategies, particularly at a
regional scale. While previous studies have investigated global network
patterns for cities, they have often overlooked detailed characterizations
within a single large urban region. Additionally, most existing research uses
metrics like degree, centrality, orientation, etc., and misses the nuances of
street networks at the intersection level, specifically the geometric angles
formed by links at intersections, which could offer a more refined feature for
characterization. To address these gaps, this study examines over 100 cities in
the San Francisco Bay Area. We introduce a novel metric for classifying
intersections, distinguishing between different types of 3-way and 4-way
intersections based on the angles formed at the intersections. Through the
application of clustering algorithms in machine learning, we have identified
three distinct typologies - grid, orthogonal, and organic cities - within the
San Francisco Bay Area. We demonstrate the effectiveness of the metric in
capturing the differences between cities based on street and intersection
patterns. The typologies generated in this study could offer valuable support
for city planners and policymakers in crafting a range of practical strategies
tailored to the complexities of each city's road network, covering aspects such
as evacuation plans, traffic signage placements, and traffic signal control.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06647v1' target='_blank'>SVOM Follow-up Observation Coordinating Service</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xu-hui Han, Pin-pin Zhang, Yu-jie Xiao, Ruo-song Zhang, Chao Wu, Li-ping Xin, Hong-bo Cai, Hai Cao, Hui-jun Chen, Jin-song Deng, Wen-long Dong, Guo-wang Du, Lei Huang, Lin Lan, Hua-li Li, Guang-wei Li, Xiao-meng Lu, Yu-lei Qiu, Jian-feng Tian, Jing Wang, Wen-jin Xie, Da-wei Xu, Yang Xu, Zhu-heng Yao, Xue-ying Zhao, Jie Zheng, Wei-kang Zheng, Ya-tong Zheng, Xiao-xiao Zhou, Jian-yan Wei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-10 02:51:52</h6>
<p class='card-text'>The Sino-French SVOM (Space Variable Objects Monitor) mission is a
space-based astronomy mission complemented with ground-based dedicated
instrumentation. It aims to explore and study high-energy cosmic phenomena,
such as gamma-ray bursts (GRBs). This unprecedented combination of space-based
and ground-based instruments will provide leading multi-wavelength
observational capabilities in gamma-rays, X-rays, optical, and near-infrared
bands. The complete observation sequence of each GRB triggered by the SVOM
mission consists of three stages, the GRB detections, followed by the on-board
and grounded automatic follow-ups, and rapid deep multi-band photometry and
spectroscopy re-visit observations. To efficiently organize all grounded
instruments performing automatic follow-ups and re-visit observations, we
develop a follow-up observation coordinating service (FOCS), which is capable
of performing GRB trigger distributing, automatic observation scheduling and
observation coordination supporting by providing a user support platform. The
FOCS also facilitates the provision of observational planning for ground-based
telescopes to conduct synchronized observations of identical celestial regions
as SVOM. The FOCS is utilized for the SVOM-dedicated ground-based telescopes as
well as for associated partner telescopes. Since the launch of SVOM in June
2024, as the FOCS system joining the operations of SVOM, multiple successful
observations have been made for SVOM GRBs. In this paper, we present the goals
of the FOCS system as well as the principle and workflow developed to achieve
these goals. The structure, technical design, implementation, and performance
of the FOCS system are also described in detail. We conclude with a summary of
the current status of the FOCS system and our near-future development plan.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06528v1' target='_blank'>Voltage-Regulated Sparse Optimization for Proactive Diagnosis of Voltage
  Collapses</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qinghua Ma, Seyyedali Hosseinalipour, Ming Shi, Jan Drgona, Shimiao Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 20:32:00</h6>
<p class='card-text'>This paper aims to proactively diagnose and manage the voltage collapse
risks, i.e., the risk of bus voltages violating the safe operational bounds,
which can be caused by extreme events and contingencies. We jointly answer two
resilience-related research questions: (Q1) Survivability: Upon having an
extreme event/contingency, will the system remain feasible with voltage staying
within a (preferred) safe range? (Q2) Dominant Vulnerability: If voltage
collapses, what are the dominant sources of system vulnerabilities responsible
for the failure? This highlights some key locations worth paying attention to
in the planning or decision-making process. To address these questions, we
propose a voltage-regulated sparse optimization that finds a minimal set of bus
locations along with quantified compensations (corrective actions) that can
simultaneously enforce AC network balance and voltage bounds. Results on
transmission systems of varying sizes (30-bus to 2383-bus) demonstrate that the
proposed method effectively mitigates voltage collapses by compensating at only
a few strategically identified nodes, while scaling efficiently to large
systems, taking on average less than 4 min for 2000+ bus cases. This work can
further serve as a backbone for more comprehensive and actionable
decision-making, such as reactive power planning to fix voltage issues.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06471v1' target='_blank'>GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jingtao Tang, Hang Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 17:34:15</h6>
<p class='card-text'>We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP)
defined over a Graph of Convex Sets (GCS) -- a powerful representation for
trajectory planning that decomposes the configuration space into convex regions
connected by a sparse graph. In this setting, edge costs are not fixed but
depend on the specific trajectory selected through each convex region, making
classical TSP methods inapplicable. We introduce GHOST, a hierarchical
framework that optimally solves the GCS-TSP by combining combinatorial tour
search with convex trajectory optimization. GHOST systematically explores tours
on a complete graph induced by the GCS, using a novel abstract-path-unfolding
algorithm to compute admissible lower bounds that guide best-first search at
both the high level (over tours) and the low level (over feasible GCS paths
realizing the tour). These bounds provide strong pruning power, enabling
efficient search while avoiding unnecessary convex optimization calls. We prove
that GHOST guarantees optimality and present a bounded-suboptimal variant for
time-critical scenarios. Experiments show that GHOST is orders-of-magnitude
faster than unified mixed-integer convex programming baselines for simple cases
and uniquely handles complex trajectory planning problems involving high-order
continuity constraints and an incomplete GCS.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06470v1' target='_blank'>Brain-Inspired Planning for Better Generalization in Reinforcement
  Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingde "Harry" Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 17:32:55</h6>
<p class='card-text'>Existing Reinforcement Learning (RL) systems encounter significant challenges
when applied to real-world scenarios, primarily due to poor generalization
across environments that differ from their training conditions. This thesis
explores the direction of enhancing agents' zero-shot systematic generalization
abilities by granting RL agents reasoning behaviors that are found to help
systematic generalization in the human brain. Inspired by human conscious
planning behaviors, we first introduced a top-down attention mechanism, which
allows a decision-time planning agent to dynamically focus its reasoning on the
most relevant aspects of the environmental state given its instantaneous
intentions, a process we call "spatial abstraction". This approach
significantly improves systematic generalization outside the training tasks.
Subsequently, building on spatial abstraction, we developed the Skipper
framework to automatically decompose complex tasks into simpler, more
manageable sub-tasks. Skipper provides robustness against distributional shifts
and efficacy in long-term, compositional planning by focusing on pertinent
spatial and temporal elements of the environment. Finally, we identified a
common failure mode and safety risk in planning agents that rely on generative
models to generate state targets during planning. It is revealed that most
agents blindly trust the targets they hallucinate, resulting in delusional
planning behaviors. Inspired by how the human brain rejects delusional
intentions, we propose learning a feasibility evaluator to enable rejecting
hallucinated infeasible targets, which led to significant performance
improvements in various kinds of planning agents. Finally, we suggest
directions for future research, aimed at achieving general task abstraction and
fully enabling abstract planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06456v1' target='_blank'>EIDSeg: A Pixel-Level Semantic Segmentation Dataset for Post-Earthquake
  Damage Assessment from Social Media Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huili Huang, Chengeng Liu, Danrong Zhang, Shail Patel, Anastasiya Masalava, Sagar Sadak, Parisa Babolhavaeji, WeiHong Low, Max Mahdi Roozbahani, J. David Frost</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 16:42:36</h6>
<p class='card-text'>Rapid post-earthquake damage assessment is crucial for rescue and resource
planning. Still, existing remote sensing methods depend on costly aerial
images, expert labeling, and produce only binary damage maps for early-stage
evaluation. Although ground-level images from social networks provide a
valuable source to fill this gap, a large pixel-level annotated dataset for
this task is still unavailable. We introduce EIDSeg, the first large-scale
semantic segmentation dataset specifically for post-earthquake social media
imagery. The dataset comprises 3,266 images from nine major earthquakes
(2008-2023), annotated across five classes of infrastructure damage: Undamaged
Building, Damaged Building, Destroyed Building, Undamaged Road, and Damaged
Road. We propose a practical three-phase cross-disciplinary annotation protocol
with labeling guidelines that enables consistent segmentation by non-expert
annotators, achieving over 70% inter-annotator agreement. We benchmark several
state-of-the-art segmentation models, identifying Encoder-only Mask Transformer
(EoMT) as the top-performing method with a Mean Intersection over Union (mIoU)
of 80.8%. By unlocking social networks' rich ground-level perspective, our work
paves the way for a faster, finer-grained damage assessment in the
post-earthquake scenario.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06337v1' target='_blank'>BuildingWorld: A Structured 3D Building Dataset for Urban Foundation
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shangfeng Huang, Ruisheng Wang, Xin Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 11:40:34</h6>
<p class='card-text'>As digital twins become central to the transformation of modern cities,
accurate and structured 3D building models emerge as a key enabler of
high-fidelity, updatable urban representations. These models underpin diverse
applications including energy modeling, urban planning, autonomous navigation,
and real-time reasoning. Despite recent advances in 3D urban modeling, most
learning-based models are trained on building datasets with limited
architectural diversity, which significantly undermines their generalizability
across heterogeneous urban environments. To address this limitation, we present
BuildingWorld, a comprehensive and structured 3D building dataset designed to
bridge the gap in stylistic diversity. It encompasses buildings from
geographically and architecturally diverse regions -- including North America,
Europe, Asia, Africa, and Oceania -- offering a globally representative dataset
for urban-scale foundation modeling and analysis. Specifically, BuildingWorld
provides about five million LOD2 building models collected from diverse
sources, accompanied by real and simulated airborne LiDAR point clouds. This
enables comprehensive research on 3D building reconstruction, detection and
segmentation. Cyber City, a virtual city model, is introduced to enable the
generation of unlimited training data with customized and structurally diverse
point cloud distributions. Furthermore, we provide standardized evaluation
metrics tailored for building reconstruction, aiming to facilitate the
training, evaluation, and comparison of large-scale vision models and
foundation models in structured 3D urban environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06316v1' target='_blank'>ALIGN: A Vision-Language Framework for High-Accuracy Accident Location
  Inference through Geo-Spatial Neural Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:MD Thamed Bin Zaman Chowdhury, Moazzem Hossain</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 10:44:26</h6>
<p class='card-text'>Reliable geospatial information on road accidents is vital for safety
analysis and infrastructure planning, yet most low- and middle-income countries
continue to face a critical shortage of accurate, location-specific crash data.
Existing text-based geocoding tools perform poorly in multilingual and
unstructured news environments, where incomplete place descriptions and mixed
Bangla-English scripts obscure spatial context. To address these limitations,
this study introduces ALIGN (Accident Location Inference through Geo-Spatial
Neural Reasoning)- a vision-language framework that emulates human spatial
reasoning to infer accident coordinates directly from textual and map-based
cues. ALIGN integrates large language and vision-language models within a
multi-stage pipeline that performs optical character recognition, linguistic
reasoning, and map-level verification through grid-based spatial scanning. The
framework systematically evaluates each predicted location against contextual
and visual evidence, ensuring interpretable, fine-grained geolocation outcomes
without requiring model retraining. Applied to Bangla-language news data, ALIGN
demonstrates consistent improvements over traditional geoparsing methods,
accurately identifying district and sub-district-level crash sites. Beyond its
technical contribution, the framework establishes a high accuracy foundation
for automated crash mapping in data-scarce regions, supporting evidence-driven
road-safety policymaking and the broader integration of multimodal artificial
intelligence in transportation analytics. The code for this paper is
open-source and available at: https://github.com/Thamed-Chowdhury/ALIGN</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06300v1' target='_blank'>3dSAGER: Geospatial Entity Resolution over 3D Objects (Technical Report)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bar Genossar, Sagi Dalyot, Roee Shraga, Avigdor Gal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 09:35:45</h6>
<p class='card-text'>Urban environments are continuously mapped and modeled by various data
collection platforms, including satellites, unmanned aerial vehicles and street
cameras. The growing availability of 3D geospatial data from multiple
modalities has introduced new opportunities and challenges for integrating
spatial knowledge at scale, particularly in high-impact domains such as urban
planning and rapid disaster management. Geospatial entity resolution is the
task of identifying matching spatial objects across different datasets, often
collected independently under varying conditions. Existing approaches typically
rely on spatial proximity, textual metadata, or external identifiers to
determine correspondence. While useful, these signals are often unavailable,
unreliable, or misaligned, especially in cross-source scenarios. To address
these limitations, we shift the focus to the intrinsic geometry of 3D spatial
objects and present 3dSAGER (3D Spatial-Aware Geospatial Entity Resolution), an
end-to-end pipeline for geospatial entity resolution over 3D objects. 3dSAGER
introduces a novel, spatial-reference-independent featurization mechanism that
captures intricate geometric characteristics of matching pairs, enabling robust
comparison even across datasets with incompatible coordinate systems where
traditional spatial methods fail. As a key component of 3dSAGER, we also
propose a new lightweight and interpretable blocking method, BKAFI, that
leverages a trained model to efficiently generate high-recall candidate sets.
We validate 3dSAGER through extensive experiments on real-world urban datasets,
demonstrating significant gains in both accuracy and efficiency over strong
baselines. Our empirical study further dissects the contributions of each
component, providing insights into their impact and the overall design choices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06277v1' target='_blank'>Non-Radial Solution Structures for Quasilinear Hamilton--Jacobi--Bellman
  Equations in Bounded Settings</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dragos-Patru Covei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 08:28:31</h6>
<p class='card-text'>We study quasilinear Hamilton--Jacobi--Bellman equations on bounded smooth
convex domains. We show that the quasilinear Hamilton--Jacobi--Bellman
equations arise naturally from stochastic optimal control problems with
exit-time costs. The PDE is obtained via dynamic programming applied to
controlled It\^{o} diffusions, providing both a probabilistic interpretation
and a rigorous derivation. Our result establishes existence and uniqueness of
positive classical solutions under sub-quadratic growth conditions on the
source term. The constructive proofs, based on monotone iteration and barrier
techniques, also provide a framework for algorithmic implementation with
applications in production planning and image restoration. We provide complete
detailed proofs with rigorous estimates and establish the connection to
stochastic control theory through the dynamic programming principle.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06272v1' target='_blank'>LaneDiffusion: Improving Centerline Graph Learning via Prior Injected
  BEV Feature Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zijie Wang, Weiming Zhang, Wei Zhang, Xiao Tan, Hongxing Liu, Yaowei Wang, Guanbin Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 08:15:58</h6>
<p class='card-text'>Centerline graphs, crucial for path planning in autonomous driving, are
traditionally learned using deterministic methods. However, these methods often
lack spatial reasoning and struggle with occluded or invisible centerlines.
Generative approaches, despite their potential, remain underexplored in this
domain. We introduce LaneDiffusion, a novel generative paradigm for centerline
graph learning. LaneDiffusion innovatively employs diffusion models to generate
lane centerline priors at the Bird's Eye View (BEV) feature level, instead of
directly predicting vectorized centerlines. Our method integrates a Lane Prior
Injection Module (LPIM) and a Lane Prior Diffusion Module (LPDM) to effectively
construct diffusion targets and manage the diffusion process. Furthermore,
vectorized centerlines and topologies are then decoded from these
prior-injected BEV features. Extensive evaluations on the nuScenes and
Argoverse2 datasets demonstrate that LaneDiffusion significantly outperforms
existing methods, achieving improvements of 4.2%, 4.6%, 4.7%, 6.4% and 1.8% on
fine-grained point-level metrics (GEO F1, TOPO F1, JTOPO F1, APLS and SDA) and
2.3%, 6.4%, 6.8% and 2.1% on segment-level metrics (IoU, mAP_cf, DET_l and
TOP_ll). These results establish state-of-the-art performance in centerline
graph learning, offering new insights into generative models for this task.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06267v1' target='_blank'>Robust Differentiable Collision Detection for General Objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiayi Chen, Wei Zhao, Liangwang Ruan, Baoquan Chen, He Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 08:04:40</h6>
<p class='card-text'>Collision detection is a core component of robotics applications such as
simulation, control, and planning. Traditional algorithms like GJK+EPA compute
witness points (i.e., the closest or deepest-penetration pairs between two
objects) but are inherently non-differentiable, preventing gradient flow and
limiting gradient-based optimization in contact-rich tasks such as grasping and
manipulation. Recent work introduced efficient first-order randomized smoothing
to make witness points differentiable; however, their direction-based
formulation is restricted to convex objects and lacks robustness for complex
geometries. In this work, we propose a robust and efficient differentiable
collision detection framework that supports both convex and concave objects
across diverse scales and configurations. Our method introduces distance-based
first-order randomized smoothing, adaptive sampling, and equivalent gradient
transport for robust and informative gradient computation. Experiments on
complex meshes from DexGraspNet and Objaverse show significant improvements
over existing baselines. Finally, we demonstrate a direct application of our
method for dexterous grasp synthesis to refine the grasp quality. The code is
available at https://github.com/JYChen18/DiffCollision.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.06240v1' target='_blank'>Affordance-Guided Coarse-to-Fine Exploration for Base Placement in
  Open-Vocabulary Mobile Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tzu-Jung Lin, Jia-Fong Yeh, Hung-Ting Su, Chung-Yi Lin, Yi-Ting Chen, Winston H. Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-09 05:52:22</h6>
<p class='card-text'>In open-vocabulary mobile manipulation (OVMM), task success often hinges on
the selection of an appropriate base placement for the robot. Existing
approaches typically navigate to proximity-based regions without considering
affordances, resulting in frequent manipulation failures. We propose
Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base
placement that integrates semantic understanding from vision-language models
(VLMs) with geometric feasibility through an iterative optimization process.
Our method constructs cross-modal representations, namely Affordance RGB and
Obstacle Map+, to align semantics with spatial context. This enables reasoning
that extends beyond the egocentric limitations of RGB perception. To ensure
interaction is guided by task-relevant affordances, we leverage coarse semantic
priors from VLMs to guide the search toward task-relevant regions and refine
placements with geometric constraints, thereby reducing the risk of convergence
to local optima. Evaluated on five diverse open-vocabulary mobile manipulation
tasks, our system achieves an 85% success rate, significantly outperforming
classical geometric planners and VLM-based methods. This demonstrates the
promise of affordance-aware and multimodal reasoning for generalizable,
instruction-conditioned planning in OVMM.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>