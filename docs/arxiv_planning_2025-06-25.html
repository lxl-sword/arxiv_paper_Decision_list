<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-06-25</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-06-25</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19843v1' target='_blank'>Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guo Li, Zixiang Xu, Wei Zhang, Yikuan Hu, Xinyu Yang, Nikolay Aristov, Mingjie Tang, Elenna R Dugundji</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 17:59:12</h6>
<p class='card-text'>Predicting port congestion is crucial for maintaining reliable global supply
chains. Accurate forecasts enableimprovedshipment planning, reducedelaysand
costs, and optimizeinventoryanddistributionstrategies, thereby ensuring timely
deliveries and enhancing supply chain resilience. To achieve accurate
predictions, analyzing vessel behavior and their stay times at specific port
terminals is essential, focusing particularly on berth scheduling under various
conditions. Crucially, the model must capture and learn the underlying
priorities and patterns of berth scheduling. Berth scheduling and planning are
influenced by a range of factors, including incoming vessel size, waiting
times, and the status of vessels within the port terminal. By observing
historical Automatic Identification System (AIS) positions of vessels, we
reconstruct berth schedules, which are subsequently utilized to determine the
reward function via Inverse Reinforcement Learning (IRL). For this purpose, we
modeled a specific terminal at the Port of New York/New Jersey and developed
Temporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel
sequencing at the terminal and estimate vessel port stay, encompassing both
waiting and berthing times, to forecast port congestion. Utilizing data from
Maher Terminal spanning January 2015 to September 2023, we trained and tested
the model, achieving demonstrably excellent results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19719v1' target='_blank'>Cross-sections and experimental signatures for detection of a
  well-defined dark matter WIMP</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bailey Tallman, Jehu Martinez, Rohan Shankar, Kane Rylander, Roland E. Allen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 15:29:57</h6>
<p class='card-text'>We report the following calculations for a recently proposed bosonic dark
matter WIMP with well-defined interactions: (1)~the mass as determined by
fitting to the relic abundance; (2)~the current annihilation cross-section for
indirect detection; (3)~cross-sections for pair production accompanied by jets
in proton colliders with center-of-mass energies ranging from 13 to 100 TeV;
(4)~for the high-luminosity LHC, and planned 100 TeV proton collider, detailed
plots of experimentally accessible quantities before and after optimal cuts;
(5)~cross-sections, and plots of experimentally accessible quantities, for
production in e$^+$e$^-$ or muon colliders with center-of-mass energies up to
10 TeV; (6)~cross-section per nucleon for direct detection. The conclusions are
given in the text, including the principal prediction that (with optimal cuts)
this particle should be detectable at the high-luminosity LHC, perhaps after
only two years with an integrated luminosity of 500 fb$^{-1}$.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19712v1' target='_blank'>Estimating Spatially-Dependent GPS Errors Using a Swarm of Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Praneeth Somisetty, Robert Griffin, Victor M. Baez, Miguel F. Arevalo-Castiblanco, Aaron T. Becker, Jason M. O'Kane</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 15:19:39</h6>
<p class='card-text'>External factors, including urban canyons and adversarial interference, can
lead to Global Positioning System (GPS) inaccuracies that vary as a function of
the position in the environment. This study addresses the challenge of
estimating a static, spatially-varying error function using a team of robots.
We introduce a State Bias Estimation Algorithm (SBE) whose purpose is to
estimate the GPS biases. The central idea is to use sensed estimates of the
range and bearing to the other robots in the team to estimate changes in bias
across the environment. A set of drones moves in a 2D environment, each
sampling data from GPS, range, and bearing sensors. The biases calculated by
the SBE at estimated positions are used to train a Gaussian Process Regression
(GPR) model. We use a Sparse Gaussian process-based Informative Path Planning
(IPP) algorithm that identifies high-value regions of the environment for data
collection. The swarm plans paths that maximize information gain in each
iteration, further refining their understanding of the environment's positional
bias landscape. We evaluated SBE and IPP in simulation and compared the IPP
methodology to an open-loop strategy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19703v1' target='_blank'>Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of
  Damaged Power Networks Coupled with Road Transportation Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nathan Maurer, Harshal Kaushik, Roshni Anna Jacob, Jie Zhang, Souma Chowdhury</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 15:12:45</h6>
<p class='card-text'>The resilience of critical infrastructure networks (CINs) after disruptions,
such as those caused by natural hazards, depends on both the speed of
restoration and the extent to which operational functionality can be regained.
Allocating resources for restoration is a combinatorial optimal planning
problem that involves determining which crews will repair specific network
nodes and in what order. This paper presents a novel graph-based formulation
that merges two interconnected graphs, representing crew and transportation
nodes and power grid nodes, into a single heterogeneous graph. To enable
efficient planning, graph reinforcement learning (GRL) is integrated with
bigraph matching. GRL is utilized to design the incentive function for
assigning crews to repair tasks based on the graph-abstracted state of the
environment, ensuring generalization across damage scenarios. Two learning
techniques are employed: a graph neural network trained using Proximal Policy
Optimization and another trained via Neuroevolution. The learned incentive
functions inform a bipartite graph that links crews to repair tasks, enabling
weighted maximum matching for crew-to-task allocations. An efficient simulation
environment that pre-computes optimal node-to-node path plans is used to train
the proposed restoration planning methods. An IEEE 8500-bus power distribution
test network coupled with a 21 square km transportation network is used as the
case study, with scenarios varying in terms of numbers of damaged nodes,
depots, and crews. Results demonstrate the approach's generalizability and
scalability across scenarios, with learned policies providing 3-fold better
performance than random policies, while also outperforming optimization-based
solutions in both computation time (by several orders of magnitude) and power
restored.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19698v1' target='_blank'>Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize
  Framework for Predictive Maintenance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuojun Xie, Adam Abdin, Yiping Fang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 15:10:15</h6>
<p class='card-text'>Recent research increasingly integrates machine learning (ML) into predictive
maintenance (PdM) to reduce operational and maintenance costs in data-rich
operational settings. However, uncertainty due to model misspecification
continues to limit widespread industrial adoption. This paper proposes a PdM
framework in which sensor-driven prognostics inform decision-making under
economic trade-offs within a finite decision space. We investigate two key
questions: (1) Does higher predictive accuracy necessarily lead to better
maintenance decisions? (2) If not, how can the impact of prediction errors on
downstream maintenance decisions be mitigated? We first demonstrate that in the
traditional estimate-then-optimize (ETO) framework, errors in probabilistic
prediction can result in inconsistent and suboptimal maintenance decisions. To
address this, we propose an integrated estimate-optimize (IEO) framework that
jointly tunes predictive models while directly optimizing for maintenance
outcomes. We establish theoretical finite-sample guarantees on decision
consistency under standard assumptions. Specifically, we develop a stochastic
perturbation gradient descent algorithm suitable for small run-to-failure
datasets. Empirical evaluations on a turbofan maintenance case study show that
the IEO framework reduces average maintenance regret up to 22% compared to ETO.
This study provides a principled approach to managing prediction errors in
data-driven PdM. By aligning prognostic model training with maintenance
objectives, the IEO framework improves robustness under model misspecification
and improves decision quality. The improvement is particularly pronounced when
the decision-making policy is misaligned with the decision-maker's target.
These findings support more reliable maintenance planning in uncertain
operational environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19686v1' target='_blank'>From memories to maps: Mechanisms of in context reinforcement learning
  in transformers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ching Fang, Kanaka Rajan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 14:55:43</h6>
<p class='card-text'>Humans and animals show remarkable learning efficiency, adapting to new
environments with minimal experience. This capability is not well captured by
standard reinforcement learning algorithms that rely on incremental value
updates. Rapid adaptation likely depends on episodic memory -- the ability to
retrieve specific past experiences to guide decisions in novel contexts.
Transformers provide a useful setting for studying these questions because of
their ability to learn rapidly in-context and because their key-value
architecture resembles episodic memory systems in the brain. We train a
transformer to in-context reinforcement learn in a distribution of planning
tasks inspired by rodent behavior. We then characterize the learning algorithms
that emerge in the model. We first find that representation learning is
supported by in-context structure learning and cross-context alignment, where
representations are aligned across environments with different sensory stimuli.
We next demonstrate that the reinforcement learning strategies developed by the
model are not interpretable as standard model-free or model-based planning.
Instead, we show that in-context reinforcement learning is supported by caching
intermediate computations within the model's memory tokens, which are then
accessed at decision time. Overall, we find that memory may serve as a
computational resource, storing both raw experience and cached computations to
support flexible behavior. Furthermore, the representations developed in the
model resemble computations associated with the hippocampal-entorhinal system
in the brain, suggesting that our findings may be relevant for natural
cognition. Taken together, our work offers a mechanistic hypothesis for the
rapid adaptation that underlies in-context learning in artificial and natural
settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19639v1' target='_blank'>HOIverse: A Synthetic Scene Graph Dataset With Human Object Interactions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mrunmai Vivek Phatak, Julian Lorenz, Nico Hörmann, Jörg Hähner, Rainer Lienhart</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 14:00:31</h6>
<p class='card-text'>When humans and robotic agents coexist in an environment, scene understanding
becomes crucial for the agents to carry out various downstream tasks like
navigation and planning. Hence, an agent must be capable of localizing and
identifying actions performed by the human. Current research lacks reliable
datasets for performing scene understanding within indoor environments where
humans are also a part of the scene. Scene Graphs enable us to generate a
structured representation of a scene or an image to perform visual scene
understanding. To tackle this, we present HOIverse a synthetic dataset at the
intersection of scene graph and human-object interaction, consisting of
accurate and dense relationship ground truths between humans and surrounding
objects along with corresponding RGB images, segmentation masks, depth images
and human keypoints. We compute parametric relations between various pairs of
objects and human-object pairs, resulting in an accurate and unambiguous
relation definitions. In addition, we benchmark our dataset on state-of-the-art
scene graph generation models to predict parametric relations and human-object
interactions. Through this dataset, we aim to accelerate research in the field
of scene understanding involving people.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19621v1' target='_blank'>VideoPCDNet: Video Parsing and Prediction with Phase Correlation
  Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Noel José Rodrigues Vicente, Enrique Lehner, Angel Villar-Corrales, Jan Nogga, Sven Behnke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 13:39:47</h6>
<p class='card-text'>Understanding and predicting video content is essential for planning and
reasoning in dynamic environments. Despite advancements, unsupervised learning
of object representations and dynamics remains challenging. We present
VideoPCDNet, an unsupervised framework for object-centric video decomposition
and prediction. Our model uses frequency-domain phase correlation techniques to
recursively parse videos into object components, which are represented as
transformed versions of learned object prototypes, enabling accurate and
interpretable tracking. By explicitly modeling object motion through a
combination of frequency domain operations and lightweight learned modules,
VideoPCDNet enables accurate unsupervised object tracking and prediction of
future video frames. In our experiments, we demonstrate that VideoPCDNet
outperforms multiple object-centric baseline models for unsupervised tracking
and prediction on several synthetic datasets, while learning interpretable
object and motion representations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19531v1' target='_blank'>ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and
  CT Domain Transformation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mubashara Rehman, Niki Martinel, Michele Avanzo, Riccardo Spizzo, Christian Micheloni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 11:34:35</h6>
<p class='card-text'>Artifacts in kilo-Voltage CT (kVCT) imaging degrade image quality, impacting
clinical decisions. We propose a deep learning framework for metal artifact
reduction (MAR) and domain transformation from kVCT to Mega-Voltage CT (MVCT).
The proposed framework, ReMAR-DS, utilizes an encoder-decoder architecture with
enhanced feature recalibration, effectively reducing artifacts while preserving
anatomical structures. This ensures that only relevant information is utilized
in the reconstruction process. By infusing recalibrated features from the
encoder block, the model focuses on relevant spatial regions (e.g., areas with
artifacts) and highlights key features across channels (e.g., anatomical
structures), leading to improved reconstruction of artifact-corrupted regions.
Unlike traditional MAR methods, our approach bridges the gap between
high-resolution kVCT and artifact-resistant MVCT, enhancing radiotherapy
planning. It produces high-quality MVCT-like reconstructions, validated through
qualitative and quantitative evaluations. Clinically, this enables oncologists
to rely on kVCT alone, reducing repeated high-dose MVCT scans and lowering
radiation exposure for cancer patients.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19479v1' target='_blank'>An analytical model of depth-dose distributions for carbon-ion beams</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fulya Halıcılar, Metin Arık</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 10:14:36</h6>
<p class='card-text'>Improving effective treatment plans in carbon ion therapy, especially for
targeting radioresistant tumors located in deep seated regions while sparing
normal tissues, depends on a precise and computationally efficient dose
calculation model. Although dose calculations are mostly performed using Monte
Carlo simulations, the large amount of computational effort required for these
simulations hinders their use in clinical practice. To address this gap, we
propose, for the first time in the literature, an analytical model for the
depth dose distribution of carbon ion beams by adapting and extending Bortfeld
proton dose model. The Bortfeld model was modified and expanded by introducing
additional terms and parameters to account for the energy deposition and
fragmentation effects characteristic of carbon ions. Our model was implemented
in MATLAB software to calculate depth-dose distributions of carbon ion beams
across the clinical energy range of 100-430 MeV/u. The calculated results for
carbon ion energies of 280 MeV/u and 430 MeV/u were compared with Monte Carlo
simulation results from TOPAS to assess the precision of our model. It is
observed that the results of the proposed model are in good agreement with
those of several analytical and experimental studies for clinical carbon ion
beams within the therapeutic energy range of 100-400 MeV/u. At 280 MeV/u, the
analytical model result exhibited strong consistency with the depth dose curve
produced by TOPAS Monte Carlo simulations. However, noticeable discrepancies
appeared at higher energies, such as 430 MeV/u, particularly in the Bragg peak
height and the dose falloff. In the clinically useful energy range, our model
could potentially be an effective tool in carbon ion therapy as an alternative
to complex Monte Carlo simulations. It will enable fast dose assessment with
accuracy and in real time, thus improving workflow efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19398v1' target='_blank'>ClearerVoice-Studio: Bridging Advanced Speech Processing Research and
  Practical Deployment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shengkui Zhao, Zexu Pan, Bin Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 08:01:33</h6>
<p class='card-text'>This paper introduces ClearerVoice-Studio, an open-source, AI-powered speech
processing toolkit designed to bridge cutting-edge research and practical
application. Unlike broad platforms like SpeechBrain and ESPnet,
ClearerVoice-Studio focuses on interconnected speech tasks of speech
enhancement, separation, super-resolution, and multimodal target speaker
extraction. A key advantage is its state-of-the-art pretrained models,
including FRCRN with 3 million uses and MossFormer with 2.5 million uses,
optimized for real-world scenarios. It also offers model optimization tools,
multi-format audio support, the SpeechScore evaluation toolkit, and
user-friendly interfaces, catering to researchers, developers, and end-users.
Its rapid adoption attracting 3000 GitHub stars and 239 forks highlights its
academic and industrial impact. This paper details ClearerVoice-Studio's
capabilities, architectures, training strategies, benchmarks, community impact,
and future plan. Source code is available at
https://github.com/modelscope/ClearerVoice-Studio.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19391v1' target='_blank'>Generate the Forest before the Trees -- A Hierarchical Diffusion model
  for Climate Downscaling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Declan J. Curran, Sanaa Hobeichi, Hira Saleem, Hao Xue, Flora D. Salim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-24 07:39:53</h6>
<p class='card-text'>Downscaling is essential for generating the high-resolution climate data
needed for local planning, but traditional methods remain computationally
demanding. Recent years have seen impressive results from AI downscaling
models, particularly diffusion models, which have attracted attention due to
their ability to generate ensembles and overcome the smoothing problem common
in other AI methods. However, these models typically remain computationally
intensive. We introduce a Hierarchical Diffusion Downscaling (HDD) model, which
introduces an easily-extensible hierarchical sampling process to the diffusion
framework. A coarse-to-fine hierarchy is imposed via a simple downsampling
scheme. HDD achieves competitive accuracy on ERA5 reanalysis datasets and CMIP6
models, significantly reducing computational load by running on up to half as
many pixels with competitive results. Additionally, a single model trained at
0.25{\deg} resolution transfers seamlessly across multiple CMIP6 models with
much coarser resolution. HDD thus offers a lightweight alternative for
probabilistic climate downscaling, facilitating affordable large-ensemble
high-resolution climate projections. See a full code implementation at:
https://github.com/HDD-Hierarchical-Diffusion-Downscaling/HDD-Hierarchical-Diffusion-Downscaling.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19069v1' target='_blank'>2D transverse laser cooling of a hexapole focused beam of cold BaF
  molecules</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joost W. F. van Hofslot, Izabella E. Thompson, Anno Touwen, Nithesh Balasubramanian, Roman Bause, Hendrick L. Bethlem, Anastasia Borschevsky, Ties H. Fikkers, Steven Hoekstra, Steven A. Jones, Jelmer E. J. Levenga, Maarten C. Mooij, Heleen Mulder, Bastiaan A. Nijman, Efion H. Prinsen, Bart J. Schellenberg, Lucas van Sloten, Rob G. E. Timmermans, Wim Ubachs, Jordy de Vries, Lorenz Willmann</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 19:40:59</h6>
<p class='card-text'>A cryogenic buffer gas beam, an electrostatic hexapole lens, and 2D
transverse Doppler laser cooling are combined to produce a bright beam of
barium monofluoride ($^{138}$Ba$^{19}$F) molecules. Experimental results and
trajectory simulations are used to study the laser cooling effect as a function
of laser detuning, laser power, laser alignment, and interaction time. A
scattering rate of 6.1(1.4) $\times 10^{5}$ s$^{-1}$ on the laser cooling
transition is obtained; this is $14 \%$ of the expected maximum, which is
attributed to limited control of the magnetic field used to remix dark states.
Using 3 tuneable lasers with appropriate sidebands and detuning, each molecule
scatters approximately 400 photons during 2D laser cooling, limited by the
interaction time and scattering rate. Leaks to dark states are less than
10$\%$. The experimental results are used to benchmark the trajectory
simulations to predict the achievable flux 3.5 m downstream for a planned
$e$EDM experiment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19037v1' target='_blank'>Plan for Speed -- Dilated Scheduling for Masked Diffusion Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Omer Luxembourg, Haim Permuter, Eliya Nachmani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 18:49:23</h6>
<p class='card-text'>Masked diffusion language models (MDLM) have shown strong promise for
non-autoregressive text generation, yet existing samplers act as implicit
planners, selecting tokens to unmask via denoiser confidence or entropy scores.
Such heuristics falter under parallel unmasking - they ignore pairwise
interactions between tokens and cannot account for dependencies when unmasking
multiple positions at once, limiting their inference time to traditional
auto-regressive (AR) models. We introduce the Dilated-scheduled Unmasking
Strategy (DUS), an inference-only, planner-model-free method that requires no
additional training. DUS leverages a first-order Markov assumption to partition
sequence positions into dilation-based groups of non-adjacent tokens, enabling
independent, parallel unmasking steps that respect local context that minimizes
the joint entropy of each iteration step. Unlike semi-AR block approaches
(e.g., LLADA and Dream) that still invoke the denoiser per block, DUS reduces
the number of denoiser calls to O(log B) per generation block - yielding
substantial speedup over the O(B) run time of state-of-the-art diffusion
models, where B is the block size in the semi-AR inference process. In
experiments on math (GSM8K) and code completion (Humaneval, MBPP) benchmarks -
domains suited to non-ordinal generation - DUS improves scores over parallel
confidence-based planner, without modifying the underlying denoiser. DUS offers
a lightweight, budget-aware approach to efficient, high-quality text
generation, paving the way to unlock the true capabilities of MDLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.19016v1' target='_blank'>Faster Motion Planning via Restarts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nancy Amato, Stav Ashur, Sariel Har-Peled%</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 18:11:41</h6>
<p class='card-text'>Randomized methods such as PRM and RRT are widely used in motion planning.
However, in some cases, their running-time suffers from inherent instability,
leading to ``catastrophic'' performance even for relatively simple instances.
We apply stochastic restart techniques, some of them new, for speeding up Las
Vegas algorithms, that provide dramatic speedups in practice (a factor of $3$
[or larger] in many cases).
  Our experiments demonstrate that the new algorithms have faster runtimes,
shorter paths, and greater gains from multi-threading (when compared with
straightforward parallel implementation). We prove the optimality of the new
variants. Our implementation is open source, available on github, and is easy
to deploy and use.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18847v1' target='_blank'>Offline Goal-Conditioned Reinforcement Learning with Projective
  Quasimetric Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anthony Kobanda, Waris Radji, Mathieu Petitbois, Odalric-Ambrym Maillard, Rémy Portelas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 17:07:20</h6>
<p class='card-text'>Offline Goal-Conditioned Reinforcement Learning seeks to train agents to
reach specified goals from previously collected trajectories. Scaling that
promises to long-horizon tasks remains challenging, notably due to compounding
value-estimation errors. Principled geometric offers a potential solution to
address these issues. Following this insight, we introduce Projective
Quasimetric Planning (ProQ), a compositional framework that learns an
asymmetric distance and then repurposes it, firstly as a repulsive energy
forcing a sparse set of keypoints to uniformly spread over the learned latent
space, and secondly as a structured directional cost guiding towards proximal
sub-goals. In particular, ProQ couples this geometry with a Lagrangian
out-of-distribution detector to ensure the learned keypoints stay within
reachable areas. By unifying metric learning, keypoint coverage, and
goal-conditioned control, our approach produces meaningful sub-goals and
robustly drives long-horizon goal-reaching on diverse a navigation benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18825v1' target='_blank'>SViP: Sequencing Bimanual Visuomotor Policies with Object-Centric Motion
  Primitives</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yizhou Chen, Hang Xu, Dongjie Yu, Zeqing Zhang, Yi Ren, Jia Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 16:38:29</h6>
<p class='card-text'>Imitation learning (IL), particularly when leveraging high-dimensional visual
inputs for policy training, has proven intuitive and effective in complex
bimanual manipulation tasks. Nonetheless, the generalization capability of
visuomotor policies remains limited, especially when small demonstration
datasets are available. Accumulated errors in visuomotor policies significantly
hinder their ability to complete long-horizon tasks. To address these
limitations, we propose SViP, a framework that seamlessly integrates visuomotor
policies into task and motion planning (TAMP). SViP partitions human
demonstrations into bimanual and unimanual operations using a semantic scene
graph monitor. Continuous decision variables from the key scene graph are
employed to train a switching condition generator. This generator produces
parameterized scripted primitives that ensure reliable performance even when
encountering out-of-the-distribution observations. Using only 20 real-world
demonstrations, we show that SViP enables visuomotor policies to generalize
across out-of-distribution initial conditions without requiring object pose
estimators. For previously unseen tasks, SViP automatically discovers effective
solutions to achieve the goal, leveraging constraint modeling in TAMP
formulism. In real-world experiments, SViP outperforms state-of-the-art
generative IL methods, indicating wider applicability for more complex tasks.
Project website: https://sites.google.com/view/svip-bimanual</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18816v1' target='_blank'>Activities of Women in Physics Group in Spain 2022 to 2023</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pascuala Garcia-Martinez, Carmen Ocal, Ana Xesus Lopez, Mariam Tortola, Milagros F. Morcillo-Arencibia, Alberto Martin-Molina, Sonia Estrade</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 16:24:38</h6>
<p class='card-text'>In this paper, we present the main actions of the Women in Physics Group of
the Spanish Royal Physics Society over the period of 2022 to 2023, in which we
celebrated the 20th anniversary of the group. We also outline relevant equality
initiatives implemented during this period by the Spanish Government as well as
analyse their impact on the status of women in Physics in our country. In 2023,
our scientific society approved the Gender Equality Plan, thus becoming a
pioneer scientific society in Spain in implementing this relevant measure</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18755v1' target='_blank'>Universal Solvability for Robot Motion Planning on Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anubhav Dhar, Ashlesha Hota, Sudeshna Kolay, Pranav Nyati, Tanishq Prasad</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 15:25:50</h6>
<p class='card-text'>We study the Universal Solvability of Robot Motion Planning on Graphs (USolR)
problem: given an undirected graph G = (V, E) and p robots, determine whether
any arbitrary configuration of the robots can be transformed into any other
arbitrary configuration via a sequence of valid, collision-free moves. We
design a canonical accumulation procedure that maps arbitrary configurations to
configurations that occupy a fixed subset of vertices, enabling us to analyze
configuration reachability in terms of equivalence classes. We prove that in
instances that are not universally solvable, at least half of all
configurations are unreachable from a given one, and leverage this to design an
efficient randomized algorithm with one-sided error, which can be derandomized
with a blow-up in the running time by a factor of p. Further, we optimize our
deterministic algorithm by using the structure of the input graph G = (V, E),
achieving a running time of O(p * (|V| + |E|)) in sparse graphs and O(|V| +
|E|) in dense graphs. Finally, we consider the Graph Edge Augmentation for
Universal Solvability (EAUS) problem, where given a connected graph G that is
not universally solvable for p robots, the question is to check if for a given
budget b, at most b edges can be added to G to make it universally solvable for
p robots. We provide an upper bound of p - 2 on b for general graphs. On the
other hand, we also provide examples of graphs that require Theta(p) edges to
be added. We further study the Graph Vertex and Edge Augmentation for Universal
Solvability (VEAUS) problem, where a vertices and b edges can be added, and we
provide lower bounds on a and b.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18697v1' target='_blank'>Safety-Aware Optimal Scheduling for Autonomous Masonry Construction
  using Collaborative Heterogeneous Aerial Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marios-Nektarios Stamatopoulos, Shridhar Velhal, Avijit Banerjee, George Nikolakopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 14:34:49</h6>
<p class='card-text'>This paper presents a novel high-level task planning and optimal coordination
framework for autonomous masonry construction, using a team of heterogeneous
aerial robotic workers, consisting of agents with separate skills for brick
placement and mortar application. This introduces new challenges in scheduling
and coordination, particularly due to the mortar curing deadline required for
structural bonding and ensuring the safety constraints among UAVs operating in
parallel. To address this, an automated pipeline generates the wall
construction plan based on the available bricks while identifying static
structural dependencies and potential conflicts for safe operation. The
proposed framework optimizes UAV task allocation and execution timing by
incorporating dynamically coupled precedence deadline constraints that account
for the curing process and static structural dependency constraints, while
enforcing spatio-temporal constraints to prevent collisions and ensure safety.
The primary objective of the scheduler is to minimize the overall construction
makespan while minimizing logistics, traveling time between tasks, and the
curing time to maintain both adhesion quality and safe workspace separation.
The effectiveness of the proposed method in achieving coordinated and
time-efficient aerial masonry construction is extensively validated through
Gazebo simulated missions. The results demonstrate the framework's capability
to streamline UAV operations, ensuring both structural integrity and safety
during the construction process.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18689v1' target='_blank'>NOVA: Navigation via Object-Centric Visual Autonomy for High-Speed
  Target Tracking in Unstructured GPS-Denied Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alessandro Saviolo, Giuseppe Loianno</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 14:28:30</h6>
<p class='card-text'>Autonomous aerial target tracking in unstructured and GPS-denied environments
remains a fundamental challenge in robotics. Many existing methods rely on
motion capture systems, pre-mapped scenes, or feature-based localization to
ensure safety and control, limiting their deployment in real-world conditions.
We introduce NOVA, a fully onboard, object-centric framework that enables
robust target tracking and collision-aware navigation using only a stereo
camera and an IMU. Rather than constructing a global map or relying on absolute
localization, NOVA formulates perception, estimation, and control entirely in
the target's reference frame. A tightly integrated stack combines a lightweight
object detector with stereo depth completion, followed by histogram-based
filtering to infer robust target distances under occlusion and noise. These
measurements feed a visual-inertial state estimator that recovers the full
6-DoF pose of the robot relative to the target. A nonlinear model predictive
controller (NMPC) plans dynamically feasible trajectories in the target frame.
To ensure safety, high-order control barrier functions are constructed online
from a compact set of high-risk collision points extracted from depth, enabling
real-time obstacle avoidance without maps or dense representations. We validate
NOVA across challenging real-world scenarios, including urban mazes, forest
trails, and repeated transitions through buildings with intermittent GPS loss
and severe lighting changes that disrupt feature-based localization. Each
experiment is repeated multiple times under similar conditions to assess
resilience, showing consistent and reliable performance. NOVA achieves agile
target following at speeds exceeding 50 km/h. These results show that
high-speed vision-based tracking is possible in the wild using only onboard
sensing, with no reliance on external localization or environment assumptions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18566v1' target='_blank'>Cosmic Ray Detection with the IceTop Enhancement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Megha Venugopal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 12:21:16</h6>
<p class='card-text'>IceTop is the cosmic-ray detector located on the surface of the IceCube
Neutrino Observatory at the South Pole, consisting of 81 pairs of ice-Cherenkov
tanks. The rise in the energy threshold of air-shower measurements in IceTop
due to accumulating snow emphasized the need for the next generation of IceCube
surface detectors. For this purpose, the Surface Array Enhancement (SAE) is set
to comprise elevated scintillator panels and radio antennas controlled by
hybrid DAQ systems. The detectors of the SAE are also expected to extend to the
planned IceCube-Gen2 Surface Array. An initial study with a prototype station
is already conducted. We briefly review the SAE and the deployment as well as
the calibration status of the upcoming stations of the planned array of 32
stations. The focus of this contribution is on the radio detection of extensive
air showers. A preliminary estimation of the position of the shower maximum
($X_\mathrm{max}$), that is sensitive to the primary mass, with data from the 3
antennas of the prototype station was carried out. An extension of the method
from previous analyses is also briefly discussed.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18526v1' target='_blank'>Design, fabrication and control of a cable-driven parallel robot</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dhruv Sorathiya, Sarthak Sahoo, Vivek Natarajan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 11:28:27</h6>
<p class='card-text'>In cable driven parallel robots (CDPRs), the payload is suspended using a
network of cables whose length can be controlled to maneuver the payload within
the workspace. Compared to rigid link robots, CDPRs provide better
maneuverability due to the flexibility of the cables and consume lesser power
due to the high strength-to-weight ratio of the cables. However, amongst other
things, the flexibility of the cables and the fact that they can only pull (and
not push) render the dynamics of CDPRs complex. Hence advanced modelling
paradigms and control algorithms must be developed to fully utilize the
potential of CDPRs. Furthermore, given the complex dynamics of CDPRs, the
models and control algorithms proposed for them must be validated on
experimental setups to ascertain their efficacy in practice. We have recently
developed an elaborate experimental setup for a CDPR with three cables and
validated elementary open-loop motion planning algorithms on it. In this paper,
we describe several aspects of the design and fabrication of our setup,
including component selection and assembly, and present our experimental
results. Our setup can reproduce complex phenomenon such as the transverse
vibration of the cables seen in large CDPRs and will in the future be used to
model and control such phenomenon and also to validate more sophisticated
motion planning algorithms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18410v1' target='_blank'>Integrating Maneuverable Planning and Adaptive Control for Robot
  Cart-Pushing under Disturbances</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhe Zhang, Peijia Xie, Zhirui Sun, Bingyi Xia, Bi-Ke Zhu, Jiankun Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 08:44:30</h6>
<p class='card-text'>Precise and flexible cart-pushing is a challenging task for mobile robots.
The motion constraints during cart-pushing and the robot's redundancy lead to
complex motion planning problems, while variable payloads and disturbances
present complicated dynamics. In this work, we propose a novel planning and
control framework for flexible whole-body coordination and robust adaptive
control. Our motion planning method employs a local coordinate representation
and a novel kinematic model to solve a nonlinear optimization problem, thereby
enhancing motion maneuverability by generating feasible and flexible push
poses. Furthermore, we present a disturbance rejection control method to resist
disturbances and reduce control errors for the complex control problem without
requiring an accurate dynamic model. We validate our method through extensive
experiments in simulation and real-world settings, demonstrating its
superiority over existing approaches. To the best of our knowledge, this is the
first work to systematically evaluate the flexibility and robustness of
cart-pushing methods in experiments. The video supplement is available at
https://sites.google.com/view/mpac-pushing/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18355v1' target='_blank'>Robotic Manipulation of a Rotating Chain with Bottom End Fixed</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qi Jing Chen, Shilin Shan, Quang-Cuong Pham</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 07:31:04</h6>
<p class='card-text'>This paper studies the problem of using a robot arm to manipulate a uniformly
rotating chain with its bottom end fixed. Existing studies have investigated
ideal rotational shapes for practical applications, yet they do not discuss how
these shapes can be consistently achieved through manipulation planning. Our
work presents a manipulation strategy for stable and consistent shape
transitions. We find that the configuration space of such a chain is
homeomorphic to a three-dimensional cube. Using this property, we suggest a
strategy to manipulate the chain into different configurations, specifically
from one rotation mode to another, while taking stability and feasibility into
consideration. We demonstrate the effectiveness of our strategy in physical
experiments by successfully transitioning from rest to the first two rotation
modes. The concepts explored in our work has critical applications in ensuring
safety and efficiency of drill string and yarn spinning operations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18260v1' target='_blank'>Advanced For-Loop for QML algorithm search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:FuTe Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 03:19:36</h6>
<p class='card-text'>This paper introduces an advanced framework leveraging Large Language
Model-based Multi-Agent Systems (LLMMA) for the automated search and
optimization of Quantum Machine Learning (QML) algorithms. Inspired by Google
DeepMind's FunSearch, the proposed system works on abstract level to
iteratively generates and refines quantum transformations of classical machine
learning algorithms (concepts), such as the Multi-Layer Perceptron,
forward-forward and backpropagation algorithms. As a proof of concept, this
work highlights the potential of agentic frameworks to systematically explore
classical machine learning concepts and adapt them for quantum computing,
paving the way for efficient and automated development of QML algorithms.
Future directions include incorporating planning mechanisms and optimizing
strategy in the search space for broader applications in quantum-enhanced
machine learning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18234v1' target='_blank'>Drive-R1: Bridging Reasoning and Planning in VLMs for Autonomous Driving
  with Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Li, Meng Tian, Dechang Zhu, Jiangtong Zhu, Zhenyu Lin, Zhiwei Xiong, Xinhai Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 01:57:14</h6>
<p class='card-text'>Large vision-language models (VLMs) for autonomous driving (AD) are evolving
beyond perception and cognition tasks toward motion planning. However, we
identify two critical challenges in this direction: (1) VLMs tend to learn
shortcuts by relying heavily on history input information, achieving seemingly
strong planning results without genuinely understanding the visual inputs; and
(2) the chain-ofthought (COT) reasoning processes are always misaligned with
the motion planning outcomes, and how to effectively leverage the complex
reasoning capability to enhance planning remains largely underexplored. In this
paper, we start from a small-scale domain-specific VLM and propose Drive-R1
designed to bridges the scenario reasoning and motion planning for AD. Drive-R1
first undergoes the supervised finetuning on a elaborate dataset containing
both long and short COT data. Drive-R1 is encouraged to reason step-by-step
from visual input to final planning decisions. Subsequently, Drive-R1 is
trained within a reinforcement learning framework that incentivizes the
discovery of reasoning paths that are more informative for planning, guided by
rewards based on predicted trajectories and meta actions. Experimental
evaluations on the nuScenes and DriveLM-nuScenes benchmarks demonstrate that
Drive-R1 achieves superior performance compared to existing state-of-the-art
VLMs. We believe that Drive-R1 presents a promising direction for bridging
reasoning and planning in AD, offering methodological insights for future
research and applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18231v1' target='_blank'>NIKA2 Cosmological Legacy Survey: Blind detection of galaxy clusters in
  the COSMOS field via the Sunyaev-Zel'dovich effect</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:D. Chérouvrier, J. F. Macias-Perez, F. X. Désert, R. Adam, P. Ade, H. Ajeddig, S. Amarantidis, P. André, H. Aussel, R. Barrena, A. Beelen, A. Benoit, S. Berta, M. Béthermin, A. Bongiovanni, J. Bounmy, O. Bourrion, L. -J. Bing, M. Calvo, A. Catalano, M. De Petris, S. Doyle, E. F. C. Driessen, G. Ejlali, A. Ferragamo, M. Fernandez-Torreiro, A. Gomez, J. Goupy, C. Hanser, S. Katsioli, F. Kéruzoré, C. Kramer, B. Ladjelate, G. Lagache, S. Leclercq, J. -F. Lestrade, S. C. Madden, A. Maury, F. Mayet, J. -B. Melin, A. Monfardini, A. Moyer-Anin, M. Mu noz-Echeverria, I. Myserlis, R. Neri, A. Paliwal, L. Perotto, G. Pisano, E. Pointecouteau, N. Ponthieu, G. W. Pratt, V. Reveret, A. J. Rigby, A. Ritacco, H. Roussel, F. Ruppin, M. Sanchez-Portal, S. Savorgnano, K. Schuster, A. Sievers, C. Tucker, R. Zylka</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 01:41:18</h6>
<p class='card-text'>(Abridged) Clusters of galaxies, formed in the latest stages of structure
formation, are unique cosmological probes. With the advent of large CMB surveys
like those from the Planck satellite, the ACT and SPT telescopes, we now have
access to a large number of galaxy clusters detected at millimeter wavelengths
via the thermal Sunyaev-Zel'dovich (tSZ) effect. Nevertheless, it is
interesting to complement them with high-angular-resolution (tens of
arcseconds) observations to target the lowest-mass and highest-redshift
clusters. This is the case of observations with the NIKA2 camera, which is
installed on the IRAM 30--m telescope in Pico Veleta, Spain. We used the
existing 150 GHz (2 mm) data from the NIKA2 Cosmological Legacy Survey (N2CLS)
Large Program to blindly search for galaxy clusters in the well-known COSMOS
field, across a 877 arcmin$^2$ region centered on (R.A., Dec.)$_{J2000}$ =
(10h00m28.81s, +02d17m30.44s). We first developed a dedicated data reduction
pipeline to construct NIKA2 maps at 2 mm. We then used a matched-filter
algorithm to extract cluster candidates assuming a universal pressure profile
to model the expected cluster tSZ signal. We computed the purity and
completeness of the sample by applying the previous algorithm to simulated maps
of the sky signal in the COSMOS field. We find a total of 16 cluster candidates
at S/N > 4, from which eight have either an optical or X-ray cluster (or group
of galaxies) counterpart. This is the first blind detection of clusters of
galaxies at mm wavelengths at 18" angular resolution. From this analysis, we
confirm that NIKA2 and the IRAM 30--m telescope should be sensitive to low-mass
clusters at intermediate and high redshift, complementing current and planned
large tSZ-based cluster surveys.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18216v1' target='_blank'>TasVisAn and InsPy -- Python Packages for Triple-Axis Spectrometer Data
  Visualization, Analysis, Instrument Resolution Calculation, and Convolution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guochu Deng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-23 00:29:37</h6>
<p class='card-text'>Experimental data collected from a triple-axis spectrometer (TAS) are
typically analysed by considering the instrument resolution, as the resolution
of a TAS instrument is often complex and significantly influences the measured
results. Two Python packages, TasVisAn and InsPy, have been developed to
visualize and analyse data from TAS instruments - particularly from the
cold-neutron TAS Sika and the thermal-neutron TAS Taipan at the Australian
Centre for Neutron Scattering. TasVisAn offers a range of functions, including
data importing, reduction, plotting, contour mapping, convolution fitting, and
more, for data collected on TAS instruments, especially on Sika and Taipan. It
also supports data reduction of the current trendy multi-analyser and
multiplexing TAS instruments, including the multiplexing mode of Sika. Besides,
it includes scan simulation and batch file validation tools for both Taipan and
Sika, assisting users in designing and planning experiments in advance. InsPy
is a general-purpose Python package designed to calculate the four-dimensional
(4D) instrument resolution in momentum-energy space for any TAS instrument.
Combined with InsPy, TasVisAn supports both instrument resolution calculation
and resolution-convoluted data fitting. Its flexible external data import
feature further allows TasVisAn to be adapted for the visualization and
convolution analysis of inelastic neutron scattering data across various TAS
instruments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2506.18160v1' target='_blank'>Automated Plan Refinement for Improving Efficiency of Robotic Layup of
  Composite Sheets</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rutvik Patel, Alec Kanyuck, Zachary McNulty, Zeren Yu, Lisa Carlson, Vann Heng, Brice Johnson, Satyandra K. Gupta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-06-22 20:27:48</h6>
<p class='card-text'>The automation of composite sheet layup is essential to meet the increasing
demand for composite materials in various industries. However, draping plans
for the robotic layup of composite sheets are not robust. A plan that works
well under a certain condition does not work well in a different condition.
Changes in operating conditions due to either changes in material properties or
working environment may lead a draping plan to exhibit suboptimal performance.
In this paper, we present a comprehensive framework aimed at refining plans
based on the observed execution performance. Our framework prioritizes the
minimization of uncompacted regions while simultaneously improving time
efficiency. To achieve this, we integrate human expertise with data-driven
decision-making to refine expert-crafted plans for diverse production
environments. We conduct experiments to validate the effectiveness of our
approach, revealing significant reductions in the number of corrective paths
required compared to initial expert-crafted plans. Through a combination of
empirical data analysis, action-effectiveness modeling, and search-based
refinement, our system achieves superior time efficiency in robotic layup.
Experimental results demonstrate the efficacy of our approach in optimizing the
layup process, thereby advancing the state-of-the-art in composite
manufacturing automation.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>