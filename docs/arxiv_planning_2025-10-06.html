<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-10-06</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-10-06</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.03192v1' target='_blank'>An Open-Access Web Tool for Light Curve Simulation and Analysis of Small
  Solar System Objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:J. L. Rizos, J. L. Ortiz, P. J. Gutierrez, I. M. Navajas, L. M. Lara</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 17:24:09</h6>
<p class='card-text'>We present a web-based application designed to simulate rotational light
curves of small airless Solar System bodies under user-defined geometrical and
physical conditions. The tool integrates both physical and empirical
photometric models and enables users to input custom shape models, surface
properties, and viewing geometries. A dedicated module also computes projected
silhouettes at the epoch of stellar occultations, allowing direct comparison
with observed chords. The application, developed in Python and Django, has been
validated using well-characterized targets such as (136108) Haumea, (101955)
Bennu, and (433) Eros, showing excellent agreement between synthetic and
observed light curves and silhouettes. Beyond standard light curve simulations,
the tool supports scenarios including surface heterogeneity, non-principal axis
rotation (tumbling), and phase-angle effects. This flexible and accessible
platform provides a powerful resource for interpreting photometric data,
supporting ongoing observation campaigns, and aiding future mission planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.03182v1' target='_blank'>Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yilun Hao, Yongchao Chen, Chuchu Fan, Yang Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 16:57:01</h6>
<p class='card-text'>Vision Language Models (VLMs) show strong potential for visual planning but
struggle with precise spatial and long-horizon reasoning. In contrast, Planning
Domain Definition Language (PDDL) planners excel at long-horizon formal
planning, but cannot interpret visual inputs. Recent works combine these
complementary advantages by enabling VLMs to turn visual planning problems into
PDDL files for formal planning. However, while VLMs can generate PDDL problem
files satisfactorily, they struggle to accurately generate the PDDL domain
files, which describe all the planning rules. As a result, prior methods rely
on human experts to predefine domain files or on constant environment access
for refinement. We propose VLMFP, a Dual-VLM-guided framework that can
autonomously generate both PDDL problem and domain files for formal visual
planning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: A
SimVLM that simulates action consequences based on input rule descriptions, and
a GenVLM that generates and iteratively refines PDDL files by comparing the
PDDL and SimVLM execution results. VLMFP unleashes multiple levels of
generalizability: The same generated PDDL domain file works for all the
different instances under the same problem, and VLMs generalize to different
problems with varied appearances and rules. We evaluate VLMFP with 6 grid-world
domains and test its generalization to unseen instances, appearance, and game
rules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios,
simulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goal
reaching for seen and unseen appearances, respectively. With the guidance of
SimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans for
unseen instances in seen and unseen appearances, respectively. Project page:
https://sites.google.com/view/vlmfp.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.03169v1' target='_blank'>Optimal Smooth Coverage Trajectory Planning for Quadrotors in Cluttered
  Environment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Duanjiao Li, Yun Chen, Ying Zhang, Junwen Yao, Dongyue Huang, Jianguo Zhang, Ning Ding</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 16:43:50</h6>
<p class='card-text'>For typical applications of UAVs in power grid scenarios, we construct the
problem as planning UAV trajectories for coverage in cluttered environments. In
this paper, we propose an optimal smooth coverage trajectory planning
algorithm. The algorithm consists of two stages. In the front-end, a Genetic
Algorithm (GA) is employed to solve the Traveling Salesman Problem (TSP) for
Points of Interest (POIs), generating an initial sequence of optimized visiting
points. In the back-end, the sequence is further optimized by considering
trajectory smoothness, time consumption, and obstacle avoidance. This is
formulated as a nonlinear least squares problem and solved to produce a smooth
coverage trajectory that satisfies these constraints. Numerical simulations
validate the effectiveness of the proposed algorithm, ensuring UAVs can
smoothly cover all POIs in cluttered environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.03152v1' target='_blank'>ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal
  Trajectories</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anantajit Subrahmanya, Chandrakanth Gudavalli, Connor Levenson, Umang Garg, B. S. Manjunath</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 16:25:11</h6>
<p class='card-text'>Accurately modeling human mobility is critical for urban planning,
epidemiology, and traffic management. In this work, we introduce Markovian Reeb
Graphs, a novel framework for simulating spatiotemporal trajectories that
preserve Patterns of Life (PoLs) learned from baseline data. By combining
individual- and population-level mobility structures within a probabilistic
topological model, our approach generates realistic future trajectories that
capture both consistency and variability in daily life. Evaluations on the
Urban Anomalies dataset (Atlanta and Berlin subsets) using the Jensen-Shannon
Divergence (JSD) across population- and agent-level metrics demonstrate that
the proposed method achieves strong fidelity while remaining data- and
compute-efficient. These results position Markovian Reeb Graphs as a scalable
framework for trajectory simulation with broad applicability across diverse
urban environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.03121v1' target='_blank'>Real Time Headway Predictions in Urban Rail Systems and Implications for
  Service Control: A Deep Learning Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Usama, Haris Koutsopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 15:50:01</h6>
<p class='card-text'>Efficient real-time dispatching in urban metro systems is essential for
ensuring service reliability, maximizing resource utilization, and improving
passenger satisfaction. This study presents a novel deep learning framework
centered on a Convolutional Long Short-Term Memory (ConvLSTM) model designed to
predict the complex spatiotemporal propagation of train headways across an
entire metro line. By directly incorporating planned terminal headways as a
critical input alongside historical headway data, the proposed model accurately
forecasts future headway dynamics, effectively capturing both their temporal
evolution and spatial dependencies across all stations. This capability
empowers dispatchers to evaluate the impact of various terminal headway control
decisions without resorting to computationally intensive simulations. We
introduce a flexible methodology to simulate diverse dispatcher strategies,
ranging from maintaining even headways to implementing custom patterns derived
from observed terminal departures. In contrast to existing research primarily
focused on passenger load predictioning or atypical disruption scenarios, our
approach emphasizes proactive operational control. Evaluated on a large-scale
dataset from an urban metro line, the proposed ConvLSTM model demonstrates
promising headway predictions, offering actionable insights for real-time
decision-making. This framework provides rail operators with a powerful,
computationally efficient tool to optimize dispatching strategies, thereby
significantly improving service consistency and passenger satisfaction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.03064v1' target='_blank'>Comparative Analysis of Parameterized Action Actor-Critic Reinforcement
  Learning Algorithms for Web Search Match Plan Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ubayd Bapoo, Clement N Nyirenda</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 14:48:57</h6>
<p class='card-text'>This study evaluates the performance of Soft Actor Critic (SAC), Greedy Actor
Critic (GAC), and Truncated Quantile Critics (TQC) in high-dimensional
decision-making tasks using fully observable environments. The focus is on
parametrized action (PA) spaces, eliminating the need for recurrent networks,
with benchmarks Platform-v0 and Goal-v0 testing discrete actions linked to
continuous action-parameter spaces. Hyperparameter optimization was performed
with Microsoft NNI, ensuring reproducibility by modifying the codebase for GAC
and TQC. Results show that Parameterized Action Greedy Actor-Critic (PAGAC)
outperformed other algorithms, achieving the fastest training times and highest
returns across benchmarks, completing 5,000 episodes in 41:24 for the Platform
game and 24:04 for the Robot Soccer Goal game. Its speed and stability provide
clear advantages in complex action spaces. Compared to PASAC and PATQC, PAGAC
demonstrated superior efficiency and reliability, making it ideal for tasks
requiring rapid convergence and robust performance. Future work could explore
hybrid strategies combining entropy-regularization with truncation-based
methods to enhance stability and expand investigations into generalizability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.03031v1' target='_blank'>Long-Term Human Motion Prediction Using Spatio-Temporal Maps of Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yufei Zhu, Andrey Rudenko, Tomasz P. Kucner, Achim J. Lilienthal, Martin Magnusson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 14:12:55</h6>
<p class='card-text'>Long-term human motion prediction (LHMP) is important for the safe and
efficient operation of autonomous robots and vehicles in environments shared
with humans. Accurate predictions are important for applications including
motion planning, tracking, human-robot interaction, and safety monitoring. In
this paper, we exploit Maps of Dynamics (MoDs), which encode spatial or
spatio-temporal motion patterns as environment features, to achieve LHMP for
horizons of up to 60 seconds. We propose an MoD-informed LHMP framework that
supports various types of MoDs and includes a ranking method to output the most
likely predicted trajectory, improving practical utility in robotics. Further,
a time-conditioned MoD is introduced to capture motion patterns that vary
across different times of day. We evaluate MoD-LHMP instantiated with three
types of MoDs. Experiments on two real-world datasets show that MoD-informed
method outperforms learning-based ones, with up to 50\% improvement in average
displacement error, and the time-conditioned variant achieves the highest
accuracy overall. Project code is available at
https://github.com/test-bai-cpu/LHMP-with-MoDs.git</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.03011v1' target='_blank'>3D-CovDiffusion: 3D-Aware Diffusion Policy for Coverage Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenyuan Chen, Haoran Ding, Ran Ding, Tianyu Liu, Zewen He, Anqing Duan, Dezhen Song, Xiaodan Liang, Yoshihiko Nakamura</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 13:55:57</h6>
<p class='card-text'>Diffusion models, as a class of deep generative models, have recently emerged
as powerful tools for robot skills by enabling stable training with reliable
convergence. In this paper, we present an end-to-end framework for generating
long, smooth trajectories that explicitly target high surface coverage across
various industrial tasks, including polishing, robotic painting, and spray
coating. The conventional methods are always fundamentally constrained by their
predefined functional forms, which limit the shapes of the trajectories they
can represent and make it difficult to handle complex and diverse tasks.
Moreover, their generalization is poor, often requiring manual redesign or
extensive parameter tuning when applied to new scenarios. These limitations
highlight the need for more expressive generative models, making
diffusion-based approaches a compelling choice for trajectory generation. By
iteratively denoising trajectories with carefully learned noise schedules and
conditioning mechanisms, diffusion models not only ensure smooth and consistent
motion but also flexibly adapt to the task context. In experiments, our method
improves trajectory continuity, maintains high coverage, and generalizes to
unseen shapes, paving the way for unified end-to-end trajectory learning across
industrial surface-processing tasks without category-specific models. On
average, our approach improves Point-wise Chamfer Distance by 98.2\% and
smoothness by 97.0\%, while increasing surface coverage by 61\% compared to
prior methods. The link to our code can be found
\href{https://anonymous.4open.science/r/spraydiffusion_ral-2FCE/README.md}{here}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02888v1' target='_blank'>Fermionic optimal transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rocco Duvenhage, Dylan van Zyl, Paola Zurlo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 10:51:23</h6>
<p class='card-text'>Quadratic Wasserstein distances are obtained between dynamical systems (with
states as special case), on $\mathbb{Z}_2$-graded von Neumann algebras. This is
achieved through a systematic translation from non-graded to
$\mathbb{Z}_2$-graded transport plans, on usual and fermionic (or
$\mathbb{Z}_2$-graded) tensor products respectively. The metric properties of
these fermionic Wasserstein distances are shown, and their symmetries relevant
to deviation of a system from quantum detailed balance are investigated. The
latter is done in conjunction with the development of a complete mathematical
framework for detailed balance in systems involving indistinguishable fermions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02885v1' target='_blank'>Point Cloud-Based Control Barrier Functions for Model Predictive Control
  in Safety-Critical Navigation of Autonomous Mobile Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Faduo Liang, Yunfeng Yang, Shi-Lu Dai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 10:43:48</h6>
<p class='card-text'>In this work, we propose a novel motion planning algorithm to facilitate
safety-critical navigation for autonomous mobile robots. The proposed algorithm
integrates a real-time dynamic obstacle tracking and mapping system that
categorizes point clouds into dynamic and static components. For dynamic point
clouds, the Kalman filter is employed to estimate and predict their motion
states. Based on these predictions, we extrapolate the future states of dynamic
point clouds, which are subsequently merged with static point clouds to
construct the forward-time-domain (FTD) map. By combining control barrier
functions (CBFs) with nonlinear model predictive control, the proposed
algorithm enables the robot to effectively avoid both static and dynamic
obstacles. The CBF constraints are formulated based on risk points identified
through collision detection between the predicted future states and the FTD
map. Experimental results from both simulated and real-world scenarios
demonstrate the efficacy of the proposed algorithm in complex environments. In
simulation experiments, the proposed algorithm is compared with two baseline
approaches, showing superior performance in terms of safety and robustness in
obstacle avoidance. The source code is released for the reference of the
robotics community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02852v1' target='_blank'>Data-Driven Bed Occupancy Planning in Intensive Care Units Using
  $M_t/G_t/\infty$ Queueing Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maryam Akbari-Moghaddam, Douglas G. Down, Na Li, Catherine Eastwood, Ayman Abou Mehrem, Alexandra Howlett</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 09:41:01</h6>
<p class='card-text'>Hospitals struggle to make effective long-term capacity planning decisions
for intensive care units (ICUs) under uncertainty in future demand. Admission
rates fluctuate over time due to temporal factors, and length of stay (LOS)
distributions vary with patient heterogeneity, hospital location, case mix, and
clinical practices. Common planning approaches rely on steady-state queueing
models or heuristic rules that assume fixed parameters, but these methods often
fall short in capturing real-world occupancy dynamics. One widely used example
is the 85\% occupancy rule, which recommends maintaining average utilization
below this level to ensure responsiveness; however, this rule is based on
stationary assumptions and may be unreliable when applied to time-varying
systems. Our analysis shows that even when long-run utilization targets are
met, day-to-day occupancy frequently exceeds 100\% capacity.
  We propose a data-driven framework for estimating ICU bed occupancy using an
$M_t/G_t/\infty$ queueing model, which incorporates time-varying arrival rates
and empirically estimated LOS distributions. The framework combines statistical
decomposition and parametric distribution fitting to capture temporal patterns
in ICU admissions and LOS. We apply it to multi-year data from neonatal ICUs
(NICUs) in Calgary as a case study. Several capacity planning scenarios are
evaluated, including average-based thresholds and surge estimates from Poisson
overflow approximations. Results demonstrate the inadequacy of static
heuristics in environments with fluctuating demand and highlight the importance
of modeling LOS variability when estimating bed needs. Although the case study
focuses on NICUs, the methodology generalizes to other ICU settings and
provides interpretable, data-informed support for healthcare systems facing
rising demand and limited capacity.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02838v1' target='_blank'>TridentServe: A Stage-level Serving System for Diffusion Pipelines</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifei Xia, Fangcheng Fu, Hao Yuan, Hanke Zhang, Xupeng Miao, Yijun Liu, Suhan Ling, Jie Jiang, Bin Cui</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 09:23:56</h6>
<p class='card-text'>Diffusion pipelines, renowned for their powerful visual generation
capabilities, have seen widespread adoption in generative vision tasks (e.g.,
text-to-image/video). These pipelines typically follow an
encode--diffuse--decode three-stage architecture. Current serving systems
deploy diffusion pipelines within a static, manual, and pipeline-level
paradigm, allocating the same resources to every request and stage. However,
through an in-depth analysis, we find that such a paradigm is inefficient due
to the discrepancy in resource needs across the three stages of each request,
as well as across different requests. Following the analysis, we propose the
dynamic stage-level serving paradigm and develop TridentServe, a brand new
diffusion serving system. TridentServe automatically, dynamically derives the
placement plan (i.e., how each stage resides) for pipeline deployment and the
dispatch plan (i.e., how the requests are routed) for request processing,
co-optimizing the resource allocation for both model and requests. Extensive
experiments show that TridentServe consistently improves SLO attainment and
reduces average/P95 latencies by up to 2.5x and 3.6x/4.1x over existing works
across a variety of workloads.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02803v1' target='_blank'>Work Zones challenge VLM Trajectory Planning: Toward Mitigation and
  Robust Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifan Liao, Zhen Sun, Xiaoyun Qiu, Zixiao Zhao, Wenbing Tang, Xinlei He, Xinhu Zheng, Tianwei Zhang, Xinyi Huang, Xingshuo Han</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 08:21:15</h6>
<p class='card-text'>Visual Language Models (VLMs), with powerful multimodal reasoning
capabilities, are gradually integrated into autonomous driving by several
automobile manufacturers to enhance planning capability in challenging
environments. However, the trajectory planning capability of VLMs in work
zones, which often include irregular layouts, temporary traffic control, and
dynamically changing geometric structures, is still unexplored. To bridge this
gap, we conduct the \textit{first} systematic study of VLMs for work zone
trajectory planning, revealing that mainstream VLMs fail to generate correct
trajectories in $68.0%$ of cases. To better understand these failures, we first
identify candidate patterns via subgraph mining and clustering analysis, and
then confirm the validity of $8$ common failure patterns through human
verification. Building on these findings, we propose REACT-Drive, a trajectory
planning framework that integrates VLMs with Retrieval-Augmented Generation
(RAG). Specifically, REACT-Drive leverages VLMs to convert prior failure cases
into constraint rules and executable trajectory planning code, while RAG
retrieves similar patterns in new scenarios to guide trajectory generation.
Experimental results on the ROADWork dataset show that REACT-Drive yields a
reduction of around $3\times$ in average displacement error relative to VLM
baselines under evaluation with Qwen2.5-VL. In addition, REACT-Drive yields the
lowest inference time ($0.58$s) compared with other methods such as fine-tuning
($17.90$s). We further conduct experiments using a real vehicle in 15 work zone
scenarios in the physical world, demonstrating the strong practicality of
REACT-Drive.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02714v1' target='_blank'>Deceptive Planning Exploiting Inattention Blindness</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mustafa O. Karabag, Jesse Milzman, Ufuk Topcu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 04:28:50</h6>
<p class='card-text'>We study decision-making with rational inattention in settings where agents
have perception constraints. In such settings, inaccurate prior beliefs or
models of others may lead to inattention blindness, where an agent is unaware
of its incorrect beliefs. We model this phenomenon in two-player zero-sum
stochastic games, where Player 1 has perception constraints and Player 2
deceptively deviates from its security policy presumed by Player 1 to gain an
advantage. We formulate the perception constraints as an online sensor
selection problem, develop a value-weighted objective function for sensor
selection capturing rational inattention, and propose the greedy algorithm for
selection under this monotone objective function. When Player 2 does not
deviate from the presumed policy, this objective function provides an upper
bound on the expected value loss compared to the security value where Player 1
has perfect information of the state. We then propose a myopic decision-making
algorithm for Player 2 to exploit Player 1's beliefs by deviating from the
presumed policy and, thereby, improve upon the security value. Numerical
examples illustrate how Player 1 persistently chooses sensors that are
consistent with its priors, allowing Player 2 to systematically exploit its
inattention.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02702v1' target='_blank'>VisitHGNN: Heterogeneous Graph Neural Networks for Modeling
  Point-of-Interest Visit Patterns</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lin Pang, Jidong J. Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 03:42:58</h6>
<p class='card-text'>Understanding how urban residents travel between neighborhoods and
destinations is critical for transportation planning, mobility management, and
public health. By mining historical origin-to-destination flow patterns with
spatial, temporal, and functional relations among urban places, we estimate
probabilities of visits from neighborhoods to specific destinations. These
probabilities capture neighborhood-level contributions to citywide vehicular
and foot traffic, supporting demand estimation, accessibility assessment, and
multimodal planning. Particularly, we introduce VisitHGNN, a heterogeneous,
relation-specific graph neural network designed to predict visit probabilities
at individual Points of interest (POIs). POIs are characterized using
numerical, JSON-derived, and textual attributes, augmented with fixed summaries
of POI--POI spatial proximity, temporal co-activity, and brand affinity, while
census block groups (CBGs) are described with 72 socio-demographic variables.
CBGs are connected via spatial adjacency, and POIs and CBGs are linked through
distance-annotated cross-type edges. Inference is constrained to a
distance-based candidate set of plausible origin CBGs, and training minimizes a
masked Kullback-Leibler (KL) divergence to yield probability distribution
across the candidate set. Using weekly mobility data from Fulton County,
Georgia, USA, VisitHGNN achieves strong predictive performance with mean KL
divergence of 0.287, MAE of 0.008, Top-1 accuracy of 0.853, and R-square of
0.892, substantially outperforming pairwise MLP and distance-only baselines,
and aligning closely with empirical visitation patterns (NDCG@50 = 0.966);
Recall@5 = 0.611). The resulting distributions closely mirror observed travel
behavior with high fidelity, highlighting the model's potential for decision
support in urban planning, transportation policy, mobility system design, and
public health.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02655v1' target='_blank'>A Concept of Possibility for Real-World Events</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel G. Schwartz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 01:15:06</h6>
<p class='card-text'>This paper offers a new concept of {\it possibility} as an alternative to the
now-a-days standard concept originally introduced by L.A. Zadeh in 1978. This
new version was inspired by the original but, formally, has nothing in common
with it other than that they both adopt the {\L}ukasiewicz multivalent
interpretation of the logical connectives. Moreover, rather than seeking to
provide a general notion of possibility, this focuses specifically on the
possibility of a real-world event. An event is viewed as having prerequisites
that enable its occurrence and constraints that may impede its occurrence, and
the possibility of the event is computed as a function of the probabilities
that the prerequisites hold and the constraints do not. This version of
possibility might appropriately be applied to problems of planning. When there
are multiple plans available for achieving a goal, this theory can be used to
determine which plan is most possible, i.e., easiest or most feasible to
complete. It is speculated that this model of reasoning correctly captures
normal human reasoning about plans. The theory is elaborated and an
illustrative example for vehicle route planning is provided. There is also a
suggestion of potential future applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02627v1' target='_blank'>A Trajectory Generator for High-Density Traffic and Diverse
  Agent-Interaction Scenarios</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruining Yang, Yi Xu, Yixiao Chen, Yun Fu, Lili Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-03 00:12:18</h6>
<p class='card-text'>Accurate trajectory prediction is fundamental to autonomous driving, as it
underpins safe motion planning and collision avoidance in complex environments.
However, existing benchmark datasets suffer from a pronounced long-tail
distribution problem, with most samples drawn from low-density scenarios and
simple straight-driving behaviors. This underrepresentation of high-density
scenarios and safety critical maneuvers such as lane changes, overtaking and
turning is an obstacle to model generalization and leads to overly optimistic
evaluations. To address these challenges, we propose a novel trajectory
generation framework that simultaneously enhances scenarios density and
enriches behavioral diversity. Specifically, our approach converts continuous
road environments into a structured grid representation that supports
fine-grained path planning, explicit conflict detection, and multi-agent
coordination. Built upon this representation, we introduce behavior-aware
generation mechanisms that combine rule-based decision triggers with
Frenet-based trajectory smoothing and dynamic feasibility constraints. This
design allows us to synthesize realistic high-density scenarios and rare
behaviors with complex interactions that are often missing in real data.
Extensive experiments on the large-scale Argoverse 1 and Argoverse 2 datasets
demonstrate that our method significantly improves both agent density and
behavior diversity, while preserving motion realism and scenario-level safety.
Our synthetic data also benefits downstream trajectory prediction models and
enhances performance in challenging high-density scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02618v1' target='_blank'>Amortized Bayesian Inference for Spatio-Temporal Extremes: A Copula
  Factor Model with Autoregression</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Carlos A. Pasquier, Luis A. Barboza</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 23:41:38</h6>
<p class='card-text'>We develop a Bayesian spatio-temporal framework for extreme-value analysis
that augments a hierarchical copula model with an autoregressive factor to
capture residual temporal dependence in threshold exceedances. The factor can
be specified as spatially varying or spatially constant, and the scale
parameter incorporates scientifically relevant covariates (e.g., longitude,
latitude, altitude), enabling flexible representation of geographic
heterogeneity. To avoid the computational burden of the full censored
likelihood, we design a Gibbs sampler that embeds amortized neural posterior
estimation within each parameter block, yielding scalable inference with full
posterior uncertainty for parameters, predictive quantiles, and return levels.
Simulation studies demonstrate that the approach improves MCMC mixing and
estimation accuracy relative to baseline specifications, particularly when
using moderately more complex network architectures, while preserving
heavy-tail behavior. We illustrate the methodology with daily precipitation in
Guanacaste, Costa Rica, evaluating a suite of nested models and selecting the
best-performing factor combination via out-of-sample diagnostics. The chosen
specification reveals coherent spatial patterns in multi-year return periods
and provides actionable information for infrastructure planning and
climate-risk management in a tropical dry region strongly influenced by
climatic factors. The proposed Gibbs scheme generalizes to other settings where
parameters can be partitioned into inferentially homogeneous blocks and
conditionals learned via amortized, likelihood-free methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02589v1' target='_blank'>A Benchmark Study of Deep Reinforcement Learning Algorithms for the
  Container Stowage Planning Problem</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yunqi Huang, Nishith Chennakeshava, Alexis Carras, Vladislav Neverov, Wei Liu, Aske Plaat, Yingjie Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 21:47:33</h6>
<p class='card-text'>Container stowage planning (CSPP) is a critical component of maritime
transportation and terminal operations, directly affecting supply chain
efficiency. Owing to its complexity, CSPP has traditionally relied on human
expertise. While reinforcement learning (RL) has recently been applied to CSPP,
systematic benchmark comparisons across different algorithms remain limited. To
address this gap, we develop a Gym environment that captures the fundamental
features of CSPP and extend it to include crane scheduling in both multi-agent
and single-agent formulations. Within this framework, we evaluate five RL
algorithms: DQN, QR-DQN, A2C, PPO, and TRPO under multiple scenarios of varying
complexity. The results reveal distinct performance gaps with increasing
complexity, underscoring the importance of algorithm choice and problem
formulation for CSPP. Overall, this paper benchmarks multiple RL methods for
CSPP while providing a reusable Gym environment with crane scheduling, thus
offering a foundation for future research and practical deployment in maritime
logistics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02584v1' target='_blank'>Efficient Optimal Path Planning in Dynamic Environments Using Koopman
  MPC</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohammad Abtahi, Navid Mojahed, Shima Nazari</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 21:43:21</h6>
<p class='card-text'>This paper presents a data-driven model predictive control framework for
mobile robots navigating in dynamic environments, leveraging Koopman operator
theory. Unlike the conventional Koopman-based approaches that focus on the
linearization of system dynamics only, our work focuses on finding a global
linear representation for the optimal path planning problem that includes both
the nonlinear robot dynamics and collision-avoidance constraints. We deploy
extended dynamic mode decomposition to identify linear and bilinear Koopman
realizations from input-state data. Our open-loop analysis demonstrates that
only the bilinear Koopman model can accurately capture nonlinear state-input
couplings and quadratic terms essential for collision avoidance, whereas linear
realizations fail to do so. We formulate a quadratic program for the robot path
planning in the presence of moving obstacles in the lifted space and determine
the optimal robot action in an MPC framework. Our approach is capable of
finding the safe optimal action 320 times faster than a nonlinear MPC
counterpart that solves the path planning problem in the original state space.
Our work highlights the potential of bilinear Koopman realizations for
linearization of highly nonlinear optimal control problems subject to nonlinear
state and input constraints to achieve computational efficiency similar to
linear problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02557v1' target='_blank'>Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research
  Challenge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Charlie Masters, Advaith Vellanki, Jiangbo Shangguan, Bart Kultys, Jonathan Gilmore, Alastair Moore, Stefano V. Albrecht</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 20:51:39</h6>
<p class='card-text'>While agentic AI has advanced in automating individual tasks, managing
complex multi-agent workflows remains a challenging problem. This paper
presents a research vision for autonomous agentic systems that orchestrate
collaboration within dynamic human-AI teams. We propose the Autonomous Manager
Agent as a core challenge: an agent that decomposes complex goals into task
graphs, allocates tasks to human and AI workers, monitors progress, adapts to
changing conditions, and maintains transparent stakeholder communication. We
formalize workflow management as a Partially Observable Stochastic Game and
identify four foundational challenges: (1) compositional reasoning for
hierarchical decomposition, (2) multi-objective optimization under shifting
preferences, (3) coordination and planning in ad hoc teams, and (4) governance
and compliance by design. To advance this agenda, we release MA-Gym, an
open-source simulation and evaluation framework for multi-agent workflow
orchestration. Evaluating GPT-5-based Manager Agents across 20 workflows, we
find they struggle to jointly optimize for goal completion, constraint
adherence, and workflow runtime - underscoring workflow management as a
difficult open problem. We conclude with organizational and ethical
implications of autonomous management systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02526v1' target='_blank'>U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anamika J H, Anujith Muraleedharan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 19:54:45</h6>
<p class='card-text'>Robots manipulating in changing environments must act on percepts that are
late, noisy, or stale. We present U-LAG, a mid-execution goal-retargeting layer
that leaves the low-level controller unchanged while re-aiming task goals
(pre-contact, contact, post) as new observations arrive. Unlike motion
retargeting or generic visual servoing, U-LAG treats in-flight goal re-aiming
as a first-class, pluggable module between perception and control. Our main
technical contribution is UAR-PF, an uncertainty-aware retargeter that
maintains a distribution over object pose under sensing lag and selects goals
that maximize expected progress. We instantiate a reproducible Shift x Lag
stress test in PyBullet/PandaGym for pick, push, stacking, and peg insertion,
where the object undergoes abrupt in-plane shifts while synthetic perception
lag is injected during approach. Across 0-10 cm shifts and 0-400 ms lags,
UAR-PF and ICP degrade gracefully relative to a no-retarget baseline, achieving
higher success with modest end-effector travel and fewer aborts; simple
operational safeguards further improve stability. Contributions: (1) UAR-PF for
lag-adaptive, uncertainty-aware goal retargeting; (2) a pluggable retargeting
interface; and (3) a reproducible Shift x Lag benchmark with evaluation on
pick, push, stacking, and peg insertion.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02507v1' target='_blank'>"Post" Pre-Analysis Plans: Valid Inference for Non-Preregistered
  Specifications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Reca Sarfati, Vod Vilfort</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 19:29:43</h6>
<p class='card-text'>Pre-analysis plans (PAPs) have become standard in experimental economics
research, but it is nevertheless common to see researchers deviating from their
PAPs to supplement preregistered estimates with non-prespecified findings.
While such ex-post analysis can yield valuable insights, there is broad
uncertainty over how to interpret -- or whether to even acknowledge --
non-preregistered results. In this paper, we consider the case of a
truth-seeking researcher who, after seeing the data, earnestly wishes to report
additional estimates alongside those preregistered in their PAP. We show that,
even absent "nefarious" behavior, conventional confidence intervals and point
estimators are invalid due to the fact that non-preregistered estimates are
only reported in a subset of potential data realizations. We propose inference
procedures that account for this conditional reporting. We apply these
procedures to Bessone et al. (2021), which studies the economic effects of
increased sleep among the urban poor. We demonstrate that, depending on the
reason for deviating, the adjustments from our procedures can range from having
no difference to an economically significant difference relative to
conventional practice. Finally, we consider the robustness of our procedure to
certain forms of misspecification, motivating possible heuristic checks and
norms for journals to adopt.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02475v1' target='_blank'>Rigorous Evaluation of Microarchitectural Side-Channels with Statistical
  Model Checking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weihang Li, Pete Crowley, Arya Tschand, Yu Wang, Miroslav Pajic, Daniel Sorin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 18:31:06</h6>
<p class='card-text'>Rigorous quantitative evaluation of microarchitectural side channels is
challenging for two reasons. First, the processors, attacks, and defenses often
exhibit probabilistic behaviors. These probabilistic behaviors arise due to
natural noise in systems (e.g., from co-running processes), probabilistic side
channel attacks, and probabilistic obfuscation defenses. Second,
microprocessors are extremely complex. Previous evaluation methods have relied
on abstract or simplified models, which are necessarily less detailed than real
systems or cycle-by-cycle simulators, and these models may miss important
phenomena. Whereas a simple model may suffice for estimating performance,
security issues frequently manifest in the details.
  We address this challenge by introducing Statistical Model Checking (SMC) to
the quantitative evaluation of microarchitectural side channels. SMC is a
rigorous statistical technique that can process the results of probabilistic
experiments and provide statistical guarantees, and it has been used in
computing applications that depend heavily on statistical guarantees (e.g.,
medical implants, vehicular computing). With SMC, we can treat processors as
opaque boxes, and we do not have to abstract or simplify them. We demonstrate
the effectiveness of SMC through three case studies, in which we experimentally
show that SMC can evaluate existing security vulnerabilities and defenses and
provide qualitatively similar conclusions with greater statistical rigor, while
making no simplifying assumptions or abstractions. We also show that SMC can
enable a defender to quantify the amount of noise necessary to have a desired
level of confidence that she has reduced an attacker's probability of success
to less than a desired threshold, thus providing the defender with an
actionable plan for obfuscation via noise injection.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02464v1' target='_blank'>ERUPT: An Open Toolkit for Interfacing with Robot Motion Planners in
  Extended Reality</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Isaac Ngui, Courtney McBeth, André Santos, Grace He, Katherine J. Mimnaugh, James D. Motes, Luciano Soares, Marco Morales, Nancy M. Amato</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 18:18:50</h6>
<p class='card-text'>We propose the Extended Reality Universal Planning Toolkit (ERUPT), an
extended reality (XR) system for interactive motion planning. Our system allows
users to create and dynamically reconfigure environments while they plan robot
paths. In immersive three-dimensional XR environments, users gain a greater
spatial understanding. XR also unlocks a broader range of natural interaction
capabilities, allowing users to grab and adjust objects in the environment
similarly to the real world, rather than using a mouse and keyboard with the
scene projected onto a two-dimensional computer screen. Our system integrates
with MoveIt, a manipulation planning framework, allowing users to send motion
planning requests and visualize the resulting robot paths in virtual or
augmented reality. We provide a broad range of interaction modalities, allowing
users to modify objects in the environment and interact with a virtual robot.
Our system allows operators to visualize robot motions, ensuring desired
behavior as it moves throughout the environment, without risk of collisions
within a virtual space, and to then deploy planned paths on physical robots in
the real world.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02189v1' target='_blank'>Hybrid Physics-ML Framework for Pan-Arctic Permafrost Infrastructure
  Risk at Record 2.9-Million Observation Scale</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Boris Kriuk</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 16:38:36</h6>
<p class='card-text'>Arctic warming threatens over 100 billion in permafrost-dependent
infrastructure across Northern territories, yet existing risk assessment
frameworks lack spatiotemporal validation, uncertainty quantification, and
operational decision-support capabilities. We present a hybrid physics-machine
learning framework integrating 2.9 million observations from 171,605 locations
(2005-2021) combining permafrost fraction data with climate reanalysis. Our
stacked ensemble model (Random Forest + Histogram Gradient Boosting + Elastic
Net) achieves R2=0.980 (RMSE=5.01 pp) with rigorous spatiotemporal
cross-validation preventing data leakage. To address machine learning
limitations in extrapolative climate scenarios, we develop a hybrid approach
combining learned climate-permafrost relationships (60%) with physical
permafrost sensitivity models (40%, -10 pp/C). Under RCP8.5 forcing (+5C over
10 years), we project mean permafrost fraction decline of -20.3 pp (median:
-20.0 pp), with 51.5% of Arctic Russia experiencing over 20 percentage point
loss. Infrastructure risk classification identifies 15% high-risk zones (25%
medium-risk) with spatially explicit uncertainty maps. Our framework represents
the largest validated permafrost ML dataset globally, provides the first
operational hybrid physics-ML forecasting system for Arctic infrastructure, and
delivers open-source tools enabling probabilistic permafrost projections for
engineering design codes and climate adaptation planning. The methodology is
generalizable to other permafrost regions and demonstrates how hybrid
approaches can overcome pure data-driven limitations in climate change
applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02166v1' target='_blank'>SIEVE: Towards Verifiable Certification for Code-datasets</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fatou Ndiaye Mbodji, El-hacen Diallo, Jordan Samhi, Kui Liu, Jacques Klein, Tegawendé F. Bissyande</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 16:14:23</h6>
<p class='card-text'>Code agents and empirical software engineering rely on public code datasets,
yet these datasets lack verifiable quality guarantees. Static 'dataset cards'
inform, but they are neither auditable nor do they offer statistical
guarantees, making it difficult to attest to dataset quality. Teams build
isolated, ad-hoc cleaning pipelines. This fragments effort and raises cost. We
present SIEVE, a community-driven framework. It turns per-property checks into
Confidence Cards-machine-readable, verifiable certificates with anytime-valid
statistical bounds. We outline a research plan to bring SIEVE to maturity,
replacing narrative cards with anytime-verifiable certification. This shift is
expected to lower quality-assurance costs and increase trust in code-datasets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02416v1' target='_blank'>Cross-Platform DNA Methylation Classifier for the Eight Molecular
  Subtypes of Group 3 & 4 Medulloblastoma</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Omer Abid, Gholamreza Rafiee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 14:53:38</h6>
<p class='card-text'>Medulloblastoma is a malignant pediatric brain cancer, and the discovery of
molecular subgroups is enabling personalized treatment strategies. In 2019, a
consensus identified eight novel subtypes within Groups 3 and 4, each
displaying heterogeneous characteristics. Classifiers are essential for
translating these findings into clinical practice by supporting clinical
trials, personalized therapy development and application, and patient
monitoring. This study presents a DNA methylation-based, cross-platform machine
learning classifier capable of distinguishing these subtypes on both HM450 and
EPIC methylation array samples. Across two independent test sets, the model
achieved weighted F1 = 0.95 and balanced accuracy = 0.957, consistent across
platforms. As the first cross-platform solution, it provides backward
compatibility while extending applicability to a newer platform, also enhancing
accessibility. It also has the potential to become the first publicly available
classifier for these subtypes once deployed through a web application, as
planned in the future. This work overall takes steps in the direction of
advancing precision medicine and improving clinical outcomes for patients
within the majority prevalence medulloblastoma subgroups, groups 3 and 4.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02086v1' target='_blank'>VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and
  Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arman Behnam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 14:52:08</h6>
<p class='card-text'>Accurate detection and segmentation of brain tumors from magnetic resonance
imaging (MRI) are essential for diagnosis, treatment planning, and clinical
monitoring. While convolutional architectures such as U-Net have long been the
backbone of medical image segmentation, their limited capacity to capture
long-range dependencies constrains performance on complex tumor structures.
Recent advances in diffusion models have demonstrated strong potential for
generating high-fidelity medical images and refining segmentation boundaries.
  In this work, we propose VGDM: Vision-Guided Diffusion Model for Brain Tumor
Detection and Segmentation framework, a transformer-driven diffusion framework
for brain tumor detection and segmentation. By embedding a vision transformer
at the core of the diffusion process, the model leverages global contextual
reasoning together with iterative denoising to enhance both volumetric accuracy
and boundary precision. The transformer backbone enables more effective
modeling of spatial relationships across entire MRI volumes, while diffusion
refinement mitigates voxel-level errors and recovers fine-grained tumor
details.
  This hybrid design provides a pathway toward improved robustness and
scalability in neuro-oncology, moving beyond conventional U-Net baselines.
Experimental validation on MRI brain tumor datasets demonstrates consistent
gains in Dice similarity and Hausdorff distance, underscoring the potential of
transformer-guided diffusion models to advance the state of the art in tumor
segmentation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.02084v2' target='_blank'>KAIROS: Unified Training for Universal Non-Autoregressive Time Series
  Forecasting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kuiye Ding, Fanda Fan, Zheya Wang, Hongxiao Li, Yifan Wang, Lei Wang, Chunjie Luo, Jianfeng Zhan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-02 14:50:50</h6>
<p class='card-text'>In the World Wide Web, reliable time series forecasts provide the
forward-looking signals that drive resource planning, cache placement, and
anomaly response, enabling platforms to operate efficiently as user behavior
and content distributions evolve. Compared with other domains, time series
forecasting for Web applications requires much faster responsiveness to support
real-time decision making. We present KAIROS, a non-autoregressive time series
forecasting framework that directly models segment-level multi-peak
distributions. Unlike autoregressive approaches, KAIROS avoids error
accumulation and achieves just-in-time inference, while improving over existing
non-autoregressive models that collapse to over-smoothed predictions. Trained
on the large-scale corpus, KAIROS demonstrates strong zero-shot generalization
on six widely used benchmarks, delivering forecasting performance comparable to
state-of-the-art foundation models with similar scale, at a fraction of their
inference cost. Beyond empirical results, KAIROS highlights the importance of
non-autoregressive design as a scalable paradigm for foundation models in time
series.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>