<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-11-06</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-11-06</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03652v1' target='_blank'>Motion Planning Under Temporal Logic Specifications In Semantically
  Unknown Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Azizollah Taheri, Derya Aksaray</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 17:09:43</h6>
<p class='card-text'>This paper addresses a motion planning problem to achieve
spatio-temporal-logical tasks, expressed by syntactically co-safe linear
temporal logic specifications (scLTL\next), in uncertain environments. Here,
the uncertainty is modeled as some probabilistic knowledge on the semantic
labels of the environment. For example, the task is "first go to region 1, then
go to region 2"; however, the exact locations of regions 1 and 2 are not known
a priori, instead a probabilistic belief is available. We propose a novel
automata-theoretic approach, where a special product automaton is constructed
to capture the uncertainty related to semantic labels, and a reward function is
designed for each edge of this product automaton. The proposed algorithm
utilizes value iteration for online replanning. We show some theoretical
results and present some simulations/experiments to demonstrate the efficacy of
the proposed approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03651v1' target='_blank'>Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrei A. Korigodskii, Oleg D. Kalachev, Artem E. Vasiunik, Matvei V. Urvantsev, Georgii E. Bondar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 17:09:16</h6>
<p class='card-text'>This paper presents the innovative design and successful deployment of a
pioneering autonomous unmanned aerial system developed for executing the
world's largest mural painted by a drone. Addressing the dual challenges of
maintaining artistic precision and operational reliability under adverse
outdoor conditions such as wind and direct sunlight, our work introduces a
robust system capable of navigating and painting outdoors with unprecedented
accuracy. Key to our approach is a novel navigation system that combines an
infrared (IR) motion capture camera and LiDAR technology, enabling precise
location tracking tailored specifically for largescale artistic applications.
We employ a unique control architecture that uses different regulation in
tangential and normal directions relative to the planned path, enabling precise
trajectory tracking and stable line rendering. We also present algorithms for
trajectory planning and path optimization, allowing for complex curve drawing
and area filling. The system includes a custom-designed paint spraying
mechanism, specifically engineered to function effectively amidst the turbulent
airflow generated by the drone's propellers, which also protects the drone's
critical components from paint-related damage, ensuring longevity and
consistent performance. Experimental results demonstrate the system's
robustness and precision in varied conditions, showcasing its potential for
autonomous large-scale art creation and expanding the functional applications
of robotics in creative fields.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03642v1' target='_blank'>Generalized k-Cell Decomposition for Visibility Planning in Polygons</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yeganeh Bahoo, Sajad Saeedi, Roni Sherman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 17:02:35</h6>
<p class='card-text'>This paper introduces a novel $k$-cell decomposition method for
pursuit-evasion problems in polygonal environments, where a searcher is
equipped with a $k$-modem: a device capable of seeing through up to $k$ walls.
The proposed decomposition ensures that as the searcher moves within a cell,
the structure of unseen regions (shadows) remains unchanged, thereby preventing
any geometric events between or on invisible regions, that is, preventing the
appearance, disappearance, merge, or split of shadow regions. The method
extends existing work on $0$- and $2$-visibility by incorporating m-visibility
polygons for all even $0 \le m \le k$, constructing partition lines that enable
robust environment division. The correctness of the decomposition is proved via
three theorems. The decomposition enables reliable path planning for intruder
detection in simulated environments and opens new avenues for visibility-based
robotic surveillance. The difficulty in constructing the cells of the
decomposition consists in computing the $k$-visibility polygon from each vertex
and finding the intersection points of the partition lines to create the cells.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03596v1' target='_blank'>Adjusting for Heavy Censoring and Double-Dipping to Compare Risk
  Stratification Abilities of Existing Models for Time to Diagnosis of
  Huntington Disease</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kyle F. Grosser, Abigail G. Foes, Stellen Li, Vraj Parikh, Tanya P. Garcia, Sarah C. Lotspeich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 16:16:48</h6>
<p class='card-text'>Huntington disease (HD) is a genetically inherited neurodegenerative disease
with progressively worsening symptoms. Accurately modeling time to HD diagnosis
is essential for clinical trial design and treatment planning. Langbehn's
model, the CAG-Age Product (CAP) model, the Prognostic Index Normed (PIN)
model, and the Multivariate Risk Score (MRS) model have all been proposed for
this task. However, differing in methodology, assumptions, and accuracy, these
models may yield conflicting predictions. Few studies have systematically
compared these models' performance, and those that have could be misleading due
to (i) testing the models on the same data used to train them and (ii) failing
to account for high rates of right censoring (80%+) in performance metrics. We
discuss the theoretical foundations of the four most common models of time to
HD diagnosis, offering intuitive comparisons about their practical feasibility.
Further, we externally validate their risk stratification abilities using data
from the ENROLL-HD study and performance metrics that adjust for censoring. Our
findings guide the selection of a model for HD clinical trial design. The MRS
model, which incorporates the most covariates, performed the best. However, the
simpler CAP and PIN models were not far behind and may be logistically simpler
to adopt. We also show how these models can be used to estimate sample sizes
for an HD clinical trial, emphasizing that previous estimates would lead to
underpowered trials.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03594v1' target='_blank'>Powered Descent Trajectory Optimization of Chandrayaan-3 using Radau
  Collocation and Controllable Sets</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Suraj Kumar, Aditya Rallapalli, Ashok Kumar Kakula, Bharat Kumar GVP</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 16:15:42</h6>
<p class='card-text'>India achieved a significant milestone on August $23^{\text{rd}}$ 2023,
becoming the fourth country to accomplish a soft landing on the Moon. This
paper presents the powered descent trajectory design for the Chandrayaan-3
mission. The optimization framework is based on pseudospectral Radau
collocation, and controllability-based waypoint refinement is employed to
further enhance the robustness of the trajectory against state and control
perturbations. Furthermore, the trade-off between fuel consumption and
robustness is explicitly quantified, providing insights into the practical
considerations of mission planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03591v1' target='_blank'>Manifold-constrained Hamilton-Jacobi Reachability Learning for
  Decentralized Multi-Agent Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingyi Chen, Ruiqi Ni, Jun Kim, Ahmed H. Qureshi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 16:11:12</h6>
<p class='card-text'>Safe multi-agent motion planning (MAMP) under task-induced constraints is a
critical challenge in robotics. Many real-world scenarios require robots to
navigate dynamic environments while adhering to manifold constraints imposed by
tasks. For example, service robots must carry cups upright while avoiding
collisions with humans or other robots. Despite recent advances in
decentralized MAMP for high-dimensional systems, incorporating manifold
constraints remains difficult. To address this, we propose a
manifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for
decentralized MAMP. Our method solves HJR problems under manifold constraints
to capture task-aware safety conditions, which are then integrated into a
decentralized trajectory optimization planner. This enables robots to generate
motion plans that are both safe and task-feasible without requiring assumptions
about other agents' policies. Our approach generalizes across diverse
manifold-constrained tasks and scales effectively to high-dimensional
multi-agent manipulation problems. Experiments show that our method outperforms
existing constrained motion planners and operates at speeds suitable for
real-world applications. Video demonstrations are available at
https://youtu.be/RYcEHMnPTH8 .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03478v1' target='_blank'>SVG Decomposition for Enhancing Large Multimodal Models Visualization
  Comprehension: A Study with Floor Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jeongah Lee, Ali Sarvghad</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 14:04:10</h6>
<p class='card-text'>Large multimodal models (LMMs) are increasingly capable of interpreting
visualizations, yet they continue to struggle with spatial reasoning. One
proposed strategy is decomposition, which breaks down complex visualizations
into structured components. In this work, we examine the efficacy of scalable
vector graphics (SVGs) as a decomposition strategy for improving LMMs'
performance on floor plans comprehension. Floor plans serve as a valuable
testbed because they combine geometry, topology, and semantics, and their
reliable comprehension has real-world applications, such as accessibility for
blind and low-vision individuals. We conducted an exploratory study with three
LMMs (GPT-4o, Claude 3.7 Sonnet, and Llama 3.2 11B Vision Instruct) across 75
floor plans. Results show that combining SVG with raster input (SVG+PNG)
improves performance on spatial understanding tasks but often hinders spatial
reasoning, particularly in pathfinding. These findings highlight both the
promise and limitations of decomposition as a strategy for advancing spatial
visualization comprehension.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03257v1' target='_blank'>Quantum-classical hybrid algorithm using quantum annealing for
  multi-objective job shop scheduling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kenta Sawamura, Kensuke Araki, Naoki Maruyama, Renichiro Haba, Masayuki Ohzeki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 07:39:09</h6>
<p class='card-text'>Efficient production planning is essential in modern manufacturing to improve
performance indicators such as lead time and to reduce reliance on human
intuition. While mathematical optimization approaches, formulated as job shop
scheduling problems, have been applied to automate this process, solving
large-scale production planning problems remains computationally demanding.
Moreover, many practical scenarios involve conflicting objectives, making
traditional scalarization techniques ineffective in finding diverse and useful
Pareto-optimal solutions. To address these challenges, we developed a
quantum-classical hybrid algorithm that decomposes the problem into two
subproblems: resource allocation and task scheduling. Resource allocation is
formulated as a quadratic unconstrained binary optimization problem and solved
using annealing-based methods that efficiently explore complex solutions. Task
scheduling is modeled as a mixed-integer linear programming problem and solved
using conventional solvers to satisfy detailed scheduling constraints. We
validated the proposed method using benchmark instances based on foundry
production scenarios. Experimental results demonstrate that our hybrid approach
achieves superior solution quality and computational efficiency compared to
traditional monolithic methods. This work offers a promising direction for
high-speed, multi-objective scheduling in industrial applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03242v1' target='_blank'>Topography, climate, land cover, and biodiversity: Explaining endemic
  richness and management implications on a Mediterranean island</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aristides Moustakas, Ioannis N Vogiatzakis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 07:09:18</h6>
<p class='card-text'>Island endemism is shaped by complex interactions among environmental,
ecological, and evolutionary factors, yet the relative contributions of
topography, climate, and land cover remain incompletely quantified. We
investigated the drivers of endemic plant richness across Crete, a
Mediterranean biodiversity hotspot, using spatially explicit data on species
distributions, topographic complexity, climatic variability, land cover, and
soil characteristics. Artificial Neural Network models, a machine learning
tool, were employed to assess the relative importance of these predictors and
to identify hotspots of endemism. We found that total species richness,
elevation range, and climatic variability were the strongest predictors of
endemic richness, reflecting the role of biodiversity, topographic
heterogeneity, and climatic gradients in generating diverse habitats and
micro-refugia that promote speciation and buffer extinction risk. Endemic
hotspots only partially overlapped with areas of high total species richness,
indicating that total species richness was the optimal from the ones examined,
yet an imperfect surrogate. These environmentally heterogeneous areas also
provide critical ecosystem services, including soil stabilization, pollination,
and cultural value, which are increasingly threatened by tourism, renewable
energy development, land-use change, and climate impacts. Our findings
underscore the importance of prioritizing mountainous and climatically variable
regions in conservation planning, integrating ecosystem service considerations,
and accounting for within-island spatial heterogeneity. By explicitly linking
the environmental drivers of endemism to both biodiversity patterns and
ecosystem function, this study provides a framework for evidence-based
conservation planning in Crete and other Mediterranean islands with similar
geological and biogeographic contexts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03238v1' target='_blank'>Incorporating Quality of Life in Climate Adaptation Planning via
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Miguel Costa, Arthur Vandervoort, Martin Drews, Karyn Morrissey, Francisco C. Pereira</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 07:00:55</h6>
<p class='card-text'>Urban flooding is expected to increase in frequency and severity as a
consequence of climate change, causing wide-ranging impacts that include a
decrease in urban Quality of Life (QoL). Meanwhile, policymakers must devise
adaptation strategies that can cope with the uncertain nature of climate change
and the complex and dynamic nature of urban flooding. Reinforcement Learning
(RL) holds significant promise in tackling such complex, dynamic, and uncertain
problems. Because of this, we use RL to identify which climate adaptation
pathways lead to a higher QoL in the long term. We do this using an Integrated
Assessment Model (IAM) which combines a rainfall projection model, a flood
model, a transport accessibility model, and a quality of life index. Our
preliminary results suggest that this approach can be used to learn optimal
adaptation measures and it outperforms other realistic and real-world planning
strategies. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03165v1' target='_blank'>SENT Map - Semantically Enhanced Topological Maps with Foundation Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Raj Surya Rajendran Kathirvel, Zach A Chavis, Stephen J. Guy, Karthik Desingh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 04:22:04</h6>
<p class='card-text'>We introduce SENT-Map, a semantically enhanced topological map for
representing indoor environments, designed to support autonomous navigation and
manipulation by leveraging advancements in foundational models (FMs). Through
representing the environment in a JSON text format, we enable semantic
information to be added and edited in a format that both humans and FMs
understand, while grounding the robot to existing nodes during planning to
avoid infeasible states during deployment. Our proposed framework employs a two
stage approach, first mapping the environment alongside an operator with a
Vision-FM, then using the SENT-Map representation alongside a natural-language
query within an FM for planning. Our experimental results show that
semantic-enhancement enables even small locally-deployable FMs to successfully
plan over indoor environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03115v1' target='_blank'>Fast SDE-based Monte Carlo dose calculation for proton therapy validated
  against Geant4</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christopher B. C. Dean, Maria L. Pérez-Lara, Emma Horton, Matthew Southerby, Jere Koskela, Andreas E. Kyprianou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-05 01:45:57</h6>
<p class='card-text'>Objective: To validate a newly proposed stochastic differential equation
(SDE)-based model for proton beam energy deposition by comparing its
predictions with those from Geant4 in simplified phantom scenarios. Approach:
Building on previous work in Crossley et al. (2025), where energy deposition
from a proton beam was modelled using an SDE framework, we implemented the
model with standard approximations to interaction cross sections and mean
excitation energies, which makes simulations easily adaptable to new materials
and configurations. The model was benchmarked against Geant4 in homogeneous and
heterogeneous phantoms. Main results: The SDE-based dose distributions agreed
well with Geant4, showing range differences within 0.4 mm and 3D gamma pass
rates exceeding 98% under 3%/2 mm criteria with a 1% dose threshold. The model
achieved a computational speed-up of approximately fivefold relative to Geant4,
consistent across different Geant4 physics lists. Significance: These results
demonstrate that the SDE approach can reproduce accuracy comparable to
high-fidelity Monte Carlo for proton therapy at a fraction of the computational
cost, highlighting its potential for accelerating dose calculations and
treatment planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03077v1' target='_blank'>WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned
  Visual World Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:R. Khorrambakht, Joaquim Ortiz-Haro, Joseph Amigo, Omar Mostafa, Daniel Dugas, Franziska Meier, Ludovic Righetti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 23:52:07</h6>
<p class='card-text'>Robots must understand their environment from raw sensory inputs and reason
about the consequences of their actions in it to solve complex tasks. Behavior
Cloning (BC) leverages task-specific human demonstrations to learn this
knowledge as end-to-end policies. However, these policies are difficult to
transfer to new tasks, and generating training data is challenging because it
requires careful demonstrations and frequent environment resets. In contrast to
such policy-based view, in this paper we take a model-based approach where we
collect a few hours of unstructured easy-to-collect play data to learn an
action-conditioned visual world model, a diffusion-based action sampler, and
optionally a reward model. The world model -- in combination with the action
sampler and a reward model -- is then used to optimize long sequences of
actions with a Monte Carlo Tree Search (MCTS) planner. The resulting plans are
executed on the robot via a zeroth-order Model Predictive Controller (MPC). We
show that the action sampler mitigates hallucinations of the world model during
planning and validate our approach on 3 real-world robotic tasks with varying
levels of planning and modeling complexity. Our experiments support the
hypothesis that planning leads to a significant improvement over BC baselines
on a standard manipulation test environment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03018v1' target='_blank'>Massive stars in the era of large spectroscopic surveys: The MEIGAS
  project</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:S. R. Berlanas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 21:28:56</h6>
<p class='card-text'>In the era of large spectroscopic surveys, a vast amount of spectra of
massive stars will be gathered and supplemented by the wealth of astrometric
and photometric data provided by the Gaia satellite. Released data will mean a
major step forward in the study of massive stars, giving us the chance to
create statistically significant samples to explore the role of almost any
parameter. In this contribution, I introduce to the community the
Multi-wavelength Exploration of massIve star-forminG regions and ASsociations
project (MEIGAS) and long-term plans for conducting comprehensive studies in
the major galactic and near extragalactic star-forming regions and OB
associations. Benefiting from current and forthcoming data from large scale
spectroscopic surveys such as WEAVE and 4MOST (among others), as well as
complementary observations at different wavelength ranges, the project aims to
achieve crucial and complementary information to adequately characterize these
regions and their stellar content, something imperative to improve our
understanding of star formation and poorly known evolutionary pathways of
massive stars.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.03014v1' target='_blank'>A Foundation Model for Brain MRI with Dynamic Modality Integration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minh Sao Khue Luu, Bair N. Tuchinov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 21:25:48</h6>
<p class='card-text'>We present a foundation model for brain MRI that can work with different
combinations of imaging sequences. The model uses one encoder with learnable
modality embeddings, conditional layer normalization, and a masked autoencoding
objective that accounts for missing modalities. A variance-covariance
regularizer is applied to stabilize feature learning and improve representation
diversity. This design removes the need for separate models for each modality
and allows the network to adapt when some sequences are missing or unseen. It
is trained on about 60,000 multi-center MRIs using self-supervised
reconstruction and modality imputation to learn flexible representations. A
learnable modality embedding guides feature extraction so the encoder can
adjust to different inputs. We describe our planned evaluation on brain tumor
and multiple sclerosis segmentation, as well as lesion classification, under
various modality settings. Preliminary results show that the method works
feasibly, and further experiments are planned to study its performance in more
detail. All code and pretrained models are available at
https://github.com/BrainFM/brainfm</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02973v1' target='_blank'>Extreme events and public debt dynamics: Lessons from Croatia's
  experience</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luka Draganić, Leonarda Srdelić, Marwil J. Davila-Fernandez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 20:25:39</h6>
<p class='card-text'>Using Croatian data and the IMF's Natural Disaster Debt Dynamic Tool, this
paper assesses how public debt adjusts to extreme events in a small open
economy. We compare debt paths under baseline and stress scenarios, the latter
simulating a major earthquake in 2025. Croatia provides a unique setting for
evaluating post-disaster recovery in countries recently incorporated into the
European Union. Our benchmark projections, which assume moderate economic
growth and a broadly neutral fiscal stance, suggest the debt-to-GDP ratio will
gradually decline to below 55% by 2040. In contrast, in the disaster scenario,
we document a sharp short-term increase and a persistent upward shift in the
debt trajectory, reaching 75% of GDP. Deterministic and stochastic simulations
allow us to assess the distribution of potential outcomes. It is shown that, in
the absence of shocks, public debt is on a sustainable downward path, but a
severe natural disaster could reverse this trend and keep it elevated for
years. Our findings highlight the importance of fiscal buffers that are
critical for creating space to absorb shocks. The paper innovates by
integrating natural disaster stress-testing into public debt analysis, with
implications for fiscal risk management and policy planning. While we focus on
Croatia, the mechanisms we uncover have broader implications for small open
economies exposed to extreme events.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02957v1' target='_blank'>Digital Twin-Driven Pavement Health Monitoring and Maintenance
  Optimization Using Graph Neural Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohsin Mahmud Topu, Mahfuz Ahmed Anik, Azmine Toushik Wasi, Md Manjurul Ahsan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 19:59:17</h6>
<p class='card-text'>Pavement infrastructure monitoring is challenged by complex spatial
dependencies, changing environmental conditions, and non-linear deterioration
across road networks. Traditional Pavement Management Systems (PMS) remain
largely reactive, lacking real-time intelligence for failure prevention and
optimal maintenance planning. To address this, we propose a unified Digital
Twin (DT) and Graph Neural Network (GNN) framework for scalable, data-driven
pavement health monitoring and predictive maintenance. Pavement segments and
spatial relations are modeled as graph nodes and edges, while real-time UAV,
sensor, and LiDAR data stream into the DT. The inductive GNN learns
deterioration patterns from graph-structured inputs to forecast distress and
enable proactive interventions. Trained on a real-world-inspired dataset with
segment attributes and dynamic connectivity, our model achieves an R2 of
0.3798, outperforming baseline regressors and effectively capturing non-linear
degradation. We also develop an interactive dashboard and reinforcement
learning module for simulation, visualization, and adaptive maintenance
planning. This DT-GNN integration enhances forecasting precision and
establishes a closed feedback loop for continuous improvement, positioning the
approach as a foundation for proactive, intelligent, and sustainable pavement
management, with future extensions toward real-world deployment, multi-agent
coordination, and smart-city integration.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02928v1' target='_blank'>Domain-Adaptive Transformer for Data-Efficient Glioma Segmentation in
  Sub-Saharan MRI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ilerioluwakiiye Abolade, Aniekan Udo, Augustine Ojo, Abdulbasit Oyetunji, Hammed Ajigbotosho, Aondana Iorumbur, Confidence Raymond, Maruf Adewole</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 19:20:55</h6>
<p class='card-text'>Glioma segmentation is critical for diagnosis and treatment planning, yet
remains challenging in Sub-Saharan Africa due to limited MRI infrastructure and
heterogeneous acquisition protocols that induce severe domain shift. We propose
SegFormer3D-plus, a radiomics-guided transformer architecture designed for
robust segmentation under domain variability. Our method combines: (1)
histogram matching for intensity harmonization across scanners, (2) radiomic
feature extraction with PCA-reduced k-means for domain-aware stratified
sampling, (3) a dual-pathway encoder with frequency-aware feature extraction
and spatial-channel attention, and (4) composite Dice-Cross-Entropy loss for
boundary refinement. Pretrained on BraTS 2023 and fine-tuned on BraTS-Africa
data, SegFormer3D-plus demonstrates improved tumor subregion delineation and
boundary localization across heterogeneous African clinical scans, highlighting
the value of radiomics-guided domain adaptation for resource-limited settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02823v1' target='_blank'>Optimizing AI Agent Attacks With Synthetic Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chloe Loughridge, Paul Colognese, Avery Griffin, Tyler Tracy, Jon Kutasov, Joe Benton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 18:48:56</h6>
<p class='card-text'>As AI deployments become more complex and high-stakes, it becomes
increasingly important to be able to estimate their risk. AI control is one
framework for doing so. However, good control evaluations require eliciting
strong attack policies. This can be challenging in complex agentic environments
where compute constraints leave us data-poor. In this work, we show how to
optimize attack policies in SHADE-Arena, a dataset of diverse realistic control
environments. We do this by decomposing attack capability into five constituent
skills -- suspicion modeling, attack selection, plan synthesis, execution and
subtlety -- and optimizing each component individually. To get around the
constraint of limited data, we develop a probabilistic model of attack
dynamics, optimize our attack hyperparameters using this simulation, and then
show that the results transfer to SHADE-Arena. This results in a substantial
improvement in attack strength, reducing safety score from a baseline of 0.87
to 0.41 using our scaffold.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02815v1' target='_blank'>Assessing win strength in MLB win prediction models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Morgan Allen, Paul Savala</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 18:40:10</h6>
<p class='card-text'>In Major League Baseball, strategy and planning are major factors in
determining the outcome of a game. Previous studies have aided this by building
machine learning models for predicting the winning team of any given game. We
extend this work by training a comprehensive set of machine learning models
using a common dataset. In addition, we relate the win probabilities produced
by these models to win strength as measured by score differential. In doing so
we show that the most common machine learning models do indeed demonstrate a
relationship between predicted win probability and the strength of the win.
Finally, we analyze the results of using predicted win probabilities as a
decision making mechanism on run-line betting. We demonstrate positive returns
when utilizing appropriate betting strategies, and show that naive use of
machine learning models for betting lead to significant loses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02893v1' target='_blank'>Optimizing the nnU-Net model for brain tumor (Glioma) segmentation Using
  a BraTS Sub-Saharan Africa (SSA) dataset</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chukwuemeka Arua Kalu, Adaobi Chiazor Emegoakor, Fortune Okafor, Augustine Okoh Uchenna, Chijioke Kelvin Ukpai, Godsent Erere Onyeugbo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 15:58:07</h6>
<p class='card-text'>Medical image segmentation is a critical achievement in modern medical
science, developed over decades of research. It allows for the exact
delineation of anatomical and pathological features in two- or
three-dimensional pictures by utilizing notions like pixel intensity, texture,
and anatomical context. With the advent of automated segmentation, physicians
and radiologists may now concentrate on diagnosis and treatment planning while
intelligent computers perform routine image processing tasks.
  This study used the BraTS Sub-Saharan Africa dataset, a selected subset of
the BraTS dataset that included 60 multimodal MRI cases from patients with
glioma. Surprisingly, the nnU Net model trained on the initial 60 instances
performed better than the network trained on an offline-augmented dataset of
360 cases. Hypothetically, the offline augmentations introduced artificial
anatomical variances or intensity distributions, reducing generalization. In
contrast, the original dataset, when paired with nnU Net's robust online
augmentation procedures, maintained realistic variability and produced better
results. The study achieved a Dice score of 0.84 for whole tumor segmentation.
These findings highlight the significance of data quality and proper
augmentation approaches in constructing accurate, generalizable medical picture
segmentation models, particularly for under-represented locations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02592v1' target='_blank'>ISAC Empowered Air-Sea Collaborative System: A UAV-USV Joint Inspection
  Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rui Zhang, Fuwang Dong, Wei Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 14:12:32</h6>
<p class='card-text'>In this paper, we construct an air-sea collaborative system framework based
on the Integrated Sensing and Communication (ISAC) techniques, where the
Unmanned Aerial Vehicle (UAV) and Unmanned Surface Vehicle (USV) jointly
inspect targets of interest while keeping communication with each other
simultaneously. First, we demonstrate the unique challenges encountered in this
collaborative system, i.e., the coupling and heterogeneity of the UAV/USV's
trajectories. Then, we formulate a total energy consumption minimization
problem to jointly optimize the trajectories, flying and hovering times, target
scheduling, and beamformers under the constraints of water currents, collision
avoidance, and Sensing and Communication (S\&C) requirements. To address the
strong coupling of the variables, we divide the original problem into two
subproblems, namely, the hover point selection and the joint trajectory
planning and beamforming design. In the first subproblem, we propose a
three-step hierarchical method including: (1) a virtual base station coverage
(VBSC) and clustering algorithm to obtain the target scheduling and rough
position of hover points; (2) a Bi-traveling salesman problem with neighborhood
(Bi-TSPN)-based algorithm to determine the visiting order sequence of the hover
points; (3) a hover point refinement and time allocation algorithm to further
optimize the time allocation. In the latter subproblem, we complete the
remaining trajectory planning and beamforming design in each flying and
hovering stage by developing a semi-definite relaxation (SDR) and successive
convex approximation (SCA) method. Finally, we conduct a series of simulations
to demonstrate the superiority of the proposed scheme over existing sequential
access and leader-follower strategies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02560v1' target='_blank'>SigmaCollab: An Application-Driven Dataset for Physically Situated
  Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dan Bohus, Sean Andrist, Ann Paradiso, Nick Saw, Tim Schoonbeek, Maia Stiber</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 13:30:15</h6>
<p class='card-text'>We introduce SigmaCollab, a dataset enabling research on physically situated
human-AI collaboration. The dataset consists of a set of 85 sessions in which
untrained participants were guided by a mixed-reality assistive AI agent in
performing procedural tasks in the physical world. SigmaCollab includes a set
of rich, multimodal data streams, such as the participant and system audio,
egocentric camera views from the head-mounted device, depth maps, head, hand
and gaze tracking information, as well as additional annotations performed
post-hoc. While the dataset is relatively small in size (~ 14 hours), its
application-driven and interactive nature brings to the fore novel research
challenges for human-AI collaboration, and provides more realistic testing
grounds for various AI models operating in this space. In future work, we plan
to use the dataset to construct a set of benchmarks for physically situated
collaboration in mixed-reality task assistive scenarios. SigmaCollab is
available at https://github.com/microsoft/SigmaCollab.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02552v1' target='_blank'>Sparse Source Identification in Transient Advection-Diffusion Problems
  with a Primal-Dual-Active-Point Strategy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marco Mattuschka, Daniel Walter, Max von Danwitz, Alexander Popp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 13:04:40</h6>
<p class='card-text'>This work presents a mathematical model to enable rapid prediction of
airborne contaminant transport based on scarce sensor measurements. The method
is designed for applications in critical infrastructure protection (CIP), such
as evacuation planning following contaminant release. In such scenarios, timely
and reliable decision-making is essential, despite limited observation data. To
identify contaminant sources, we formulate an inverse problem governed by an
advection-diffusion equation. Given the problem's underdetermined nature, we
further employ a variational regularization ansatz and model the unknown
contaminant sources as distribution over the spatial domain. To efficiently
solve the arising inverse problem, we employ a problem-specific variant of the
Primal-Dual-Active-Point (PDAP) algorithm which efficiently approximates sparse
minimizers of the inverse problem by alternating between greedy location
updates and source intensity optimization. The approach is demonstrated on two-
and three-dimensional test cases involving both instantaneous and continuous
contaminant sources and outperforms state-of-the-art techniques with
$L^2$-regularization. Its effectiveness is further illustrated in complex
domains with real-world building geometries imported from OpenStreetMap.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02532v1' target='_blank'>Agentic AI for Mobile Network RAN Management and Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jorge Pellejero, Luis A. Hernández Gómez, Luis Mendo Tomás, Zoraida Frias Barroso</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 12:34:57</h6>
<p class='card-text'>Agentic AI represents a new paradigm for automating complex systems by using
Large AI Models (LAMs) to provide human-level cognitive abilities with
multimodal perception, planning, memory, and reasoning capabilities. This will
lead to a new generation of AI systems that autonomously decompose goals,
retain context over time, learn continuously, operate across tools and
environments, and adapt dynamically. The complexity of 5G and upcoming 6G
networks renders manual optimization ineffective, pointing to Agentic AI as a
method for automating decisions in dynamic RAN environments. However, despite
its rapid advances, there is no established framework outlining the
foundational components and operational principles of Agentic AI systems nor a
universally accepted definition.
  This paper contributes to ongoing research on Agentic AI in 5G and 6G
networks by outlining its core concepts and then proposing a practical use case
that applies Agentic principles to RAN optimization. We first introduce Agentic
AI, tracing its evolution from classical agents and discussing the progress
from workflows and simple AI agents to Agentic AI. Core design
patterns-reflection, planning, tool use, and multi-agent collaboration-are then
described to illustrate how intelligent behaviors are orchestrated. These
theorical concepts are grounded in the context of mobile networks, with a focus
on RAN management and optimization. A practical 5G RAN case study shows how
time-series analytics and LAM-driven agents collaborate for KPI-based
autonomous decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02484v1' target='_blank'>Using ensemble learning with hybrid graph neural networks and
  transformers to predict traffic in cities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ismail Zrigui, Samira Khoulji, Mohamed Larbi Kerkeb</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 11:14:49</h6>
<p class='card-text'>Intelligent transportation systems (ITS) still have a hard time accurately
predicting traffic in cities, especially in big, multimodal settings with
complicated spatiotemporal dynamics. This paper presents HybridST, a hybrid
architecture that integrates Graph Neural Networks (GNNs), multi-head temporal
Transformers, and supervised ensemble learning methods (XGBoost or Random
Forest) to collectively capture spatial dependencies, long-range temporal
patterns, and exogenous signals, including weather, calendar, or control
states. We test our model on the METR-LA, PEMS-BAY, and Seattle Loop tree
public benchmark datasets. These datasets include situations ranging from
freeway sensor networks to vehicle-infrastructure cooperative perception.
Experimental results show that HybridST consistently beats classical baselines
(LSTM, GCN, DCRNN, PDFormer) on important metrics like MAE and RMSE, while
still being very scalable and easy to understand. The proposed framework
presents a promising avenue for real-time urban mobility planning, energy
optimization, and congestion alleviation strategies, especially within the
framework of smart cities and significant events such as the 2030 FIFA World
Cup.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02395v1' target='_blank'>Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar
  Point Clouds</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Leon Schwarzer, Matthias Zeller, Daniel Casado Herraez, Simon Dierl, Michael Heidingsfeld, Cyrill Stachniss</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 09:21:45</h6>
<p class='card-text'>Moving object segmentation is a crucial task for safe and reliable autonomous
mobile systems like self-driving cars, improving the reliability and robustness
of subsequent tasks like SLAM or path planning. While the segmentation of
camera or LiDAR data is widely researched and achieves great results, it often
introduces an increased latency by requiring the accumulation of temporal
sequences to gain the necessary temporal context. Radar sensors overcome this
problem with their ability to provide a direct measurement of a point's Doppler
velocity, which can be exploited for single-scan moving object segmentation.
However, radar point clouds are often sparse and noisy, making data annotation
for use in supervised learning very tedious, time-consuming, and
cost-intensive. To overcome this problem, we address the task of
self-supervised moving object segmentation of sparse and noisy radar point
clouds. We follow a two-step approach of contrastive self-supervised
representation learning with subsequent supervised fine-tuning using limited
amounts of annotated data. We propose a novel clustering-based contrastive loss
function with cluster refinement based on dynamic points removal to pretrain
the network to produce motion-aware representations of the radar data. Our
method improves label efficiency after fine-tuning, effectively boosting
state-of-the-art performance by self-supervised pretraining.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02342v1' target='_blank'>Whole-body motion planning and safety-critical control for aerial
  manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lin Yang, Jinwoo Lee, Domenico Campolo, H. Jin Kim, Jeonghyun Byun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 08:00:59</h6>
<p class='card-text'>Aerial manipulation combines the maneuverability of multirotors with the
dexterity of robotic arms to perform complex tasks in cluttered spaces. Yet
planning safe, dynamically feasible trajectories remains difficult due to
whole-body collision avoidance and the conservativeness of common geometric
abstractions such as bounding boxes or ellipsoids. We present a whole-body
motion planning and safety-critical control framework for aerial manipulators
built on superquadrics (SQs). Using an SQ-plus-proxy representation, we model
both the vehicle and obstacles with differentiable, geometry-accurate surfaces.
Leveraging this representation, we introduce a maximum-clearance planner that
fuses Voronoi diagrams with an equilibrium-manifold formulation to generate
smooth, collision-aware trajectories. We further design a safety-critical
controller that jointly enforces thrust limits and collision avoidance via
high-order control barrier functions. In simulation, our approach outperforms
sampling-based planners in cluttered environments, producing faster, safer, and
smoother trajectories and exceeding ellipsoid-based baselines in geometric
fidelity. Actual experiments on a physical aerial-manipulation platform confirm
feasibility and robustness, demonstrating consistent performance across
simulation and hardware settings. The video can be found at
https://youtu.be/hQYKwrWf1Ak.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02315v1' target='_blank'>ZJUNlict Extended Team Description Paper 2025</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zifei Wu, Lijie Wang, Zhe Yang, Shijie Yang, Liang Wang, Haoran Fu, Yinliang Cai, Rong Xiong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 07:00:34</h6>
<p class='card-text'>This paper presents the ZJUNlict team's work over the past year, covering
both hardware and software advancements. In the hardware domain, the
integration of an IMU into the v2023 robot was completed to enhance posture
accuracy and angular velocity planning. On the software side, key modules were
optimized, including the strategy and CUDA modules, with significant
improvements in decision making efficiency, ball pursuit prediction, and ball
possession prediction to adapt to high-tempo game dynamics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2511.02314v1' target='_blank'>Large-scale automatic carbon ion treatment planning for head and neck
  cancers via parallel multi-agent reinforcement learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jueye Zhang, Chao Yang, Youfang Lai, Kai-Wen Li, Wenting Yan, Yunzhou Xia, Haimei Zhang, Jingjing Zhou, Gen Yang, Chen Lin, Tian Li, Yibao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-04 06:57:31</h6>
<p class='card-text'>Head-and-neck cancer (HNC) planning is difficult because multiple critical
organs-at-risk (OARs) are close to complex targets. Intensity-modulated
carbon-ion therapy (IMCT) offers superior dose conformity and OAR sparing but
remains slow due to relative biological effectiveness (RBE) modeling, leading
to laborious, experience-based, and often suboptimal tuning of many
treatment-planning parameters (TPPs). Recent deep learning (DL) methods are
limited by data bias and plan feasibility, while reinforcement learning (RL)
struggles to efficiently explore the exponentially large TPP search space. We
propose a scalable multi-agent RL (MARL) framework for parallel tuning of 45
TPPs in IMCT. It uses a centralized-training decentralized-execution (CTDE)
QMIX backbone with Double DQN, Dueling DQN, and recurrent encoding (DRQN) for
stable learning in a high-dimensional, non-stationary environment. To enhance
efficiency, we (1) use compact historical DVH vectors as state inputs, (2)
apply a linear action-to-value transform mapping small discrete actions to
uniform parameter adjustments, and (3) design an absolute, clinically informed
piecewise reward aligned with plan scores. A synchronous multi-process worker
system interfaces with the PHOENIX TPS for parallel optimization and
accelerated data collection. On a head-and-neck dataset (10 training, 10
testing), the method tuned 45 parameters simultaneously and produced plans
comparable to or better than expert manual ones (relative plan score: RL
$85.93\pm7.85%$ vs Manual $85.02\pm6.92%$), with significant (p-value $<$ 0.05)
improvements for five OARs. The framework efficiently explores high-dimensional
TPP spaces and generates clinically competitive IMCT plans through direct TPS
interaction, notably improving OAR sparing.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>