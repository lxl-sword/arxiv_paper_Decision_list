<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-09-15</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-09-15</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10444v1' target='_blank'>Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced
  Human-Robot Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chaerim Moon, Joohyung Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 17:51:27</h6>
<p class='card-text'>Supernumerary Robotic Limbs (SRLs) can enhance human capability within close
proximity. However, as a wearable device, the generated moment from its
operation acts on the human body as an external torque. When the moments
increase, more muscle units are activated for balancing, and it can result in
reduced muscular null space. Therefore, this paper suggests a concept of a
motion planning layer that reduces the generated moment for enhanced
Human-Robot Interaction. It modifies given trajectories with desirable angular
acceleration and position deviation limits. Its performance to reduce the
moment is demonstrated through the simulation, which uses simplified human and
robotic system models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10363v1' target='_blank'>Physics-informed sensor coverage through structure preserving machine
  learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benjamin David Shaffer, Brooks Kinch, Joseph Klobusicky, M. Ani Hsieh, Nathaniel Trask</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 15:54:13</h6>
<p class='card-text'>We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10362v1' target='_blank'>Spatial Modeling and Risk Zoning of Global Extreme Precipitation via
  Graph Neural Networks and r-Pareto Processes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zimu Wang, Yifan Wu, Daning Bi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 15:53:16</h6>
<p class='card-text'>Extreme precipitation events occurring over large spatial domains pose
substantial threats to societies because they can trigger compound flooding,
landslides, and infrastructure failures across wide areas. A hybrid framework
for spatial extreme precipitation modeling and risk zoning is proposed that
integrates graph neural networks with r-Pareto processes (GNN-rP). Unlike
traditional statistical spatial extremes models, this approach learns
nonlinear, nonstationary dependence structures from precipitation-derived
spatial graphs and applies a data-driven tail functional to model joint
exceedances in a low-dimensional embedding space. Using NASA's IMERG
observations (2000-2021) and CMIP6 SSP5-8.5 projections, the framework
delineates coherent high-risk zones, quantifies their temporal persistence, and
detects emerging hotspots under climate change. Compared with two baseline
approaches, the GNN-rP pipeline substantially improves pointwise detection of
high-risk grid cells while yielding comparable clustering stability. Results
highlight persistent high-risk regions in the tropical belt, especially monsoon
and convective zones, and reveal decadal-scale persistence that is punctuated
by episodic reconfigurations under high-emission scenarios. By coupling machine
learning with extreme value theory, GNN-rP offers a scalable, interpretable
tool for adaptive climate risk zoning, with direct applications in
infrastructure planning, disaster preparedness, and climate-resilient policy
design.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10349v1' target='_blank'>Acetrans: An Autonomous Corridor-Based and Efficient UAV Suspended
  Transport System</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiyan Lu, Huizhe Li, Yuhao Fang, Zhexuan Zhou, Junda Wu, Yude Li, Youmin Gong, Jie Mei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 15:36:35</h6>
<p class='card-text'>Unmanned aerial vehicles (UAVs) with suspended payloads offer significant
advantages for aerial transportation in complex and cluttered environments.
However, existing systems face critical limitations, including unreliable
perception of the cable-payload dynamics, inefficient planning in large-scale
environments, and the inability to guarantee whole-body safety under cable
bending and external disturbances. This paper presents Acetrans, an Autonomous,
Corridor-based, and Efficient UAV suspended transport system that addresses
these challenges through a unified perception, planning, and control framework.
A LiDAR-IMU fusion module is proposed to jointly estimate both payload pose and
cable shape under taut and bent modes, enabling robust whole-body state
estimation and real-time filtering of cable point clouds. To enhance planning
scalability, we introduce the Multi-size-Aware Configuration-space Iterative
Regional Inflation (MACIRI) algorithm, which generates safe flight corridors
while accounting for varying UAV and payload geometries. A spatio-temporal,
corridor-constrained trajectory optimization scheme is then developed to ensure
dynamically feasible and collision-free trajectories. Finally, a nonlinear
model predictive controller (NMPC) augmented with cable-bending constraints
provides robust whole-body safety during execution. Simulation and experimental
results validate the effectiveness of Acetrans, demonstrating substantial
improvements in perception accuracy, planning efficiency, and control safety
compared to state-of-the-art methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10305v1' target='_blank'>GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust
  Robot Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yutong Shen, Ruizhe Xia, Bokai Yan, Shunqi zhang, Pengrui Xiang, Sicheng He, Yixin Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 14:46:20</h6>
<p class='card-text'>In dynamic and uncertain environments, robotic path planning demands accurate
spatiotemporal environment understanding combined with robust decision-making
under partial observability. However, current deep reinforcement learning-based
path planning methods face two fundamental limitations: (1) insufficient
modeling of multi-scale temporal dependencies, resulting in suboptimal
adaptability in dynamic scenarios, and (2) inefficient exploration-exploitation
balance, leading to degraded path quality. To address these challenges, we
propose GundamQ: A Multi-Scale Spatiotemporal Q-Network for Robotic Path
Planning. The framework comprises two key modules: (i) the Spatiotemporal
Perception module, which hierarchically extracts multi-granularity spatial
features and multi-scale temporal dependencies ranging from instantaneous to
extended time horizons, thereby improving perception accuracy in dynamic
environments; and (ii) the Adaptive Policy Optimization module, which balances
exploration and exploitation during training while optimizing for smoothness
and collision probability through constrained policy updates. Experiments in
dynamic environments demonstrate that GundamQ achieves a 15.3\% improvement in
success rate and a 21.7\% increase in overall path quality, significantly
outperforming existing state-of-the-art methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10284v1' target='_blank'>A Holistic Architecture for Monitoring and Optimization of Robust
  Multi-Agent Path Finding Plan Execution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David Zahrádka, Denisa Mužíková, David Woller, Miroslav Kulich, Jiří Švancara, Roman Barták</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 14:23:02</h6>
<p class='card-text'>The goal of Multi-Agent Path Finding (MAPF) is to find a set of paths for a
fleet of agents moving in a shared environment such that the agents reach their
goals without colliding with each other. In practice, some of the robots
executing the plan may get delayed, which can introduce collision risk.
Although robust execution methods are used to ensure safety even in the
presence of delays, the delays may still have a significant impact on the
duration of the execution. At some point, the accumulated delays may become
significant enough that instead of continuing with the execution of the
original plan, even if it was optimal, there may now exist an alternate plan
which will lead to a shorter execution. However, the problem is how to decide
when to search for the alternate plan, since it is a costly procedure. In this
paper, we propose a holistic architecture for robust execution of MAPF plans,
its monitoring and optimization. We exploit a robust execution method called
Action Dependency Graph to maintain an estimate of the expected execution
duration during the plan's execution. This estimate is used to predict the
potential that finding an alternate plan would lead to shorter execution. We
empirically evaluate the architecture in experiments in a real-time simulator
which we designed to mimic our real-life demonstrator of an autonomous
warehouse robotic fleet.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10274v1' target='_blank'>A Differentiable Surrogate Model for the Generation of Radio Pulses from
  In-Ice Neutrino Interactions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Philipp Pilar, Martin Ravn, Christian Glaser, Niklas Wahlström</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 14:17:17</h6>
<p class='card-text'>The planned IceCube-Gen2 radio neutrino detector at the South Pole will
enhance the detection of cosmic ultra-high-energy neutrinos. It is crucial to
utilize the available time until construction to optimize the detector design.
A fully differentiable pipeline, from signal generation to detector response,
would allow for the application of gradient descent techniques to explore the
parameter space of the detector. In our work, we focus on the aspect of signal
generation, and propose a modularized deep learning architecture to generate
radio signals from in-ice neutrino interactions conditioned on the shower
energy and viewing angle. The model is capable of generating differentiable
signals with amplitudes spanning multiple orders of magnitude, as well as
consistently producing signals corresponding to the same underlying event for
different viewing angles. The modularized approach ensures physical consistency
of the samples and leads to advantageous computational properties when using
the model as part of a bigger optimization pipeline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10162v1' target='_blank'>Online Robust Planning under Model Uncertainty: A Sample-Based Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tamir Shazman, Idan Lev-Yehudi, Ron Benchetit, Vadim Indelman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 11:41:23</h6>
<p class='card-text'>Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10125v1' target='_blank'>Soft Tissue Simulation and Force Estimation from Heterogeneous
  Structures using Equivariant Graph Neural Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Madina Kojanazarova, Sidady El Hadramy, Jack Wilkie, Georg Rauter, Philippe C. Cattin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 10:36:57</h6>
<p class='card-text'>Accurately simulating soft tissue deformation is crucial for surgical
training, pre-operative planning, and real-time haptic feedback systems. While
physics-based models such as the finite element method (FEM) provide
high-fidelity results, they are often computationally expensive and require
extensive preprocessing. We propose a graph neural network (GNN) architecture
that predicts both tissue surface deformation and applied force from sparse
point clouds. The model incorporates internal anatomical information through
binary tissue profiles beneath each point and leverages E(n)-equivariant
message passing to improve robustness. We collected experimental data that
comprises a real silicone and bone-like phantom, and complemented it with
synthetic simulations generated using FEM. Our model achieves a comparable
performance to a baseline GNN on standard test cases and significantly
outperforms it in rotated and cross-resolution scenarios, showing a strong
generalization to unseen orientations and point densities. It also achieves a
significant speed improvement, offering a solution for real-time applications.
When fine-tuned on experimental data, the model maintains sub-millimeter
deformation accuracy despite limited sample size and measurement noise. The
results demonstrate that our approach offers an efficient, data-driven
alternative to traditional simulations, capable of generalizing across
anatomical configurations and supporting interactive surgical environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10083v1' target='_blank'>The Hierarchical Morphotope Classification: A Theory-Driven Framework
  for Large-Scale Analysis of Built Form</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Martin Fleischmann, Krasen Samardzhiev, Anna Brázdová, Daniela Dančejová, Lisa Winkler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 09:19:17</h6>
<p class='card-text'>Built environment, formed of a plethora of patterns of building, streets, and
plots, has a profound impact on how cities are perceived and function. While
various methods exist to classify urban patterns, they often lack a strong
theoretical foundation, are not scalable beyond a local level, or sacrifice
detail for broader application. This paper introduces the Hierarchical
Morphotope Classification (HiMoC), a novel, theory-driven, and computationally
scalable method of classification of built form. HiMoC operationalises the idea
of a morphotope - the smallest locality with a distinctive character - using a
bespoke regionalisation method SA3 (Spatial Agglomerative Adaptive
Aggregation), to delineate contiguous, morphologically distinct localities.
These are further organised into a hierarchical taxonomic tree reflecting their
dissimilarity based on morphometric profile derived from buildings and streets
retrieved from open data, allowing flexible, interpretable classification of
built fabric, that can be applied beyond a scale of a single country. The
method is tested on a subset of countries of Central Europe, grouping over 90
million building footprints into over 500,000 morphotopes. The method extends
the capabilities of available morphometric analyses, while offering a
complementary perspective to existing large scale data products, which are
focusing primarily on land use or use conceptual definition of urban fabric
types. This theory-grounded, reproducible, unsupervised and scalable method
facilitates a nuanced understanding of urban structure, with broad applications
in urban planning, environmental analysis, and socio-spatial studies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10077v1' target='_blank'>Predictive Spike Timing Enables Distributed Shortest Path Computation in
  Spiking Neural Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simen Storesund, Kristian Valset Aars, Robin Dietrich, Nicolai Waniek</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 09:13:47</h6>
<p class='card-text'>Efficient planning and sequence selection are central to intelligence, yet
current approaches remain largely incompatible with biological computation.
Classical graph algorithms like Dijkstra's or A* require global state and
biologically implausible operations such as backtracing, while reinforcement
learning methods rely on slow gradient-based policy updates that appear
inconsistent with rapid behavioral adaptation observed in natural systems.
  We propose a biologically plausible algorithm for shortest-path computation
that operates through local spike-based message-passing with realistic
processing delays. The algorithm exploits spike-timing coincidences to identify
nodes on optimal paths: Neurons that receive inhibitory-excitatory message
pairs earlier than predicted reduce their response delays, creating a temporal
compression that propagates backwards from target to source. Through analytical
proof and simulations on random spatial networks, we demonstrate that the
algorithm converges and discovers all shortest paths using purely timing-based
mechanisms. By showing how short-term timing dynamics alone can compute
shortest paths, this work provides new insights into how biological networks
might solve complex computational problems through purely local computation and
relative spike-time prediction. These findings open new directions for
understanding distributed computation in biological and artificial systems,
with possible implications for computational neuroscience, AI, reinforcement
learning, and neuromorphic systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.10075v1' target='_blank'>The Bin Packing Problem with Setups: Formulation, Structural Properties
  and Computational Insights</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Roberto Baldacci, Fabio Ciccarelli, Stefano Conglio, Valerio Dose, Fabio Furini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 09:11:03</h6>
<p class='card-text'>We introduce and study a novel generalization of the classical Bin Packing
Problem (BPP), called the Bin Packing Problem with Setups (BPPS). In this
problem, which has many practical applications in production planning and
logistics, the items are partitioned into classes and, whenever an item from a
given class is packed into a bin, a setup weight and cost are incurred. We
present a natural Integer Linear Programming (ILP) formulation for the BPPS and
analyze the structural properties of its Linear Programming relaxation. We show
that the lower bound provided by the relaxation can be arbitrarily poor in the
worst case. We introduce the Minimum Classes Inequalities (MCIs), which
strengthen the relaxation and restore a worst-case performance guarantee of
1/2, matching that of the classical BPP. In addition, we derive the Minimum
Bins Inequality (MBI) to further reinforce the relaxation, together with an
upper bound on the number of bins in any optimal BPPS solution, which leads to
a significant reduction in the number of variables and constraints of the ILP
formulation. Finally, we establish a comprehensive benchmark of 480 BPPS
instances and conduct extensive computational experiments. The results show
that the integration of MCIs, the MBI, and the upper bound on the number of
bins substantially improves the performance of the ILP formulation in terms of
solution time and number of instances solved to optimality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09922v1' target='_blank'>Robo-Advisors Beyond Automation: Principles and Roadmap for AI-Driven
  Financial Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Runhuan Feng, Hong Li, Ming Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-12 02:06:15</h6>
<p class='card-text'>Artificial intelligence (AI) is transforming financial planning by expanding
access, lowering costs, and enabling dynamic, data-driven advice. Yet without
clear safeguards, digital platforms risk reproducing longstanding market
inefficiencies such as information asymmetry, misaligned incentives, and
systemic fragility. This paper develops a framework for responsible AI in
financial planning, anchored in five principles: fiduciary duty, adaptive
personalization, technical robustness, ethical and fairness constraints, and
auditability. We illustrate these risks and opportunities through case studies,
and extend the framework into a five-level roadmap of AI financial
intermediaries. By linking technological design to economic theory, we show how
AI can either amplify vulnerabilities or create more resilient, trustworthy
forms of financial intermediation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09780v1' target='_blank'>Progress toward a demonstration of high contrast imaging at ultraviolet
  wavelengths</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kyle Van Gorkom, Ramya M. Anche, Christopher B. Mendillo, Jessica Gersh-Range, G. C. Hathaway, Saraswathi Kalyani Subramanian, Justin Hom, Tyler D. Robinson, Mamadou N'Diaye, Nikole K. Lewis, Bruce Macintosh, Ewan S. Douglas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 18:24:24</h6>
<p class='card-text'>NASA's Habitable Worlds Observatory (HWO) aims to achieve starlight
suppression to the $10^{-10}$ level for the detection and spectral
characterization of Earth-like exoplanets. Broadband ozone absorption features
are key biosignatures that appear in the 200-400nm near-ultraviolet (UV)
regime. Extending coronagraphy from visible wavelengths to the UV, however,
brings with it a number of challenges, including tighter requirements on
wavefront sensing and control, optical surface quality, scattered light, and
polarization aberrations, among other things. We aim to partially quantify and
address these challenges with a combination of modeling, high-resolution
metrology to the scales required for UV coronagraphy, and ultimately a
demonstration of UV coronagraphy on the Space Coronagraph Optical Bench (SCoOB)
vacuum testbed. In these proceedings, we provide a status update on our
modeling and contrast budgeting efforts, characterization efforts to understand
performance limitations set by key optical components, and our plans to move
toward a demonstration of UV coronagraphy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09674v1' target='_blank'>SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haozhan Li, Yuxin Zuo, Jiale Yu, Yuhao Zhang, Zhaohui Yang, Kaiyan Zhang, Xuekai Zhu, Yuchen Zhang, Tianxing Chen, Ganqu Cui, Dehui Wang, Dingxiang Luo, Yuchen Fan, Youbang Sun, Jia Zeng, Jiangmiao Pang, Shanghang Zhang, Yu Wang, Yao Mu, Bowen Zhou, Ning Ding</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 17:59:17</h6>
<p class='card-text'>Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipulation. Despite substantial progress enabled by
large-scale pretraining and supervised fine-tuning (SFT), these models face two
fundamental challenges: (i) the scarcity and high cost of large-scale
human-operated robotic trajectories required for SFT scaling, and (ii) limited
generalization to tasks involving distribution shift. Recent breakthroughs in
Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can
dramatically enhance step-by-step reasoning capabilities, raising a natural
question: Can RL similarly improve the long-horizon step-by-step action
planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL
framework tailored for VLA models. Building upon veRL, we introduce
VLA-specific trajectory sampling, scalable parallelization, multi-environment
rendering, and optimized loss computation. When applied to OpenVLA-OFT,
SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$
on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce.
SimpleVLA-RL not only reduces dependence on large-scale data and enables robust
generalization, but also remarkably surpasses SFT in real-world tasks.
Moreover, we identify a novel phenomenon ``pushcut'' during RL training,
wherein the policy discovers previously unseen patterns beyond those seen in
the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09637v1' target='_blank'>A neural drift-plus-penalty algorithm for network power allocation and
  routing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ahmed Rashwan, Keith Briggs, Chris Budd</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 17:23:47</h6>
<p class='card-text'>The drift-plus-penalty method is a Lyapunov optimisation technique commonly
applied to network routing problems. It reduces the original stochastic
planning task to a sequence of greedy optimizations, enabling the design of
distributed routing algorithms which stabilize data queues while simultaneously
optimizing a specified penalty function. While drift-plus-penalty methods have
desirable asymptotic properties, they tend to incur higher network delay than
alternative control methods, especially under light network load. In this work,
we propose a learned variant of the drift-plus-penalty method that can preserve
its theoretical guarantees, while being flexible enough to learn routing
strategies directly from a model of the problem. Our approach introduces a
novel mechanism for learning routing decisions and employs an optimal
transport-based method for link scheduling. Applied to the joint task of
transmit-power allocation and data routing, the method achieves consistent
improvements over common baselines under a broad set of scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09594v1' target='_blank'>ObjectReact: Learning Object-Relative Control for Visual Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sourav Garg, Dustin Craggs, Vineeth Bhat, Lachlan Mares, Stefan Podgorski, Madhava Krishna, Feras Dayoub, Ian Reid</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 16:34:17</h6>
<p class='card-text'>Visual navigation using only a single camera and a topological map has
recently become an appealing alternative to methods that require additional
sensors and 3D maps. This is typically achieved through an "image-relative"
approach to estimating control from a given pair of current observation and
subgoal image. However, image-level representations of the world have
limitations because images are strictly tied to the agent's pose and
embodiment. In contrast, objects, being a property of the map, offer an
embodiment- and trajectory-invariant world representation. In this work, we
present a new paradigm of learning "object-relative" control that exhibits
several desirable characteristics: a) new routes can be traversed without
strictly requiring to imitate prior experience, b) the control prediction
problem can be decoupled from solving the image matching problem, and c) high
invariance can be achieved in cross-embodiment deployment for variations across
both training-testing and mapping-execution settings. We propose a topometric
map representation in the form of a "relative" 3D scene graph, which is used to
obtain more informative object-level global path planning costs. We train a
local controller, dubbed "ObjectReact", conditioned directly on a high-level
"WayObject Costmap" representation that eliminates the need for an explicit RGB
input. We demonstrate the advantages of learning object-relative control over
its image-relative counterpart across sensor height variations and multiple
navigation tasks that challenge the underlying spatial understanding
capability, e.g., navigating a map trajectory in the reverse direction. We
further show that our sim-only policy is able to generalize well to real-world
indoor environments. Code and supplementary material are accessible via project
page: https://object-react.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09575v1' target='_blank'>Deep learning-based prediction of Precipitable Water Vapor in the
  Chajnantor area</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alison Matus-Bello, Silvia E. Restrepo, Ricardo Bustos, Yi Hu, Fujia Du, Jaime Cariñe, Pablo García, Rodrigo Reeves, Zhaohui Shang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 16:11:09</h6>
<p class='card-text'>Astronomical observations at millimeter and submillimeter wavelengths heavily
depend on the amount of Precipitable Water Vapor (PWV) in the atmosphere,
directly affecting the sky transparency and degrading the quality of the
signals received by radio telescopes. Predictions of PWV at different
forecasting horizons is crucial to support telescope operations, engineering
planning, and observational scheduling and efficiency of radio observatories
installed in the Chajnantor area in northern Chile. We developed and validated
a Long Short-Term Memory (LSTM) deep learning-based model to predict PWV at
forecasting horizons of 12, 24, 36, and 48 hours using historical data from two
183 GHz radiometers and a weather station in the Chajnantor area. We find the
LSTM method is able to predict PWV in the 12 and 24 hours forecasting horizons
with Mean Absolute Percentage Error (MAPE) of 22% compared to 36% of the
traditional Global Forecast System (GFS) method used by Atacama Pathfinder
EXperiment (APEX) and the Root Mean Square Error (RMSE) in mm are reduced by
50%. We present a first application of deep learning techniques for preliminary
predictions of PWV in the Chajnantor area. The prediction performance shows
significant improvements to traditional methods in 12 and 24 hours time
windows. We also propose upgrades to improve our method in short (< 1 hour) and
long (> 36 hours) forecasting timescales for future work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09556v1' target='_blank'>A Hybrid Analytical Framework for Asymmetric Pressure and Boundary Layer
  Wind Simulation in Nor'easters</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seyedeh Fatemeh Mirfakhar, Reda Snaiki, Frank Lombardo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 15:45:44</h6>
<p class='card-text'>Nor'easters frequently impact the North American East Coast, bringing
hazardous precipitation, winds, and coastal flooding. Accurate simulation of
their pressure and wind fields is essential for forecasting, risk assessment,
and infrastructure planning, yet remains challenging due to their complex,
asymmetric structure. This study introduces a novel hybrid
analytical-data-driven model designed to efficiently simulate Nor'easter
pressure and boundary layer wind fields. The pressure field is modeled using an
adapted Holland-type formulation, with azimuthally varying parameters estimated
through Kriging surrogate models informed by sensitivity analysis of reanalysis
data. The wind field is then derived analytically from the momentum equations
by decomposing the wind flow into gradient and frictional components. Model
performance is assessed against ERA-Interim reanalysis data and surface wind
observations from a historical event. Results show that the proposed pressure
model accurately reproduces elliptical isobars and key asymmetrical patterns,
while the wind model captures the fundamental structure and intensity of the
boundary layer flow, including the presence of supergradient winds. Owing to
its physical basis, computational efficiency, and ability to represent critical
storm asymmetries, the model offers a valuable alternative to computationally
expensive numerical simulations for hazard assessment and scenario analysis of
extreme Nor'easters.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09514v1' target='_blank'>Mapping of discrete range modulated proton radiograph to
  water-equivalent path length using machine learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Atiq Ur Rahman, Chun-Chieh Wang, Shu-Wei Wu, Tsi-Chian Chao, I-Chun Cho</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 14:55:55</h6>
<p class='card-text'>Objective. Proton beams enable localized dose delivery. Accurate range
estimation is essential, but planning still relies on X-ray CT, which
introduces uncertainty in stopping power and range. Proton CT measures water
equivalent thickness directly but suffers resolution loss from multiple Coulomb
scattering. We develop a data driven method that reconstructs water equivalent
path length (WEPL) maps from energy resolved proton radiographs, bypassing
intermediate reconstructions. Approach. We present a machine learning pipeline
for WEPL from high dimensional radiographs. Data were generated with the TOPAS
Monte Carlo toolkit, modeling a clinical nozzle and a patient CT. Proton
energies spanned 70-230 MeV across 72 projection angles. Principal component
analysis reduced input dimensionality while preserving signal. A conditional
GAN with gradient penalty was trained for WEPL prediction using a composite
loss (adversarial, MSE, SSIM, perceptual) to balance sharpness, accuracy, and
stability. Main results. The model reached a mean relative WEPL deviation of
2.5 percent, an SSIM of 0.97, and a proton radiography gamma index passing rate
of 97.1 percent (2 percent delta WEPL, 3 mm distance-to-agreement) on a
simulated head phantom. Results indicate high spatial fidelity and strong
structural agreement. Significance. WEPL can be mapped directly from proton
radiographs with deep learning while avoiding intermediate steps. The method
mitigates limits of analytic techniques and may improve treatment planning.
Future work will tune the number of PCA components, include detector response,
explore low dose settings, and extend multi angle data toward full proton CT
reconstruction; it is compatible with clinical workflows.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09484v1' target='_blank'>BagIt! An Adaptive Dual-Arm Manipulation of Fabric Bags for Object
  Bagging</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peng Zhou, Jiaming Qi, Hongmin Wu, Chen Wang, Yizhou Chen, Zeqing Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 14:15:20</h6>
<p class='card-text'>Bagging tasks, commonly found in industrial scenarios, are challenging
considering deformable bags' complicated and unpredictable nature. This paper
presents an automated bagging system from the proposed adaptive
Structure-of-Interest (SOI) manipulation strategy for dual robot arms. The
system dynamically adjusts its actions based on real-time visual feedback,
removing the need for pre-existing knowledge of bag properties. Our framework
incorporates Gaussian Mixture Models (GMM) for estimating SOI states,
optimization techniques for SOI generation, motion planning via Constrained
Bidirectional Rapidly-exploring Random Tree (CBiRRT), and dual-arm coordination
using Model Predictive Control (MPC). Extensive experiments validate the
capability of our system to perform precise and robust bagging across various
objects, showcasing its adaptability. This work offers a new solution for
robotic deformable object manipulation (DOM), particularly in automated bagging
tasks. Video of this work is available at https://youtu.be/6JWjCOeTGiQ.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09469v1' target='_blank'>Resource-Efficient Glioma Segmentation on Sub-Saharan MRI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Freedmore Sidume, Oumayma Soula, Joseph Muthui Wacira, YunFei Zhu, Abbas Rabiu Muhammad, Abderrazek Zeraii, Oluwaseun Kalejaye, Hajer Ibrahim, Olfa Gaddour, Brain Halubanza, Dong Zhang, Udunna C Anazodo, Confidence Raymond</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 13:52:47</h6>
<p class='card-text'>Gliomas are the most prevalent type of primary brain tumors, and their
accurate segmentation from MRI is critical for diagnosis, treatment planning,
and longitudinal monitoring. However, the scarcity of high-quality annotated
imaging data in Sub-Saharan Africa (SSA) poses a significant challenge for
deploying advanced segmentation models in clinical workflows. This study
introduces a robust and computationally efficient deep learning framework
tailored for resource-constrained settings. We leveraged a 3D Attention UNet
architecture augmented with residual blocks and enhanced through transfer
learning from pre-trained weights on the BraTS 2021 dataset. Our model was
evaluated on 95 MRI cases from the BraTS-Africa dataset, a benchmark for glioma
segmentation in SSA MRI data. Despite the limited data quality and quantity,
our approach achieved Dice scores of 0.76 for the Enhancing Tumor (ET), 0.80
for Necrotic and Non-Enhancing Tumor Core (NETC), and 0.85 for Surrounding
Non-Functional Hemisphere (SNFH). These results demonstrate the
generalizability of the proposed model and its potential to support clinical
decision making in low-resource settings. The compact architecture,
approximately 90 MB, and sub-minute per-volume inference time on consumer-grade
hardware further underscore its practicality for deployment in SSA health
systems. This work contributes toward closing the gap in equitable AI for
global health by empowering underserved regions with high-performing and
accessible medical imaging solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09332v2' target='_blank'>OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and
  Embodiment-aware Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuecheng Liu, Dafeng Chi, Shiguang Wu, Zhanguang Zhang, Yuzheng Zhuang, Bowen Yang, He Zhu, Lingfeng Zhang, Pengwei Xie, David Gamaliel Arcos Bravo, Yingxue Zhang, Jianye Hao, Xingyue Quan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 10:32:22</h6>
<p class='card-text'>Recent advances in multimodal large language models (MLLMs) have opened new
opportunities for embodied intelligence, enabling multimodal understanding,
reasoning, and interaction, as well as continuous spatial decision-making.
Nevertheless, current MLLM-based embodied systems face two critical
limitations. First, Geometric Adaptability Gap: models trained solely on 2D
inputs or with hard-coded 3D geometry injection suffer from either insufficient
spatial information or restricted 2D generalization, leading to poor
adaptability across tasks with diverse spatial demands. Second, Embodiment
Constraint Gap: prior work often neglects the physical constraints and
capacities of real robots, resulting in task plans that are theoretically valid
but practically infeasible. To address these gaps, we introduce OmniEVA -- an
embodied versatile planner that enables advanced embodied reasoning and task
planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding
mechanism, which introduces a gated router to perform explicit selective
regulation of 3D fusion based on contextual requirements, enabling
context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware
Reasoning framework that jointly incorporates task goals and embodiment
constraints into the reasoning loop, resulting in planning decisions that are
both goal-directed and executable. Extensive experimental results demonstrate
that OmniEVA not only achieves state-of-the-art general embodied reasoning
performance, but also exhibits a strong ability across a wide range of
downstream scenarios. Evaluations of a suite of proposed embodied benchmarks,
including both primitive and composite tasks, confirm its robust and versatile
planning capabilities. Project page: https://omnieva.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09325v1' target='_blank'>Swept Volume Computation with Enhanced Geometric Detail Preservation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pengfei Wang, Yuexin Yang, Shuangmin Chen, Shiqing Xin, Changhe Tu, Wenping Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 10:18:34</h6>
<p class='card-text'>Swept volume computation, the determination of regions occupied by moving
objects, is essential in graphics, robotics, and manufacturing. Existing
approaches either explicitly track surfaces, suffering from robustness issues
under complex interactions, or employ implicit representations that trade off
geometric fidelity and face optimization difficulties. We propose a novel
inversion of motion perspective: rather than tracking object motion, we fix the
object and trace spatial points backward in time, reducing complex trajectories
to efficiently linearizable point motions. Based on this, we introduce a multi
field tetrahedral framework that maintains multiple distance fileds per
element, preserving fine geometric details at trajectory intersections where
single field methods fail. Our method robustly computes swept volumes for
diverse motions, including translations and screw motions, and enables
practical applications in path planning and collision detection.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09219v1' target='_blank'>Vejde: A Framework for Inductive Deep Reinforcement Learning Based on
  Factor Graph Color Refinement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jakob Nyberg, Pontus Johnson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 07:51:38</h6>
<p class='card-text'>We present and evaluate Vejde; a framework which combines data abstraction,
graph neural networks and reinforcement learning to produce inductive policy
functions for decision problems with richly structured states, such as object
classes and relations. MDP states are represented as data bases of facts about
entities, and Vejde converts each state to a bipartite graph, which is mapped
to latent states through neural message passing. The factored representation of
both states and actions allows Vejde agents to handle problems of varying size
and structure. We tested Vejde agents on eight problem domains defined in RDDL,
with ten problem instances each, where policies were trained using both
supervised and reinforcement learning. To test policy generalization, we
separate problem instances in two sets, one for training and the other solely
for testing. Test results on unseen instances for the Vejde agents were
compared to MLP agents trained on each problem instance, as well as the online
planning algorithm Prost. Our results show that Vejde policies in average
generalize to the test instances without a significant loss in score.
Additionally, the inductive agents received scores on unseen test instances
that on average were close to the instance-specific MLP agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09210v1' target='_blank'>ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint
  Multi-agent Motion Forecasting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xing Gao, Zherui Huang, Weiyao Lin, Xiao Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 07:36:54</h6>
<p class='card-text'>Accurate motion prediction of surrounding agents is crucial for the safe
planning of autonomous vehicles. Recent advancements have extended prediction
techniques from individual agents to joint predictions of multiple interacting
agents, with various strategies to address complex interactions within future
motions of agents. However, these methods overlook the evolving nature of these
interactions. To address this limitation, we propose a novel progressive
multi-scale decoding strategy, termed ProgD, with the help of dynamic
heterogeneous graph-based scenario modeling. In particular, to explicitly and
comprehensively capture the evolving social interactions in future scenarios,
given their inherent uncertainty, we design a progressive modeling of scenarios
with dynamic heterogeneous graphs. With the unfolding of such dynamic
heterogeneous graphs, a factorized architecture is designed to process the
spatio-temporal dependencies within future scenarios and progressively
eliminate uncertainty in future motions of multiple agents. Furthermore, a
multi-scale decoding procedure is incorporated to improve on the future
scenario modeling and consistent prediction of agents' future motion. The
proposed ProgD achieves state-of-the-art performance on the INTERACTION
multi-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2
multi-world forecasting benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09206v1' target='_blank'>Occupancy-aware Trajectory Planning for Autonomous Valet Parking in
  Uncertain Dynamic Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Farhad Nawaz, Faizan M. Tariq, Sangjae Bae, David Isele, Avinash Singh, Nadia Figueroa, Nikolai Matni, Jovin D'sa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 07:29:19</h6>
<p class='card-text'>Accurately reasoning about future parking spot availability and integrated
planning is critical for enabling safe and efficient autonomous valet parking
in dynamic, uncertain environments. Unlike existing methods that rely solely on
instantaneous observations or static assumptions, we present an approach that
predicts future parking spot occupancy by explicitly distinguishing between
initially vacant and occupied spots, and by leveraging the predicted motion of
dynamic agents. We introduce a probabilistic spot occupancy estimator that
incorporates partial and noisy observations within a limited Field-of-View
(FoV) model and accounts for the evolving uncertainty of unobserved regions.
Coupled with this, we design a strategy planner that adaptively balances
goal-directed parking maneuvers with exploratory navigation based on
information gain, and intelligently incorporates wait-and-go behaviors at
promising spots. Through randomized simulations emulating large parking lots,
we demonstrate that our framework significantly improves parking efficiency,
safety margins, and trajectory smoothness compared to existing approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09074v1' target='_blank'>KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for
  Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alice Kate Li, Thales C Silva, Victoria Edwards, Vijay Kumar, M. Ani Hsieh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-11 00:42:01</h6>
<p class='card-text'>In this work, we propose a novel flow field-based motion planning method that
drives a robot from any initial state to a desired reference trajectory such
that it converges to the trajectory's end point. Despite demonstrated efficacy
in using Koopman operator theory for modeling dynamical systems, Koopman does
not inherently enforce convergence to desired trajectories nor to specified
goals -- a requirement when learning from demonstrations (LfD). We present
KoopMotion which represents motion flow fields as dynamical systems,
parameterized by Koopman Operators to mimic desired trajectories, and leverages
the divergence properties of the learnt flow fields to obtain smooth motion
fields that converge to a desired reference trajectory when a robot is placed
away from the desired trajectory, and tracks the trajectory until the end
point. To demonstrate the effectiveness of our approach, we show evaluations of
KoopMotion on the LASA human handwriting dataset and a 3D manipulator
end-effector trajectory dataset, including spectral analysis. We also perform
experiments on a physical robot, verifying KoopMotion on a miniature autonomous
surface vehicle operating in a non-static fluid flow environment. Our approach
is highly sample efficient in both space and time, requiring only 3\% of the
LASA dataset to generate dense motion plans. Additionally, KoopMotion provides
a significant improvement over baselines when comparing metrics that measure
spatial and temporal dynamics modeling efficacy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.09058v1' target='_blank'>Optimizing the Variant Calling Pipeline Execution on Human Genomes Using
  GPU-Enabled Machines</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ajay Kumar, Praveen Rao, Peter Sanders</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-10 23:40:54</h6>
<p class='card-text'>Variant calling is the first step in analyzing a human genome and aims to
detect variants in an individual's genome compared to a reference genome. Due
to the computationally-intensive nature of variant calling, genomic data are
increasingly processed in cloud environments as large amounts of compute and
storage resources can be acquired with the pay-as-you-go pricing model. In this
paper, we address the problem of efficiently executing a variant calling
pipeline for a workload of human genomes on graphics processing unit
(GPU)-enabled machines. We propose a novel machine learning (ML)-based approach
for optimizing the workload execution to minimize the total execution time. Our
approach encompasses two key techniques: The first technique employs ML to
predict the execution times of different stages in a variant calling pipeline
based on the characteristics of a genome sequence. Using the predicted times,
the second technique generates optimal execution plans for the machines by
drawing inspiration from the flexible job shop scheduling problem. The plans
are executed via careful synchronization across different machines. We
evaluated our approach on a workload of publicly available genome sequences
using a testbed with different types of GPU hardware. We observed that our
approach was effective in predicting the execution times of variant calling
pipeline stages using ML on features such as sequence size, read quality,
percentage of duplicate reads, and average read length. In addition, our
approach achieved 2X speedup (on an average) over a greedy approach that also
used ML for predicting the execution times on the tested workload of sequences.
Finally, our approach achieved 1.6X speedup (on an average) over a dynamic
approach that executed the workload based on availability of resources without
using any ML-based time predictions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.08976v1' target='_blank'>Toward a Multi-Echelon Cyber Warfare Theory: A Meta-Game-Theoretic
  Paradigm for Defense and Dominance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ya-Ting Yang, Quanyan Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-10 20:20:12</h6>
<p class='card-text'>Cyber warfare has become a central element of modern conflict, especially
within multi-domain operations. As both a distinct and critical domain, cyber
warfare requires integrating defensive and offensive technologies into coherent
strategies. While prior research has emphasized isolated tactics or fragmented
technologies, a holistic understanding is essential for effective resource
deployment and risk mitigation. Game theory offers a unifying framework for
this purpose. It not only models attacker-defender interactions but also
provides quantitative tools for equilibrium analysis, risk assessment, and
strategic reasoning. Integrated with modern AI techniques, game-theoretic
models enable the design and optimization of strategies across multiple levels
of cyber warfare, from policy and strategy to operations, tactics, and
technical implementations. These models capture the paradoxical logic of
conflict, where more resources do not always translate into greater advantage,
and where nonlinear dynamics govern outcomes. To illustrate the approach, this
chapter examines RedCyber, a synthetic cyber conflict, demonstrating how
game-theoretic methods capture the interdependencies of cyber operations. The
chapter concludes with directions for future research on resilience,
cros-echelon planning, and the evolving role of AI in cyber warfare.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>