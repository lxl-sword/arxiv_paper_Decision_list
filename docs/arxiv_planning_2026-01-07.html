<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2026-01-07</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2026-01-07</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.03250v1' target='_blank'>A Versatile Multimodal Agent for Multimedia Content Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daoan Zhang, Wenlin Yao, Xiaoyang Wang, Yebowen Hu, Jiebo Luo, Dong Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 18:49:47</h6>
<p class='card-text'>With the advancement of AIGC (AI-generated content) technologies, an increasing number of generative models are revolutionizing fields such as video editing, music generation, and even film production. However, due to the limitations of current AIGC models, most models can only serve as individual components within specific application scenarios and are not capable of completing tasks end-to-end in real-world applications. In real-world applications, editing experts often work with a wide variety of images and video inputs, producing multimodal outputs -- a video typically includes audio, text, and other elements. This level of integration across multiple modalities is something current models are unable to achieve effectively. However, the rise of agent-based systems has made it possible to use AI tools to tackle complex content generation tasks. To deal with the complex scenarios, in this paper, we propose a MultiMedia-Agent designed to automate complex content creation. Our agent system includes a data generation pipeline, a tool library for content creation, and a set of metrics for evaluating preference alignment. Notably, we introduce the skill acquisition theory to model the training data curation and agent training. We designed a two-stage correlation strategy for plan optimization, including self-correlation and model preference correlation. Additionally, we utilized the generated plans to train the MultiMedia-Agent via a three stage approach including base/success plan finetune and preference optimization. The comparison results demonstrate that the our approaches are effective and the MultiMedia-Agent can generate better multimedia content compared to novel models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.03200v1' target='_blank'>A High-Fidelity Digital Twin for Robotic Manipulation Based on 3D Gaussian Splatting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziyang Sun, Lingfan Bao, Tianhu Peng, Jingcheng Sun, Chengxu Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 17:29:10</h6>
<p class='card-text'>Developing high-fidelity, interactive digital twins is crucial for enabling closed-loop motion planning and reliable real-world robot execution, which are essential to advancing sim-to-real transfer. However, existing approaches often suffer from slow reconstruction, limited visual fidelity, and difficulties in converting photorealistic models into planning-ready collision geometry. We present a practical framework that constructs high-quality digital twins within minutes from sparse RGB inputs. Our system employs 3D Gaussian Splatting (3DGS) for fast, photorealistic reconstruction as a unified scene representation. We enhance 3DGS with visibility-aware semantic fusion for accurate 3D labelling and introduce an efficient, filter-based geometry conversion method to produce collision-ready models seamlessly integrated with a Unity-ROS2-MoveIt physics engine. In experiments with a Franka Emika Panda robot performing pick-and-place tasks, we demonstrate that this enhanced geometric accuracy effectively supports robust manipulation in real-world trials. These results demonstrate that 3DGS-based digital twins, enriched with semantic and geometric consistency, offer a fast, reliable, and scalable path from perception to manipulation in unstructured environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.03182v1' target='_blank'>Subjective-Objective Median-based Importance Technique (SOMIT) to Aid Multi-Criteria Renewable Energy Evaluation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ding Ding, Yang Li, Poh Ling Neo, Zhiyuan Wang, Chongwu Xia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 17:02:13</h6>
<p class='card-text'>Accelerating the renewable energy transition requires informed decision-making that accounts for the diverse financial, technical, environmental, and social trade-offs across different renewable energy technologies. A critical step in this multi-criteria decision-making (MCDM) process is the determination of appropriate criteria weights. However, deriving these weights often solely involves either subjective assessment from decision-makers or objective weighting methods, each of which has limitations in terms of cognitive burden, potential bias, and insufficient contextual relevance. This study proposes the subjective-objective median-based importance technique (SOMIT), a novel hybrid approach for determining criteria weights in MCDM. By tailoring SOMIT to renewable energy evaluation, the method directly supports applied energy system planning, policy analysis, and technology prioritization under carbon neutrality goals. The practical utility of SOMIT is demonstrated through two MCDM case studies on renewable energy decision-making in India and Saudi Arabia. Using the derived weights from SOMIT, the TOPSIS method ranks the renewable energy alternatives, with solar power achieving the highest performance scores in both cases. The main contributions of this work are five-fold: 1) the proposed SOMIT reduces the number of required subjective comparisons from the conventional quadratic order to a linear order; 2) SOMIT is more robust to outliers in the alternatives-criteria matrix (ACM); 3) SOMIT balances subjective expert knowledge with objective data-driven insights, thereby mitigating bias; 4) SOMIT is inherently modular, allowing both its individual parts and the complete approach to be seamlessly coupled with a wide range of MCDM methods commonly applied in energy systems and policy analysis; 5) a dedicated Python library, pysomit, is developed for SOMIT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.03127v1' target='_blank'>Unified Thinker: A General Reasoning Modular Core for Image Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sashuai Zhou, Qiang Zhou, Jijin Hu, Hanqing Yang, Yue Cao, Junpeng Ma, Yinchao Ma, Jun Song, Tiezheng Ge, Cheng Yu, Bo Zheng, Zhou Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 15:59:33</h6>
<p class='card-text'>Despite impressive progress in high-fidelity image synthesis, generative models still struggle with logic-intensive instruction following, exposing a persistent reasoning--execution gap. Meanwhile, closed-source systems (e.g., Nano Banana) have demonstrated strong reasoning-driven image generation, highlighting a substantial gap to current open-source models. We argue that closing this gap requires not merely better visual generators, but executable reasoning: decomposing high-level intents into grounded, verifiable plans that directly steer the generative process. To this end, we propose Unified Thinker, a task-agnostic reasoning architecture for general image generation, designed as a unified planning core that can plug into diverse generators and workflows. Unified Thinker decouples a dedicated Thinker from the image Generator, enabling modular upgrades of reasoning without retraining the entire generative model. We further introduce a two-stage training paradigm: we first build a structured planning interface for the Thinker, then apply reinforcement learning to ground its policy in pixel-level feedback, encouraging plans that optimize visual correctness over textual plausibility. Extensive experiments on text-to-image generation and image editing show that Unified Thinker substantially improves image reasoning and generation quality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.03075v1' target='_blank'>Fast Surrogate Models for Adaptive Aircraft Trajectory Prediction in En route Airspace</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nick Pepper, Marc Thomas, Zack Xuereb Conti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 15:00:47</h6>
<p class='card-text'>Trajectory prediction (TP) is crucial for ensuring safety and efficiency in modern air traffic management systems. It is, for example, a core component of conflict detection and resolution tools, arrival sequencing algorithms, capacity planning, as well as several future concepts. However, TP accuracy within operational systems is hampered by a range of epistemic uncertainties such as the mass and performance settings of aircraft and the effect of meteorological conditions on aircraft performance. It can also require considerable computational resources.
  This paper proposes a method for adaptive TP that has two components: first, a fast surrogate TP model based on linear state space models (LSSM)s with an execution time that was 6.7 times lower on average than an implementation of the Base of Aircraft Data (BADA) in Python. It is demonstrated that such models can effectively emulate the BADA aircraft performance model, which is based on the numerical solution of a partial differential equation (PDE), and that the LSSMs can be fitted to trajectories in a dataset of historic flight data. Secondly, the paper proposes an algorithm to assimilate radar observations using particle filtering to adaptively refine TP accuracy. Comparison with baselines using BADA and Kalman filtering demonstrate that the proposed framework improves system identification and state estimation for both climb and descent phases, with 46.3% and 64.7% better estimates for time to top of climb and bottom of descent compared to the best performing benchmark model. In particular, the particle filtering approach provides the flexibility to capture non-linear performance effects including the CAS-Mach transition.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.03037v1' target='_blank'>A Bi-directional Adaptive Framework for Agile UAV Landing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chunhui Zhao, Xirui Kao, Yilin Lu, Yang Lyu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 14:10:06</h6>
<p class='card-text'>Autonomous landing on mobile platforms is crucial for extending quadcopter operational flexibility, yet conventional methods are often too inefficient for highly dynamic scenarios. The core limitation lies in the prevalent ``track-then-descend'' paradigm, which treats the platform as a passive target and forces the quadcopter to perform complex, sequential maneuvers. This paper challenges that paradigm by introducing a bi-directional cooperative landing framework that redefines the roles of the vehicle and the platform. The essential innovation is transforming the problem from a single-agent tracking challenge into a coupled system optimization. Our key insight is that the mobile platform is not merely a target, but an active agent in the landing process. It proactively tilts its surface to create an optimal, stable terminal attitude for the approaching quadcopter. This active cooperation fundamentally breaks the sequential model by parallelizing the alignment and descent phases. Concurrently, the quadcopter's planning pipeline focuses on generating a time-optimal and dynamically feasible trajectory that minimizes energy consumption. This bi-directional coordination allows the system to execute the recovery in an agile manner, characterized by aggressive trajectory tracking and rapid state synchronization within transient windows. The framework's effectiveness, validated in dynamic scenarios, significantly improves the efficiency, precision, and robustness of autonomous quadrotor recovery in complex and time-constrained missions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.03024v1' target='_blank'>SA-ResGS: Self-Augmented Residual 3D Gaussian Splatting for Next Best View Selection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kim Jun-Seong, Tae-Hyun Oh, Eduardo Pérez-Pellitero, Youngkyoon Jang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 13:59:07</h6>
<p class='card-text'>We propose Self-Augmented Residual 3D Gaussian Splatting (SA-ResGS), a novel framework to stabilize uncertainty quantification and enhancing uncertainty-aware supervision in next-best-view (NBV) selection for active scene reconstruction. SA-ResGS improves both the reliability of uncertainty estimates and their effectiveness for supervision by generating Self-Augmented point clouds (SA-Points) via triangulation between a training view and a rasterized extrapolated view, enabling efficient scene coverage estimation. While improving scene coverage through physically guided view selection, SA-ResGS also addresses the challenge of under-supervised Gaussians, exacerbated by sparse and wide-baseline views, by introducing the first residual learning strategy tailored for 3D Gaussian Splatting. This targeted supervision enhances gradient flow in high-uncertainty Gaussians by combining uncertainty-driven filtering with dropout- and hard-negative-mining-inspired sampling. Our contributions are threefold: (1) a physically grounded view selection strategy that promotes efficient and uniform scene coverage; (2) an uncertainty-aware residual supervision scheme that amplifies learning signals for weakly contributing Gaussians, improving training stability and uncertainty estimation across scenes with diverse camera distributions; (3) an implicit unbiasing of uncertainty quantification as a consequence of constrained view selection and residual supervision, which together mitigate conflicting effects of wide-baseline exploration and sparse-view ambiguity in NBV planning. Experiments on active view selection demonstrate that SA-ResGS outperforms state-of-the-art baselines in both reconstruction quality and view selection robustness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02889v1' target='_blank'>Probing ionized bubbles around luminous sources during reionization with SKA 21-cm observations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arnab Mishra, Kanan Kumar Datta, Chandra Shekhar Murmu, Samir Choudhuri, Iffat Nasreen, Snehasish Saha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 10:23:37</h6>
<p class='card-text'>Detecting and characterizing individual ionized bubbles during the Epoch of Reionization (EoR) using the redshifted HI 21-cm signal provides a direct probe of the early ionizing sources and the intergalactic medium. We develop and validate a computationally efficient estimator that operates on gridded visibilities to detect ionized bubbles. This serves as an accurate alternative to the more computationally demanding bare estimator that uses all baselines and frequency channels. Further, we employ a non-parametric foreground-subtraction method based on Gaussian process regression, which minimizes loss of the HI 21-cm signal and yields improved signal-to-noise ratios. Our analysis indicates that ionized bubbles at redshifts $z \sim 7 - 8$ can be detected with SNR $\gtrsim 10$ using $\sim 100$ hours of SKA1-Low AA$^*$ and AA4 observations. We further derive a scaling relation that connects the SNR to the bubble radius, redshift, total observing time, and the mean neutral hydrogen fraction of the surrounding IGM. This helps to quickly predict the observational outcome for any planned observations and is, therefore, useful for devising observational strategies. Finally, we apply a Bayesian likelihood framework with Markov Chain Monte Carlo sampling to the residual visibilities to recover ionized bubble properties, including radius, position, and the mean neutral fraction. The resulting posterior distributions demonstrate accurate recovery of the bubble parameters. This confirms the feasibility of robustly characterizing individual ionized regions with the SKA1-Low.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02864v1' target='_blank'>Lesion Segmentation in FDG-PET/CT Using Swin Transformer U-Net 3D: A Robust Deep Learning Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shovini Guha, Dwaipayan Nandi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 09:52:00</h6>
<p class='card-text'>Accurate and automated lesion segmentation in Positron Emission Tomography / Computed Tomography (PET/CT) imaging is essential for cancer diagnosis and therapy planning. This paper presents a Swin Transformer UNet 3D (SwinUNet3D) framework for lesion segmentation in Fluorodeoxyglucose Positron Emission Tomography / Computed Tomography (FDG-PET/CT) scans. By combining shifted window self-attention with U-Net style skip connections, the model captures both global context and fine anatomical detail. We evaluate SwinUNet3D on the AutoPET III FDG dataset and compare it against a baseline 3D U-Net. Results show that SwinUNet3D achieves a Dice score of 0.88 and IoU of 0.78, surpassing 3D U-Net (Dice 0.48, IoU 0.32) while also delivering faster inference times. Qualitative analysis demonstrates improved detection of small and irregular lesions, reduced false positives, and more accurate PET/CT fusion. While the framework is currently limited to FDG scans and trained under modest GPU resources, it establishes a strong foundation for future multi-tracer, multi-center evaluations and benchmarking against other transformer-based architectures. Overall, SwinUNet3D represents an efficient and robust approach to PET/CT lesion segmentation, advancing the integration of transformer-based models into oncology imaging workflows.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02856v1' target='_blank'>Electricity Price Forecasting: Bridging Linear Models, Neural Networks and Online Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Btissame El Mahtout, Florian Ziel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 09:35:02</h6>
<p class='card-text'>Precise day-ahead forecasts for electricity prices are crucial to ensure efficient portfolio management, support strategic decision-making for power plant operations, enable efficient battery storage optimization, and facilitate demand response planning. However, developing an accurate prediction model is highly challenging in an uncertain and volatile market environment. For instance, although linear models generally exhibit competitive performance in predicting electricity prices with minimal computational requirements, they fail to capture relevant nonlinear relationships. Nonlinear models, on the other hand, can improve forecasting accuracy with a surge in computational costs. We propose a novel multivariate neural network approach that combines linear and nonlinear feed-forward neural structures. Unlike previous hybrid models, our approach integrates online learning and forecast combination for efficient training and accuracy improvement. It also incorporates all relevant characteristics, particularly the fundamental relationships arising from wind and solar generation, electricity demand patterns, related energy fuel and carbon markets, in addition to autoregressive dynamics and calendar effects. Compared to the current state-of-the-art benchmark models, the proposed forecasting method significantly reduces computational cost while delivering superior forecasting accuracy (12-13% RMSE and 15-18% MAE reductions). Our results are derived from a six-year forecasting study conducted on major European electricity markets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02850v1' target='_blank'>Sample-Efficient Neurosymbolic Deep Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Celeste Veronese, Daniele Meli, Alessandro Farinelli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 09:28:53</h6>
<p class='card-text'>Reinforcement Learning (RL) is a well-established framework for sequential decision-making in complex environments. However, state-of-the-art Deep RL (DRL) algorithms typically require large training datasets and often struggle to generalize beyond small-scale training scenarios, even within standard benchmarks. We propose a neuro-symbolic DRL approach that integrates background symbolic knowledge to improve sample efficiency and generalization to more challenging, unseen tasks. Partial policies defined for simple domain instances, where high performance is easily attained, are transferred as useful priors to accelerate learning in more complex settings and avoid tuning DRL parameters from scratch. To do so, partial policies are represented as logical rules, and online reasoning is performed to guide the training process through two mechanisms: (i) biasing the action distribution during exploration, and (ii) rescaling Q-values during exploitation. This neuro-symbolic integration enhances interpretability and trustworthiness while accelerating convergence, particularly in sparse-reward environments and tasks with long planning horizons. We empirically validate our methodology on challenging variants of gridworld environments, both in the fully observable and partially observable setting. We show improved performance over a state-of-the-art reward machine baseline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02812v1' target='_blank'>Beyond Sgr A* and M87*: Sub-Microarcsecond Black Hole Shadow Detection via Lunar-based Extremely Long Baseline Interferometry</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shan-Shan Zhao, Ru-Sen Lu, Lei Liu, Zhiqiang Shen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 08:40:25</h6>
<p class='card-text'>The 1.3 mm ground-based very long baseline interferometry (VLBI) array, the Event Horizon Telescope (EHT), is limited by the Earth's diameter and can image the supermassive black hole (SMBH) shadows of only M87* and Sgr A*. Extending the array with an assumed lunar-based telescope could achieve $\sim 0.85\ μ$as angular resolution at 230 GHz, enabling black hole shadow detection for a larger SMBH sample. The concept is motivated by space VLBI missions and lunar exploration, including the ongoing Lunar Orbit VLBI Experiment (LOVEX) aboard QueQiao-2 (Chang'E-7) and the planned International Lunar Research Station (ILRS). We assess shadow detectability for 31 SMBH with predicted large angular sizes, exploring different telescope location and antenna size. Assuming a telescope at the lunar antipode, we simulate the Moon-Earth (u,v) coverage and show that source geometry relative to the Moon's orbit determines whether the primary indicator of shadow, first visibility null, can be sampled. Using a geometric ring model, we identify six high-priority targets: M104, NGC 524, PGC 049940, NGC 5077, NGC 5252, and NGC 1052. Shadows of M104, NGC 5077, and NGC 1052 are detectable with a 5 m lunar-based telescope; PGC 049940 requires 20 m; NGC 524 and NGC 5252 require 100 m. Photon ring detection for Sgr A*, M87*, NGC 1600, and M31 is possible if space telescopes fill the baseline coverage gaps and sensitivity requirements are met. These results provide a clear scientific and technical motivation for lunar-based telescopes in future black hole shadow studies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02779v1' target='_blank'>Hierarchical Preemptive Holistic Collaborative Systems for Embodied Multi-Agent Systems: Framework, Hybrid Stability, and Scalability Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ting Peng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 07:31:04</h6>
<p class='card-text'>The coordination of Embodied Multi-Agent Systems in constrained physical environments requires a rigorous balance between safety, scalability, and efficiency. Traditional decentralized approaches, e.g., reactive collision avoidance, are prone to local minima or reciprocal yielding standoffs due to the lack of future intent awareness. In contrast, centralized planning suffers from intractable computational complexity and single-point-of-failure vulnerabilities. To address these limitations, we propose the Hierarchical Preemptive Holistic Collaborative (Prollect) framework, which generalizes the Preemptive Holistic Collaborative System (PHCS) by decomposing the global coordination problem into topologically connected subspace optimizations. We formalize the system as a Hybrid Automaton and introduce a three-stage receding horizon mechanism (frozen execution, preliminary planning, proactive look-ahead windows) with explicit padding to prevent races between coordination dissemination and intent updates. Notably, we design a robust timing protocol with a mandatory Idle Buffer that acts as a dwell-time constraint to eliminate Zeno behaviors and ensure computational stability under jitter. Furthermore, we formalize a Shadow Agent protocol to guarantee seamless trajectory consistency across subspace boundaries, which we treat as an Input-to-State Stability (ISS) problem.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02645v1' target='_blank'>Making Infeasible Tasks Feasible: Planning to Reconfigure Disconnected 3D Environments with Movable Objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Samarth Kalluraya, Yiannis Kantaros</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-06 01:36:09</h6>
<p class='card-text'>Several planners have been developed to compute dynamically feasible, collision-free robot paths from an initial to a goal configuration. A key assumption in these works is that the goal region is reachable; an assumption that often fails in practice when environments are disconnected. Motivated by this limitation, we consider known 3D environments comprising objects, also called blocks, that form distinct navigable support surfaces (planes), and that are either non-movable (e.g., tables) or movable (e.g., boxes). These surfaces may be mutually disconnected due to height differences, holes, or lateral separations. Our focus is on tasks where the robot must reach a goal region residing on an elevated plane that is unreachable. Rather than declaring such tasks infeasible, an effective strategy is to enable the robot to interact with the environment, rearranging movable objects to create new traversable connections; a problem known as Navigation Among Movable Objects (NAMO). Existing NAMO planners typically address 2D environments, where obstacles are pushed aside to clear a path. These methods cannot directly handle the considered 3D setting; in such cases, obstacles must be placed strategically to bridge these physical disconnections. We address this challenge by developing BRiDGE (Block-based Reconfiguration in Disconnected 3D Geometric Environments), a sampling-based planner that incrementally builds trees over robot and object configurations to compute feasible plans specifying which objects to move, where to place them, and in what order, while accounting for a limited number of movable objects. To accelerate planning, we introduce non-uniform sampling strategies. We show that our method is probabilistically complete and we provide extensive numerical and hardware experiments validating its effectiveness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02505v1' target='_blank'>Learning and Optimizing the Efficacy of Spatio-Temporal Task Allocation under Temporal and Resource Constraints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiazhen Liu, Glen Neville, Jinwoo Park, Sonia Chernova, Harish Ravichandar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 19:21:56</h6>
<p class='card-text'>Complex multi-robot missions often require heterogeneous teams to jointly optimize task allocation, scheduling, and path planning to improve team performance under strict constraints. We formalize these complexities into a new class of problems, dubbed Spatio-Temporal Efficacy-optimized Allocation for Multi-robot systems (STEAM). STEAM builds upon trait-based frameworks that model robots using their capabilities (e.g., payload and speed), but goes beyond the typical binary success-failure model by explicitly modeling the efficacy of allocations as trait-efficacy maps. These maps encode how the aggregated capabilities assigned to a task determine performance. Further, STEAM accommodates spatio-temporal constraints, including a user-specified time budget (i.e., maximum makespan). To solve STEAM problems, we contribute a novel algorithm named Efficacy-optimized Incremental Task Allocation Graph Search (E-ITAGS) that simultaneously optimizes task performance and respects time budgets by interleaving task allocation, scheduling, and path planning. Motivated by the fact that trait-efficacy maps are difficult, if not impossible, to specify, E-ITAGS efficiently learns them using a realizability-aware active learning module. Our approach is realizability-aware since it explicitly accounts for the fact that not all combinations of traits are realizable by the robots available during learning. Further, we derive experimentally-validated bounds on E-ITAGS' suboptimality with respect to efficacy. Detailed numerical simulations and experiments using an emergency response domain demonstrate that E-ITAGS generates allocations of higher efficacy compared to baselines, while respecting resource and spatio-temporal constraints. We also show that our active learning approach is sample efficient and establishes a principled tradeoff between data and computational efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02325v1' target='_blank'>A translation of "What is differential geometry: curves and surfaces"</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anton Petrunin, Sergio Zamora Barrera</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 18:16:44</h6>
<p class='card-text'>These notes are designed for those who either plan to work in differential geometry, or at least want to have a good reason not to do it. We discuss smooth curves and surfaces -- the main gate to differential geometry. We focus on the techniques that are absolutely essential for further study, keeping it problem-centered, elementary, visual, and virtually rigorous.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02453v1' target='_blank'>Validation of Satellite Lifetime Predictions at Leonid Space</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Scott Shambaugh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 17:52:33</h6>
<p class='card-text'>We validate Leonid Space's satellite lifetime prediction pipeline through comprehensive backtesting against 934 non-maneuvering satellites that deorbited from LEO between 1961 and 2024. This represents the first large-scale validation of lifetime prediction tooling using forecasted space weather conditions rather than historical hindsight. Our toolchain combines ballistic coefficient estimation from on-orbit data with probabilistic orbit propagation under varying environmental conditions. Using TLE data and space weather records spanning six solar cycles, our three-stage validation approach progressively removes hindsight bias to arrive at fully predictive operational conditions. We achieve 1-year prediction accuracy (median continuously ranked probability score) of 6.0 days (1.6%) under perfect knowledge conditions, 18.6 days (5.1%) with estimated ballistic coefficients and known space weather, and 45.5 days (12.4%) under fully predictive conditions. Comparison against ESA's standard DRAMA & DISCOS toolchain demonstrates a 4x improvement in state-of-the-art accuracy for well-characterized satellites. A custom semianalytic propagator provides a >3500x speedup over Orekit and 4.5x speedup over DRAMA, enabling rapid Monte Carlo analysis across large satellite populations. Our analysis reveals that solar cycle forecasting dominates error budgets after ballistic coefficient estimation, with higher-fidelity propagators and atmosphere models providing marginal benefit. These results establish a validated performance baseline for operational lifetime prediction services supporting LEO mission planning and regulatory compliance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02210v1' target='_blank'>Impact of Spatial Proximity on Drone Services</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vejaykarthy Srithar, Syeda Amna Rizvi, Amani Abusafia, Athman Bouguettaya, Balsam Alkouz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 15:32:21</h6>
<p class='card-text'>We demonstrate the peer-to-peer impact of drones flying in close proximity. Understanding these impacts is crucial for planning efficient drone delivery services. In this regard, we conducted a set of experiments using drones at varying positions in a 3D space under different wind conditions. We collected data on drone energy consumption traveling in a skyway segment. We developed a Graphical User Interface (GUI) that plots drone trajectories within a segment. The GUI facilitates analyzing the peer-to-peer influence of drones on their energy consumption. The analysis includes drones' positions, distance of separation, and wind impact.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02207v1' target='_blank'>Risk-Averse Markov Decision Processes: Applications to Electricity Grid and Reservoir Management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arash Khojaste, Jonathan Pearce, Daniela Pucci de Farias, Geoffrey Pritchard, Golbon Zakeri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 15:31:27</h6>
<p class='card-text'>This paper develops risk-averse models to support system operators in planning and operating the electricity grid under uncertainty from renewable power generation. We incorporate financial risk hedging using conditional value at risk (CVaR) within a Markov Decision Process (MDP) framework and propose efficient, exact solution methods for these models. In addition, we introduce a power reliability-oriented risk measure and present new, computationally efficient models for risk-averse grid planning and operations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02196v1' target='_blank'>ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Li, Sizhe Tang, Rongqian Chen, Fei Xu Yu, Guangyu Jiang, Mahdi Imani, Nathaniel D. Bastian, Tian Lan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 15:18:54</h6>
<p class='card-text'>Automated cyber defense (ACD) seeks to protect computer networks with minimal or no human intervention, reacting to intrusions by taking corrective actions such as isolating hosts, resetting services, deploying decoys, or updating access controls. However, existing approaches for ACD, such as deep reinforcement learning (RL), often face difficult exploration in complex networks with large decision/state spaces and thus require an expensive amount of samples. Inspired by the need to learn sample-efficient defense policies, we frame ACD in CAGE Challenge 4 (CAGE-4 / CC4) as a context-based partially observable Markov decision problem and propose a planning-centric defense policy based on Monte Carlo Tree Search (MCTS). It explicitly models the exploration-exploitation tradeoff in ACD and uses statistical sampling to guide exploration and decision making. We make novel use of graph neural networks (GNNs) to embed observations from the network as attributed graphs, to enable permutation-invariant reasoning over hosts and their relationships. To make our solution practical in complex search spaces, we guide MCTS with learned graph embeddings and priors over graph-edit actions, combining model-free generalization and policy distillation with look-ahead planning. We evaluate the resulting agent on CC4 scenarios involving diverse network structures and adversary behaviors, and show that our search-guided, graph-embedding-based planning improves defense reward and robustness relative to state-of-the-art RL baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02114v1' target='_blank'>AI-Driven Stabilization in Power Grids through Controlling Line Admittances</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sangjoon Park, Hoyun Choi, Yongsun Lee, Seungchan Jo, Jürgen Kurths, B. Kahng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 13:44:01</h6>
<p class='card-text'>The global transition from traditional power plants to renewable energy sources introduces new challenges in grid stability, primarily because inverter-based technologies provide insufficient inertia. To address this, we introduce an artificial intelligence algorithm that autonomously stabilizes power grids by adaptively tuning admittance regulators in response to disturbances. This Adaptive Admittance Controller (AAC) algorithm not only stabilizes the system in real time but also identifies the best regulator locations, thereby unifying grid planning and real time control within a single framework. When tested on a real UK power grid, the AAC markedly reduces frequency deviations and rapidly restores nominal operation. In addition, the algorithm isolates a small number of key regulators and intervenes only on these, lowering both system complexity and cost. The AAC algorithm further reduces the nonlinearity effect, quickly stabilizing the frequency and power flow. This intelligent control scheme enables power grids to reliably return to stable operating conditions under a broad spectrum of fault scenarios. The proposed framework can also be used to mitigate cascading failures by adaptively controlling critical links in a variety of networked infrastructures, such as cascades of traffic congestion on road networks or fuse failures in energy-saving systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02096v1' target='_blank'>Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peizhuo Li, Sebastian Starke, Yuting Ye, Olga Sorkine-Hornung</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 13:24:12</h6>
<p class='card-text'>Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02088v2' target='_blank'>PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiahao Bao, Huazhen Liu, Yu Zhuang, Leran Tao, Xinyu Xu, Yongtao Shi, Mengjia Cheng, Yiming Wang, Congshuang Ku, Ting Zeng, Yilang Du, Siyi Chen, Shunyao Shen, Suncheng Xiang, Hongbo Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 13:14:19</h6>
<p class='card-text'>Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.02046v1' target='_blank'>Agentic Retoucher for Text-To-Image Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaocheng Shen, Jianfeng Liang. Chunlei Cai, Cong Geng, Huiyu Duan, Xiaoyun Zhang, Qiang Hu, Guangtao Zhai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 12:06:43</h6>
<p class='card-text'>Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.01980v1' target='_blank'>Bringing computation to the data: A MOEA-driven approach for optimising data processing in the context of the SKA and SRCNet</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Manuel Parra-Royón, Álvaro Rodríguez-Gallardo, Susana Sánchez-Expósito, Laura Darriba-Pol, Jesús Sánchez-Castañeda, M. Ángeles Mendoza, Julián Garrido, Javier Moldón, Lourdes Verdes-Montenegro</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 10:35:34</h6>
<p class='card-text'>The Square Kilometre Array (SKA) will generate unprecedented data volumes, making efficient data processing a critical challenge. Within this context, the SKA Regional Centres Network (SRCNet) must operate in a near-exascale environment where traditional data-centric computing models based on moving large datasets to centralised resources are no longer viable due to network and storage bottlenecks.
  To address this limitation, this work proposes a shift towards distributed and in-situ computing, where computation is moved closer to the data. We explore the integration of Function-as-a-Service (FaaS) with an intelligent decision-making entity based on Evolutionary Algorithms (EAs) to optimise data-intensive workflows within SRCNet. FaaS enables lightweight and modular function execution near data sources while abstracting infrastructure management.
  The proposed decision-making entity employs Multi-Objective Evolutionary Algorithms (MOEAs) to explore near-optimal execution plans considering execution time and energy consumption, together with constraints related to data location and transfer costs. This work establishes a baseline framework for efficient and cost-aware computation-to-data strategies within the SRCNet architecture.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.01948v1' target='_blank'>Learning Diffusion Policy from Primitive Skills for Robot Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhihao Gu, Ming Yang, Difan Zou, Dong Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 09:56:24</h6>
<p class='card-text'>Diffusion policies (DP) have recently shown great promise for generating actions in robotic manipulation. However, existing approaches often rely on global instructions to produce short-term control signals, which can result in misalignment in action generation. We conjecture that the primitive skills, referred to as fine-grained, short-horizon manipulations, such as ``move up'' and ``open the gripper'', provide a more intuitive and effective interface for robot learning. To bridge this gap, we propose SDP, a skill-conditioned DP that integrates interpretable skill learning with conditional action planning. SDP abstracts eight reusable primitive skills across tasks and employs a vision-language model to extract discrete representations from visual observations and language instructions. Based on them, a lightweight router network is designed to assign a desired primitive skill for each state, which helps construct a single-skill policy to generate skill-aligned actions. By decomposing complex tasks into a sequence of primitive skills and selecting a single-skill policy, SDP ensures skill-consistent behavior across diverse tasks. Extensive experiments on two challenging simulation benchmarks and real-world robot deployments demonstrate that SDP consistently outperforms SOTA methods, providing a new paradigm for skill-based robot learning with diffusion policies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.01943v1' target='_blank'>SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tieu-Long Phan, Nhu-Ngoc Nguyen Song, Peter F. Stadler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 09:49:58</h6>
<p class='card-text'>We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.01910v1' target='_blank'>MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minh Hieu Ha, Khanh Ly Ta, Hung Phan, Tung Doan, Tung Dao, Dao Tran, Huynh Thi Thanh Binh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 08:55:27</h6>
<p class='card-text'>Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.01891v1' target='_blank'>Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Niloufar Alipour Talemi, Julia Boone, Fatemeh Afghah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 08:34:17</h6>
<p class='card-text'>The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2601.01864v1' target='_blank'>Extending SST Anomaly Forecasts Through Simultaneous Decomposition of Seasonal and PDO Modes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rameshan Kallummal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-01-05 07:47:12</h6>
<p class='card-text'>We present a new approach to forecasting North Pacific Sea Surface Temperatures (SST) by recognizing that interannual variability primarily reflects amplitude changes in four dominant seasonal cycles. Our multivariate linear model simultaneously captures these amplitude-modulated seasonal cycles along with the Pacific Decadal Oscillation (PDO), which naturally emerges as an intrinsic feature of the system rather than a separate phenomenon. Using sixteen-dimensional regression based on four spatially distributed time series per variable, the model delivers unprecedented forecast accuracy for both interannual amplitude modulations and PDO evolution, maintaining skill beyond 36 months -- a substantial improvement over current operational and research forecasts, including machine learning methods. Predictions initialized in 2024 project that the PDO will remain in its negative phase through late 2026, implying reduced likelihood of severe marine heatwaves in the eastern North Pacific during this period. These findings have direct implications for regional climate impacts, including storm tracks, precipitation patterns, and marine ecosystem health. By treating seasonal and interannual variability as coupled rather than independent processes, this framework advances our understanding of North Pacific climate dynamics and provides a powerful tool for stakeholders managing climate-sensitive resources and planning adaptation strategies in regions strongly influenced by North Pacific conditions.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>