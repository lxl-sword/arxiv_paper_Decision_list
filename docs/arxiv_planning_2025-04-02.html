<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-04-02</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-04-02</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24378v1' target='_blank'>ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 17:58:25</h6>
<p class='card-text'>The ACPBench dataset provides atomic reasoning tasks required for efficient
planning. The dataset is aimed at distilling the complex plan generation task
into separate atomic reasoning tasks in their easiest possible form, boolean or
multiple-choice questions, where the model has to choose the right answer from
the provided options. While the aim of ACPBench is to test the simplest form of
reasoning about action and change, when tasked with planning, a model does not
typically have options to choose from and thus the reasoning required for
planning dictates an open-ended, generative form for these tasks. To that end,
we introduce ACPBench Hard, a generative version of ACPBench, with open-ended
questions which the model needs to answer. Models that perform well on these
tasks could in principle be integrated into a planner or be used directly as a
policy. We discuss the complexity of these tasks as well as the complexity of
validating the correctness of their answers and present validation algorithms
for each task. Equipped with these validators, we test the performance of a
variety of models on our tasks and find that for most of these tasks the
performance of even the largest models is still subpar. Our experiments show
that no model outperforms another in these tasks and with a few exceptions all
tested language models score below 65%, indicating that even the current
frontier language models have a long way to go before they can reliably reason
about planning. In fact, even the so-called reasoning models struggle with
solving these reasoning tasks. ACPBench Hard collection is available at the
following link: https://ibm.github.io/ACPBench</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24352v1' target='_blank'>CMS Token Transition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Brian Bockelman, Rahul Chauhan, Diego Ciangottini, Dave Dykstra, Edita Kizinevic, Stephan Lammel, Marco Mascheroni, Sarun Nuntaviriyakul, Panos Paparrigopoulos, Alan Malta Rodrigues, Chan-anun Rungphitakchai, Eric Vaandering, Vaiva Zokaite</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 17:34:56</h6>
<p class='card-text'>Within the LHC community, a momentous transition has been occurring in
authorization. For nearly 20 years, services within the Worldwide LHC Computing
Grid (WLCG) have authorized based on mapping an identity, derived from an X.509
credential, or a group/role, derived from a VOMS extension issued by the
experiment. A fundamental shift is occurring to capabilities: the credential, a
bearer token, asserts the authorizations of the bearer, not the identity. By
the HL-LHC era, the CMS experiment plans for the transition to tokens, based on
the WLCG Common JSON Web Token profile, to be complete. Services in the
technology architecture include the INDIGO Identity and Access Management
server to issue tokens; a HashiCorp Vault server to store and refresh access
tokens for users and jobs; a managed token bastion server to push credentials
to the HTCondor CredMon service; and HTCondor to maintain valid tokens in
long-running batch jobs. We will describe the transition plans of the
experiment, current status, configuration of the central authorization server,
lessons learned in commissioning token-based access with sites, and operational
experience using tokens for both job submissions and file transfers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24346v1' target='_blank'>Projections for Key Measurements in Heavy Flavour Physics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:The ATLAS, Belle II, CMS, LHCb collaborations</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 17:32:03</h6>
<p class='card-text'>Precision studies of flavour-changing processes involving quarks and leptons
provide a number of ways to improve knowledge of the Standard Model and search
for physics beyond it. There are excellent short- and mid-term prospects for
significantly improved measurements in heavy flavour physics (involving b and c
hadrons and $\tau$ leptons), with upgrades in progress or planned for the
ATLAS, CMS and LHCb experiments exploiting proton-proton collisions at CERN's
Large Hadron Collider, and for the Belle II experiment operating with
electron-positron collisions from the SuperKEKB accelerator in KEK. The
expected sensitivities that can be achieved from these experiments for a number
of key observables are presented, highlighting the complementarity of the
different experiments and showing how the precision will improve with time.
This international programme in heavy flavour physics will result in
unprecedented capability to probe this sector of the Standard Model and,
potentially, observe imprints of physics at higher energy scales than can be
accessed directly.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24324v1' target='_blank'>Predicting and Mitigating Agricultural Price Volatility Using Climate
  Scenarios and Risk Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sourish Das, Sudeep Shukla, Abbinav Sankar Kailasam, Anish Rai, Anirban Chakraborti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 17:11:00</h6>
<p class='card-text'>Agricultural price volatility challenges sustainable finance, planning, and
policy, driven by market dynamics and meteorological factors such as
temperature and precipitation. In India, the Minimum Support Price (MSP) system
acts as implicit crop insurance, shielding farmers from price drops without
premium payments. We analyze the impact of climate on price volatility for
soybean (Madhya Pradesh), rice (Assam), and cotton (Gujarat). Using ERA5-Land
reanalysis data from the Copernicus Climate Change Service, we analyze
historical climate patterns and evaluate two scenarios: SSP2.4.5 (moderate
case) and SSP5.8.5 (severe case). Our findings show that weather conditions
strongly influence price fluctuations and that integrating meteorological data
into volatility models enhances risk-hedging. Using the Exponential Generalized
Autoregressive Conditional Heteroskedasticity (EGARCH) model, we estimate
conditional price volatility and identify cross-correlations between weather
and price volatility movements. Recognizing MSP's equivalence to a European put
option, we apply the Black-Scholes model to estimate its implicit premium,
quantifying its fiscal cost. We propose this novel market-based risk-hedging
mechanism wherein the government purchases insurance equivalent to MSP,
leveraging Black-Scholes for accurate premium estimation. Our results
underscore the importance of meteorological data in agricultural risk modeling,
supporting targeted insurance and strengthening resilience in agricultural
finance. This climate-informed financial framework enhances risk-sharing,
stabilizes prices, and informs sustainable agricultural policy under growing
climate uncertainty.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24288v1' target='_blank'>Magnetic Confinement of a Bubble of Supercooled $^3$He-A</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luke Whitehead, Andrew Casey, Richard P. Haley, Petri J. Heikkinen, Lev V. Levitin, Adam J. Mayer, Xavier Rojas, Tineke Salmon, John Saunders, Alex Thomson, Dmitry E. Zmeev, Samuli Autti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 16:35:56</h6>
<p class='card-text'>We have designed and constructed a magnet surrounding a cylindrical volume of
superfluid helium-3 to isolate a region of metastable, supercooled A-phase,
entirely surrounded by bulk A-phase - isolating the 'bubble' from rough
surfaces that can trigger the transition to the stable B-phase. We outline the
design of the experimental cell and magnet, and show that the performance of
the magnet is consistent with simulations, including the capability to
producing the high field gradient required for generating a bubble. Future
plans include the investigation of possible intrinsic mechanisms underpinning
the A-B transition, with potential implications for early-universe cosmological
phase transitions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24284v1' target='_blank'>Value of Information-based Deceptive Path Planning Under Adversarial
  Interventions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wesley A. Suttle, Jesse Milzman, Mustafa O. Karabag, Brian M. Sadler, Ufuk Topcu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 16:31:29</h6>
<p class='card-text'>Existing methods for deceptive path planning (DPP) address the problem of
designing paths that conceal their true goal from a passive, external observer.
Such methods do not apply to problems where the observer has the ability to
perform adversarial interventions to impede the path planning agent. In this
paper, we propose a novel Markov decision process (MDP)-based model for the DPP
problem under adversarial interventions and develop new value of information
(VoI) objectives to guide the design of DPP policies. Using the VoI objectives
we propose, path planning agents deceive the adversarial observer into choosing
suboptimal interventions by selecting trajectories that are of low
informational value to the observer. Leveraging connections to the linear
programming theory for MDPs, we derive computationally efficient solution
methods for synthesizing policies for performing DPP under adversarial
interventions. In our experiments, we illustrate the effectiveness of the
proposed solution method in achieving deceptiveness under adversarial
interventions and demonstrate the superior performance of our approach to both
existing DPP methods and conservative path planning approaches on illustrative
gridworld problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24214v1' target='_blank'>Moving Edge for On-Demand Edge Computing: An Uncertainty-aware Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fangtong Zhou, Ruozhou Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 15:32:05</h6>
<p class='card-text'>We study an edge demand response problem where, based on historical edge
workload demands, an edge provider needs to dispatch moving computing units,
e.g. truck-carried modular data centers, in response to emerging hotspots
within service area. The goal of edge provider is to maximize the expected
revenue brought by serving congested users with satisfactory performance, while
minimizing the costs of moving units and the potential service-level agreement
violation penalty for interrupted services. The challenge is to make robust
predictions for future demands, as well as optimized moving unit dispatching
decisions. We propose a learning-based, uncertain-aware moving unit scheduling
framework, URANUS, to address this problem. Our framework novelly combines
Bayesian deep learning and distributionally robust approximation to make
predictions that are robust to data, model and distributional uncertainties in
deep learning-based prediction models. Based on the robust prediction outputs,
we further propose an efficient planning algorithm to optimize moving unit
scheduling in an online manner. Simulation experiments show that URANUS can
significantly improve robustness in decision making, and achieve superior
performance compared to state-of-the-art reinforcement learning,
uncertainty-agnostic learning-based methods, and other baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24204v1' target='_blank'>Many-to-Many Matching via Sparsity Controlled Optimal Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weijie Liu, Han Bao, Makoto Yamada, Zenan Huang, Nenggan Zheng, Hui Qian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 15:22:02</h6>
<p class='card-text'>Many-to-many matching seeks to match multiple points in one set and multiple
points in another set, which is a basis for a wide range of data mining
problems. It can be naturally recast in the framework of Optimal Transport
(OT). However, existing OT methods either lack the ability to accomplish
many-to-many matching or necessitate careful tuning of a regularization
parameter to achieve satisfactory results. This paper proposes a novel
many-to-many matching method to explicitly encode many-to-many constraints
while preventing the degeneration into one-to-one matching. The proposed method
consists of the following two components. The first component is the matching
budget constraints on each row and column of a transport plan, which specify
how many points can be matched to a point at most. The second component is the
deformed $q$-entropy regularization, which encourages a point to meet the
matching budget maximally. While the deformed $q$-entropy was initially
proposed to sparsify a transport plan, we employ it to avoid the degeneration
into one-to-one matching. We optimize the objective via a penalty algorithm,
which is efficient and theoretically guaranteed to converge. Experimental
results on various tasks demonstrate that the proposed method achieves good
performance by gleaning meaningful many-to-many matchings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24121v1' target='_blank'>IMPACT: A Generic Semantic Loss for Multimodal Medical Image
  Registration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Valentin Boussot, Cédric Hémon, Jean-Claude Nunes, Jason Downling, Simon Rouzé, Caroline Lafond, Anaïs Barateau, Jean-Louis Dillenseger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 14:08:21</h6>
<p class='card-text'>Image registration is fundamental in medical imaging, enabling precise
alignment of anatomical structures for diagnosis, treatment planning,
image-guided treatment or longitudinal monitoring. This work introduces IMPACT
(Image Metric with Pretrained model-Agnostic Comparison for Transmodality
registration), a generic semantic similarity metric designed for seamless
integration into diverse image registration frameworks (such as Elastix and
Voxelmorph). It compares deep learning-based features extracted from medical
images without requiring task-specific training, ensuring broad applicability
across various modalities. By leveraging the features of the large-scale
pretrained TotalSegmentator models and the ability to integrate Segment
Anything Model (SAM) and other large-scale segmentation networks, this approach
offers significant advantages. It provides robust, scalable, and efficient
solutions for multimodal image registration. The IMPACT loss was evaluated on
five challenging registration tasks involving thoracic CT/CBCT, and pelvic
MR/CT datasets. Quantitative metrics, such as Target Registration Error and
Dice Similarity Coefficient, demonstrated significant improvements in
anatomical alignment compared to baseline methods. Qualitative analyses further
confirmed the increased robustness of the proposed metric in the face of noise,
artifacts, and modality variations. IMPACT's versatility and efficiency make it
a valuable tool for advancing registration performance in clinical and research
applications, addressing critical challenges in multimodal medical imaging.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.24044v1' target='_blank'>Bi-Level Route Optimization and Path Planning with Hazard Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jimin Choi, Grant Stagg, Cameron K. Peterson, Max Z. Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 13:08:51</h6>
<p class='card-text'>Effective risk monitoring in dynamic environments such as disaster zones
requires an adaptive exploration strategy to detect hidden threats. We propose
a bi-level unmanned aerial vehicle (UAV) monitoring strategy that efficiently
integrates high-level route optimization with low-level path planning for known
and unknown hazards. At the high level, we formulate the route optimization as
a vehicle routing problem (VRP) to determine the optimal sequence for visiting
known hazard locations. To strategically incorporate exploration efficiency, we
introduce an edge-based centroidal Voronoi tessellation (CVT), which refines
baseline routes using pseudo-nodes and allocates path budgets based on the
UAV's battery capacity using a line segment Voronoi diagram. At the low level,
path planning maximizes information gain within the allocated path budget by
generating kinematically feasible B-spline trajectories. Bayesian inference is
applied to dynamically update hazard probabilities, enabling the UAVs to
prioritize unexplored regions. Simulation results demonstrate that edge-based
CVT improves spatial coverage and route uniformity compared to the node-based
method. Additionally, our optimized path planning consistently outperforms
baselines in hazard discovery rates across a diverse set of scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23975v1' target='_blank'>A Reactive Framework for Whole-Body Motion Planning of Mobile
  Manipulators Combining Reinforcement Learning and SDF-Constrained Quadratic
  Programmi</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenyu Zhang, Shiying Sun, Kuan Liu, Chuanbao Zhou, Xiaoguang Zhao, Min Tan, Yanlong Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 11:37:02</h6>
<p class='card-text'>As an important branch of embodied artificial intelligence, mobile
manipulators are increasingly applied in intelligent services, but their
redundant degrees of freedom also limit efficient motion planning in cluttered
environments. To address this issue, this paper proposes a hybrid learning and
optimization framework for reactive whole-body motion planning of mobile
manipulators. We develop the Bayesian distributional soft actor-critic
(Bayes-DSAC) algorithm to improve the quality of value estimation and the
convergence performance of the learning. Additionally, we introduce a quadratic
programming method constrained by the signed distance field to enhance the
safety of the obstacle avoidance motion. We conduct experiments and make
comparison with standard benchmark. The experimental results verify that our
proposed framework significantly improves the efficiency of reactive whole-body
motion planning, reduces the planning time, and improves the success rate of
motion planning. Additionally, the proposed reinforcement learning method
ensures a rapid learning process in the whole-body planning task. The novel
framework allows mobile manipulators to adapt to complex environments more
safely and efficiently.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23908v1' target='_blank'>MAER-Nav: Bidirectional Motion Learning Through Mirror-Augmented
  Experience Replay for Robot Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shanze Wang, Mingao Tan, Zhibo Yang, Biao Huang, Xiaoyu Shen, Hailong Huang, Wei Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 09:58:28</h6>
<p class='card-text'>Deep Reinforcement Learning (DRL) based navigation methods have demonstrated
promising results for mobile robots, but suffer from limited action flexibility
in confined spaces. Conventional DRL approaches predominantly learn
forward-motion policies, causing robots to become trapped in complex
environments where backward maneuvers are necessary for recovery. This paper
presents MAER-Nav (Mirror-Augmented Experience Replay for Robot Navigation), a
novel framework that enables bidirectional motion learning without requiring
explicit failure-driven hindsight experience replay or reward function
modifications. Our approach integrates a mirror-augmented experience replay
mechanism with curriculum learning to generate synthetic backward navigation
experiences from successful trajectories. Experimental results in both
simulation and real-world environments demonstrate that MAER-Nav significantly
outperforms state-of-the-art methods while maintaining strong forward
navigation capabilities. The framework effectively bridges the gap between the
comprehensive action space utilization of traditional planning methods and the
environmental adaptability of learning-based approaches, enabling robust
navigation in scenarios where conventional DRL methods consistently fail.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23890v1' target='_blank'>Less is More: Contextual Sampling for Nonlinear Data-Enabled Predictive
  Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Julius Beerwerth, Bassam Alrifaee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 09:41:44</h6>
<p class='card-text'>Data-enabled Predictive Control (DeePC) is a powerful data-driven approach
for predictive control without requiring an explicit system model. However, its
high computational cost limits its applicability to real-time robotic systems.
For robotic applications such as motion planning and trajectory tracking,
real-time control is crucial. Nonlinear DeePC either relies on large datasets
or learning the nonlinearities to ensure predictive accuracy, leading to high
computational complexity. This work introduces contextual sampling, a novel
data selection strategy to handle nonlinearities for DeePC by dynamically
selecting the most relevant data at each time step. By reducing the dataset
size while preserving prediction accuracy, our method improves computational
efficiency, of DeePC for real-time robotic applications. We validate our
approach for autonomous vehicle motion planning. For a dataset size of 100
sub-trajectories, Contextual sampling DeePC reduces tracking error by 53.2 %
compared to Leverage Score sampling. Additionally, Contextual sampling reduces
max computation time by 87.2 % compared to using the full dataset of 491
sub-trajectories while achieving comparable tracking performance. These results
highlight the potential of Contextual sampling to enable real-time, data-driven
control for robotic systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23863v1' target='_blank'>GRACEFUL: A Learned Cost Estimator For UDFs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Johannes Wehrstein, Tiemo Bang, Roman Heinrich, Carsten Binnig</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 09:09:12</h6>
<p class='card-text'>User-Defined-Functions (UDFs) are a pivotal feature in modern DBMS, enabling
the extension of native DBMS functionality with custom logic. However, the
integration of UDFs into query optimization processes poses significant
challenges, primarily due to the difficulty of estimating UDF execution costs.
Consequently, existing cost models in DBMS optimizers largely ignore UDFs or
rely on static assumptions, resulting in suboptimal performance for queries
involving UDFs. In this paper, we introduce GRACEFUL, a novel learned cost
model to make accurate cost predictions of query plans with UDFs enabling
optimization decisions for UDFs in DBMS. For example, as we show in our
evaluation, using our cost model, we can achieve 50x speedups through informed
pull-up/push-down filter decisions of the UDF compared to the standard case
where always a filter push-down is applied. Additionally, we release a
synthetic dataset of over 90,000 UDF queries to promote further research in
this area.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23795v1' target='_blank'>Trajectory Planning for Automated Driving using Target Funnels</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benjamin Bogenberger, Johannes Bürger, Vladislav Nenchev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 07:15:55</h6>
<p class='card-text'>Self-driving vehicles rely on sensory input to monitor their surroundings and
continuously adapt to the most likely future road course. Predictive trajectory
planning is based on snapshots of the (uncertain) road course as a key input.
Under noisy perception data, estimates of the road course can vary
significantly, leading to indecisive and erratic steering behavior. To overcome
this issue, this paper introduces a predictive trajectory planning algorithm
with a novel objective function: instead of targeting a single reference
trajectory based on the most likely road course, tracking a series of target
reference sets, called a target funnel, is considered. The proposed planning
algorithm integrates probabilistic information about the road course, and thus
implicitly considers regular updates to road perception. Our solution is
assessed in a case study using real driving data collected from a prototype
vehicle. The results demonstrate that the algorithm maintains tracking accuracy
and substantially reduces undesirable steering commands in the presence of
noisy road perception, achieving a 56% reduction in input costs compared to a
certainty equivalent formulation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23776v1' target='_blank'>VIDEX: A Disaggregated and Extensible Virtual Index for the Cloud and AI
  Era</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rong Kang, Shuai Wang, Tieying Zhang, Xianghong Xu, Linhui Xu, Zhimin Liang, Lei Zhang, Rui Shi, Jianjun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 06:52:13</h6>
<p class='card-text'>Virtual index, also known as hypothetical indexes, play a crucial role in
database query optimization. However, with the rapid advancement of cloud
computing and AI-driven models for database optimization, traditional virtual
index approaches face significant challenges. Cloud-native environments often
prohibit direct conducting query optimization process on production databases
due to stability requirements and data privacy concerns. Moreover, while AI
models show promising progress, their integration with database systems poses
challenges in system complexity, inference acceleration, and model hot updates.
In this paper, we present VIDEX, a three-layer disaggregated architecture that
decouples database instances, the virtual index optimizer, and algorithm
services, providing standardized interfaces for AI model integration. Users can
configure VIDEX by either collecting production statistics or by loading from a
prepared file; this setup allows for high-accurate what-if analyses based on
virtual indexes, achieving query plans that are identical to those of the
production instance. Additionally, users can freely integrate new AI-driven
algorithms into VIDEX. VIDEX has been successfully deployed at ByteDance,
serving thousands of MySQL instances daily and over millions of SQL queries for
index optimization tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23766v1' target='_blank'>Accelerating High-Efficiency Organic Photovoltaic Discovery via
  Pretrained Graph Neural Networks and Generative Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiangjie Qiu, Hou Hei Lam, Xiuyuan Hu, Wentao Li, Siwei Fu, Fankun Zeng, Hao Zhang, Xiaonan Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 06:31:15</h6>
<p class='card-text'>Organic photovoltaic (OPV) materials offer a promising avenue toward
cost-effective solar energy utilization. However, optimizing donor-acceptor
(D-A) combinations to achieve high power conversion efficiency (PCE) remains a
significant challenge. In this work, we propose a framework that integrates
large-scale pretraining of graph neural networks (GNNs) with a GPT-2
(Generative Pretrained Transformer 2)-based reinforcement learning (RL)
strategy to design OPV molecules with potentially high PCE. This approach
produces candidate molecules with predicted efficiencies approaching 21\%,
although further experimental validation is required. Moreover, we conducted a
preliminary fragment-level analysis to identify structural motifs recognized by
the RL model that may contribute to enhanced PCE, thus providing design
guidelines for the broader research community. To facilitate continued
discovery, we are building the largest open-source OPV dataset to date,
expected to include nearly 3,000 donor-acceptor pairs. Finally, we discuss
plans to collaborate with experimental teams on synthesizing and characterizing
AI-designed molecules, which will provide new data to refine and improve our
predictive and generative models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23744v1' target='_blank'>European Contributions to Fermilab Accelerator Upgrades and Facilities
  for the DUNE Experiment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:DUNE Collaboration, A. Abed Abud, R. Acciarri, M. A. Acero, M. R. Adames, G. Adamov, M. Adamowski, D. Adams, M. Adinolfi, C. Adriano, A. Aduszkiewicz, J. Aguilar, F. Akbar, F. Alemanno, N. S. Alex, K. Allison, M. Alrashed, A. Alton, R. Alvarez, T. Alves, A. Aman, H. Amar, P. Amedo, J. Anderson, D. A. Andrade, C. Andreopoulos, M. Andreotti, M. P. Andrews, F. Andrianala, S. Andringa, F. Anjarazafy, D. Antic, M. Antoniassi, M. Antonova, A. Aranda-Fernandez, L. Arellano, E. Arrieta Diaz, M. A. Arroyave, J. Asaadi, M. Ascencio, A. Ashkenazi, D. Asner, L. Asquith, E. Atkin, D. Auguste, A. Aurisano, V. Aushev, D. Autiero, D. Ávila Gómez, M. B. Azam, F. Azfar, A. Back, H. Back, J. J. Back, I. Bagaturia, L. Bagby, D. Baigarashev, S. Balasubramanian, A. Balboni, P. Baldi, W. Baldini, J. Baldonedo, B. Baller, B. Bambah, R. Banerjee, F. Barao, D. Barbu, G. Barenboim, P. Barham Alzás, G. J. Barker, W. Barkhouse, G. Barr, J. Barranco Monarca, A. Barros, N. Barros, D. Barrow, J. L. Barrow, A. Basharina-Freshville, A. Bashyal, V. Basque, D. Basu, C. Batchelor, L. Bathe-Peters, J. B. R. Battat, F. Battisti, F. Bay, M. C. Q. Bazetto, J. L. L. Bazo Alba, J. F. Beacom, E. Bechetoille, B. Behera, E. Belchior, B. Bell, G. Bell, L. Bellantoni, G. Bellettini, V. Bellini, O. Beltramello, C. Benitez Montiel, D. Benjamin, F. Bento Neves, J. Berger, S. Berkman, J. Bernal, P. Bernardini, A. Bersani, E. Bertolini, S. Bertolucci, M. Betancourt, A. Betancur Rodríguez, Y. Bezawada, A. T. Bezerra, A. Bhat, V. Bhatnagar, J. Bhatt, M. Bhattacharjee, M. Bhattacharya, S. Bhuller, B. Bhuyan, S. Biagi, J. Bian, K. Biery, B. Bilki, M. Bishai, A. Blake, F. D. Blaszczyk, G. C. Blazey, E. Blucher, B. Bogart, J. Bogenschuetz, J. Boissevain, S. Bolognesi, T. Bolton, L. Bomben, M. Bonesini, C. Bonilla-Diaz, A. Booth, F. Boran, R. Borges Merlo, N. Bostan, G. Botogoske, B. Bottino, R. Bouet, J. Boza, J. Bracinik, B. Brahma, D. Brailsford, F. Bramati, A. Branca, A. Brandt, J. Bremer, S. J. Brice, V. Brio, C. Brizzolari, C. Bromberg, J. Brooke, A. Bross, G. Brunetti, M. B. Brunetti, N. Buchanan, H. Budd, J. Buergi, A. Bundock, D. Burgardt, S. Butchart, G. Caceres V., T. Cai, R. Calabrese, R. Calabrese, J. Calcutt, L. Calivers, E. Calvo, A. Caminata, A. F. Camino, W. Campanelli, A. Campani, A. Campos Benitez, N. Canci, J. Capó, I. Caracas, D. Caratelli, D. Carber, J. M. Carceller, G. Carini, B. Carlus, M. F. Carneiro, P. Carniti, I. Caro Terrazas, H. Carranza, N. Carrara, L. Carroll, T. Carroll, A. Carter, E. Casarejos, D. Casazza, J. F. Castaño Forero, F. A. Castaño, A. Castillo, C. Castromonte, E. Catano-Mur, C. Cattadori, F. Cavalier, F. Cavanna, S. Centro, G. Cerati, C. Cerna, A. Cervelli, A. Cervera Villanueva, J. Chakrani, M. Chalifour, A. Chappell, A. Chatterjee, B. Chauhan, C. Chavez Barajas, H. Chen, M. Chen, W. C. Chen, Y. Chen, Z. Chen, D. Cherdack, S. S. Chhibra, C. Chi, F. Chiapponi, R. Chirco, N. Chitirasreemadam, K. Cho, S. Choate, G. Choi, D. Chokheli, P. S. Chong, B. Chowdhury, D. Christian, M. Chung, E. Church, M. F. Cicala, M. Cicerchia, V. Cicero, R. Ciolini, P. Clarke, G. Cline, A. G. Cocco, J. A. B. Coelho, A. Cohen, J. Collazo, J. Collot, J. M. Conrad, M. Convery, K. Conway, S. Copello, P. Cova, C. Cox, L. Cremonesi, J. I. Crespo-Anadón, M. Crisler, E. Cristaldo, J. Crnkovic, G. Crone, R. Cross, A. Cudd, C. Cuesta, Y. Cui, F. Curciarello, D. Cussans, J. Dai, O. Dalager, W. Dallaway, R. D'Amico, H. da Motta, Z. A. Dar, R. Darby, L. Da Silva Peres, Q. David, G. S. Davies, S. Davini, J. Dawson, R. De Aguiar, P. De Almeida, P. Debbins, M. P. Decowski, A. de Gouvêa, P. C. De Holanda, P. De Jong, P. Del Amo Sanchez, G. De Lauretis, A. Delbart, D. Delepine, M. Delgado, A. Dell'Acqua, G. Delle Monache, N. Delmonte, P. De Lurgio, R. Demario, G. De Matteis, J. R. T. de Mello Neto, A. P. A. De Mendonca, D. M. DeMuth, S. Dennis, C. Densham, P. Denton, G. W. Deptuch, A. De Roeck, V. De Romeri, J. P. Detje, J. Devine, R. Dharmapalan, M. Dias, A. Diaz, J. S. Díaz, F. Díaz, F. Di Capua, A. Di Domenico, S. Di Domizio, S. Di Falco, L. Di Giulio, P. Ding, L. Di Noto, E. Diociaiuti, V. Di Silvestre, C. Distefano, R. Diurba, M. Diwan, Z. Djurcic, S. Dolan, M. Dolce, F. Dolek, M. J. Dolinski, D. Domenici, S. Donati, Y. Donon, S. Doran, D. Douglas, T. A. Doyle, F. Drielsma, L. Duarte, D. Duchesneau, K. Duffy, K. Dugas, P. Dunne, B. Dutta, H. Duyang, D. A. Dwyer, A. S. Dyshkant, S. Dytman, M. Eads, A. Earle, S. Edayath, D. Edmunds, J. Eisch, W. Emark, P. Englezos, A. Ereditato, T. Erjavec, C. O. Escobar, J. J. Evans, E. Ewart, A. C. Ezeribe, K. Fahey, A. Falcone, M. Fani', C. Farnese, S. Farrell, Y. Farzan, J. Felix, Y. Feng, M. Ferreira da Silva, G. Ferry, E. Fialova, L. Fields, P. Filip, A. Filkins, F. Filthaut, G. Fiorillo, M. Fiorini, S. Fogarty, W. Foreman, J. Fowler, J. Franc, K. Francis, D. Franco, J. Freeman, J. Fried, A. Friedland, M. Fucci, S. Fuess, I. K. Furic, K. Furman, A. P. Furmanski, R. Gaba, A. Gabrielli, A. M. Gago, F. Galizzi, H. Gallagher, M. Galli, N. Gallice, V. Galymov, E. Gamberini, T. Gamble, R. Gandhi, S. Ganguly, F. Gao, S. Gao, D. Garcia-Gamez, M. Á. García-Peris, F. Gardim, S. Gardiner, D. Gastler, A. Gauch, P. Gauzzi, S. Gazzana, G. Ge, N. Geffroy, B. Gelli, S. Gent, L. Gerlach, A. Ghosh, T. Giammaria, D. Gibin, I. Gil-Botella, S. Gilligan, A. Gioiosa, S. Giovannella, A. K. Giri, C. Giugliano, V. Giusti, D. Gnani, O. Gogota, S. Gollapinni, K. Gollwitzer, R. A. Gomes, L. V. Gomez Bermeo, L. S. Gomez Fajardo, D. Gonzalez-Diaz, M. C. Goodman, S. Goswami, C. Gotti, J. Goudeau, E. Goudzovski, C. Grace, E. Gramellini, R. Gran, E. Granados, P. Granger, C. Grant, D. R. Gratieri, G. Grauso, P. Green, S. Greenberg, J. Greer, W. C. Griffith, K. Grzelak, L. Gu, W. Gu, V. Guarino, M. Guarise, R. Guenette, M. Guerzoni, D. Guffanti, A. Guglielmi, B. Guo, F. Y. Guo, V. Gupta, G. Gurung, D. Gutierrez, P. Guzowski, M. M. Guzzo, S. Gwon, A. Habig, L. Haegel, R. Hafeji, L. Hagaman, A. Hahn, J. Hakenmüller, T. Hamernik, P. Hamilton, J. Hancock, M. Handley, F. Happacher, D. A. Harris, A. L. Hart, J. Hartnell, T. Hartnett, J. Harton, T. Hasegawa, C. M. Hasnip, R. Hatcher, S. Hawkins, J. Hays, M. He, A. Heavey, K. M. Heeger, A. Heindel, J. Heise, P. Hellmuth, L. Henderson, K. Herner, V. Hewes, A. Higuera, C. Hilgenberg, A. Himmel, E. Hinkle, L. R. Hirsch, J. Ho, J. Hoefken Zink, J. Hoff, A. Holin, T. Holvey, C. Hong, E. Hoppe, S. Horiuchi, G. A. Horton-Smith, R. Hosokawa, T. Houdy, B. Howard, R. Howell, I. Hristova, M. S. Hronek, H. Hua, J. Huang, R. G. Huang, X. Huang, Z. Hulcher, G. Iles, N. Ilic, A. M. Iliescu, R. Illingworth, G. Ingratta, A. Ioannisian, B. Irwin, M. Ismerio Oliveira, C. M. Jackson, V. Jain, E. James, W. Jang, B. Jargowsky, D. Jena, I. Jentz, X. Ji, C. Jiang, J. Jiang, A. Jipa, J. H. Jo, F. R. Joaquim, W. Johnson, C. Jollet, R. Jones, N. Jovancevic, M. Judah, C. K. Jung, K. Y. Jung, T. Junk, Y. Jwa, M. Kabirnezhad, A. C. Kaboth, I. Kadenko, O. Kalikulov, D. Kalra, M. Kandemir, D. M. Kaplan, G. Karagiorgi, G. Karaman, A. Karcher, Y. Karyotakis, S. P. Kasetti, L. Kashur, A. Kauther, N. Kazaryan, L. Ke, E. Kearns, P. T. Keener, K. J. Kelly, R. Keloth, E. Kemp, O. Kemularia, Y. Kermaidic, W. Ketchum, S. H. Kettell, N. Khan, A. Khvedelidze, D. Kim, J. Kim, M. J. Kim, S. Kim, B. King, M. King, M. Kirby, A. Kish, J. Klein, J. Kleykamp, A. Klustova, T. Kobilarcik, L. Koch, K. Koehler, L. W. Koerner, D. H. Koh, M. Kordosky, T. Kosc, V. A. Kostelecký, K. Kothekar, I. Kotler, M. Kovalcuk, R. Kralik, M. Kramer, L. Kreczko, F. Krennrich, T. Kroupova, S. Kubota, M. Kubu, V. A. Kudryavtsev, G. Kufatty, S. Kuhlmann, J. Kumar, M. Kumar, P. Kumar, P. Kumar, S. Kumaran, J. Kunzmann, R. Kuravi, V. Kus, T. Kutter, J. Kvasnicka, T. Labree, T. Lackey, I. Lalău, A. Lambert, B. J. Land, C. E. Lane, N. Lane, K. Lang, T. Langford, M. Langstaff, F. Lanni, J. Larkin, P. Lasorak, D. Last, A. Laundrie, G. Laurenti, E. Lavaut, P. Laycock, I. Lazanu, R. LaZur, M. Lazzaroni, T. Le, S. Leardini, J. Learned, T. LeCompte, G. Lehmann Miotto, R. Lehnert, M. Leitner, H. Lemoine, D. Leon Silverio, L. M. Lepin, J. -Y. Li, S. W. Li, Y. Li, H. Liao, R. Lima, C. S. Lin, D. Lindebaum, S. Linden, R. A. Lineros, A. Lister, B. R. Littlejohn, H. Liu, J. Liu, Y. Liu, S. Lockwitz, I. Lomidze, K. Long, T. V. Lopes, J. Lopez, I. López de Rego, N. López-March, J. M. LoSecco, W. C. Louis, A. Lozano Sanchez, X. -G. Lu, K. B. Luk, X. Luo, E. Luppi, A. A. Machado, P. Machado, C. T. Macias, J. R. Macier, M. MacMahon, S. Magill, C. Magueur, K. Mahn, A. Maio, A. Major, K. Majumdar, A. Malige, S. Mameli, M. Man, R. C. Mandujano, J. Maneira, S. Manly, A. Mann, K. Manolopoulos, M. Manrique Plata, S. Manthey Corchado, V. N. Manyam, L. Manzanillas-Velez, M. Marchan, A. Marchionni, W. Marciano, D. Marfatia, C. Mariani, J. Maricic, F. Marinho, A. D. Marino, T. Markiewicz, F. Das Chagas Marques, C. Marquet, M. Marshak, C. M. Marshall, J. Marshall, L. Martina, J. Martín-Albo, N. Martinez, D. A. Martinez Caicedo, M. Martinez-Casales, F. Martínez López, P. Martínez Miravé, S. Martynenko, V. Mascagna, A. Mastbaum, M. Masud, F. Matichard, G. Matteucci, J. Matthews, C. Mauger, N. Mauri, K. Mavrokoridis, I. Mawby, F. Mayhew, R. Mazza, T. McAskill, N. McConkey, K. S. McFarland, C. McGrew, A. McNab, C. McNulty, J. Mead, L. Meazza, V. C. N. Meddage, M. Mehmood, B. Mehta, P. Mehta, F. Mei, P. Melas, L. Mellet, O. Mena, H. Mendez, D. P. Méndez, A. Menegolli, G. Meng, A. C. E. A. Mercuri, A. Meregaglia, M. D. Messier, S. Metallo, W. Metcalf, M. Mewes, H. Meyer, T. Miao, J. Micallef, A. Miccoli, G. Michna, R. Milincic, F. Miller, G. Miller, W. Miller, A. Minotti, L. Miralles Verge, C. Mironov, S. Miryala, S. Miscetti, C. S. Mishra, P. Mishra, S. R. Mishra, A. Mislivec, D. Mladenov, I. Mocioiu, A. Mogan, R. Mohanta, T. A. Mohayai, N. Mokhov, J. Molina, L. Molina Bueno, E. Montagna, A. Montanari, C. Montanari, D. Montanari, D. Montanino, L. M. Montaño Zetina, M. Mooney, A. F. Moor, M. Moore, Z. Moore, D. Moreno, G. Moreno-Granados, O. Moreno-Palacios, L. Morescalchi, R. Moretti, C. Morris, C. Mossey, E. Motuk, C. A. Moura, G. Mouster, W. Mu, L. Mualem, J. Mueller, M. Muether, F. Muheim, A. Muir, Y. Mukhamejanov, A. Mukhamejanova, M. Mulhearn, D. Munford, L. J. Munteanu, H. Muramatsu, J. Muraz, M. Murphy, T. Murphy, J. Muse, A. Mytilinaki, J. Nachtman, Y. Nagai, S. Nagu, D. Naples, S. Narita, J. Nava, A. Navrer-Agasson, N. Nayak, M. Nebot-Guinot, A. Nehm, J. K. Nelson, O. Neogi, J. Nesbit, M. Nessi, D. Newbold, M. Newcomer, R. Nichol, F. Nicolas-Arnaldos, A. Nielsen, A. Nikolica, J. Nikolov, E. Niner, X. Ning, K. Nishimura, A. Norman, A. Norrick, P. Novella, A. Nowak, J. A. Nowak, M. Oberling, J. P. Ochoa-Ricoux, S. Oh, S. B. Oh, A. Olivier, T. Olson, Y. Onel, Y. Onishchuk, A. Oranday, M. Osbiston, J. A. Osorio Vélez, L. O'Sullivan, L. Otiniano Ormachea, L. Pagani, G. Palacio, O. Palamara, S. Palestini, J. M. Paley, M. Pallavicini, C. Palomares, S. Pan, M. Panareo, P. Panda, V. Pandey, W. Panduro Vazquez, E. Pantic, V. Paolone, A. Papadopoulou, R. Papaleo, D. Papoulias, S. Paramesvaran, S. Parke, S. Parsa, Z. Parsa, S. Parveen, M. Parvu, D. Pasciuto, S. Pascoli, L. Pasqualini, J. Pasternak, J. L. Paton, C. Patrick, L. Patrizii, R. B. Patterson, T. Patzak, A. Paudel, L. Paulucci, Z. Pavlovic, G. Pawloski, D. Payne, A. Peake, V. Pec, E. Pedreschi, S. J. M. Peeters, W. Pellico, E. Pennacchio, A. Penzo, O. L. G. Peres, L. Pérez-Molina, C. Pernas, J. Perry, D. Pershey, G. Pessina, G. Petrillo, C. Petta, R. Petti, M. Pfaff, V. Pia, L. Pickering, L. Pierini, F. Pietropaolo, V. L. Pimentel, G. Pinaroli, S. Pincha, J. Pinchault, K. Pitts, K. Pletcher, K. Plows, C. Pollack, T. Pollmann, F. Pompa, X. Pons, N. Poonthottathil, V. Popov, F. Poppi, J. Porter, L. G. Porto Paixão, M. Potekhin, M. Pozzato, R. Pradhan, T. Prakash, M. Prest, F. Psihas, D. Pugnere, D. Pullia, X. Qian, J. Queen, J. L. Raaf, M. Rabelhofer, V. Radeka, J. Rademacker, B. Radics, F. Raffaelli, A. Rafique, E. Raguzin, A. Rahe, S. Rajagopalan, M. Rajaoalisoa, I. Rakhno, L. Rakotondravohitra, M. A. Ralaikoto, L. Ralte, M. A. Ramirez Delgado, B. Ramson, S. S. Randriamanampisoa, A. Rappoldi, G. Raselli, T. Rath, P. Ratoff, R. Ray, H. Razafinime, R. F. Razakamiandra, E. M. Rea, J. S. Real, B. Rebel, R. Rechenmacher, J. Reichenbacher, S. D. Reitzner, E. Renner, S. Repetto, S. Rescia, F. Resnati, C. Reynolds, M. Ribas, S. Riboldi, C. Riccio, G. Riccobene, J. S. Ricol, M. Rigan, A. Rikalo, E. V. Rincón, A. Ritchie-Yates, S. Ritter, D. Rivera, A. Robert, A. Roberts, E. Robles, J. L. Rocabado Rocha, M. Roda, D. Rodas Rodríguez, M. J. O. Rodrigues, J. Rodriguez Rondon, S. Rosauro-Alcaraz, P. Rosier, D. Ross, M. Rossella, M. Rossi, M. Ross-Lonergan, N. Roy, P. Roy, P. Roy, C. Rubbia, D. Rudik, A. Ruggeri, G. Ruiz Ferreira, K. Rushiya, B. Russell, S. Sacerdoti, N. Saduyev, S. K. Sahoo, N. Sahu, S. Sakhiyev, P. Sala, G. Salmoria, S. Samanta, N. Samios, M. C. Sanchez, A. Sánchez Bravo, A. Sánchez-Castillo, P. Sanchez-Lucas, D. A. Sanders, S. Sanfilippo, D. Santoro, N. Saoulidou, P. Sapienza, I. Sarcevic, I. Sarra, G. Savage, V. Savinov, G. Scanavini, A. Scaramelli, A. Scarff, T. Schefke, H. Schellman, S. Schifano, P. Schlabach, D. Schmitz, A. W. Schneider, K. Scholberg, A. Schukraft, B. Schuld, S. Schwartz, A. Segade, E. Segreto, C. R. Senise, J. Sensenig, S. H. Seo, D. Seppela, M. H. Shaevitz, P. Shanahan, P. Sharma, R. Kumar, S. Sharma Poudel, K. Shaw, T. Shaw, K. Shchablo, J. Shen, C. Shepherd-Themistocleous, J. Shi, W. Shi, S. Shin, S. Shivakoti, A. Shmakov, I. Shoemaker, D. Shooltz, R. Shrock, M. Siden, J. Silber, L. Simard, J. Sinclair, G. Sinev, Jaydip Singh, J. Singh, L. Singh, P. Singh, V. Singh, S. Singh Chauhan, R. Sipos, C. Sironneau, G. Sirri, K. Siyeon, K. Skarpaas, J. Smedley, J. Smith, P. Smith, J. Smolik, M. Smy, M. Snape, E. L. Snider, P. Snopok, M. Soares Nunes, H. Sobel, M. Soderberg, C. J. Solano Salinas, S. Söldner-Rembold, N. Solomey, V. Solovov, W. E. Sondheim, M. Sorbara, M. Sorel, J. Soto-Oton, A. Sousa, K. Soustruznik, D. Souza Correia, F. Spinella, J. Spitz, N. J. C. Spooner, D. Stalder, M. Stancari, L. Stanco, J. Steenis, R. Stein, H. M. Steiner, A. F. Steklain Lisbôa, J. Stewart, B. Stillwell, J. Stock, T. Stokes, M. Strait, T. Strauss, L. Strigari, A. Stuart, J. G. Suarez, J. Subash, A. Surdo, L. Suter, K. Sutton, Y. Suvorov, R. Svoboda, S. K. Swain, C. Sweeney, B. Szczerbinska, A. M. Szelc, A. Sztuc, A. Taffara, N. Talukdar, J. Tamara, H. A. Tanaka, S. Tang, N. Taniuchi, A. M. Tapia Casanova, A. Tapper, S. Tariq, E. Tarpara, E. Tatar, R. Tayloe, D. Tedeschi, A. M. Teklu, K. Tellez Giron Flores, J. Tena Vidal, P. Tennessen, M. Tenti, K. Terao, F. Terranova, G. Testera, T. Thakore, A. Thea, S. Thomas, A. Thompson, C. Thorn, C. Thorpe, S. C. Timm, E. Tiras, V. Tishchenko, S. Tiwari, N. Todorović, L. Tomassetti, A. Tonazzo, D. Torbunov, D. Torres Muñoz, M. Torti, M. Tortola, Y. Torun, N. Tosi, D. Totani, M. Toups, C. Touramanis, V. Trabattoni, D. Tran, R. Travaglini, J. Trevor, E. Triller, S. Trilov, D. Trotta, J. Truchon, D. Truncali, W. H. Trzaska, Y. Tsai, Y. -T. Tsai, Z. Tsamalaidze, K. V. Tsang, N. Tsverava, S. Z. Tu, S. Tufanli, C. Tunnell, M. Tuzi, J. Tyler, E. Tyley, M. Tzanov, M. A. Uchida, J. Ureña González, J. Urheim, T. Usher, H. Utaegbulam, S. Uzunyan, M. R. Vagins, P. Vahle, G. A. Valdiviesso, V. Vale, E. Valencia, R. Valentim, Z. Vallari, E. Vallazza, J. W. F. Valle, R. Van Berg, D. V. Forero, A. Vannozzi, M. Van Nuland-Troost, F. Varanini, D. Vargas Oliva, N. Vaughan, K. Vaziri, A. Vázquez-Ramos, J. Vega, J. Vences, S. Ventura, A. Verdugo, S. Vergani, M. Verzocchi, K. Vetter, M. Vicenzi, H. Vieira de Souza, C. Vignoli, C. Vilela, E. Villa, S. Viola, B. Viren, G. V. Stenico, R. Vizarreta, A. P. Vizcaya Hernandez, S. Vlachos, G. Vorobyev, Q. Vuong, A. V. Waldron, M. Wallach, J. Walsh, T. Walton, L. Wan, B. Wang, H. Wang, J. Wang, L. Wang, M. H. L. S. Wang, X. Wang, Y. Wang, K. Warburton, D. Warner, L. Warsame, M. O. Wascko, D. Waters, A. Watson, K. Wawrowska, A. Weber, C. M. Weber, M. Weber, H. Wei, A. Weinstein, S. Westerdale, M. Wetstein, K. Whalen, A. White, L. H. Whitehead, D. Whittington, F. Wieler, J. Wilhlemi, M. J. Wilking, A. Wilkinson, C. Wilkinson, F. Wilson, R. J. Wilson, P. Winter, J. Wolcott, J. Wolfs, T. Wongjirad, A. Wood, K. Wood, E. Worcester, M. Worcester, K. Wresilo, M. Wright, M. Wrobel, S. Wu, W. Wu, W. Wu, M. Wurm, J. Wyenberg, B. M. Wynne, Y. Xiao, I. Xiotidis, B. Yaeggy, N. Yahlali, E. Yandel, G. Yang, J. Yang, T. Yang, A. Yankelevich, L. Yates, K. Yonehara, T. Young, B. Yu, H. Yu, J. Yu, Y. Yu, W. Yuan, R. Zaki, J. Zalesak, L. Zambelli, B. Zamorano, A. Zani, O. Zapata, L. Zazueta, G. P. Zeller, J. Zennamo, J. Zettlemoyer, K. Zeug, C. Zhang, S. Zhang, M. Zhao, E. Zhivun, E. D. Zimmerman, S. Zucchelli, V. Zutshi, R. Zwaska</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 05:47:29</h6>
<p class='card-text'>The Proton Improvement Plan (PIP-II) to the FNAL accelerator chain and the
Long-Baseline Neutrino Facility (LBNF) will provide the world's most intense
neutrino beam to the Deep Underground Neutrino Experiment (DUNE) enabling a
wide-ranging physics program. This document outlines the significant
contributions made by European national laboratories and institutes towards
realizing the first phase of the project with a 1.2 MW neutrino beam.
Construction of this first phase is well underway. For DUNE Phase II, this will
be closely followed by an upgrade of the beam power to > 2 MW, for which the
European groups again have a key role and which will require the continued
support of the European community for machine aspects of neutrino physics.
Beyond the neutrino beam aspects, LBNF is also responsible for providing unique
infrastructure to install and operate the DUNE neutrino detectors at FNAL and
at the Sanford Underground Research Facility (SURF). The cryostats for the
first two Liquid Argon Time Projection Chamber detector modules at SURF, a
contribution of CERN to LBNF, are central to the success of the ongoing
execution of DUNE Phase I. Likewise, successful and timely procurement of
cryostats for two additional detector modules at SURF will be critical to the
success of DUNE Phase II and the overall physics program. The DUNE
Collaboration is submitting four main contributions to the 2026 Update of the
European Strategy for Particle Physics process. This paper is being submitted
to the 'Accelerator technologies' and 'Projects and Large Experiments' streams.
Additional inputs related to the DUNE science program, DUNE detector
technologies and R&D, and DUNE software and computing, are also being submitted
to other streams.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23695v1' target='_blank'>United States Muon Collider Community White Paper for the European
  Strategy for Particle Physics Update</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:M. Begel, P. Bhat, N. Craig, S. Dasu, K. DiPetrillo, S. Gourlay, T. Holmes, S. Jindariani, P. Meade, S. Pagan-Griso, M. Palmer, D. Stratakis, A. Abdelhamid, D. Acosta, P. Affleck, G. Agarwal, K. Agashe, P. Agrawal, B. Allmond, D. Ally, G. Ambrosio, O. Amram, A. Apresyan, C. Aruta, C. Arzate, P. Asadi, S. Ashanujjaman, J. Ashley, J. Backus, R. Bartek, A. Batz, L. Bauerdick, C. Bell, S. Belomestnykh, J. Scott Berg, D. Berry, J. Berryhill, S. Bhattacharya, I. Bigaran, O. Bitter, K. Black, K. Bloom, S. Alex Bogacz, J. Bonilla, T. Bose, D. Bourilkov, G. Brooijmans, E. Brost, D. Brown, M. Buen-Abad, J. Butler, C. Campagnari, M. Campana, A. Canepa, R. Capdevilla, K. Capobianco-Hogan, C. Cesarotti, Z. Chacko, P. Chang, S. Chang, S. Chekanov, Y. Chien, W. Han Chiu, W. Chung, R. Clark, C. Cox, M. Cremonesi, C. Csaki, G. Cummings, D. Curtin, S. Das Bakshi, A. Datta, H. de la Torre Perez, S. Demers, D. Denisov, R. Dermisek, J. Dervan, A. Dhar, D. Diaz, M. Dittrich, T. Du, J. Duarte, I. Dutta, J. Dutta, B. Echenard, J. Eldred, P. Elmer, G. Eremeev, N. Evans, P. Everaerts, J. Fan, S. Ferrante, S. Ferraro, T. Figy, M. Forslund, P. Fox, M. Franklin, K. Fraser, A. Freitas, A. Gandrakota, A. Gaponenko, M. Garcia-Sciveres, R. Garg, C. Geddes, S. Gessner, A. Sofia Giannakopoulou, S. Gleyzer, D. Green, L. Grossman, Y. Grossman, D. Guerrero, T. Han, S. Hedges, T. Heim, M. Herndon, G. Herrera, C. Herwig, S. Homiller, A. Hook, A. Hoover, W. Hopkins, M. Hostert, J. Howard, J. Hoya, P. Huber, R. Husain, B. Jayatilaka, L. Jeanty, D. Jenkins, D. Jiang, G. Kane, K. Kelly, K. Kennedy, C. Kianian, D. Kim, D. Kim, M. Kolosova, K. Kong, J. Konigsberg, S. Koren, A. Korytov, A. Kotwal, G. Konstantinos Krintiras, K. Hei Martin Kwok, S. Lammers, D. Lange, D. Larson, M. Larson, J. Lawless, C. Lee, L. Lee, L. Le Pottier, I. Lewis, L. Li, P. Li, M. Liepe, G. Lima, M. Littmann, M. Liu, Z. Liu, A. Loeliger, V. Lombardo, S. Lomte, M. Low, X. Lu, T. Luo, N. Luongo, C. Madrid, S. Malik, A. Mallampalli, N. Manganelli, G. Marques-Tavares, Z. Marshall, V. Ingrid Martinez Outschoorn, K. Matchev, A. Mazzacane, N. McGinnis, C. McLean, D. Merenich, E. Mettner, C. Mills, D. Minic, M. Mironova, R. Mishra, C. Mitchell, A. Mohammadi, V. Morozov, S. Nahn, E. Nanni, A. Narayanan, M. Neubauer, D. Neuffer, C. Ng, D. Noonan, Y. Nosochkov, A. Novak, J. Offermann, I. Ojalvo, T. Oli, T. Orimoto, M. Othman, K. Panchal, V. Papadimitriou, A. Parikh, K. Pedro, F. Pellemoine, C. Pena, G. Penn, M. Perelstein, M. Peskin, A. Petrov, M. Pleier, S. Posen, R. Powers, S. Prestemon, M. Purohit, T. Raubenheimer, J. Qiang, L. Rainbolt, C. Rasmussen, A. Rastogi, M. Reece, I. Reed, L. Ricci, C. Riggall, R. Rimmer, B. Roberts, B. Rosser, L. Rozanov, R. Ruber, B. S Acharya, T. Sabitsch, M. Safdari, A. Safonov, D. Saltzberg, D. Sathyan, H. Schellman, C. Scherb, R. Schmitz, S. Seidel, E. Sexton-Kennedy, V. Sharma, V. Shiltsev, M. Shochet, I. Shoemaker, R. Simeon, B. Simons, E. Sledge, E. Smith, P. Snopok, S. Snyder, S. Spanier, G. Stancari, G. Stark, N. Strobbe, S. Stucci, J. Stupak, R. Sundrum, C. Thompson, E. Thompson, C. Thoreson, C. Tosciri, N. Tran, A. Tricoli, C. Tully, A. Tuna, I. Valenzuela Lombera, K. Van Tilburg, J. Vay, W. Vetens, C. Vuosalo, C. E. M. Wagner, B. Wang, C. Wang, L. Wang, Z. Wang, J. Watts, M. Williams, H. Witte, J. Womersley, D. Wood, Y. Wu, K. Xie, S. Xie, W. Linda Xu, A. Yagil, K. Yonehara, B. Yu, T. Yu, R. Luz Zamora Peinado, G. Zecchinelli, J. Zhang, Y. Zhong, I. Zoi, J. Zupan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 03:48:33</h6>
<p class='card-text'>This document is being submitted to the 2024-2026 European Strategy for
Particle Physics Update (ESPPU) process on behalf of the US Muon Collider
community, with its preparation coordinated by the interim US Muon Collider
Coordination Group. The US Muon Collider Community comprises a few hundred
American scientists. The purpose of the document is to inform ESPPU about the
US plans for Muon Collider research and development (R&D), explain how these
efforts align with the broader international R&D initiatives, and present the
US community vision for the future realization of this transformative project.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23650v1' target='_blank'>A Survey of Reinforcement Learning-Based Motion Planning for Autonomous
  Driving: Lessons Learned from a Driving Task Perspective</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuoren Li, Guizhe Jin, Ran Yu, Zhiwen Chen, Nan Li, Wei Han, Lu Xiong, Bo Leng, Jia Hu, Ilya Kolmanovsky, Dimitar Filev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-31 01:31:14</h6>
<p class='card-text'>Reinforcement learning (RL), with its ability to explore and optimize
policies in complex, dynamic decision-making tasks, has emerged as a promising
approach to addressing motion planning (MoP) challenges in autonomous driving
(AD). Despite rapid advancements in RL and AD, a systematic description and
interpretation of the RL design process tailored to diverse driving tasks
remains underdeveloped. This survey provides a comprehensive review of RL-based
MoP for AD, focusing on lessons from task-specific perspectives. We first
outline the fundamentals of RL methodologies, and then survey their
applications in MoP, analyzing scenario-specific features and task requirements
to shed light on their influence on RL design choices. Building on this
analysis, we summarize key design experiences, extract insights from various
driving task applications, and provide guidance for future implementations.
Additionally, we examine the frontier challenges in RL-based MoP, review recent
efforts to addresse these challenges, and propose strategies for overcoming
unresolved issues.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23486v1' target='_blank'>A Systematic Decade Review of Trip Route Planning with Travel Time
  Estimation based on User Preferences and Behavior</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nikil Jayasuriya, Deshan Sumanathilaka</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-30 15:41:44</h6>
<p class='card-text'>This paper systematically explores the advancements in adaptive trip route
planning and travel time estimation (TTE) through Artificial Intelligence (AI).
With the increasing complexity of urban transportation systems, traditional
navigation methods often struggle to accommodate dynamic user preferences,
real-time traffic conditions, and scalability requirements. This study explores
the contributions of established AI techniques, including Machine Learning
(ML), Reinforcement Learning (RL), and Graph Neural Networks (GNNs), alongside
emerging methodologies like Meta-Learning, Explainable AI (XAI), Generative AI,
and Federated Learning. In addition to highlighting these innovations, the
paper identifies critical challenges such as ethical concerns, computational
scalability, and effective data integration, which must be addressed to advance
the field. The paper concludes with recommendations for leveraging AI to build
efficient, transparent, and sustainable navigation systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23463v1' target='_blank'>OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision
  Language Action Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xingcheng Zhou, Xuyuan Han, Feng Yang, Yunpu Ma, Alois C. Knoll</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-30 14:45:54</h6>
<p class='card-text'>We present OpenDriveVLA, a Vision-Language Action (VLA) model designed for
end-to-end autonomous driving. OpenDriveVLA builds upon open-source pre-trained
large Vision-Language Models (VLMs) to generate reliable driving actions,
conditioned on 3D environmental perception, ego vehicle states, and driver
commands. To bridge the modality gap between driving visual representations and
language embeddings, we propose a hierarchical vision-language alignment
process, projecting both 2D and 3D structured visual tokens into a unified
semantic space. Besides, OpenDriveVLA models the dynamic relationships between
the ego vehicle, surrounding agents, and static road elements through an
autoregressive agent-env-ego interaction process, ensuring both spatially and
behaviorally informed trajectory planning. Extensive experiments on the
nuScenes dataset demonstrate that OpenDriveVLA achieves state-of-the-art
results across open-loop trajectory planning and driving-related
question-answering tasks. Qualitative analyses further illustrate
OpenDriveVLA's superior capability to follow high-level driving commands and
robustly generate trajectories under challenging scenarios, highlighting its
potential for next-generation end-to-end autonomous driving. We will release
our code to facilitate further research in this domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23374v1' target='_blank'>RuleAgent: Discovering Rules for Recommendation Denoising with
  Autonomous Language Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zongwei Wang, Min Gao, Junliang Yu, Yupeng Hou, Shazia Sadiq, Hongzhi Yin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-30 09:19:03</h6>
<p class='card-text'>The implicit feedback (e.g., clicks) in real-world recommender systems is
often prone to severe noise caused by unintentional interactions, such as
misclicks or curiosity-driven behavior. A common approach to denoising this
feedback is manually crafting rules based on observations of training loss
patterns. However, this approach is labor-intensive and the resulting rules
often lack generalization across diverse scenarios. To overcome these
limitations, we introduce RuleAgent, a language agent based framework which
mimics real-world data experts to autonomously discover rules for
recommendation denoising. Unlike the high-cost process of manual rule mining,
RuleAgent offers rapid and dynamic rule discovery, ensuring adaptability to
evolving data and varying scenarios. To achieve this, RuleAgent is equipped
with tailored profile, memory, planning, and action modules and leverages
reflection mechanisms to enhance its reasoning capabilities for rule discovery.
Furthermore, to avoid the frequent retraining in rule discovery, we propose
LossEraser-an unlearning strategy that streamlines training without
compromising denoising performance. Experiments on benchmark datasets
demonstrate that, compared with existing denoising methods, RuleAgent not only
derives the optimal recommendation performance but also produces generalizable
denoising rules, assisting researchers in efficient data cleaning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23368v1' target='_blank'>Towards Physically Plausible Video Generation via VLM Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xindi Yang, Baolu Li, Yiming Zhang, Zhenfei Yin, Lei Bai, Liqian Ma, Zhiyong Wang, Jianfei Cai, Tien-Tsin Wong, Huchuan Lu, Xu Jia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-30 09:03:09</h6>
<p class='card-text'>Video diffusion models (VDMs) have advanced significantly in recent years,
enabling the generation of highly realistic videos and drawing the attention of
the community in their potential as world simulators. However, despite their
capabilities, VDMs often fail to produce physically plausible videos due to an
inherent lack of understanding of physics, resulting in incorrect dynamics and
event sequences. To address this limitation, we propose a novel two-stage
image-to-video generation framework that explicitly incorporates physics. In
the first stage, we employ a Vision Language Model (VLM) as a coarse-grained
motion planner, integrating chain-of-thought and physics-aware reasoning to
predict a rough motion trajectories/changes that approximate real-world
physical dynamics while ensuring the inter-frame consistency. In the second
stage, we use the predicted motion trajectories/changes to guide the video
generation of a VDM. As the predicted motion trajectories/changes are rough,
noise is added during inference to provide freedom to the VDM in generating
motion with more fine details. Extensive experimental results demonstrate that
our framework can produce physically plausible motion, and comparative
evaluations highlight the notable superiority of our approach over existing
methods. More video results are available on our Project Page:
https://madaoer.github.io/projects/physically_plausible_video_generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23328v1' target='_blank'>Generalized Capacity Planning for the Hospital-Residents Problem</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haricharan Balasundaram, Girija Limaye, Meghana Nasre, Abhinav Raja</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-30 06:06:34</h6>
<p class='card-text'>The Hospital Residents setting models important problems like school choice,
assignment of undergraduate students to degree programs, among many others. In
this setting, fixed quotas are associated with the programs that limit the
number of agents that can be assigned to them. Motivated by scenarios where all
agents must be matched, we propose and study a generalized capacity planning
problem, which allows cost-controlled flexibility with respect to quotas.
  Our setting is an extension of the Hospital Resident setting where programs
have the usual quota as well as an associated cost, indicating the cost of
matching an agent beyond the initial quotas. We seek to compute a matching that
matches all agents and is optimal with respect to preferences, and minimizes
either a local or a global objective on cost.
  We show that there is a sharp contrast -- minimizing the local objective is
polynomial-time solvable, whereas minimizing the global objective is NP-hard.
On the positive side, we present approximation algorithms for the global
objective in the general case and a particular hard case. We achieve the
approximation guarantee for the special hard case via a linear programming
based algorithm. We strengthen the NP-hardness by showing a matching lower
bound to our algorithmic result.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23326v1' target='_blank'>Exploring Explainable Multi-player MCTS-minimax Hybrids in Board Game
  Using Process Mining</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiyu Qian, Tim Miller, Zheng Qian, Liyuan Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-30 05:48:53</h6>
<p class='card-text'>Monte-Carlo Tree Search (MCTS) is a family of sampling-based search
algorithms widely used for online planning in sequential decision-making
domains and at the heart of many recent advances in artificial intelligence.
Understanding the behavior of MCTS agents is difficult for developers and users
due to the frequently large and complex search trees that result from the
simulation of many possible futures, their evaluations, and their
relationships. This paper presents our ongoing investigation into potential
explanations for the decision-making and behavior of MCTS. A weakness of MCTS
is that it constructs a highly selective tree and, as a result, can miss
crucial moves and fall into tactical traps. Full-width minimax search
constitutes the solution. We integrate shallow minimax search into the rollout
phase of multi-player MCTS and use process mining technique to explain agents'
strategies in 3v3 checkers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23255v1' target='_blank'>Iterative VCG-based Mechanism Fosters Cooperation in Multi-Regional
  Network Design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingjia He, Yannik Werner, Andrea Censi, Emilio Frazzoli, Gioele Zardini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-29 23:40:30</h6>
<p class='card-text'>Transportation network design often involves multiple stakeholders with
diverse priorities. We consider a system with a hierarchical multi-agent
structure, featuring self-optimized subnetwork operators at the lower level and
a central organization at the upper level. Independent regional planning can
lead to inefficiencies due to the lack of coordination, hindering interregional
travel and cross-border infrastructure development, while centralized methods
may struggle to align local interests and can be impractical to implement. To
support decision making for such a system, we introduce an iterative VCG-based
mechanism for multi-regional network design that fosters cooperation among
subnetwork operators. By leveraging the Vickery-Clarke-Groves (VCG) mechanism,
the framework determines collective investment decisions and the necessary
payments from both operators and the central organization to achieve efficient
outcomes. A case study on the European Railway System validates the
effectiveness of the proposed method, demonstrating significant improvements in
overall network performance through enhanced cross-region cooperation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23228v1' target='_blank'>Energy-Aware Lane Planning for Connected Electric Vehicles in Urban
  Traffic: Design and Vehicle-in-the-Loop Validation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hansung Kim, Eric Yongkeun Choi, Eunhyek Joa, Hotae Lee, Linda Lim, Scott Moura, Francesco Borrelli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-29 21:19:22</h6>
<p class='card-text'>Urban driving with connected and automated vehicles (CAVs) offers potential
for energy savings, yet most eco-driving strategies focus solely on
longitudinal speed control within a single lane. This neglects the significant
impact of lateral decisions, such as lane changes, on overall energy
efficiency, especially in environments with traffic signals and heterogeneous
traffic flow. To address this gap, we propose a novel energy-aware motion
planning framework that jointly optimizes longitudinal speed and lateral
lane-change decisions using vehicle-to-infrastructure (V2I) communication. Our
approach estimates long-term energy costs using a graph-based approximation and
solves short-horizon optimal control problems under traffic constraints. Using
a data-driven energy model calibrated to an actual battery electric vehicle, we
demonstrate with vehicle-in-the-loop experiments that our method reduces motion
energy consumption by up to 24 percent compared to a human driver, highlighting
the potential of connectivity-enabled planning for sustainable urban autonomy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23204v1' target='_blank'>The Challenge of Achieving Attributability in Multilingual Table-to-Text
  Generation with Question-Answer Blueprints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aden Haussmann</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-29 20:04:00</h6>
<p class='card-text'>Multilingual Natural Language Generation (NLG) is challenging due to the lack
of training data for low-resource languages. However, some low-resource
languages have up to tens of millions of speakers globally, making it important
to improve NLG tools for them. Table-to-Text NLG is an excellent measure of
models' reasoning abilities but is very challenging in the multilingual
setting. System outputs are often not attributable, or faithful, to the data in
the source table. Intermediate planning techniques like Question-Answer (QA)
blueprints have been shown to improve attributability on summarisation tasks.
This work explores whether QA blueprints make multilingual Table-to-Text
outputs more attributable to the input tables. This paper extends the
challenging multilingual Table-to-Text dataset, TaTA, which includes African
languages, with QA blueprints. Sequence-to-sequence language models are then
finetuned on this dataset, with and without blueprints. Results show that QA
blueprints improve performance for models finetuned and evaluated only on
English examples, but do not demonstrate gains in the multilingual setting.
This is due to inaccuracies in machine translating the blueprints from English
into target languages when generating the training data, and models failing to
rely closely on the blueprints they generate. An in-depth analysis is conducted
on why this is challenging.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.23179v2' target='_blank'>OncoReg: Medical Image Registration for Oncological Challenges</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wiebke Heyer, Yannic Elser, Lennart Berkel, Xinrui Song, Xuanang Xu, Pingkun Yan, Xi Jia, Jinming Duan, Zi Li, Tony C. W. Mok, BoWen LI, Christian Staackmann, Christoph Großbröhmer, Lasse Hansen, Alessa Hering, Malte M. Sieren, Mattias P. Heinrich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-29 18:16:10</h6>
<p class='card-text'>In modern cancer research, the vast volume of medical data generated is often
underutilised due to challenges related to patient privacy. The OncoReg
Challenge addresses this issue by enabling researchers to develop and validate
image registration methods through a two-phase framework that ensures patient
privacy while fostering the development of more generalisable AI models. Phase
one involves working with a publicly available dataset, while phase two focuses
on training models on a private dataset within secure hospital networks.
OncoReg builds upon the foundation established by the Learn2Reg Challenge by
incorporating the registration of interventional cone-beam computed tomography
(CBCT) with standard planning fan-beam CT (FBCT) images in radiotherapy.
Accurate image registration is crucial in oncology, particularly for dynamic
treatment adjustments in image-guided radiotherapy, where precise alignment is
necessary to minimise radiation exposure to healthy tissues while effectively
targeting tumours. This work details the methodology and data behind the
OncoReg Challenge and provides a comprehensive analysis of the competition
entries and results. Findings reveal that feature extraction plays a pivotal
role in this registration task. A new method emerging from this challenge
demonstrated its versatility, while established approaches continue to perform
comparably to newer techniques. Both deep learning and classical approaches
still play significant roles in image registration, with the combination of
methods - particularly in feature extraction - proving most effective.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>