<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-03-02</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-03-02</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20386v1' target='_blank'>ATLAS Navigator: Active Task-driven LAnguage-embedded Gaussian Splatting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dexter Ong, Yuezhan Tao, Varun Murali, Igor Spasojevic, Vijay Kumar, Pratik Chaudhari</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 18:58:04</h6>
<p class='card-text'>We address the challenge of task-oriented navigation in unstructured and
unknown environments, where robots must incrementally build and reason on rich,
metric-semantic maps in real time. Since tasks may require clarification or
re-specification, it is necessary for the information in the map to be rich
enough to enable generalization across a wide range of tasks. To effectively
execute tasks specified in natural language, we propose a hierarchical
representation built on language-embedded Gaussian splatting that enables both
sparse semantic planning that lends itself to online operation and dense
geometric representation for collision-free navigation. We validate the
effectiveness of our method through real-world robot experiments conducted in
both cluttered indoor and kilometer-scale outdoor environments, with a
competitive ratio of about 60% against privileged baselines. Experiment videos
and more details can be found on our project page: https://atlasnav.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20382v1' target='_blank'>Physics-Driven Data Generation for Contact-Rich Manipulation via
  Trajectory Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lujie Yang, H. J. Terry Suh, Tong Zhao, Bernhard Paus Graesdal, Tarik Kelestemur, Jiuguang Wang, Tao Pang, Russ Tedrake</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 18:56:01</h6>
<p class='card-text'>We present a low-cost data generation pipeline that integrates physics-based
simulation, human demonstrations, and model-based planning to efficiently
generate large-scale, high-quality datasets for contact-rich robotic
manipulation tasks. Starting with a small number of embodiment-flexible human
demonstrations collected in a virtual reality simulation environment, the
pipeline refines these demonstrations using optimization-based kinematic
retargeting and trajectory optimization to adapt them across various robot
embodiments and physical parameters. This process yields a diverse, physically
consistent dataset that enables cross-embodiment data transfer, and offers the
potential to reuse legacy datasets collected under different hardware
configurations or physical parameters. We validate the pipeline's effectiveness
by training diffusion policies from the generated datasets for challenging
contact-rich manipulation tasks across multiple robot embodiments, including a
floating Allegro hand and bimanual robot arms. The trained policies are
deployed zero-shot on hardware for bimanual iiwa arms, achieving high success
rates with minimal human input. Project website:
https://lujieyang.github.io/physicsgen/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20371v1' target='_blank'>Constrained Generative Modeling with Manually Bridged Diffusion Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saeid Naderiparizi, Xiaoxuan Liang, Berend Zwartsenberg, Frank Wood</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 18:41:46</h6>
<p class='card-text'>In this paper we describe a novel framework for diffusion-based generative
modeling on constrained spaces. In particular, we introduce manual bridges, a
framework that expands the kinds of constraints that can be practically used to
form so-called diffusion bridges. We develop a mechanism for combining multiple
such constraints so that the resulting multiply-constrained model remains a
manual bridge that respects all constraints. We also develop a mechanism for
training a diffusion model that respects such multiple constraints while also
adapting it to match a data distribution. We develop and extend theory
demonstrating the mathematical validity of our mechanisms. Additionally, we
demonstrate our mechanism in constrained generative modeling tasks,
highlighting a particular high-value application in modeling trajectory
initializations for path planning and control in autonomous vehicles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20369v1' target='_blank'>Multi-Agent Path Planning in Complex Environments using Gaussian Belief
  Propagation with Global Path Finding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jens Høigaard Jensen, Kristoffer Plagborg Bak Sørensen, Jonas le Fevre Sejersen, Andriy Sarabakha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 18:37:49</h6>
<p class='card-text'>Multi-agent path planning is a critical challenge in robotics, requiring
agents to navigate complex environments while avoiding collisions and
optimizing travel efficiency. This work addresses the limitations of existing
approaches by combining Gaussian belief propagation with path integration and
introducing a novel tracking factor to ensure strict adherence to global paths.
The proposed method is tested with two different global path-planning
approaches: rapidly exploring random trees and a structured planner, which
leverages predefined lane structures to improve coordination. A simulation
environment was developed to validate the proposed method across diverse
scenarios, each posing unique challenges in navigation and communication.
Simulation results demonstrate that the tracking factor reduces path deviation
by 28% in single-agent and 16% in multi-agent scenarios, highlighting its
effectiveness in improving multi-agent coordination, especially when combined
with structured global planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20367v1' target='_blank'>The Role of Tactile Sensing for Learning Reach and Grasp</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Boya Zhang, Iris Andrussow, Andreas Zell, Georg Martius</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 18:36:37</h6>
<p class='card-text'>Stable and robust robotic grasping is essential for current and future robot
applications. In recent works, the use of large datasets and supervised
learning has enhanced speed and precision in antipodal grasping. However, these
methods struggle with perception and calibration errors due to large planning
horizons. To obtain more robust and reactive grasping motions, leveraging
reinforcement learning combined with tactile sensing is a promising direction.
Yet, there is no systematic evaluation of how the complexity of force-based
tactile sensing affects the learning behavior for grasping tasks. This paper
compares various tactile and environmental setups using two model-free
reinforcement learning approaches for antipodal grasping. Our findings suggest
that under imperfect visual perception, various tactile features improve
learning outcomes, while complex tactile inputs complicate training.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20317v1' target='_blank'>Mixture of Structural-and-Textual Retrieval over Text-rich Graph
  Knowledge Bases</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yongjia Lei, Haoyu Han, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka, Mahantesh M Halappanavar, Jiliang Tang, Yu Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 17:42:52</h6>
<p class='card-text'>Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for
answering queries by providing textual and structural knowledge. However,
current retrieval methods often retrieve these two types of knowledge in
isolation without considering their mutual reinforcement and some hybrid
methods even bypass structural retrieval entirely after neighboring
aggregation. To fill in this gap, we propose a Mixture of
Structural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge
via a Planning-Reasoning-Organizing framework. In the Planning stage, MoR
generates textual planning graphs delineating the logic for answering queries.
Following planning graphs, in the Reasoning stage, MoR interweaves structural
traversal and textual matching to obtain candidates from TG-KBs. In the
Organizing stage, MoR further reranks fetched candidates based on their
structural trajectory. Extensive experiments demonstrate the superiority of MoR
in harmonizing structural and textual retrieval with insights, including uneven
retrieving performance across different query logics and the benefits of
integrating structural trajectories for candidate reranking. Our code is
available at https://github.com/Yoega/MoR.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20217v1' target='_blank'>MARVEL: Multi-Agent Reinforcement Learning for constrained field-of-View
  multi-robot Exploration in Large-scale environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jimmy Chiun, Shizhe Zhang, Yizhuo Wang, Yuhong Cao, Guillaume Sartoretti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 15:58:42</h6>
<p class='card-text'>In multi-robot exploration, a team of mobile robot is tasked with efficiently
mapping an unknown environments. While most exploration planners assume
omnidirectional sensors like LiDAR, this is impractical for small robots such
as drones, where lightweight, directional sensors like cameras may be the only
option due to payload constraints. These sensors have a constrained
field-of-view (FoV), which adds complexity to the exploration problem,
requiring not only optimal robot positioning but also sensor orientation during
movement. In this work, we propose MARVEL, a neural framework that leverages
graph attention networks, together with novel frontiers and orientation
features fusion technique, to develop a collaborative, decentralized policy
using multi-agent reinforcement learning (MARL) for robots with constrained
FoV. To handle the large action space of viewpoints planning, we further
introduce a novel information-driven action pruning strategy. MARVEL improves
multi-robot coordination and decision-making in challenging large-scale indoor
environments, while adapting to various team sizes and sensor configurations
(i.e., FoV and sensor range) without additional training. Our extensive
evaluation shows that MARVEL's learned policies exhibit effective coordinated
behaviors, outperforming state-of-the-art exploration planners across multiple
metrics. We experimentally demonstrate MARVEL's generalizability in large-scale
environments, of up to 90m by 90m, and validate its practical applicability
through successful deployment on a team of real drone hardware.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20178v1' target='_blank'>SSD: A State-based Stealthy Backdoor Attack For Navigation System in UAV
  Route Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaoxuan Wang, Yang Li, Jie Zhang, Xingshuo Han, Kangbo Liu, Lyu Yang, yuan Zhou, Tianwei Zhang, Quan Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 15:17:58</h6>
<p class='card-text'>Unmanned aerial vehicles (UAVs) are increasingly employed to perform
high-risk tasks that require minimal human intervention. However, UAVs face
escalating cybersecurity threats, particularly from GNSS spoofing attacks.
While previous studies have extensively investigated the impacts of GNSS
spoofing on UAVs, few have focused on its effects on specific tasks. Moreover,
the influence of UAV motion states on the assessment of network security risks
is often overlooked. To address these gaps, we first provide a detailed
evaluation of how motion states affect the effectiveness of network attacks. We
demonstrate that nonlinear motion states not only enhance the effectiveness of
position spoofing in GNSS spoofing attacks but also reduce the probability of
speed-related attack detection. Building upon this, we propose a
state-triggered backdoor attack method (SSD) to deceive GNSS systems and assess
its risk to trajectory planning tasks. Extensive validation of SSD's
effectiveness and stealthiness is conducted. Experimental results show that,
with appropriately tuned hyperparameters, SSD significantly increases
positioning errors and the risk of task failure, while maintaining 100% stealth
across three state-of-the-art detectors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20168v1' target='_blank'>Accelerating Model-Based Reinforcement Learning with State-Space World
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maria Krinner, Elie Aljalbout, Angel Romero, Davide Scaramuzza</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 15:05:25</h6>
<p class='card-text'>Reinforcement learning (RL) is a powerful approach for robot learning.
However, model-free RL (MFRL) requires a large number of environment
interactions to learn successful control policies. This is due to the noisy RL
training updates and the complexity of robotic systems, which typically involve
highly non-linear dynamics and noisy sensor signals. In contrast, model-based
RL (MBRL) not only trains a policy but simultaneously learns a world model that
captures the environment's dynamics and rewards. The world model can either be
used for planning, for data collection, or to provide first-order policy
gradients for training. Leveraging a world model significantly improves sample
efficiency compared to model-free RL. However, training a world model alongside
the policy increases the computational complexity, leading to longer training
times that are often intractable for complex real-world scenarios. In this
work, we propose a new method for accelerating model-based RL using state-space
world models. Our approach leverages state-space models (SSMs) to parallelize
the training of the dynamics model, which is typically the main computational
bottleneck. Additionally, we propose an architecture that provides privileged
information to the world model during training, which is particularly relevant
for partially observable environments. We evaluate our method in several
real-world agile quadrotor flight tasks, involving complex dynamics, for both
fully and partially observable environments. We demonstrate a significant
speedup, reducing the world model training time by up to 10 times, and the
overall MBRL training time by up to 4 times. This benefit comes without
compromising performance, as our method achieves similar sample efficiency and
task rewards to state-of-the-art MBRL methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20132v1' target='_blank'>Regional climate projections using a deep learning--based model-ranking
  and downscaling framework: Application to European climate zones</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Parthiban Loganathan, Elias Zea, Ricardo Vinuesa, Evelyn Otero</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 14:27:09</h6>
<p class='card-text'>Accurate regional climate forecast calls for high-resolution downscaling of
Global Climate Models (GCMs). This work presents a deep-learning-based
multi-model evaluation and downscaling framework ranking 32 Coupled Model
Intercomparison Project Phase 6 (CMIP6) models using a Deep Learning-TOPSIS
(DL-TOPSIS) mechanism and so refines outputs using advanced deep-learning
models. Using nine performance criteria, five K\"oppen-Geiger climate zones --
Tropical, Arid, Temperate, Continental, and Polar -- are investigated over four
seasons. While TaiESM1 and CMCC-CM2-SR5 show notable biases, ranking results
show that NorESM2-LM, GISS-E2-1-G, and HadGEM3-GC31-LL outperform other models.
Four models contribute to downscaling the top-ranked GCMs to 0.1$^{\circ}$
resolution: Vision Transformer (ViT), Geospatial Spatiotemporal Transformer
with Attention and Imbalance-Aware Network (GeoSTANet), CNN-LSTM, and CNN-Long
Short-Term Memory (ConvLSTM). Effectively capturing temperature extremes (TXx,
TNn), GeoSTANet achieves the highest accuracy (Root Mean Square Error (RMSE) =
1.57$^{\circ}$C, Kling-Gupta Efficiency (KGE) = 0.89, Nash-Sutcliffe Efficiency
(NSE) = 0.85, Correlation ($r$) = 0.92), so reducing RMSE by 20\% over
ConvLSTM. CNN-LSTM and ConvLSTM do well in Continental and Temperate zones; ViT
finds fine-scale temperature fluctuations difficult. These results confirm that
multi-criteria ranking improves GCM selection for regional climate studies and
transformer-based downscaling exceeds conventional deep-learning methods. This
framework offers a scalable method to enhance high-resolution climate
projections, benefiting impact assessments and adaptation plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20108v1' target='_blank'>VDT-Auto: End-to-end Autonomous Driving with VLM-Guided Diffusion
  Transformers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziang Guo, Konstantin Gubernatorov, Selamawit Asfaw, Zakhar Yagudin, Dzmitry Tsetserukou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 14:02:14</h6>
<p class='card-text'>In autonomous driving, dynamic environment and corner cases pose significant
challenges to the robustness of ego vehicle's decision-making. To address these
challenges, commencing with the representation of state-action mapping in the
end-to-end autonomous driving paradigm, we introduce a novel pipeline,
VDT-Auto. Leveraging the advancement of the state understanding of Visual
Language Model (VLM), incorporating with diffusion Transformer-based action
generation, our VDT-Auto parses the environment geometrically and contextually
for the conditioning of the diffusion process. Geometrically, we use a
bird's-eye view (BEV) encoder to extract feature grids from the surrounding
images. Contextually, the structured output of our fine-tuned VLM is processed
into textual embeddings and noisy paths. During our diffusion process, the
added noise for the forward process is sampled from the noisy path output of
the fine-tuned VLM, while the extracted BEV feature grids and embedded texts
condition the reverse process of our diffusion Transformers. Our VDT-Auto
achieved 0.52m on average L2 errors and 21% on average collision rate in the
nuScenes open-loop planning evaluation. Moreover, the real-world demonstration
exhibited prominent generalizability of our VDT-Auto. The code and dataset will
be released after acceptance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20106v1' target='_blank'>Pushing Through Clutter With Movability Awareness of Blocking Obstacles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joris J. Weeda, Saray Bakker, Gang Chen, Javier Alonso-Mora</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 14:00:29</h6>
<p class='card-text'>Navigation Among Movable Obstacles (NAMO) poses a challenge for traditional
path-planning methods when obstacles block the path, requiring push actions to
reach the goal. We propose a framework that enables movability-aware planning
to overcome this challenge without relying on explicit obstacle placement. Our
framework integrates a global Semantic Visibility Graph and a local Model
Predictive Path Integral (SVG-MPPI) approach to efficiently sample rollouts,
taking into account the continuous range of obstacle movability. A physics
engine is adopted to simulate the interaction result of the rollouts with the
environment, and generate trajectories that minimize contact force. In
qualitative and quantitative experiments, SVG-MPPI outperforms the existing
paradigm that uses only binary movability for planning, achieving higher
success rates with reduced cumulative contact forces. Our code is available at:
https://github.com/tud-amr/SVG-MPPI</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20021v1' target='_blank'>Systems-of-Systems for Environmental Sustainability: A Systematic
  Mapping Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ana Clara Araújo Gomes da Silva, Gilmar Teixeira Junior, Lívia Mancine C. de Campos, Renato F. Bulcão-Neto, Valdemar Vicente Graciano Neto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 12:00:27</h6>
<p class='card-text'>Environmental sustainability in Systems-of-Systems (SoS) is an emerging field
that seeks to integrate technological solutions to promote the efficient
management of natural resources. While systematic reviews address
sustainability in the context of Smart Cities (a category of SoS), a systematic
study synthesizing the existing knowledge on environmental sustainability
applied to SoS in general does not exist. Although literature includes other
types of sustainability, such as financial and social, this study focuses on
environmental sustainability, analyzing how SoS contribute to sustainable
practices such as carbon emission reduction, energy efficiency, and
biodiversity conservation. We conducted a Systematic Mapping Study to identify
the application domains of SoS in sustainability, the challenges faced, and
research opportunities. We planned and executed a research protocol including
an automated search over four scientific databases. Of 926 studies retrieved,
we selected, analyzed, and reported the results of 39 relevant studies. Our
findings reveal that most studies focus on Smart Cities and Smart Grids, while
applications such as sustainable agriculture and wildfire prevention are less
explored. We identified challenges such as system interoperability,
scalability, and data governance. Finally, we propose future research
directions for SoS and environmental sustainability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19908v1' target='_blank'>CarPlanner: Consistent Auto-regressive Trajectory Planning for
  Large-scale Reinforcement Learning in Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dongkun Zhang, Jiaming Liang, Ke Guo, Sha Lu, Qi Wang, Rong Xiong, Zhenwei Miao, Yue Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 09:26:22</h6>
<p class='card-text'>Trajectory planning is vital for autonomous driving, ensuring safe and
efficient navigation in complex environments. While recent learning-based
methods, particularly reinforcement learning (RL), have shown promise in
specific scenarios, RL planners struggle with training inefficiencies and
managing large-scale, real-world driving scenarios. In this paper, we introduce
\textbf{CarPlanner}, a \textbf{C}onsistent \textbf{a}uto-\textbf{r}egressive
\textbf{Planner} that uses RL to generate multi-modal trajectories. The
auto-regressive structure enables efficient large-scale RL training, while the
incorporation of consistency ensures stable policy learning by maintaining
coherent temporal consistency across time steps. Moreover, CarPlanner employs a
generation-selection framework with an expert-guided reward function and an
invariant-view module, simplifying RL training and enhancing policy
performance. Extensive analysis demonstrates that our proposed RL framework
effectively addresses the challenges of training efficiency and performance
enhancement, positioning CarPlanner as a promising solution for trajectory
planning in autonomous driving. To the best of our knowledge, we are the first
to demonstrate that the RL-based planner can surpass both IL- and rule-based
state-of-the-arts (SOTAs) on the challenging large-scale real-world dataset
nuPlan. Our proposed CarPlanner surpasses RL-, IL-, and rule-based SOTA
approaches within this demanding dataset.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19902v1' target='_blank'>Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action
  Conditioned Policy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 09:18:04</h6>
<p class='card-text'>Building an agent that can mimic human behavior patterns to accomplish
various open-world tasks is a long-term goal. To enable agents to effectively
learn behavioral patterns across diverse tasks, a key challenge lies in
modeling the intricate relationships among observations, actions, and language.
To this end, we propose Optimus-2, a novel Minecraft agent that incorporates a
Multimodal Large Language Model (MLLM) for high-level planning, alongside a
Goal-Observation-Action Conditioned Policy (GOAP) for low-level control. GOAP
contains (1) an Action-guided Behavior Encoder that models causal relationships
between observations and actions at each timestep, then dynamically interacts
with the historical observation-action sequence, consolidating it into
fixed-length behavior tokens, and (2) an MLLM that aligns behavior tokens with
open-ended language instructions to predict actions auto-regressively.
Moreover, we introduce a high-quality Minecraft Goal-Observation-Action (MGOA)}
dataset, which contains 25,000 videos across 8 atomic tasks, providing about
30M goal-observation-action pairs. The automated construction method, along
with the MGOA dataset, can contribute to the community's efforts to train
Minecraft agents. Extensive experimental results demonstrate that Optimus-2
exhibits superior performance across atomic tasks, long-horizon tasks, and
open-ended instruction tasks in Minecraft.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19892v1' target='_blank'>ColorDynamic: Generalizable, Scalable, Real-time, End-to-end Local
  Planner for Unstructured and Dynamic Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinghao Xin, Zhichao Liang, Zihuan Zhang, Peng Wang, Ning Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 09:01:11</h6>
<p class='card-text'>Deep Reinforcement Learning (DRL) has demonstrated potential in addressing
robotic local planning problems, yet its efficacy remains constrained in highly
unstructured and dynamic environments. To address these challenges, this study
proposes the ColorDynamic framework. First, an end-to-end DRL formulation is
established, which maps raw sensor data directly to control commands, thereby
ensuring compatibility with unstructured environments. Under this formulation,
a novel network, Transqer, is introduced. The Transqer enables online DRL
learning from temporal transitions, substantially enhancing decision-making in
dynamic scenarios. To facilitate scalable training of Transqer with diverse
data, an efficient simulation platform E-Sparrow, along with a data
augmentation technique leveraging symmetric invariance, are developed.
Comparative evaluations against state-of-the-art methods, alongside assessments
of generalizability, scalability, and real-time performance, were conducted to
validate the effectiveness of ColorDynamic. Results indicate that our approach
achieves a success rate exceeding 90% while exhibiting real-time capacity
(1.2-1.3 ms per planning). Additionally, ablation studies were performed to
corroborate the contributions of individual components. Building on this, the
OkayPlan-ColorDynamic (OPCD) navigation system is presented, with simulated and
real-world experiments demonstrating its superiority and applicability in
complex scenarios. The codebase and experimental demonstrations have been
open-sourced on our website to facilitate reproducibility and further research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19890v1' target='_blank'>Physics-Informed Neural Networks for Optimal Vaccination Plan in SIR
  Epidemic Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minseok Kim, Yeongjong Kim, Yeoneung Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 08:59:22</h6>
<p class='card-text'>This work focuses on understanding the minimum eradication time for the
controlled Susceptible-Infectious-Recovered (SIR) model in the time-homogeneous
setting, where the infection and recovery rates are constant. The eradication
time is defined as the earliest time the infectious population drops below a
given threshold and remains below it. For time-homogeneous models, the
eradication time is well-defined due to the predictable dynamics of the
infectious population, and optimal control strategies can be systematically
studied. We utilize Physics-Informed Neural Networks (PINNs) to solve the
partial differential equation (PDE) governing the eradication time and derive
the corresponding optimal vaccination control. The PINN framework enables a
mesh-free solution to the PDE by embedding the dynamics directly into the loss
function of a deep neural network. We use a variable scaling method to ensure
stable training of PINN and mathematically analyze that this method is
effective in our setting. This approach provides an efficient computational
alternative to traditional numerical methods, allowing for an approximation of
the eradication time and the optimal control strategy. Through numerical
experiments, we validate the effectiveness of the proposed method in computing
the minimum eradication time and achieving optimal control. This work offers a
novel application of PINNs to epidemic modeling, bridging mathematical theory
and computational practice for time-homogeneous SIR models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19888v1' target='_blank'>Accessibility for Whom? Perceptions of Sidewalk Barriers Across
  Disability Groups and Implications for Designing Personalized Maps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chu Li, Rock Yuren Pang, Delphine Labbé, Yochai Eisenberg, Maryam Hosseini, Jon E. Froehlich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 08:48:47</h6>
<p class='card-text'>Despite diverse mobility needs worldwide, existing mapping tools fail to
address the varied experiences of different mobility device users. This paper
presents a large-scale online survey exploring how five mobility groups --
users of canes, walkers, mobility scooters, manual wheelchairs, and motorized
wheelchairs -- perceive sidewalk barriers. Using 52 sidewalk barrier images,
respondents evaluated their confidence in navigating each scenario. Our
findings (N=190) reveal variations in barrier perceptions across groups, while
also identifying shared concerns. To further demonstrate the value of this
data, we showcase its use in two custom prototypes: a visual analytics tool and
a personalized routing tool. Our survey findings and open dataset advance work
in accessibility-focused maps, routing algorithms, and urban planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19832v1' target='_blank'>Tracailer: An Efficient Trajectory Planner for Tractor-Trailer Vehicles
  in Unstructured Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Long Xu, Kaixin Chai, Boyuan An, Jiaxiang Gan, Qianhao Wang, Yuan Zhou, Xiaoying Li, Junxiao Lin, Zhichao Han, Chao Xu, Yanjun Cao, Fei Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 07:08:53</h6>
<p class='card-text'>The tractor-trailer vehicle (robot) consists of a drivable tractor and one or
more non-drivable trailers connected via hitches. Compared to typical car-like
robots, the addition of trailers provides greater transportation capability.
However, this also complicates motion planning due to the robot's complex
kinematics, high-dimensional state space, and deformable structure. To
efficiently plan safe, time-optimal trajectories that adhere to the kinematic
constraints of the robot and address the challenges posed by its unique
features, this paper introduces a lightweight, compact, and high-order smooth
trajectory representation for tractor-trailer robots. Based on it, we design an
efficiently solvable spatio-temporal trajectory optimization problem. To deal
with deformable structures, which leads to difficulties in collision avoidance,
we fully leverage the collision-free regions of the environment, directly
applying deformations to trajectories in continuous space. This approach not
requires constructing safe regions from the environment using convex
approximations through collision-free seed points before each optimization,
avoiding the loss of the solution space, thus reducing the dependency of the
optimization on initial values. Moreover, a multi-terminal fast path search
algorithm is proposed to generate the initial values for optimization.
Extensive simulation experiments demonstrate that our approach achieves
several-fold improvements in efficiency compared to existing algorithms, while
also ensuring lower curvature and trajectory duration. Real-world experiments
involving the transportation, loading and unloading of goods in both indoor and
outdoor scenarios further validate the effectiveness of our method. The source
code is accessible at https://github.com/ZJU-FAST-Lab/tracailer/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19823v1' target='_blank'>GraphSparseNet: a Novel Method for Large Scale Trafffic Flow Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiyang Kong, Kaiqi Wu, Sen Zhang, Yubao Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 06:51:20</h6>
<p class='card-text'>Traffic flow forecasting is a critical spatio-temporal data mining task with
wide-ranging applications in intelligent route planning and dynamic traffic
management. Recent advancements in deep learning, particularly through Graph
Neural Networks (GNNs), have significantly enhanced the accuracy of these
forecasts by capturing complex spatio-temporal dynamics. However, the
scalability of GNNs remains a challenge due to their exponential growth in
model complexity with increasing nodes in the graph. Existing methods to
address this issue, including sparsification, decomposition, and kernel-based
approaches, either do not fully resolve the complexity issue or risk
compromising predictive accuracy. This paper introduces GraphSparseNet (GSNet),
a novel framework designed to improve both the scalability and accuracy of
GNN-based traffic forecasting models. GraphSparseNet is comprised of two core
modules: the Feature Extractor and the Relational Compressor. These modules
operate with linear time and space complexity, thereby reducing the overall
computational complexity of the model to a linear scale. Our extensive
experiments on multiple real-world datasets demonstrate that GraphSparseNet not
only significantly reduces training time by 3.51x compared to state-of-the-art
linear models but also maintains high predictive performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19750v1' target='_blank'>CirT: Global Subseasonal-to-Seasonal Forecasting with Geometry-inspired
  Transformer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Liu, Zinan Zheng, Jiashun Cheng, Fugee Tsung, Deli Zhao, Yu Rong, Jia Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 04:26:23</h6>
<p class='card-text'>Accurate Subseasonal-to-Seasonal (S2S) climate forecasting is pivotal for
decision-making including agriculture planning and disaster preparedness but is
known to be challenging due to its chaotic nature. Although recent data-driven
models have shown promising results, their performance is limited by inadequate
consideration of geometric inductive biases. Usually, they treat the spherical
weather data as planar images, resulting in an inaccurate representation of
locations and spatial relations. In this work, we propose the
geometric-inspired Circular Transformer (CirT) to model the cyclic
characteristic of the graticule, consisting of two key designs: (1) Decomposing
the weather data by latitude into circular patches that serve as input tokens
to the Transformer; (2) Leveraging Fourier transform in self-attention to
capture the global information and model the spatial periodicity. Extensive
experiments on the Earth Reanalysis 5 (ERA5) reanalysis dataset demonstrate our
model yields a significant improvement over the advanced data-driven models,
including PanguWeather and GraphCast, as well as skillful ECMWF systems.
Additionally, we empirically show the effectiveness of our model designs and
high-quality prediction over spatial and temporal dimensions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19717v1' target='_blank'>Exponential Topology-enabled Scalable Communication in Multi-agent
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinran Li, Xiaolu Wang, Chenjia Bai, Jun Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 03:15:31</h6>
<p class='card-text'>In cooperative multi-agent reinforcement learning (MARL), well-designed
communication protocols can effectively facilitate consensus among agents,
thereby enhancing task performance. Moreover, in large-scale multi-agent
systems commonly found in real-world applications, effective communication
plays an even more critical role due to the escalated challenge of partial
observability compared to smaller-scale setups. In this work, we endeavor to
develop a scalable communication protocol for MARL. Unlike previous methods
that focus on selecting optimal pairwise communication links-a task that
becomes increasingly complex as the number of agents grows-we adopt a global
perspective on communication topology design. Specifically, we propose
utilizing the exponential topology to enable rapid information dissemination
among agents by leveraging its small-diameter and small-size properties. This
approach leads to a scalable communication protocol, named ExpoComm. To fully
unlock the potential of exponential graphs as communication topologies, we
employ memory-based message processors and auxiliary tasks to ground messages,
ensuring that they reflect global information and benefit decision-making.
Extensive experiments on large-scale cooperative benchmarks, including MAgent
and Infrastructure Management Planning, demonstrate the superior performance
and robust zero-shot transferability of ExpoComm compared to existing
communication strategies. The code is publicly available at
https://github.com/LXXXXR/ExpoComm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19690v1' target='_blank'>Risk-aware Integrated Task and Motion Planning for Versatile Snake
  Robots under Localization Failures</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ashkan Jasour, Guglielmo Daddi, Masafumi Endo, Tiago S. Vaquero, Michael Paton, Marlin P. Strub, Sabrina Corpino, Michel Ingham, Masahiro Ono, Rohan Thakker</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 02:02:51</h6>
<p class='card-text'>Snake robots enable mobility through extreme terrains and confined
environments in terrestrial and space applications. However, robust perception
and localization for snake robots remain an open challenge due to the proximity
of the sensor payload to the ground coupled with a limited field of view. To
address this issue, we propose Blind-motion with Intermittently Scheduled Scans
(BLISS) which combines proprioception-only mobility with intermittent scans to
be resilient against both localization failures and collision risks. BLISS is
formulated as an integrated Task and Motion Planning (TAMP) problem that leads
to a Chance-Constrained Hybrid Partially Observable Markov Decision Process
(CC-HPOMDP), known to be computationally intractable due to the curse of
history. Our novelty lies in reformulating CC-HPOMDP as a tractable, convex
Mixed Integer Linear Program. This allows us to solve BLISS-TAMP significantly
faster and jointly derive optimal task-motion plans. Simulations and hardware
experiments on the EELS snake robot show our method achieves over an order of
magnitude computational improvement compared to state-of-the-art POMDP planners
and $>$ 50\% better navigation time optimality versus classical two-stage
planners.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19617v1' target='_blank'>Image-Based Roadmaps for Vision-Only Planning and Control of Robotic
  Manipulators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sreejani Chatterjee, Abhinav Gandhi, Berk Calli, Constantinos Chamzas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 23:09:17</h6>
<p class='card-text'>This work presents a motion planning framework for robotic manipulators that
computes collision-free paths directly in image space. The generated paths can
then be tracked using vision-based control, eliminating the need for an
explicit robot model or proprioceptive sensing. At the core of our approach is
the construction of a roadmap entirely in image space. To achieve this, we
explicitly define sampling, nearest-neighbor selection, and collision checking
based on visual features rather than geometric models. We first collect a set
of image-space samples by moving the robot within its workspace, capturing
keypoints along its body at different configurations. These samples serve as
nodes in the roadmap, which we construct using either learned or predefined
distance metrics. At runtime, the roadmap generates collision-free paths
directly in image space, removing the need for a robot model or joint encoders.
We validate our approach through an experimental study in which a robotic arm
follows planned paths using an adaptive vision-based control scheme to avoid
obstacles. The results show that paths generated with the learned-distance
roadmap achieved 100% success in control convergence, whereas the predefined
image-space distance roadmap enabled faster transient responses but had a lower
success rate in convergence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19610v1' target='_blank'>Program Synthesis Dialog Agents for Interactive Decision-Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Matthew Toles, Nikhil Balwani, Rattandeep Singh, Valentina Giulia Sartori Rodriguez, Zhou Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 22:53:01</h6>
<p class='card-text'>Many real-world eligibility problems, ranging from medical diagnosis to tax
planning, can be mapped to decision problems expressed in natural language,
wherein a model must make a binary choice based on user features. Large-scale
domains such as legal codes or frequently updated funding opportunities render
human annotation (e.g., web forms or decision trees) impractical, highlighting
the need for agents that can automatically assist in decision-making. Since
relevant information is often only known to the user, it is crucial that these
agents ask the right questions. As agents determine when to terminate a
conversation, they face a trade-off between accuracy and the number of
questions asked, a key metric for both user experience and cost. To evaluate
this task, we propose BeNYfits, a new benchmark for determining user
eligibility for multiple overlapping social benefits opportunities through
interactive decision-making. Our experiments show that current language models
struggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a
ReAct-style chain-of-thought. To address this, we introduce ProADA, a novel
approach that leverages program synthesis to assist in decision-making by
mapping dialog planning to a code generation problem and using gaps in
structured data to determine the best next action. Our agent, ProADA, improves
the F1 score to 55.6 while maintaining nearly the same number of dialog turns.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19603v1' target='_blank'>Planning with Linear Temporal Logic Specifications: Handling
  Quantifiable and Unquantifiable Uncertainty</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pian Yu, Yong Li, David Parker, Marta Kwiatkowska</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 22:38:29</h6>
<p class='card-text'>This work studies the planning problem for robotic systems under both
quantifiable and unquantifiable uncertainty. The objective is to enable the
robotic systems to optimally fulfill high-level tasks specified by Linear
Temporal Logic (LTL) formulas. To capture both types of uncertainty in a
unified modelling framework, we utilise Markov Decision Processes with
Set-valued Transitions (MDPSTs). We introduce a novel solution technique for
the optimal robust strategy synthesis of MDPSTs with LTL specifications. To
improve efficiency, our work leverages limit-deterministic B\"uchi automata
(LDBAs) as the automaton representation for LTL to take advantage of their
efficient constructions. To tackle the inherent nondeterminism in MDPSTs, which
presents a significant challenge for reducing the LTL planning problem to a
reachability problem, we introduce the concept of a Winning Region (WR) for
MDPSTs. Additionally, we propose an algorithm for computing the WR over the
product of the MDPST and the LDBA. Finally, a robust value iteration algorithm
is invoked to solve the reachability problem. We validate the effectiveness of
our approach through a case study involving a mobile robot operating in the
hexagonal world, demonstrating promising efficiency gains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19591v1' target='_blank'>Hierarchically Accelerated Coverage Path Planning for Redundant
  Manipulators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yeping Wang, Michael Gleicher</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 22:15:35</h6>
<p class='card-text'>Many robotic applications, such as sanding, polishing, wiping and sensor
scanning, require a manipulator to dexterously cover a surface using its
end-effector. In this paper, we provide an efficient and effective coverage
path planning approach that leverages a manipulator's redundancy and task
tolerances to minimize costs in joint space. We formulate the problem as a
Generalized Traveling Salesman Problem and hierarchically streamline the graph
size. Our strategy is to identify guide paths that roughly cover the surface
and accelerate the computation by solving a sequence of smaller problems. We
demonstrate the effectiveness of our method through a simulation experiment and
an illustrative demonstration using a physical robot.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19564v1' target='_blank'>Diffusion-based Planning with Learned Viability Filters</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicholas Ioannidis, Daniele Reda, Setareh Cohan, Michiel van de Panne</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 21:08:38</h6>
<p class='card-text'>Diffusion models can be used as a motion planner by sampling from a
distribution of possible futures. However, the samples may not satisfy hard
constraints that exist only implicitly in the training data, e.g., avoiding
falls or not colliding with a wall. We propose learned viability filters that
efficiently predict the future success of any given plan, i.e., diffusion
sample, and thereby enforce an implicit future-success constraint. Multiple
viability filters can also be composed together. We demonstrate the approach on
detailed footstep planning for challenging 3D human locomotion tasks, showing
the effectiveness of viability filters in performing online planning and
control for box-climbing, step-over walls, and obstacle avoidance. We further
show that using viability filters is significantly faster than guidance-based
diffusion prediction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19515v1' target='_blank'>Evaluating the Suitability of Different Intraoral Scan Resolutions for
  Deep Learning-Based Tooth Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daron Weekley, Jace Duckworth, Anastasiia Sukhanova, Ananya Jana</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 19:30:29</h6>
<p class='card-text'>Intraoral scans are widely used in digital dentistry for tasks such as dental
restoration, treatment planning, and orthodontic procedures. These scans
contain detailed topological information, but manual annotation of these scans
remains a time-consuming task. Deep learning-based methods have been developed
to automate tasks such as tooth segmentation. A typical intraoral scan contains
over 200,000 mesh cells, making direct processing computationally expensive.
Models are often trained on downsampled versions, typically with 10,000 or
16,000 cells. Previous studies suggest that downsampling may degrade
segmentation accuracy, but the extent of this degradation remains unclear.
Understanding the extent of degradation is crucial for deploying ML models on
edge devices. This study evaluates the extent of performance degradation with
decreasing resolution. We train a deep learning model (PointMLP) on intraoral
scans decimated to 16K, 10K, 8K, 6K, 4K, and 2K mesh cells. Models trained at
lower resolutions are tested on high-resolution scans to assess performance.
Our goal is to identify a resolution that balances computational efficiency and
segmentation accuracy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19401v1' target='_blank'>ARENA: Adaptive Risk-aware and Energy-efficient NAvigation for
  Multi-Objective 3D Infrastructure Inspection with a UAV</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David-Alexandre Poissant, Alexis Lussier Desbiens, François Ferland, Louis Petit</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 18:50:49</h6>
<p class='card-text'>Autonomous robotic inspection missions require balancing multiple conflicting
objectives while navigating near costly obstacles. Current multi-objective path
planning (MOPP) methods struggle to adapt to evolving risks like localization
errors, weather, battery state, and communication issues. This letter presents
an Adaptive Risk-aware and Energy-efficient NAvigation (ARENA) MOPP approach
for UAVs in complex 3D environments. Our method enables online trajectory
adaptation by optimizing safety, time, and energy using 4D NURBS representation
and a genetic-based algorithm to generate the Pareto front. A novel risk-aware
voting algorithm ensures adaptivity. Simulations and real-world tests
demonstrate the planner's ability to produce diverse, optimized trajectories
covering 95% or more of the range defined by single-objective benchmarks and
its ability to estimate power consumption with a mean error representing 14% of
the full power range. The ARENA framework enhances UAV autonomy and reliability
in critical, evolving 3D missions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19356v1' target='_blank'>Recurrent Auto-Encoders for Enhanced Deep Reinforcement Learning in
  Wilderness Search and Rescue Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jan-Hendrik Ewers, David Anderson, Douglas Thomson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 17:54:47</h6>
<p class='card-text'>Wilderness search and rescue operations are often carried out over vast
landscapes. The search efforts, however, must be undertaken in minimum time to
maximize the chance of survival of the victim. Whilst the advent of cheap
multicopters in recent years has changed the way search operations are handled,
it has not solved the challenges of the massive areas at hand. The problem
therefore is not one of complete coverage, but one of maximizing the
information gathered in the limited time available. In this work we propose
that a combination of a recurrent autoencoder and deep reinforcement learning
is a more efficient solution to the search problem than previous pure deep
reinforcement learning or optimisation approaches. The autoencoder training
paradigm efficiently maximizes the information throughput of the encoder into
its latent space representation which deep reinforcement learning is primed to
leverage. Without the overhead of independently solving the problem that the
recurrent autoencoder is designed for, it is more efficient in learning the
control task. We further implement three additional architectures for a
comprehensive comparison of the main proposed architecture. Similarly, we apply
both soft actor-critic and proximal policy optimisation to provide an insight
into the performance of both in a highly non-linear and complex application
with a large observation Results show that the proposed architecture is vastly
superior to the benchmarks, with soft actor-critic achieving the best
performance. This model further outperformed work from the literature whilst
having below a fifth of the total learnable parameters and training in a
quarter of the time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19340v1' target='_blank'>Hybrid Robot Learning for Automatic Robot Motion Planning in
  Manufacturing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siddharth Singh, Tian Yu, Qing Chang, John Karigiannis, Shaopeng Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 17:32:22</h6>
<p class='card-text'>Industrial robots are widely used in diverse manufacturing environments.
Nonetheless, how to enable robots to automatically plan trajectories for
changing tasks presents a considerable challenge. Further complexities arise
when robots operate within work cells alongside machines, humans, or other
robots. This paper introduces a multi-level hybrid robot motion planning method
combining a task space Reinforcement Learning-based Learning from Demonstration
(RL-LfD) agent and a joint-space based Deep Reinforcement Learning (DRL) based
agent. A higher level agent learns to switch between the two agents to enable
feasible and smooth motion. The feasibility is computed by incorporating
reachability, joint limits, manipulability, and collision risks of the robot in
the given environment. Therefore, the derived hybrid motion planning policy
generates a feasible trajectory that adheres to task constraints. The
effectiveness of the method is validated through sim ulated robotic scenarios
and in a real-world setup.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19297v1' target='_blank'>Combining Planning and Reinforcement Learning for Solving Relational
  Multiagent Domains</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nikhilesh Prabhakar, Ranveer Singh, Harsha Kokel, Sriraam Natarajan, Prasad Tadepalli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 16:55:23</h6>
<p class='card-text'>Multiagent Reinforcement Learning (MARL) poses significant challenges due to
the exponential growth of state and action spaces and the non-stationary nature
of multiagent environments. This results in notable sample inefficiency and
hinders generalization across diverse tasks. The complexity is further
pronounced in relational settings, where domain knowledge is crucial but often
underutilized by existing MARL algorithms. To overcome these hurdles, we
propose integrating relational planners as centralized controllers with
efficient state abstractions and reinforcement learning. This approach proves
to be sample-efficient and facilitates effective task transfer and
generalization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19258v1' target='_blank'>Deep learning and classical computer vision techniques in medical image
  analysis: Case studies on brain MRI tissue segmentation, lung CT COPD
  registration, and skin lesion classification</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anyimadu Daniel Tweneboah, Suleiman Taofik Ahmed, Hossain Mohammad Imran</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 16:05:08</h6>
<p class='card-text'>Medical imaging spans diverse tasks and modalities which play a pivotal role
in disease diagnosis, treatment planning, and monitoring. This study presents a
novel exploration, being the first to systematically evaluate segmentation,
registration, and classification tasks across multiple imaging modalities.
Integrating both classical and deep learning (DL) approaches in addressing
brain MRI tissue segmentation, lung CT image registration, and skin lesion
classification from dermoscopic images, we demonstrate the complementary
strengths of these methodologies in diverse applications. For brain tissue
segmentation, 3D DL models outperformed 2D and patch-based models, specifically
nnU-Net achieving Dice of 0.9397, with 3D U-Net models on ResNet34 backbone,
offering competitive results with Dice 0.8946. Multi-Atlas methods provided
robust alternatives for cases where DL methods are not feasible, achieving
average Dice of 0.7267. In lung CT registration, classical Elastix-based
methods outperformed DL models, achieving a minimum Target Registration Error
(TRE) of 6.68 mm, highlighting the effectiveness of parameter tuning.
HighResNet performed best among DL models with a TRE of 7.40 mm. For skin
lesion classification, ensembles of DL models like InceptionResNetV2 and
ResNet50 excelled, achieving up to 90.44%, and 93.62% accuracies for binary and
multiclass classification respectively. Also, adopting One-vs-All method, DL
attained accuracies of 94.64% (mel vs. others), 95.35% (bcc vs. others), and
96.93% (scc vs. others), while ML models specifically Multi-Layer Perceptron
(MLP) on handcrafted features offered interpretable alternatives with 85.04%
accuracy using SMOTE for class imbalance correction on the multi-class task and
83.27% on the binary-class task. Links to source code are available on request.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19243v1' target='_blank'>Modelling Regional Solar Photovoltaic Capacity in Great Britain</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hussah Alghanem, Alastair Buckley</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 15:51:38</h6>
<p class='card-text'>Great Britain aims to meet growing electricity demand and achieve a fully
decarbonised grid by 2035, targeting 70 GW of solar photovoltaic (PV) capacity.
However, grid constraints and connection delays hinder solar integration. To
address these integration challenges, various connection reform processes and
policies are being developed [1]. This study supports the connection reforms
with a model that estimates regional PV capacity at the NUTS 3 level,
explaining 89% of the variation in capacity, with a mean absolute error of 20
MW and a national mean absolute percentage error of 5.4%. Artificial surfaces
and agricultural areas are identified as key factors in deployment. The model
has three primary applications: disaggregating national PV capacity into
regional capacity, benchmarking regional PV deployment between different
regions, and forecasting future PV capacity distribution. These applications
support grid operators in generation monitoring and strategic grid planning by
identifying regions where capacity is likely to be concentrated. This can
address grid connection delays, plan network expansions, and resolve land-use
conflicts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19012v1' target='_blank'>Developing heuristic solution techniques for large-scale unit commitment
  models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nils-Christian Kempke, Tim Kunt, Bassel Katamish, Charlie Vanaret, Shima Sasanpour, Jan-Patrick Clarner, Thorsten Koch</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 10:19:27</h6>
<p class='card-text'>Shifting towards renewable energy sources and reducing carbon emissions
necessitate sophisticated energy system planning, optimization, and extension.
Energy systems optimization models (ESOMs) often form the basis for political
and operational decision-making. ESOMs are frequently formulated as linear
(LPs) and mixed-integer linear (MIP) problems. MIPs allow continuous and
discrete decision variables. Consequently, they are substantially more
expressive than LPs but also more challenging to solve. The ever-growing size
and complexity of ESOMs take a toll on the computational time of
state-of-the-art commercial solvers. Indeed, for large-scale ESOMs, solving the
LP relaxation -- the basis of modern MIP solution algorithms -- can be very
costly. These time requirements can render ESOM MIPs impractical for real-world
applications. This article considers a set of large-scale
decarbonization-focused unit commitment models with expansion decisions based
on the REMix framework (up to 83 million variables and 900,000 discrete
decision variables). For these particular instances, the solution to the LP
relaxation and the MIP optimum lie close. Based on this observation, we
investigate the application of relaxation-enforced neighborhood search (RENS),
machine learning guided rounding, and a fix-and-propagate (FP) heuristic as a
standalone solution method. Our approach generated feasible solutions 20 to 100
times faster than GUROBI, achieving comparable solution quality with
primal-dual gaps as low as 1% and up to 35%. This enabled us to solve numerous
scenarios without lowering the quality of our models. For some instances that
GUROBI could not solve within two days, our \FP method provided feasible
solutions in under one hour.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19009v1' target='_blank'>Distilling Reinforcement Learning Algorithms for In-Context Model-Based
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jaehyeon Son, Soochan Lee, Gunhee Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 10:16:57</h6>
<p class='card-text'>Recent studies have shown that Transformers can perform in-context
reinforcement learning (RL) by imitating existing RL algorithms, enabling
sample-efficient adaptation to unseen tasks without parameter updates. However,
these models also inherit the suboptimal behaviors of the RL algorithms they
imitate. This issue primarily arises due to the gradual update rule employed by
those algorithms. Model-based planning offers a promising solution to this
limitation by allowing the models to simulate potential outcomes before taking
action, providing an additional mechanism to deviate from the suboptimal
behavior. Rather than learning a separate dynamics model, we propose
Distillation for In-Context Planning (DICP), an in-context model-based RL
framework where Transformers simultaneously learn environment dynamics and
improve policy in-context. We evaluate DICP across a range of discrete and
continuous environments, including Darkroom variants and Meta-World. Our
results show that DICP achieves state-of-the-art performance while requiring
significantly fewer environment interactions than baselines, which include both
model-free counterparts and existing meta-RL methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18973v2' target='_blank'>Impact of deep learning model uncertainty on manual corrections to
  auto-segmentation in prostate cancer radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Viktor Rogowski, Angelica Svalkvist, Matteo Maspero, Tomas Janssen, Federica Carmen Maruccio, Jenny Gorgisyan, Jonas Scherman, Ida Häggström, Victor Wåhlstrand, Adalsteinn Gunnlaugsson, Martin P Nilsson, Mathieu Moreau, Nándor Vass, Niclas Pettersson, Christian Jamtheim Gustafsson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 09:34:55</h6>
<p class='card-text'>Background: Deep learning (DL)-based organ segmentation is increasingly used
in radiotherapy, yet voxel-wise DL uncertainty maps are rarely presented to
clinicians. Purpose: This study assessed how DL-generated uncertainty maps
impact radiation oncologists during manual correction of prostate radiotherapy
DL segmentations. Methods: Two nnUNet models were trained by 10-fold
cross-validation on 434 MRI-only prostate cancer cases to segment the prostate
and rectum. Each model was evaluated on 35 independent cases. Voxel-wise
uncertainty was calculated using the SoftMax standard deviation (n=10) and
visualized as a color-coded map. Four oncologists performed segmentation in two
steps: Step 1: Rated segmentation quality and confidence using Likert scales
and edited DL segmentations without uncertainty maps. Step 2 ($\geq 4$ weeks
later): Repeated step 1, but with uncertainty maps available. Segmentation time
was recorded for both steps, and oncologists provided qualitative free-text
feedback. Histogram analysis compared voxel edits across uncertainty levels.
Results: DL segmentations showed high agreement with oncologist edits. Quality
ratings varied: rectum segmentation ratings slightly decreased overall in step
2, while prostate ratings differed among oncologists. Confidence ratings also
varied. Three oncologists reduced segmentation time with uncertainty maps,
saving 1-2 minutes per case. Histogram analysis showed 50% fewer edits for step
2 in low-uncertainty areas. Conclusions: Presenting DL segmentation uncertainty
information to radiation oncologists influences their decision-making, quality
perception, and confidence in the DL segmentations. Low-uncertainty regions
were edited less frequently, indicating increased trust in DL predictions.
Uncertainty maps improve efficiency by reducing segmentation time and can be a
valuable clinical tool, enhancing radiotherapy planning efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18966v1' target='_blank'>One Set to Rule Them All: How to Obtain General Chemical Conditions via
  Bayesian Optimization over Curried Functions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stefan P. Schmid, Ella Miray Rajaonson, Cher Tian Ser, Mohammad Haddadnia, Shi Xuan Leong, Alán Aspuru-Guzik, Agustinus Kristiadi, Kjell Jorner, Felix Strieth-Kalthoff</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 09:25:48</h6>
<p class='card-text'>General parameters are highly desirable in the natural sciences - e.g.,
chemical reaction conditions that enable high yields across a range of related
transformations. This has a significant practical impact since those general
parameters can be transferred to related tasks without the need for laborious
and time-intensive re-optimization. While Bayesian optimization (BO) is widely
applied to find optimal parameter sets for specific tasks, it has remained
underused in experiment planning towards such general optima. In this work, we
consider the real-world problem of condition optimization for chemical
reactions to study how performing generality-oriented BO can accelerate the
identification of general optima, and whether these optima also translate to
unseen examples. This is achieved through a careful formulation of the problem
as an optimization over curried functions, as well as systematic evaluations of
generality-oriented strategies for optimization tasks on real-world
experimental data. We find that for generality-oriented optimization, simple
myopic optimization strategies that decouple parameter and task selection
perform comparably to more complex ones, and that effective optimization is
merely determined by an effective exploration of both parameter and task space.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18893v1' target='_blank'>Distributed Online Task Assignment via Inexact ADMM for unplanned online
  tasks and its Applications to Security</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziqi Yang, Roberto Tron</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 07:17:24</h6>
<p class='card-text'>In multi-robot system (MRS) applications, efficient task assignment is
essential not only for coordinating agents and ensuring mission success but
also for maintaining overall system security. In this work, we first propose an
optimization-based distributed task assignment algorithm that dynamically
assigns mandatory security-critical tasks and optional tasks among teams.
Leveraging an inexact Alternating Direction Method of Multipliers (ADMM)-based
approach, we decompose the task assignment problem into separable and
non-separable subproblems. The non-separable subproblems are transformed into
an inexact ADMM update by projected gradient descent, which can be performed
through several communication steps within the team.
  In the second part of this paper, we formulate a comprehensive framework that
enables MRS under plan-deviation attacks to handle online tasks without
compromising security. The process begins with a security analysis that
determines whether an online task can be executed securely by a robot and, if
so, the required time and location for the robot to rejoin the team. Next, the
proposed task assignment algorithm is used to allocate security-related tasks
and verified online tasks. Finally, task fulfillment is managed using a Control
Lyapunov Function (CLF)-based controller, while security enforcement is ensured
through a Control Barrier Function (CBF)-based security filter. Through
simulations, we demonstrate that the proposed framework allows MRS to
effectively respond to unplanned online tasks while maintaining security
guarantees.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18846v1' target='_blank'>RL-OGM-Parking: Lidar OGM-Based Hybrid Reinforcement Learning Planner
  for Autonomous Parking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhitao Wang, Zhe Chen, Mingyang Jiang, Tong Qin, Ming Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 05:32:20</h6>
<p class='card-text'>Autonomous parking has become a critical application in automatic driving
research and development. Parking operations often suffer from limited space
and complex environments, requiring accurate perception and precise
maneuvering. Traditional rule-based parking algorithms struggle to adapt to
diverse and unpredictable conditions, while learning-based algorithms lack
consistent and stable performance in various scenarios. Therefore, a hybrid
approach is necessary that combines the stability of rule-based methods and the
generalizability of learning-based methods. Recently, reinforcement learning
(RL) based policy has shown robust capability in planning tasks. However, the
simulation-to-reality (sim-to-real) transfer gap seriously blocks the
real-world deployment. To address these problems, we employ a hybrid policy,
consisting of a rule-based Reeds-Shepp (RS) planner and a learning-based
reinforcement learning (RL) planner. A real-time LiDAR-based Occupancy Grid Map
(OGM) representation is adopted to bridge the sim-to-real gap, leading the
hybrid policy can be applied to real-world systems seamlessly. We conducted
extensive experiments both in the simulation environment and real-world
scenarios, and the result demonstrates that the proposed method outperforms
pure rule-based and learning-based methods. The real-world experiment further
validates the feasibility and efficiency of the proposed method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18775v1' target='_blank'>Subclass Classification of Gliomas Using MRI Fusion Technique</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kiranmayee Janardhan, Christy Bobby Thomas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 03:10:33</h6>
<p class='card-text'>Glioma, the prevalent primary brain tumor, exhibits diverse aggressiveness
levels and prognoses. Precise classification of glioma is paramount for
treatment planning and predicting prognosis. This study aims to develop an
algorithm to fuse the MRI images from T1, T2, T1ce, and fluid-attenuated
inversion recovery (FLAIR) sequences to enhance the efficacy of glioma subclass
classification as no tumor, necrotic core, peritumoral edema, and enhancing
tumor. The MRI images from BraTS datasets were used in this work. The images
were pre-processed using max-min normalization to ensure consistency in pixel
intensity values across different images. The segmentation of the necrotic
core, peritumoral edema, and enhancing tumor was performed on 2D and 3D images
separately using UNET architecture. Further, the segmented regions from
multimodal MRI images were fused using the weighted averaging technique.
Integrating 2D and 3D segmented outputs enhances classification accuracy by
capturing detailed features like tumor shape, boundaries, and intensity
distribution in slices, while also providing a comprehensive view of spatial
extent, shape, texture, and localization within the brain volume. The fused
images were used as input to the pre-trained ResNet50 model for glioma subclass
classification. The network is trained on 80% and validated on 20% of the data.
The proposed method achieved a classification of accuracy of 99.25%, precision
of 99.30%, recall of 99.10, F1 score of 99.19%, Intersection Over Union of
84.49%, and specificity of 99.76, which showed a significantly higher
performance than existing techniques. These findings emphasize the significance
of glioma segmentation and classification in aiding accurate diagnosis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18745v1' target='_blank'>MaskPlanner: Learning-Based Object-Centric Motion Generation from 3D
  Point Clouds</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gabriele Tiboni, Raffaello Camoriano, Tatiana Tommasi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 01:39:25</h6>
<p class='card-text'>Object-Centric Motion Generation (OCMG) plays a key role in a variety of
industrial applications$\unicode{x2014}$such as robotic spray painting and
welding$\unicode{x2014}$requiring efficient, scalable, and generalizable
algorithms to plan multiple long-horizon trajectories over free-form 3D
objects. However, existing solutions rely on specialized heuristics, expensive
optimization routines, or restrictive geometry assumptions that limit their
adaptability to real-world scenarios. In this work, we introduce a novel, fully
data-driven framework that tackles OCMG directly from 3D point clouds, learning
to generalize expert path patterns across free-form surfaces. We propose
MaskPlanner, a deep learning method that predicts local path segments for a
given object while simultaneously inferring "path masks" to group these
segments into distinct paths. This design induces the network to capture both
local geometric patterns and global task requirements in a single forward pass.
Extensive experimentation on a realistic robotic spray painting scenario shows
that our approach attains near-complete coverage (above 99%) for unseen
objects, while it remains task-agnostic and does not explicitly optimize for
paint deposition. Moreover, our real-world validation on a 6-DoF specialized
painting robot demonstrates that the generated trajectories are directly
executable and yield expert-level painting quality. Our findings crucially
highlight the potential of the proposed learning method for OCMG to reduce
engineering overhead and seamlessly adapt to several industrial use cases.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18689v1' target='_blank'>Emerging Practices in Participatory AI Design in Public Sector
  Innovation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Devansh Saxena, Zoe Kahn, Erina Seh-Young Moon, Lauren M. Chambers, Corey Jackson, Min Kyung Lee, Motahhare Eslami, Shion Guha, Sheena Erete, Lilly Irani, Deirdre Mulligan, John Zimmerman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 22:58:02</h6>
<p class='card-text'>Local and federal agencies are rapidly adopting AI systems to augment or
automate critical decisions, efficiently use resources, and improve public
service delivery. AI systems are being used to support tasks associated with
urban planning, security, surveillance, energy and critical infrastructure, and
support decisions that directly affect citizens and their ability to access
essential services. Local governments act as the governance tier closest to
citizens and must play a critical role in upholding democratic values and
building community trust especially as it relates to smart city initiatives
that seek to transform public services through the adoption of AI.
Community-centered and participatory approaches have been central for ensuring
the appropriate adoption of technology; however, AI innovation introduces new
challenges in this context because participatory AI design methods require more
robust formulation and face higher standards for implementation in the public
sector compared to the private sector. This requires us to reassess traditional
methods used in this space as well as develop new resources and methods. This
workshop will explore emerging practices in participatory algorithm design - or
the use of public participation and community engagement - in the scoping,
design, adoption, and implementation of public sector algorithms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18683v1' target='_blank'>Robots, Chatbots, Self-Driving Cars: Perceptions of Mind and Morality
  Across Artificial Intelligences</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ali Ladak, Matti Wilks, Steve Loughnan, Jacy Reese Anthis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 22:44:16</h6>
<p class='card-text'>AI systems have rapidly advanced, diversified, and proliferated, but our
knowledge of people's perceptions of mind and morality in them is limited,
despite its importance for outcomes such as whether people trust AIs and how
they assign responsibility for AI-caused harms. In a preregistered online
study, 975 participants rated 26 AI and non-AI entities. Overall, AIs were
perceived to have low-to-moderate agency (e.g., planning, acting), between
inanimate objects and ants, and low experience (e.g., sensing, feeling). For
example, ChatGPT was rated only as capable of feeling pleasure and pain as a
rock. The analogous moral faculties, moral agency (doing right or wrong) and
moral patiency (being treated rightly or wrongly) were higher and more varied,
particularly moral agency: The highest-rated AI, a Tesla Full Self-Driving car,
was rated as morally responsible for harm as a chimpanzee. We discuss how
design choices can help manage perceptions, particularly in high-stakes moral
contexts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18639v1' target='_blank'>Quantum Machine Learning in Precision Medicine and Drug Discovery -- A
  Game Changer for Tailored Treatments?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Markus Bertl, Alan Mott, Salvatore Sinno, Bhavika Bhalgamiya</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 20:59:22</h6>
<p class='card-text'>The digitization of healthcare presents numerous challenges, including the
complexity of biological systems, vast data generation, and the need for
personalized treatment plans. Traditional computational methods often fall
short, leading to delayed and sometimes ineffective diagnoses and treatments.
Quantum Computing (QC) and Quantum Machine Learning (QML) offer transformative
advancements with the potential to revolutionize medicine. This paper
summarizes areas where QC promises unprecedented computational power, enabling
faster, more accurate diagnostics, personalized treatments, and enhanced drug
discovery processes. However, integrating quantum technologies into precision
medicine also presents challenges, including errors in algorithms and high
costs. We show that mathematically-based techniques for specifying, developing,
and verifying software (formal methods) can enhance the reliability and
correctness of QC. By providing a rigorous mathematical framework, formal
methods help to specify, develop, and verify systems with high precision. In
genomic data analysis, formal specification languages can precisely (1) define
the behavior and properties of quantum algorithms designed to identify genetic
markers associated with diseases. Model checking tools can systematically
explore all possible states of the algorithm to (2) ensure it behaves correctly
under all conditions, while theorem proving techniques provide mathematical (3)
proof that the algorithm meets its specified properties, ensuring accuracy and
reliability. Additionally, formal optimization techniques can (4) enhance the
efficiency and performance of quantum algorithms by reducing resource usage,
such as the number of qubits and gate operations. Therefore, we posit that
formal methods can significantly contribute to enabling QC to realize its full
potential as a game changer in precision medicine.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18586v1' target='_blank'>Autonomous Vision-Guided Resection of Central Airway Obstruction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:M. E. Smith, N. Yilmaz, T. Watts, P. M. Scheikl, J. Ge, A. Deguet, A. Kuntz, A. Krieger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 19:11:11</h6>
<p class='card-text'>Existing tracheal tumor resection methods often lack the precision required
for effective airway clearance, and robotic advancements offer new potential
for autonomous resection. We present a vision-guided, autonomous approach for
palliative resection of tracheal tumors. This system models the tracheal
surface with a fifth-degree polynomial to plan tool trajectories, while a
custom Faster R-CNN segmentation pipeline identifies the trachea and tumor
boundaries. The electrocautery tool angle is optimized using handheld surgical
demonstrations, and trajectories are planned to maintain a 1 mm safety
clearance from the tracheal surface. We validated the workflow successfully in
five consecutive experiments on ex-vivo animal tissue models, successfully
clearing the airway obstruction without trachea perforation in all cases (with
more than 90% volumetric tumor removal). These results support the feasibility
of an autonomous resection platform, paving the way for future developments in
minimally-invasive autonomous resection.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18447v1' target='_blank'>Supervised Reward Inference</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Will Schwarzer, Jordan Schneider, Philip S. Thomas, Scott Niekum</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 18:42:05</h6>
<p class='card-text'>Existing approaches to reward inference from behavior typically assume that
humans provide demonstrations according to specific models of behavior.
However, humans often indicate their goals through a wide range of behaviors,
from actions that are suboptimal due to poor planning or execution to behaviors
which are intended to communicate goals rather than achieve them. We propose
that supervised learning offers a unified framework to infer reward functions
from any class of behavior, and show that such an approach is asymptotically
Bayes-optimal under mild assumptions. Experiments on simulated robotic
manipulation tasks show that our method can efficiently infer rewards from a
wide variety of arbitrarily suboptimal demonstrations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18438v1' target='_blank'>ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent
  Diffusion Policies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pedro Sequeira, Vidyasagar Sadhu, Melinda Gervasio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 18:31:55</h6>
<p class='card-text'>In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in
Teams), a new framework for generating ToM-conditioned trajectories. It
combines a meta-learning mechanism, that performs ToM reasoning over teammates'
underlying goals and future behavior, with a multiagent denoising-diffusion
model, that generates plans for an agent and its teammates conditioned on both
the agent's goals and its teammates' characteristics, as computed via ToM. We
implemented an online planning system that dynamically samples new trajectories
(replans) from the diffusion model whenever it detects a divergence between a
previously generated plan and the current state of the world. We conducted
several experiments using ToMCAT in a simulated cooking domain. Our results
highlight the importance of the dynamic replanning mechanism in reducing the
usage of resources without sacrificing team performance. We also show that
recent observations about the world and teammates' behavior collected by an
agent over the course of an episode combined with ToM inferences are crucial to
generate team-aware plans for dynamic adaptation to teammates, especially when
no prior information is provided about them.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18381v1' target='_blank'>Semantic and Goal-oriented Wireless Network Coverage: The Area of
  Effectiveness</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mattia Merluzzi, Giuseppe Di Poce, Paolo Di Lorenzo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 17:24:26</h6>
<p class='card-text'>Assessing wireless coverage is a fundamental task for public network
operators and private deployments, whose goal is to guarantee quality of
service across the network while minimizing material waste and energy
consumption. These maps are usually built through ray tracing techniques and/or
channel measurements that can be consequently translated into network Key
Performance Indicators (KPIs), such as capacity or throughput. However, next
generation networks (e.g., 6G) typically involve beyond communication
resources, towards services that require data transmission, but also processing
(local and remote) to perform complex decision making in real time, with the
best balance between performance, energy consumption, material waste, and
privacy. In this paper, we introduce the novel concept of areas of
effectiveness, which goes beyond the legacy notion of coverage, towards one
that takes into account capability of the network of offering edge Artificial
Intelligence (AI)-related computation. We will show that radio coverage is a
poor indicator of real system performance, depending on the application and the
computing capabilities of network and devices. This opens new challenges in
network planning, but also resource orchestration during operation to achieve
the specific goal of communication.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18546v1' target='_blank'>Multi-class Seismic Building Damage Assessment from InSAR Imagery using
  Quadratic Variational Causal Bayesian Inference</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuechun Li, Susu Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 15:40:16</h6>
<p class='card-text'>Interferometric Synthetic Aperture Radar (InSAR) technology uses satellite
radar to detect surface deformation patterns and monitor earthquake impacts on
buildings. While vital for emergency response planning, extracting multi-class
building damage classifications from InSAR data faces challenges: overlapping
damage signatures with environmental noise, computational complexity in
multi-class scenarios, and the need for rapid regional-scale processing. Our
novel multi-class variational causal Bayesian inference framework with
quadratic variational bounds provides rigorous approximations while ensuring
efficiency. By integrating InSAR observations with USGS ground failure models
and building fragility functions, our approach separates building damage
signals while maintaining computational efficiency through strategic pruning.
Evaluation across five major earthquakes (Haiti 2021, Puerto Rico 2020, Zagreb
2020, Italy 2016, Ridgecrest 2019) shows improved damage classification
accuracy (AUC: 0.94-0.96), achieving up to 35.7% improvement over existing
methods. Our approach maintains high accuracy (AUC > 0.93) across all damage
categories while reducing computational overhead by over 40% without requiring
extensive ground truth data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18286v1' target='_blank'>Controllability and Displacement Analysis of a Three-Link Elastic
  Microswimmer: A Geometric Control Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rossella Attanasi, Marta Zoppello, Gaetano Napoli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 15:20:11</h6>
<p class='card-text'>This study investigates the dynamics and controllability of a Purcell
three-link microswimmer equipped with passive elastic torsional coils at its
joints. By controlling the spontaneous curvature, we analyse the swimmers
motion using both linear and weakly nonlinear approaches. Linear analysis
reveals steady harmonic solutions for small-amplitude controls but does not
predict any net displacement, whereas weakly nonlinear analysis predicts
translation along the orientation of the central link. Using geometric control
theory, we prove that the system is small time locally controllable near
equilibrium and derive displacement estimates for periodic piecewise constant
controls, which are validated through numerical simulations. These findings
indicate that oscillatory controls can enable motion in all directions near
equilibrium. This work offers foundational insights into the controllability of
elastic microswimmers, paving the way for advanced motion planning and control
strategies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18234v1' target='_blank'>The Electric Location-Routing Problem: Improved Formulations and Effects
  of Nonlinear Charging</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luiz Eduardo Cotta Monteiro, Rafael Martinelli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 14:18:42</h6>
<p class='card-text'>Electric Location-Routing models (ELRP) can contribute to the effective
planning of electric vehicles (EVs) fleets and charging infrastructure within
EV logistic networks because it simultaneously combines routing and location
decisions to find optimal solutions to the network design. This study
introduces ELRP models that incorporate nonlinear charging process, multiple
charging station types and develop new improved formulations to the problem.
Existing ELRP models commonly assume a linear charging process and employ a
node-based formulation for tracking EV energy and time consumption. In
contrast, we propose novel formulations offering alternative approaches for
modeling EV energy, time consumption, and nonlinear charging. Through extensive
computational experiments, our analysis demonstrates the effectiveness of the
new formulations, reducing the average gap from 29.1% to 11.9%, yielding
improved solutions for 28 out of 74 instances compared to the node-based
formulation. Moreover, our findings provide valuable insights into the
strategic implications of nonlinear charging in ELRP decision-making, offering
new perspectives for planning charging infrastructure in EV logistic networks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18185v1' target='_blank'>VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and
  Atrous Attention</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Adnan Iltaf, Rayan Merghani Ahmed, Bin Li, Shoujun Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 13:26:06</h6>
<p class='card-text'>Medical image segmentation is crucial for clinical diagnosis and treatment
planning, particularly for complex anatomical structures like vessels. In this
work, we propose VesselSAM, a modified version of the Segmentation Anything
Model (SAM), specifically designed for aortic vessel segmentation. VesselSAM
incorporates AtrousLoRA, a novel module that combines Atrous Attention with
Low-Rank Adaptation (LoRA), to improve segmentation performance. Atrous
Attention enables the model to capture multi-scale contextual information,
preserving both fine local details and broader global context. At the same
time, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder,
reducing the number of trainable parameters and ensuring computational
efficiency. We evaluate VesselSAM on two challenging datasets: the Aortic
Vessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset.
VesselSAM achieves state-of-the-art performance with DSC scores of 93.50\%,
93.25\%, 93.02\%, and 93.26\% across multiple medical centers. Our results
demonstrate that VesselSAM delivers high segmentation accuracy while
significantly reducing computational overhead compared to existing large-scale
models. This development paves the way for enhanced AI-based aortic vessel
segmentation in clinical environments. The code and models will be released at
https://github.com/Adnan-CAS/AtrousLora.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18151v1' target='_blank'>A Real-time Spatio-Temporal Trajectory Planner for Autonomous Vehicles
  with Semantic Graph Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shan He, Yalong Ma, Tao Song, Yongzhi Jiang, Xinkai Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 12:27:06</h6>
<p class='card-text'>Planning a safe and feasible trajectory for autonomous vehicles in real-time
by fully utilizing perceptual information in complex urban environments is
challenging. In this paper, we propose a spatio-temporal trajectory planning
method based on graph optimization. It efficiently extracts the multi-modal
information of the perception module by constructing a semantic spatio-temporal
map through separation processing of static and dynamic obstacles, and then
quickly generates feasible trajectories via sparse graph optimization based on
a semantic spatio-temporal hypergraph. Extensive experiments have proven that
the proposed method can effectively handle complex urban public road scenarios
and perform in real time. We will also release our codes to accommodate
benchmarking for the research community</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18047v1' target='_blank'>Progressive Local Alignment for Medical Multimodal Pre-training</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huimin Yan, Xian Yang, Liang Bai, Jiye Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 10:13:13</h6>
<p class='card-text'>Local alignment between medical images and text is essential for accurate
diagnosis, though it remains challenging due to the absence of natural local
pairings and the limitations of rigid region recognition methods. Traditional
approaches rely on hard boundaries, which introduce uncertainty, whereas
medical imaging demands flexible soft region recognition to handle irregular
structures. To overcome these challenges, we propose the Progressive Local
Alignment Network (PLAN), which designs a novel contrastive learning-based
approach for local alignment to establish meaningful word-pixel relationships
and introduces a progressive learning strategy to iteratively refine these
relationships, enhancing alignment precision and robustness. By combining these
techniques, PLAN effectively improves soft region recognition while suppressing
noise interference. Extensive experiments on multiple medical datasets
demonstrate that PLAN surpasses state-of-the-art methods in phrase grounding,
image-text retrieval, object detection, and zero-shot classification, setting a
new benchmark for medical image-text alignment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18015v2' target='_blank'>From planning to policy: distilling $\texttt{Skill-RRT}$ for
  long-horizon prehensile and non-prehensile manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haewon Jung, Donguk Lee, Haecheol Park, JunHyeop Kim, Beomjoon Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 09:23:52</h6>
<p class='card-text'>Current robots face challenges in manipulation tasks that require a long
sequence of prehensile and non-prehensile skills. This involves handling
contact-rich interactions and chaining multiple skills while considering their
long-term consequences. This paper presents a framework that leverages
imitation learning to distill a planning algorithm, capable of solving
long-horizon problems but requiring extensive computation time, into a policy
for efficient action inference. We introduce $\texttt{Skill-RRT}$, an extension
of the rapidly-exploring random tree (RRT) that incorporates skill
applicability checks and intermediate object pose sampling for efficient
long-horizon planning. To enable skill chaining, we propose
$\textit{connectors}$, goal-conditioned policies that transition between skills
while minimizing object disturbance. Using lazy planning, connectors are
selectively trained on relevant transitions, reducing the cost of training.
High-quality demonstrations are generated with $\texttt{Skill-RRT}$ and refined
by a noise-based replay mechanism to ensure robust policy performance. The
distilled policy, trained entirely in simulation, zero-shot transfer to the
real world, and achieves over 80% success rates across three challenging
manipulation tasks. In simulation, our approach outperforms the
state-of-the-art skill-based reinforcement learning method, $\texttt{MAPLE}$,
and $\texttt{Skill-RRT}$.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18542v1' target='_blank'>Behavioural Predictors that Influence Digital Legacy Management
  Intentions among Individuals in South Africa</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jordan Young, Ayanda Pekane, Popyeni Kautondokwa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 09:13:29</h6>
<p class='card-text'>An emerging phenomenon, digital legacy management explores the management of
digital data individuals accumulate throughout their lifetime. With the
integration of digital systems and data into people's daily lives, it becomes
crucial to understand the intricacies of managing data to eventually form one's
digital legacy. This can be understood by investigating the significance of
behavioral predictors in shaping digital legacy management.
  The objective of this study is to explore how behavioral predictors influence
the intentions of individuals in South Africa towards managing their digital
legacy. This entailed:
  Investigating the impact of attitude, subjective norms, and perceived
behavioral control on these intentions. Exploring the perceived usefulness of
digital legacy management systems. Understanding the implications of response
cost and task-technology fit on individuals' inclinations towards digital
legacy planning. Data were collected (n = 203 valid responses) from South
African residents using an online survey and analyzed using partial least
squares structural equation analysis (PLS-SEM). Results indicate that
attitudes, peer opinions, personal resources, and skills are significant
positive influences on digital legacy management intention. Recognizing and
understanding these behavioral predictors is key when developing
region-specific and culturally sensitive digital legacy management tools,
awareness campaigns, and policies. Furthermore, it could pave the way for more
tailored strategies, ensuring effective transfer of post-mortem data, reducing
potential conflicts, and providing clarity when dealing with post-mortem data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17949v1' target='_blank'>InVDriver: Intra-Instance Aware Vectorized Query-Based Autonomous
  Driving Transformer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bo Zhang, Heye Huang, Chunyang Liu, Yaqin Zhang, Zhenhua Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 08:20:16</h6>
<p class='card-text'>End-to-end autonomous driving with its holistic optimization capabilities,
has gained increasing traction in academia and industry. Vectorized
representations, which preserve instance-level topological information while
reducing computational overhead, have emerged as a promising paradigm. While
existing vectorized query-based frameworks often overlook the inherent spatial
correlations among intra-instance points, resulting in geometrically
inconsistent outputs (e.g., fragmented HD map elements or oscillatory
trajectories). To address these limitations, we propose InVDriver, a novel
vectorized query-based system that systematically models intra-instance spatial
dependencies through masked self-attention layers, thereby enhancing planning
accuracy and trajectory smoothness. Across all core modules, i.e., perception,
prediction, and planning, InVDriver incorporates masked self-attention
mechanisms that restrict attention to intra-instance point interactions,
enabling coordinated refinement of structural elements while suppressing
irrelevant inter-instance noise. Experimental results on the nuScenes benchmark
demonstrate that InVDriver achieves state-of-the-art performance, surpassing
prior methods in both accuracy and safety, while maintaining high computational
efficiency. Our work validates that explicit modeling of intra-instance
geometric coherence is critical for advancing vectorized autonomous driving
systems, bridging the gap between theoretical advantages of end-to-end
frameworks and practical deployment requirements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17885v1' target='_blank'>A Simple Walk Model for Reproducing Power Laws in Human mobility</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuji Shinohara, Daiki Morita, Hayato Hirai, Ryosuke Kuribayashi, Nobuhito Manome, Toru Moriyama, Yoshihiro Nakajima, Yukio-Pegio Gunji, Ung-il Chung</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 06:14:15</h6>
<p class='card-text'>Identifying statistical patterns characterizing human trajectories is crucial
for public health, traffic engineering, city planning, and epidemic modeling.
Recent developments in global positioning systems and mobile phone networks
have enabled the collection of substantial information on human movement.
Analyses of these data have revealed various power laws in the temporal and
spatial statistical patterns of human mobility. For example, jump size and
waiting time distributions follow power laws. Zipf's law was also established
for the frequency of visits to each location and rank. Relationship $S(t)\sim
t^\mu$ exists between time t and the number of sites visited up to that time t.
Recently, a universal law of visitation for human mobility was established.
Specifically, the number of people per unit area $\rho(r,f)$, who reside at
distance r from a particular location and visit that location f times in a
given period, is inversely proportional to the square of rf, i.e., $\rho(r,f)
\propto (rf)^{-2}$ holds. The exploration and preferential return (EPR) model
and its improved versions have been proposed to reproduce the above scaling
laws. However, some rules that follow the power law are preinstalled in the EPR
model. We propose a simple walking model to generate movements toward and away
from a target via a single mechanism by relaxing the concept of approaching a
target. Our model can reproduce the abovementioned power laws and some of the
rules used in the EPR model are generated. These results provide a new
perspective on why or how the scaling laws observed in human mobility behavior
arise.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17813v1' target='_blank'>Safe Multi-Agent Navigation guided by Goal-Conditioned Safe
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Meng Feng, Viraj Parimi, Brian Williams</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 03:38:52</h6>
<p class='card-text'>Safe navigation is essential for autonomous systems operating in hazardous
environments. Traditional planning methods excel at long-horizon tasks but rely
on a predefined graph with fixed distance metrics. In contrast, safe
Reinforcement Learning (RL) can learn complex behaviors without relying on
manual heuristics but fails to solve long-horizon tasks, particularly in
goal-conditioned and multi-agent scenarios.
  In this paper, we introduce a novel method that integrates the strengths of
both planning and safe RL. Our method leverages goal-conditioned RL and safe RL
to learn a goal-conditioned policy for navigation while concurrently estimating
cumulative distance and safety levels using learned value functions via an
automated self-training algorithm. By constructing a graph with states from the
replay buffer, our method prunes unsafe edges and generates a waypoint-based
plan that the agent follows until reaching its goal, effectively balancing
faster and safer routes over extended distances.
  Utilizing this unified high-level graph and a shared low-level
goal-conditioned safe RL policy, we extend this approach to address the
multi-agent safe navigation problem. In particular, we leverage Conflict-Based
Search (CBS) to create waypoint-based plans for multiple agents allowing for
their safe navigation over extended horizons. This integration enhances the
scalability of goal-conditioned safe RL in multi-agent scenarios, enabling
efficient coordination among agents.
  Extensive benchmarking against state-of-the-art baselines demonstrates the
effectiveness of our method in achieving distance goals safely for multiple
agents in complex and hazardous environments. Our code will be released to
support future research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17758v1' target='_blank'>Applications of deep reinforcement learning to urban transit network
  design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrew Holliday</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 01:24:20</h6>
<p class='card-text'>This thesis concerns the use of reinforcement learning to train neural
networks to aid in the design of public transit networks. The Transit Network
Design Problem (TNDP) is an optimization problem of considerable practical
importance. Given a city with an existing road network and travel demands, the
goal is to find a set of transit routes - each of which is a path through the
graph - that collectively satisfy all demands, while minimizing a cost function
that may depend both on passenger satisfaction and operating costs. The
existing literature on this problem mainly considers metaheuristic optimization
algorithms, such as genetic algorithms and ant-colony optimization. By
contrast, we begin by taking a reinforcement learning approach, formulating the
construction of a set of transit routes as a Markov Decision Process (MDP) and
training a neural net policy to act as the agent in this MDP. We then show
that, beyond using this policy to plan a transit network directly, it can be
combined with existing metaheuristic algorithms, both to initialize the
solution and to suggest promising moves at each step of a search through
solution space. We find that such hybrid algorithms, which use a neural policy
trained via reinforcement learning as a core component within a classical
metaheuristic framework, can plan transit networks that are superior to those
planned by either the neural policy or the metaheuristic algorithm. We
demonstrate the utility of our approach by using it to redesign the transit
network for the city of Laval, Quebec, and show that in simulation, the
resulting transit network provides better service at lower cost than the
existing transit network.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18529v1' target='_blank'>Heterogeneous Decision Making in Mixed Traffic: Uncertainty-aware
  Planning and Bounded Rationality</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hang Wang, Qiaoyi Fang, Junshan Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 00:32:33</h6>
<p class='card-text'>The past few years have witnessed a rapid growth of the deployment of
automated vehicles (AVs). Clearly, AVs and human-driven vehicles (HVs) will
co-exist for many years, and AVs will have to operate around HVs, pedestrians,
cyclists, and more, calling for fundamental breakthroughs in AI designed for
mixed traffic to achieve mixed autonomy. Thus motivated, we study heterogeneous
decision making by AVs and HVs in a mixed traffic environment, aiming to
capture the interactions between human and machine decision-making and develop
an AI foundation that enables vehicles to operate safely and efficiently. There
are a number of challenges to achieve mixed autonomy, including 1) humans
drivers make driving decisions with bounded rationality, and it remains open to
develop accurate models for HVs' decision making; and 2) uncertainty-aware
planning plays a critical role for AVs to take safety maneuvers in response to
the human behavior. In this paper, we introduce a formulation of AV-HV
interaction, where the HV makes decisions with bounded rationality and the AV
employs uncertainty-aware planning based on the prediction on HV's future
actions. We conduct a comprehensive analysis on AV and HV's learning regret to
answer the questions: 1) {How does the learning performance depend on HV's
bounded rationality and AV's planning}; 2) {How do different decision making
strategies impact the overall learning performance}? Our findings reveal some
intriguing phenomena, such as Goodhart's Law in AV's learning performance and
compounding effects in HV's decision making process. By examining the dynamics
of the regrets, we gain insights into the interplay between human and machine
decision making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17679v1' target='_blank'>Protocol For An Observational Study On The Effects Of Combinations Of
  Adverse Childhood Experiences On Adult Depression</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruizhe Zhang, Jooyoung Kong, Dylan S. Small, William Bekerman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 21:54:13</h6>
<p class='card-text'>Adverse childhood experiences (ACEs) have been linked to a wide range of
negative health outcomes in adulthood. However, few studies have investigated
what specific combinations of ACEs most substantially impact mental health. In
this article, we provide the protocol for our observational study of the
effects of combinations of ACEs on adult depression. We use data from the 2023
Behavioral Risk Factor Surveillance System (BRFSS) to assess these effects. We
will evaluate the replicability of our findings by splitting the sample into
two discrete subpopulations of individuals. We employ data turnover for this
analysis, enabling a single team of statisticians and domain experts to
collaboratively evaluate the strength of evidence, and also integrating both
qualitative and quantitative insights from exploratory data analysis. We
outline our analysis plan using this method and conclude with a brief
discussion of several specifics for our study.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17672v1' target='_blank'>The Geometry of Optimal Gait Families for Steering Kinematic Locomoting
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinwoo Choi, Siming Deng, Nathan Justus, Noah J. Cowan, Ross L. Hatton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 21:38:38</h6>
<p class='card-text'>Motion planning for locomotion systems typically requires translating
high-level rigid-body tasks into low-level joint trajectories-a process that is
straightforward for car-like robots with fixed, unbounded actuation inputs but
more challenging for systems like snake robots, where the mapping depends on
the current configuration and is constrained by joint limits. In this paper, we
focus on generating continuous families of optimal gaits-collections of gaits
parameterized by step size or steering rate-to enhance controllability and
maneuverability. We uncover the underlying geometric structure of these optimal
gait families and propose methods for constructing them using both global and
local search strategies, where the local method and the global method
compensate each other. The global search approach is robust to nonsmooth
behavior, albeit yielding reduced-order solutions, while the local search
provides higher accuracy but can be unstable near nonsmooth regions. To
demonstrate our framework, we generate optimal gait families for viscous and
perfect-fluid three-link swimmers. This work lays a foundation for integrating
low-level joint controllers with higher-level motion planners in complex
locomotion systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17609v1' target='_blank'>SynthRAD2025 Grand Challenge dataset: generating synthetic CTs for
  radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Adrian Thummerer, Erik van der Bijl, Arthur Jr Galapon, Florian Kamp, Mark Savenije, Christina Muijs, Shafak Aluwini, Roel J. H. M. Steenbakkers, Stephanie Beuel, Martijn P. W. Intven, Johannes A. Langendijk, Stefan Both, Stefanie Corradini, Viktor Rogowski, Maarten Terpstra, Niklas Wahl, Christopher Kurz, Guillaume Landry, Matteo Maspero</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 19:53:09</h6>
<p class='card-text'>Medical imaging is essential in modern radiotherapy, supporting diagnosis,
treatment planning, and monitoring. Synthetic imaging, particularly synthetic
computed tomography (sCT), is gaining traction in radiotherapy. The
SynthRAD2025 dataset and Grand Challenge promote advancements in sCT generation
by providing a benchmarking platform for algorithms using cone-beam CT (CBCT)
and magnetic resonance imaging (MRI).
  The dataset includes 2362 cases: 890 MRI-CT and 1472 CBCT-CT pairs from
head-and-neck, thoracic, and abdominal cancer patients treated at five European
university medical centers (UMC Groningen, UMC Utrecht, Radboud UMC, LMU
University Hospital Munich, and University Hospital of Cologne). Data were
acquired with diverse scanners and protocols. Pre-processing, including rigid
and deformable image registration, ensures high-quality, modality-aligned
images. Extensive quality assurance validates image consistency and usability.
  All imaging data is provided in MetaImage (.mha) format, ensuring
compatibility with medical image processing tools. Metadata, including
acquisition parameters and registration details, is available in structured CSV
files. To maintain dataset integrity, SynthRAD2025 is divided into training
(65%), validation (10%), and test (25%) sets. The dataset is accessible at
https://doi.org/10.5281/zenodo.14918089 under the SynthRAD2025 collection.
  This dataset supports benchmarking and the development of synthetic imaging
techniques for radiotherapy applications. Use cases include sCT generation for
MRI-only and MR-guided photon/proton therapy, CBCT-based dose calculations, and
adaptive radiotherapy workflows. By integrating diverse acquisition settings,
SynthRAD2025 fosters robust, generalizable image synthesis algorithms,
advancing personalized cancer care and adaptive radiotherapy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17560v1' target='_blank'>Optimal Follow-Up of Gravitational-Wave Events with the UltraViolet
  EXplorer (UVEX)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Leo P. Singer, Alexander W. Criswell, Sydney C. Leggio, R. Weizmann Kiendrebeogo, Michael W. Coughlin, Hannah P. Earnshaw, Suvi Gezari, Brian W. Grefenstette, Fiona A. Harrison, Mansi M. Kasliwal, Brett M. Morris, Erik Tollerud, S. Bradley Cenko</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 19:00:02</h6>
<p class='card-text'>The UltraViolet EXplorer (UVEX) is a wide-field ultraviolet space telescope
selected as a NASA Medium-Class Explorer (MIDEX) mission for launch in 2030.
UVEX will undertake deep, cadenced surveys of the entire sky to probe low mass
galaxies and explore the ultraviolet (UV) time-domain sky, and it will carry
the first rapidly deployable UV spectroscopic capability for a broad range of
science applications. One of UVEX's prime objectives is to follow up
gravitational wave (GW) binary neutron star mergers as targets of opportunity
(ToOs), rapidly scanning across their localization regions to search for their
kilonova (KN) counterparts. Early-time multiband ultraviolet light curves of
KNe are key to explaining the interplay between jet and ejecta in binary
neutron star mergers. Owing to high Galactic extinction in the ultraviolet and
the variation of GW distance estimates over the sky, the sensitivity to
kilonovae can vary significantly across the GW localization and even across the
footprint of a single image given UVEX's large field of view. Good ToO
observing strategies to trade off between area and depth are neither simple nor
obvious. We present an optimal strategy for GW follow-up with UVEX in which
exposure time is adjusted dynamically for each field individually to maximize
the overall probability of detection. We model the scheduling problem using the
expressive and powerful mathematical framework of mixed integer linear
programming (MILP), and employ a state-of-the-art MILP solver to automatically
generate observing plan timelines that achieve high probabilities of kilonova
detection. We have implemented this strategy in an open-source astronomical
scheduling software package called the Multi-Mission Multi-Messenger
Observation Planning Toolkit (M4OPT), on GitHub at
https://github.com/m4opt/m4opt.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17553v1' target='_blank'>SHAM-OT: Rapid Subhalo Abundance Matching with Optimal Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Silvan Fischbacher, Tomasz Kacprzak, Luis Fernando Machado Poletti Valle, Alexandre Refregier</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 19:00:01</h6>
<p class='card-text'>Subhalo abundance matching (SHAM) is widely used for connecting galaxies to
dark matter haloes. In SHAM, galaxies and (sub-)haloes are sorted according to
their mass (or mass proxy) and matched by their rank order. In this work, we
show that SHAM is the solution of the optimal transport (OT) problem on
empirical distributions (samples or catalogues) for any metric transport cost
function. In the limit of large number of samples, it converges to the solution
of the OT problem between continuous distributions. We propose SHAM-OT: a
formulation of abundance matching where the halo-galaxy relation is obtained as
the optimal transport plan between galaxy and halo mass functions. By working
directly on these (discretized) functions, SHAM-OT eliminates the need for
sampling or sorting and is solved using efficient OT algorithms at negligible
compute and memory cost. Scatter in the galaxy-halo relation can be naturally
incorporated through regularization of the transport plan. SHAM-OT can easily
be generalized to multiple marginal distributions. We validate our method using
analytical tests with varying cosmology and luminosity function parameters, and
on simulated halo catalogues. The efficiency of SHAM-OT makes it particularly
advantageous for Bayesian inference that requires marginalization over stellar
mass or luminosity function uncertainties.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17434v1' target='_blank'>V-HOP: Visuo-Haptic 6D Object Pose Tracking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongyu Li, Mingxi Jia, Tuluhan Akbulut, Yu Xiang, George Konidaris, Srinath Sridhar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 18:59:50</h6>
<p class='card-text'>Humans naturally integrate vision and haptics for robust object perception
during manipulation. The loss of either modality significantly degrades
performance. Inspired by this multisensory integration, prior object pose
estimation research has attempted to combine visual and haptic/tactile
feedback. Although these works demonstrate improvements in controlled
environments or synthetic datasets, they often underperform vision-only
approaches in real-world settings due to poor generalization across diverse
grippers, sensor layouts, or sim-to-real environments. Furthermore, they
typically estimate the object pose for each frame independently, resulting in
less coherent tracking over sequences in real-world deployments. To address
these limitations, we introduce a novel unified haptic representation that
effectively handles multiple gripper embodiments. Building on this
representation, we introduce a new visuo-haptic transformer-based object pose
tracker that seamlessly integrates visual and haptic input. We validate our
framework in our dataset and the Feelsight dataset, demonstrating significant
performance improvement on challenging sequences. Notably, our method achieves
superior generalization and robustness across novel embodiments, objects, and
sensor types (both taxel-based and vision-based tactile sensors). In real-world
experiments, we demonstrate that our approach outperforms state-of-the-art
visual trackers by a large margin. We further show that we can achieve precise
manipulation tasks by incorporating our real-time object tracking result into
motion plans, underscoring the advantages of visuo-haptic perception. Our model
and dataset will be made open source upon acceptance of the paper. Project
website: https://lhy.xyz/projects/v-hop/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17372v1' target='_blank'>Experimental validation of UAV search and detection system in real
  wilderness environment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stella Dumenčić, Luka Lanča, Karlo Jakac, Stefan Ivić</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 17:53:54</h6>
<p class='card-text'>Search and rescue (SAR) missions require reliable search methods to locate
survivors, especially in challenging or inaccessible environments. This is why
introducing unmanned aerial vehicles (UAVs) can be of great help to enhance the
efficiency of SAR missions while simultaneously increasing the safety of
everyone involved in the mission. Motivated by this, we design and experiment
with autonomous UAV search for humans in a Mediterranean karst environment. The
UAVs are directed using Heat equation-driven area coverage (HEDAC) ergodic
control method according to known probability density and detection function.
The implemented sensing framework consists of a probabilistic search model,
motion control system, and computer vision object detection. It enables
calculation of the probability of the target being detected in the SAR mission,
and this paper focuses on experimental validation of proposed probabilistic
framework and UAV control. The uniform probability density to ensure the even
probability of finding the targets in the desired search area is achieved by
assigning suitably thought-out tasks to 78 volunteers. The detection model is
based on YOLO and trained with a previously collected ortho-photo image
database. The experimental search is carefully planned and conducted, while as
many parameters as possible are recorded. The thorough analysis consists of the
motion control system, object detection, and the search validation. The
assessment of the detection and search performance provides strong indication
that the designed detection model in the UAV control algorithm is aligned with
real-world results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17359v1' target='_blank'>Travel Time Reliability in Stochastic Kinematic Flow Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexander Hammerl, Ravi Seshadri, Thomas Kjær Rasmussen, Otto Anker Nielsen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 17:37:15</h6>
<p class='card-text'>This paper analyzes the time-dependent relationship between the mean and
variance of travel time on a single corridor under rush hour like congestion
patterns. To model this phenomenon, we apply the LWR ((Lighthill & Whitham,
1955), (Richards, 1956)) theory on a homogenous freeway with a discontinuous
bottleneck at its downstream end, assuming a uni-modal demand profile with a
stochastic peak. We establish conditions for typical counterclockwise
hysteresis loops under these assumptions. It is demonstrated that shapes of the
fundamental diagram which always produce a counterclockwise loop can be
interpreted as an indication of aggressive driving behavior, while deviations
may occur under defensive driving. This classification enables a detailed
explanation of the qualitative physical mechanisms behind this pattern, as well
as an analysis of the causes for quantitatively limited deviations. Some of the
mathematical properties of the LWR model identified in our analysis have not
yet been addressed in the literature and we critically examine the extent to
which these reflect actual traffic flow behavior. Our considerations are
supported by numerical experiments. The obtained results aim to improve the
fundamental understanding of the physical causes of this hysteresis pattern and
to facilitate its better estimation in traffic planning and control.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17346v1' target='_blank'>User-Centric Evaluation Methods for Digital Twin Applications in
  Extended Reality</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Francesco Vona, Maximilian Warsinke, Tanja Kojic, Jan-Niklas Voit-Antons, Sebastian Moller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 17:19:07</h6>
<p class='card-text'>The integration of Digital Twins with Extended Reality technologies, such as
Virtual Reality and Augmented Reality, is transforming industries by enabling
more immersive, interactive experiences and enhancing real time decision
making. User centered evaluations are crucial for aligning XR enhanced DT
systems with user expectations, enhancing acceptance and utility in real world
settings. This paper proposes a user centric evaluation method for XR enhanced
DT applications to assess usability, cognitive load, and user experience. By
employing a range of assessment tools, including questionnaires and
observational studies across various use cases, such as virtual tourism, city
planning, and industrial maintenance, this method provides a structured
approach to capturing the users perspective.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17345v2' target='_blank'>+Tour: Recommending personalized itineraries for smart tourism</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:João Paulo Esper, Luciano de S. Fraga, Aline C. Viana, Kleber Vieira Cardoso, Sand Luz Correa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 17:18:54</h6>
<p class='card-text'>Next-generation touristic services will rely on the advanced mobile networks'
high bandwidth and low latency and the Multi-access Edge Computing (MEC)
paradigm to provide fully immersive mobile experiences. As an integral part of
travel planning systems, recommendation algorithms devise personalized tour
itineraries for individual users considering the popularity of a city's Points
of Interest (POIs) as well as the tourist preferences and constraints. However,
in the context of next-generation touristic services, recommendation algorithms
should also consider the applications (e.g., social network, mobile video
streaming, mobile augmented reality) the tourist will consume in the POIs and
the quality in which the MEC infrastructure will deliver such applications. In
this paper, we address the joint problem of recommending personalized tour
itineraries for tourists and efficiently allocating MEC resources for advanced
touristic applications. We formulate an optimization problem that maximizes the
itinerary of individual tourists while optimizing the resource allocation at
the network edge. We then propose an exact algorithm that quickly solves the
problem optimally, considering instances of realistic size. Using a real-world
location-based photo-sharing database, we conduct and present an exploratory
analysis to understand preferences and users' visiting patterns. Using this
understanding, we propose a methodology to identify user interest in
applications. Finally, we evaluate our algorithm using this dataset. Results
show that our algorithm outperforms a modified version of a state-of-the-art
solution for personalized tour itinerary recommendation, demonstrating gains up
to 11% for resource allocation efficiency and 40% for user experience. In
addition, our algorithm performs similarly to the modified state-of-the-art
solution regarding traditional itinerary recommendation metrics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17296v1' target='_blank'>Qoala: an Application Execution Environment for Quantum Internet Nodes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bart van der Vecht, Atak Talay Yücel, Hana Jirovská, Stephanie Wehner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 16:25:20</h6>
<p class='card-text'>Recently, a first-of-its-kind operating system for programmable quantum
network nodes was developed, called QNodeOS. Here, we present an extension of
QNodeOS called Qoala, which introduces (1) a unified program format for hybrid
interactive classical-quantum programs, providing a well-defined target for
compilers, and (2) a runtime representation of a program that allows joint
scheduling of the hybrid classical-quantum program, multitasking, and
asynchronous program execution. Based on concrete design considerations, we put
forward the architecture of Qoala, including the program structure and
execution mechanism. We implement Qoala in the form of a modular and extendible
simulator that is validated against real-world quantum network hardware
(available online). However, Qoala is not meant to be purely a simulator, and
implementation is planned on real hardware. We evaluate Qoala's effectiveness
and performance sensitivity to latencies and network schedules using an
extensive simulation study. Qoala provides a framework that opens the door for
future computer science research into quantum network applications, including
scheduling algorithms and compilation strategies that can now readily be
explored using the framework and tools provided.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17054v1' target='_blank'>Optimizing Urban Mobility Through Complex Network Analysis and Big Data
  from Smart Cards</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Li Sun, Negin Ashrafi, Maryam Pishgar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 11:08:08</h6>
<p class='card-text'>This study investigates the network characteristics of high-frequency (HF)
and low-frequency (LF) travelers in urban public transport systems by analyzing
20 million smart card records from Beijing's transit network. A novel
methodology integrates advanced data preprocessing, clustering techniques, and
complex network analysis to differentiate HF and LF passenger behaviors and
their impacts on network structure, robustness, and efficiency. The primary
challenge is accurately segmenting and modeling the behaviors of diverse
passenger groups within a large-scale, noisy dataset while maintaining
computational efficiency and scalability. HF networks, representing the top 25%
of travelers by usage frequency, exhibit high connectivity with an average
clustering coefficient of 0.72 and greater node degree centrality. However,
they have lower robustness, with efficiency declining by 35% under targeted
disruptions and longer average path lengths of 6.2 during peak hours. In
contrast, LF networks, which include 75% of travelers, are more dispersed yet
resilient, with efficiency declining by only 10% under similar disruptions and
stronger intracommunity connectivity. Temporal analysis reveals that HF
passengers significantly contribute to peak-hour congestion, with 57.4% of HF
trips occurring between 6:00 and 10:00 AM, while LF passengers show a broader
temporal distribution, helping to mitigate congestion hotspots. Understanding
these travel patterns is crucial for optimizing public transit systems. The
findings suggest targeted strategies such as enhancing robustness in HF
networks by diversifying key routes and improving accessibility in LF-dominated
areas. This research provides a scalable framework for analyzing smart card
data and offers actionable insights for optimizing transit networks, improving
congestion management, and advancing sustainable urban mobility planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16866v1' target='_blank'>Toward Agentic AI: Generative Information Retrieval Inspired Intelligent
  Communications and Networking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruichen Zhang, Shunpu Tang, Yinqiu Liu, Dusit Niyato, Zehui Xiong, Sumei Sun, Shiwen Mao, Zhu Han</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 06:02:25</h6>
<p class='card-text'>The increasing complexity and scale of modern telecommunications networks
demand intelligent automation to enhance efficiency, adaptability, and
resilience. Agentic AI has emerged as a key paradigm for intelligent
communications and networking, enabling AI-driven agents to perceive, reason,
decide, and act within dynamic networking environments. However, effective
decision-making in telecom applications, such as network planning, management,
and resource allocation, requires integrating retrieval mechanisms that support
multi-hop reasoning, historical cross-referencing, and compliance with evolving
3GPP standards. This article presents a forward-looking perspective on
generative information retrieval-inspired intelligent communications and
networking, emphasizing the role of knowledge acquisition, processing, and
retrieval in agentic AI for telecom systems. We first provide a comprehensive
review of generative information retrieval strategies, including traditional
retrieval, hybrid retrieval, semantic retrieval, knowledge-based retrieval, and
agentic contextual retrieval. We then analyze their advantages, limitations,
and suitability for various networking scenarios. Next, we present a survey
about their applications in communications and networking. Additionally, we
introduce an agentic contextual retrieval framework to enhance telecom-specific
planning by integrating multi-source retrieval, structured reasoning, and
self-reflective validation. Experimental results demonstrate that our framework
significantly improves answer accuracy, explanation consistency, and retrieval
efficiency compared to traditional and semantic retrieval methods. Finally, we
outline future research directions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16827v1' target='_blank'>Random matrices acting on sets: Independent columns</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yaniv Plan, Roman Vershynin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 04:24:02</h6>
<p class='card-text'>We study random matrices with independent subgaussian columns. Assuming each
column has a fixed Euclidean norm, we establish conditions under which such
matrices act as near-isometries when restricted to a given subset of their
domain. We show that, with high probability, the maximum distortion caused by
such a matrix is proportional to the Gaussian complexity of the subset, scaled
by the subgaussian norm of the matrix columns. This linear dependence on the
subgaussian norm is a new phenomenon, as random matrices with independent rows
or independent entries typically exhibit superlinear dependence. As a
consequence, normalizing the columns of random sparse matrices leads to
stronger embedding guarantees.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16755v1' target='_blank'>Watch Out E-scooter Coming Through: Multimodal Sensing of Mixed Traffic
  Use and Conflicts Through Riders Ego-centric Views</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hiruni Nuwanthika Kegalle, Danula Hettiachchi, Jeffrey Chan, Mark Sanderson, Flora D. Salim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 00:16:18</h6>
<p class='card-text'>E-scooters are becoming a popular means of urban transportation. However,
this increased popularity brings challenges, such as road accidents and
conflicts when sharing space with traditional transport modes. An in-depth
understanding of e-scooter rider behaviour is crucial for ensuring rider
safety, guiding infrastructure planning, and enforcing traffic rules. This
study investigated the rider behaviour through a naturalistic study with 23
participants equipped with a bike computer, eye-tracking glasses and cameras.
They followed a pre-determined route, enabling multi-modal data collection. We
analysed and compared gaze movements, speed, and video feeds across three
transport infrastructure types: a pedestrian-shared path, a cycle lane and a
roadway. Our findings reveal unique challenges e-scooter riders face, including
difficulty keeping up with cyclists and motor vehicles due to speed limits on
shared e-scooters, risks in signalling turns due to control lose, and limited
acceptance in mixed-use spaces. The cycle lane showed the highest average
speed, the least speed change points, and the least head movements, supporting
its suitability as dedicated infrastructure for e-scooters. These findings are
facilitated through multimodal sensing and analysing the e-scooter riders'
ego-centric view, which show the efficacy of our method in discovering the
behavioural dynamics of the riders in the wild. Our study highlights the
critical need to align infrastructure with user behaviour to improve safety and
emphasises the importance of targeted safety measures and regulations,
especially when e-scooter riders share spaces with pedestrians or motor
vehicles. The dataset and analysis code are available at
https://github.com/HiruniNuwanthika/Electric-Scooter-Riders-Multi-Modal-Data-Analysis.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16718v1' target='_blank'>NatSGLD: A Dataset with Speech, Gesture, Logic, and Demonstration for
  Robot Learning in Natural Human-Robot Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Snehesh Shrestha, Yantian Zha, Saketh Banagiri, Ge Gao, Yiannis Aloimonos, Cornelia Fermüller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 21:27:06</h6>
<p class='card-text'>Recent advances in multimodal Human-Robot Interaction (HRI) datasets
emphasize the integration of speech and gestures, allowing robots to absorb
explicit knowledge and tacit understanding. However, existing datasets
primarily focus on elementary tasks like object pointing and pushing, limiting
their applicability to complex domains. They prioritize simpler human command
data but place less emphasis on training robots to correctly interpret tasks
and respond appropriately. To address these gaps, we present the NatSGLD
dataset, which was collected using a Wizard of Oz (WoZ) method, where
participants interacted with a robot they believed to be autonomous. NatSGLD
records humans' multimodal commands (speech and gestures), each paired with a
demonstration trajectory and a Linear Temporal Logic (LTL) formula that
provides a ground-truth interpretation of the commanded tasks. This dataset
serves as a foundational resource for research at the intersection of HRI and
machine learning. By providing multimodal inputs and detailed annotations,
NatSGLD enables exploration in areas such as multimodal instruction following,
plan recognition, and human-advisable reinforcement learning from
demonstrations. We release the dataset and code under the MIT License at
https://www.snehesh.com/natsgld/ to support future HRI research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16707v1' target='_blank'>Reflective Planning: Vision-Language Models for Multi-Stage Long-Horizon
  Robotic Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yunhai Feng, Jiaming Han, Zhuoran Yang, Xiangyu Yue, Sergey Levine, Jianlan Luo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 20:42:15</h6>
<p class='card-text'>Solving complex long-horizon robotic manipulation problems requires
sophisticated high-level planning capabilities, the ability to reason about the
physical world, and reactively choose appropriate motor skills. Vision-language
models (VLMs) pretrained on Internet data could in principle offer a framework
for tackling such problems. However, in their current form, VLMs lack both the
nuanced understanding of intricate physics required for robotic manipulation
and the ability to reason over long horizons to address error compounding
issues. In this paper, we introduce a novel test-time computation framework
that enhances VLMs' physical reasoning capabilities for multi-stage
manipulation tasks. At its core, our approach iteratively improves a pretrained
VLM with a "reflection" mechanism - it uses a generative model to imagine
future world states, leverages these predictions to guide action selection, and
critically reflects on potential suboptimalities to refine its reasoning.
Experimental results demonstrate that our method significantly outperforms
several state-of-the-art commercial VLMs as well as other post-training
approaches such as Monte Carlo Tree Search (MCTS). Videos are available at
https://reflect-vlm.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16674v1' target='_blank'>Design and Implementation of a Scalable Clinical Data Warehouse for
  Resource-Constrained Healthcare Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shovito Barua Soumma, Fahim Shahriar, Umme Niraj Mahi, Md Hasin Abrar, Md Abdur Rahman Fahad, Abu Sayed Md. Latiful Hoque</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 18:19:30</h6>
<p class='card-text'>Centralized electronic health record repositories are critical for advancing
disease surveillance, public health research, and evidence-based policymaking.
However, developing countries face persistent challenges in achieving this due
to fragmented healthcare data sources, inconsistent record-keeping practices,
and the absence of standardized patient identifiers, limiting reliable record
linkage, compromise data interoperability, and limit scalability-obstacles
exacerbated by infrastructural constraints and privacy concerns. To address
these barriers, this study proposes a scalable, privacy-preserving clinical
data warehouse, NCDW, designed for heterogeneous EHR integration in
resource-limited settings and tested with 1.16 million clinical records. The
framework incorporates a wrapper-based data acquisition layer for secure,
automated ingestion of multisource health data and introduces a soundex
algorithm to resolve patient identity mismatches in the absence of unique IDs.
A modular data mart is designed for disease-specific analytics, demonstrated
through a dengue fever case study in Bangladesh, integrating clinical,
demographic, and environmental data for outbreak prediction and resource
planning. Quantitative assessment of the data mart underscores its utility in
strengthening national decision-support systems, highlighting the model's
adaptability for infectious disease management. Comparative evaluation of
database technologies reveals NoSQL outperforms relational SQL by 40-69% in
complex query processing, while system load estimates validate the
architecture's capacity to manage 19 million daily records (34TB over 5 years).
The framework can be adapted to various healthcare settings across developing
nations by modifying the ingestion layer to accommodate standards like ICD-11
and HL7 FHIR, facilitating interoperability for managing infectious diseases
(i.e., COVID, tuberculosis).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16634v2' target='_blank'>OptionZero: Planning with Learned Options</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Po-Wei Huang, Pei-Chiun Peng, Hung Guei, Ti-Rong Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 16:20:15</h6>
<p class='card-text'>Planning with options -- a sequence of primitive actions -- has been shown
effective in reinforcement learning within complex environments. Previous
studies have focused on planning with predefined options or learned options
through expert demonstration data. Inspired by MuZero, which learns superhuman
heuristics without any human knowledge, we propose a novel approach, named
OptionZero. OptionZero incorporates an option network into MuZero, providing
autonomous discovery of options through self-play games. Furthermore, we modify
the dynamics network to provide environment transitions when using options,
allowing searching deeper under the same simulation constraints. Empirical
experiments conducted in 26 Atari games demonstrate that OptionZero outperforms
MuZero, achieving a 131.58% improvement in mean human-normalized score. Our
behavior analysis shows that OptionZero not only learns options but also
acquires strategic skills tailored to different game characteristics. Our
findings show promising directions for discovering and using options in
planning. Our code is available at
https://rlg.iis.sinica.edu.tw/papers/optionzero.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16589v2' target='_blank'>Co-MTP: A Cooperative Trajectory Prediction Framework with
  Multi-Temporal Fusion for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyu Zhang, Zewei Zhou, Zhaoyi Wang, Yangjie Ji, Yanjun Huang, Hong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 14:38:13</h6>
<p class='card-text'>Vehicle-to-everything technologies (V2X) have become an ideal paradigm to
extend the perception range and see through the occlusion. Exiting efforts
focus on single-frame cooperative perception, however, how to capture the
temporal cue between frames with V2X to facilitate the prediction task even the
planning task is still underexplored. In this paper, we introduce the Co-MTP, a
general cooperative trajectory prediction framework with multi-temporal fusion
for autonomous driving, which leverages the V2X system to fully capture the
interaction among agents in both history and future domains to benefit the
planning. In the history domain, V2X can complement the incomplete history
trajectory in single-vehicle perception, and we design a heterogeneous graph
transformer to learn the fusion of the history feature from multiple agents and
capture the history interaction. Moreover, the goal of prediction is to support
future planning. Thus, in the future domain, V2X can provide the prediction
results of surrounding objects, and we further extend the graph transformer to
capture the future interaction among the ego planning and the other vehicles'
intentions and obtain the final future scenario state under a certain planning
action. We evaluate the Co-MTP framework on the real-world dataset V2X-Seq, and
the results show that Co-MTP achieves state-of-the-art performance and that
both history and future fusion can greatly benefit prediction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16548v1' target='_blank'>Composable Strategy Framework with Integrated Video-Text based Large
  Language Models for Heart Failure Assessment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jianzhou Chen, Xiumei Wang, Jinyang Sun, Xi Chen, Heyu Chu, Guo Song, Yuji Luo, Xingping Zhou, Rong Gu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 12:06:08</h6>
<p class='card-text'>Heart failure is one of the leading causes of death worldwide, with millons
of deaths each year, according to data from the World Health Organization (WHO)
and other public health agencies. While significant progress has been made in
the field of heart failure, leading to improved survival rates and improvement
of ejection fraction, there remains substantial unmet needs, due to the
complexity and multifactorial characteristics. Therefore, we propose a
composable strategy framework for assessment and treatment optimization in
heart failure. This framework simulates the doctor-patient consultation process
and leverages multi-modal algorithms to analyze a range of data, including
video, physical examination, text results as well as medical history. By
integrating these various data sources, our framework offers a more holistic
evaluation and optimized treatment plan for patients. Our results demonstrate
that this multi-modal approach outperforms single-modal artificial intelligence
(AI) algorithms in terms of accuracy in heart failure (HF) prognosis
prediction. Through this method, we can further evaluate the impact of various
pathological indicators on HF prognosis,providing a more comprehensive
evaluation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16531v1' target='_blank'>Efficient Coordination and Synchronization of Multi-Robot Systems Under
  Recurring Linear Temporal Logic</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Davide Peron, Victor Nan Fernandez-Ayala, Eleftherios E. Vlahakis, Dimos V. Dimarogonas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 10:35:04</h6>
<p class='card-text'>We consider multi-robot systems under recurring tasks formalized as linear
temporal logic (LTL) specifications. To solve the planning problem efficiently,
we propose a bottom-up approach combining offline plan synthesis with online
coordination, dynamically adjusting plans via real-time communication. To
address action delays, we introduce a synchronization mechanism ensuring
coordinated task execution, leading to a multi-agent coordination and
synchronization framework that is adaptable to a wide range of multi-robot
applications. The software package is developed in Python and ROS2 for broad
deployment. We validate our findings through lab experiments involving nine
robots showing enhanced adaptability compared to previous methods.
Additionally, we conduct simulations with up to ninety agents to demonstrate
the reduced computational complexity and the scalability features of our work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16458v1' target='_blank'>Transformer-based Approach for Accurate Asteroid Spectra taxonomy and
  albedo estimation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yijun Tang, Jiang Yunxiao, Yuxiang Feng, Xiaoming Zhang, Xiaojun Jiang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 06:19:33</h6>
<p class='card-text'>China plans to launch a probe (Tianwen-2) around 2025, mainly for exploring
the near-Earth asteroid 2016 HO3 . The mission involves close-range
exploration, landing, and mining operations that require three-dimensional
modeling of the asteroid, which requires prior knowledge of its material
composition and uniformity. This information is crucial in progressive or
ground exploration processes. Our research focuses on high-precision
intelligent inversion of complex physical properties of asteroids based on
spectral data, providing support for further analysis of aster oid materials,
density, and structure. We have developed a platform for asteroid spectral
classification, albedo estimation, and composition analysis, which includes
three types of neural networks based on Transformer attention mechanism: One
for spectral classification, achieving a four-class classification accuracy of
97.28% and an eleven-class classification accuracy of 95.69%; second one for
albedo estimation, with an average absolute error of 0.0308 in S-type asteroid
albedo estimation, and the third one for composition analysis, with a predicted
spectral angular distance of only 0.0340 and a root mean square error of 0.1759
for the abundance of end members. These results indicate that our network can
provide high-precision asteroid spectral classification, albedo estimation, and
composition analysis results. In addition, we utilized the platform to analyze
and provide results for six asteroids.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17517v1' target='_blank'>Attention-based UAV Trajectory Optimization for Wireless Power
  Transfer-assisted IoT Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Li Dong, Feibo Jiang, Yubo Peng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 02:57:06</h6>
<p class='card-text'>Unmanned Aerial Vehicles (UAVs) in Wireless Power Transfer (WPT)-assisted
Internet of Things (IoT) systems face the following challenges: limited
resources and suboptimal trajectory planning. Reinforcement learning-based
trajectory planning schemes face issues of low search efficiency and learning
instability when optimizing large-scale systems. To address these issues, we
present an Attention-based UAV Trajectory Optimization (AUTO) framework based
on the graph transformer, which consists of an Attention Trajectory
Optimization Model (ATOM) and a Trajectory lEarNing Method based on
Actor-critic (TENMA). In ATOM, a graph encoder is used to calculate the
self-attention characteristics of all IoTDs, and a trajectory decoder is
developed to optimize the number and trajectories of UAVs. TENMA then trains
the ATOM using an improved Actor-Critic method, in which the real reward of the
system is applied as the baseline to reduce variances in the critic network.
This method is suitable for high-quality and large-scale multi-UAV trajectory
planning. Finally, we develop numerous experiments, including a hardware
experiment in the field case, to verify the feasibility and efficiency of the
AUTO framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16370v1' target='_blank'>Entropic Selection Principle for Monge's Optimal Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shrey Aryan, Promit Ghosal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 22:13:29</h6>
<p class='card-text'>We investigate the small regularization limit of entropic optimal transport
when the cost function is the Euclidean distance in dimensions $d > 1$, and the
marginal measures are absolutely continuous with respect to the Lebesgue
measure. Our results establish that the limiting optimal transport plan is
supported on transport rays. Furthermore, within each transport ray, the
limiting transport plan uniquely minimizes a relative entropy functional with
respect to specific reference measures supported on the rays. This provides a
complete and unique characterization of the limiting transport plan. While
similar results have been obtained for $d = 1$ in \cite{Marino} and for
discrete measures in \cite{peyr\'e2020computationaloptimaltransport}, this work
resolves the previously open case in higher dimensions $d>1.$</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16365v1' target='_blank'>Demand Forecasting for Electric Vehicle Charging Stations using
  Multivariate Time-Series Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saba Sanami, Hesam Mosalli, Yu Yang, Hen-Geul Yeh, Amir G. Aghdam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 21:46:23</h6>
<p class='card-text'>As the number of electric vehicles (EVs) continues to grow, the demand for
charging stations is also increasing, leading to challenges such as long wait
times and insufficient infrastructure. High-precision forecasting of EV
charging demand is crucial for efficient station management, to address some of
these challenges. This paper presents an approach to predict the charging
demand at 15-minute intervals for the day ahead using a multivariate long
short-term memory (LSTM) network with an attention mechanism. Additionally, the
model leverages explainable AI techniques to evaluate the influence of various
factors on the predictions, including weather conditions, day of the week,
month, and any holiday. SHapley Additive exPlanations (SHAP) are used to
quantify the contribution of each feature to the final forecast, providing
deeper insights into how these factors affect prediction accuracy. As a result,
the framework offers enhanced decision-making for infrastructure planning. The
efficacy of the proposed method is demonstrated by simulations using the test
data collected from the EV charging stations at California State University,
Long Beach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16364v1' target='_blank'>Risk Measures for DC Pension Plan Decumulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peter A. Forsyth, Yuying Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 21:40:20</h6>
<p class='card-text'>As the developed world replaces Defined Benefit (DB) pension plans with
Defined Contribution (DC) plans, there is a need to develop decumulation
strategies for DC plan holders. Optimal decumulation can be viewed as a problem
in optimal stochastic control. Formulation as a control problem requires
specification of an objective function, which in turn requires a definition of
reward and risk. An intuitive specification of reward is the total withdrawals
over the retirement period. Most retirees view risk as the possibility of
running out of savings. This paper investigates several possible left tail risk
measures, in conjunction with DC plan decumulation. The risk measures studied
include (i) expected shortfall (ii) linear shortfall and (iii) probability of
shortfall. We establish that, under certain assumptions, the set of optimal
controls associated with all expected reward and expected shortfall Pareto
efficient frontier curves is identical to the set of optimal controls for all
expected reward and linear shortfall Pareto efficient frontier curves. Optimal
efficient frontiers are determined computationally for each risk measure, based
on a parametric market model. Robustness of these strategies is determined by
testing the strategies out-of-sample using block bootstrapping of historical
data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16346v1' target='_blank'>Analysis and Improvement of Eviction Enforcement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Baris Ata, Yuwei Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 20:27:39</h6>
<p class='card-text'>Each year, nearly 13,000 eviction orders are issued in Cook County, Illinois.
While most of these orders have an enforcement deadline, a portion does not.
The Cook County Sheriff's Office (CCSO) is responsible for enforcing these
orders, which involves selecting the orders to prioritize and planning daily
enforcement routes. This task presents a challenge: balancing "equity" (i.e.,
prioritizing orders that have been waiting longer) with "efficiency" (i.e.,
maximizing the number of orders served). Although the current CCSO policy is
highly efficient, a significant fraction of eviction orders miss their
deadline. Motivated by the CCSO's operations, we study a model of eviction
enforcement planning and propose a policy that dynamically prioritizes orders
based on their type (deadline or no deadline), location, and waiting time. Our
approach employs a budgeted prize-collecting vehicle routing problem (VRP) for
daily planning, where the "prizes" are determined by solving a stochastic
control problem. This stochastic control problem, which relies on the VRP for
determining feasible actions at each decision point, is high-dimensional due to
its spatial nature, leading to the curse of dimensionality. We overcome this
challenge by building on recent advances in high-dimensional stochastic control
using deep neural networks. We compare the performance of our proposed policy
with two practical benchmark policies, including one that mimics the current
CCSO policy, using data from CCSO. Similar to the CCSO policy, our proposed
policy leads to efficient resource utilization, but it also reduces the
percentage of orders that miss their deadline by 72.38% without degrading the
overall service effort for either type of orders. In a counterfactual study, we
show that increasing the service capacity or extending the enforcement deadline
further reduces the fraction of orders missing their deadline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16333v1' target='_blank'>Optimizing normal tissue sparing via spatiotemporal optimization under
  equivalent tumor-radical efficacy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nimita Shinde, Wangyao Li, Ronald C Chen, Hao Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 19:46:22</h6>
<p class='card-text'>Objective: Spatiotemporal optimization in radiation therapy involves
determining the optimal number of dose delivery fractions (temporal) and the
optimal dose per fraction (spatial). Traditional approaches focus on maximizing
the biologically effective dose (BED) to the target while constraining BED to
organs-at-risk (OAR), which may lead to insufficient BED for complete tumor
cell kill. This work proposes a formulation that ensures adequate BED delivery
to the target while minimizing BED to the OAR. Approach: A spatiotemporal
optimization model is developed that incorporates an inequality constraint to
guarantee sufficient BED for tumor cell kill while minimizing BED to the OAR.
The model accounts for tumor proliferation dynamics, including lag time (delay
before proliferation begins) and doubling time (time for tumor volume to
double), to optimize dose fractionation. Results: The performance of our
formulation is evaluated for varying lag and doubling times. The results show
that mean BED to the target consistently meets the minimum requirement for
tumor cell kill. Additionally, the mean BED to OAR varies based on tumor
proliferation dynamics. In the prostate case with lag time of 7 days and
doubling time of 2 days, it is observed that mean BED delivered to femoral head
is lowest at around 20 fractions, making this an optimal choice. While in the
head-and-neck case, mean BED to OAR decreases as the number of fractions
increases, suggesting that a higher number of fractions is optimal.
Significance: A spatiotemporal optimization model is presented that minimizes
BED to the OAR while ensuring sufficient BED for tumor cell kill. By
incorporating tumor lag and doubling time, the approach identifies optimal
number of fractions. This model can be extended to support hyperfractionation
or accelerated fractionation strategies, offering a versatile tool for clinical
treatment planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16332v2' target='_blank'>Minibeam-pLATTICE: A novel proton LATTICE modality using minibeams</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nimita Shinde, Weijie Zhang, Yuting Lin, Hao Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 19:37:49</h6>
<p class='card-text'>Purpose: LATTICE, a form of spatially fractionated radiation therapy that
delivers high-dose peaks and low-dose valleys within the target, has been
clinically utilized for treating bulky tumors. However, its application to
small-to-medium-sized target remains challenging due to beam size limitations.
To address this challenge, this work proposes a novel proton LATTICE (pLATTICE)
modality using minibeams, namely minibeam-pLATTICE, that extends LATTICE
approach for small-to-medium targets. Methods: Three minibeam-pLATTICE methods
are introduced. (1) M0: a fixed minibeam orientation for all beam angles; (2)
M1: alternated minibeam orientations, for consecutive beam angles; (3) M2:
multiple minibeam orientations for each beam angle. For each minibeam-pLATTICE
method, an optimization problem is formulated to optimize dose uniformity in
target peaks and valleys, as well as dose-volume-histogram-based objectives.
This problem is solved using iterative convex relaxation and alternating
direction method of multipliers. Results: Three minibeam-pLATTICE methods are
validated to demonstrate the feasibility of minibeam-pLATTICE for head-and-neck
cases. The advantages of this modality over conventional beam (CONV) pLATTICE
are evaluated by comparing peak-to-valley dose ratio (PVDR) and dose delivered
to organs at risk (OAR). All three minibeam-pLATTICE modalities achieved
improved plan quality compared to CONV, with M2 yielding the best results. For
example, in terms of PVDR, M2=5.89, compared to CONV=4.13, M0=4.87 and M1=4.7.
Conclusion: A novel minibeam-pLATTICE modality is proposed that generates
lattice dose patterns for small-to-medium targets, which are not achievable
with conventional pLATTICE due to beam size limitations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16326v1' target='_blank'>A mixed integer programming approach to minibeam aperture optimization
  for multi-collimator proton minibeam radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nimita Shinde, Weijie Zhang, Yuting Lin, Hao Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 19:03:25</h6>
<p class='card-text'>Background: Multi-collimator proton minibeam radiation therapy (MC-pMBRT) has
recently emerged as a versatile technique for dose shaping, enabling
peak-valley dose patterns in organs-at-risk (OAR) while maintaining a uniform
dose distribution in tumor. MC-pMBRT leverages a set of generic multi-slit
collimators (MSC) with varying center-to-center distances. However, the current
method for minibeam aperture optimization (MAO), i.e., the selection of MSC per
beam angle, is manual and heuristic, resulting in computational inefficiencies
and no guarantee of optimality. This work introduces a novel mixed integer
programming (MIP) approach to MAO for optimizing MC-pMBRT plan quality.
Methods: The proposed MIP approach jointly optimizes dose distributions,
peak-to-valley dose ratio (PVDR), and selects the optimal set of MSC per beam
angle. The optimization problem includes decision variables for MSC selection
per beam angle and spot weights. The proposed MIP approach is a two-step
process: Step1: the binary variables are optimally determined to select MSC for
each beam angle; Step 2: the continuous variables are solved to determine the
spot weights. Both steps utilize iterative convex relaxation and the
alternating direction method of multipliers to solve the problems. Results: The
proposed MIP method for MAO (MIP-MAO) was validated against the conventional
heuristic method (CONV) for MC-pMBRT treatment planning. Results indicate that
MIP-MAO enhances the conformity index (CI) for the target and improves PVDR for
OAR. For instance, in a head-and-neck case, CI improved from 0.61 (CONV) to
0.70 (MIP-MAO); in an abdomen case, CI improved from 0.78 (CONV) to 0.83
(MIP-MAO). Additionally, MIP-MAO reduced mean doses in the body and OAR.
Conclusions: A novel MIP approach for MAO in MC-pMBRT is presented, showing
demonstrated improvements in plan quality and PVDR compared to the heuristic
method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16144v1' target='_blank'>Epilepsy and its driving forces: understanding the forces behind
  epileptical pathogenisis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shreya Shah, Manan Shah, Bhavin Parekh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 08:37:02</h6>
<p class='card-text'>Epilepsy is a neurological disorder characterized by seizures and epileptic
events intertwined with religious and personal beliefs since prehistoric times.
This review paper explores the historical context and challenges in defining
epilepsy. The formal definition was established twenty years ago, and the
multifaceted causes of this neurological disorder. It aims to pave the way for
personalised therapeutic strategies, research advancements, and informed public
health planning to enhance the lives of those affected by this complex
neurological condition. In addition, this review paper focuses on the
mechanisms and etiologies of epileptogenesis, categorizing them by mechanisms
and the underlying causes of the disorder. The review paper provides a brief
overview of the current state of the art in the diagnosis, diagnosis,
treatment, and treatment of epileptiform seizures.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16134v1' target='_blank'>Motion-Coupled Mapping Algorithm for Hybrid Rice Canopy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huaiqu Feng, Guoyang Zhao, Cheng Liu, Yongwei Wang, Jun Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 08:12:23</h6>
<p class='card-text'>This paper presents a motion-coupled mapping algorithm for contour mapping of
hybrid rice canopies, specifically designed for Agricultural Unmanned Ground
Vehicles (Agri-UGV) navigating complex and unknown rice fields. Precise canopy
mapping is essential for Agri-UGVs to plan efficient routes and avoid protected
zones. The motion control of Agri-UGVs, tasked with impurity removal and other
operations, depends heavily on accurate estimation of rice canopy height and
structure. To achieve this, the proposed algorithm integrates real-time RGB-D
sensor data with kinematic and inertial measurements, enabling efficient
mapping and proprioceptive localization. The algorithm produces grid-based
elevation maps that reflect the probabilistic distribution of canopy contours,
accounting for motion-induced uncertainties. It is implemented on a
high-clearance Agri-UGV platform and tested in various environments, including
both controlled and dynamic rice field settings. This approach significantly
enhances the mapping accuracy and operational reliability of Agri-UGVs,
contributing to more efficient autonomous agricultural operations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16111v1' target='_blank'>PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning
  Trajectories for Complex Problem Solving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mihir Parmar, Xin Liu, Palash Goyal, Yanfei Chen, Long Le, Swaroop Mishra, Hossein Mobahi, Jindong Gu, Zifeng Wang, Hootan Nakhost, Chitta Baral, Chen-Yu Lee, Tomas Pfister, Hamid Palangi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 06:21:56</h6>
<p class='card-text'>Recent agent frameworks and inference-time algorithms often struggle with
complex planning problems due to limitations in verifying generated plans or
reasoning and varying complexity of instances within a single task. Many
existing methods for these tasks either perform task-level verification without
considering constraints or apply inference-time algorithms without adapting to
instance-level complexity. To address these limitations, we propose PlanGEN, a
model-agnostic and easily scalable agent framework with three key components:
constraint, verification, and selection agents. Specifically, our approach
proposes constraint-guided iterative verification to enhance performance of
inference-time algorithms--Best of N, Tree-of-Thought, and REBASE. In PlanGEN
framework, the selection agent optimizes algorithm choice based on instance
complexity, ensuring better adaptability to complex planning problems.
Experimental results demonstrate significant improvements over the strongest
baseline across multiple benchmarks, achieving state-of-the-art results on
NATURAL PLAN ($\sim$8%$\uparrow$), OlympiadBench ($\sim$4%$\uparrow$), DocFinQA
($\sim$7%$\uparrow$), and GPQA ($\sim$1%$\uparrow$). Our key finding highlights
that constraint-guided iterative verification improves inference-time
algorithms, and adaptive selection further boosts performance on complex
planning and reasoning problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16008v1' target='_blank'>Exact Recovery of Sparse Binary Vectors from Generalized Linear
  Measurements</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arya Mazumdar, Neha Sangwan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 23:46:24</h6>
<p class='card-text'>We consider the problem of exact recovery of a $k$-sparse binary vector from
generalized linear measurements (such as logistic regression). We analyze the
linear estimation algorithm (Plan, Vershynin, Yudovina, 2017), and also show
information theoretic lower bounds on the number of required measurements. As a
consequence of our results, for noisy one bit quantized linear measurements
($\mathsf{1bCSbinary}$), we obtain a sample complexity of
$O((k+\sigma^2)\log{n})$, where $\sigma^2$ is the noise variance. This is shown
to be optimal due to the information theoretic lower bound. We also obtain
tight sample complexity characterization for logistic regression.
  Since $\mathsf{1bCSbinary}$ is a strictly harder problem than noisy linear
measurements ($\mathsf{SparseLinearReg}$) because of added quantization, the
same sample complexity is achievable for $\mathsf{SparseLinearReg}$. While this
sample complexity can be obtained via the popular lasso algorithm, linear
estimation is computationally more efficient. Our lower bound holds for any set
of measurements for $\mathsf{SparseLinearReg}$, (similar bound was known for
Gaussian measurement matrices) and is closely matched by the maximum-likelihood
upper bound. For $\mathsf{SparseLinearReg}$, it was conjectured in Gamarnik and
Zadik, 2017 that there is a statistical-computational gap and the number of
measurements should be at least $(2k+\sigma^2)\log{n}$ for efficient algorithms
to exist. It is worth noting that our results imply that there is no such
statistical-computational gap for $\mathsf{1bCSbinary}$ and logistic
regression.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15971v1' target='_blank'>Towards Autonomous Navigation of Neuroendovascular Tools for Timely
  Stroke Treatment via Contact-aware Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aabha Tamhankar, Giovanni Pittiglio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 22:16:35</h6>
<p class='card-text'>In this paper, we propose a model-based contact-aware motion planner for
autonomous navigation of neuroendovascular tools in acute ischemic stroke. The
planner is designed to find the optimal control strategy for telescopic
pre-bent catheterization tools such as guidewire and catheters, currently used
for neuroendovascular procedures. A kinematic model for the telescoping tools
and their interaction with the surrounding anatomy is derived to predict tools
steering. By leveraging geometrical knowledge of the anatomy, obtained from
pre-operative segmented 3D images, and the mechanics of the telescoping tools,
the planner finds paths to the target enabled by interacting with the
surroundings. We propose an actuation platform for insertion and rotation of
the telescopic tools and present experimental results for the navigation from
the base of the descending aorta to the LCCA. We demonstrate that, by
leveraging the pre-operative plan, we can consistently navigate the LCCA with
100% success of over 50 independent trials. We also study the robustness of the
planner towards motion of the aorta and errors in the initial positioning of
the robotic tools. The proposed plan can successfully reach the LCCA for
rotations of the aorta of up to 10{\deg}, and displacement of up to 10mm, on
the coronal plane.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15961v1' target='_blank'>IA-TIGRIS: An Incremental and Adaptive Sampling-Based Planner for Online
  Informative Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Brady Moon, Nayana Suvarna, Andrew Jong, Satrajit Chatterjee, Junbin Yuan, Sebastian Scherer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 21:46:56</h6>
<p class='card-text'>Planning paths that maximize information gain for robotic platforms has
wide-ranging applications and significant potential impact. To effectively
adapt to real-time data collection, informative path planning must be computed
online and be responsive to new observations. In this work, we present
IA-TIGRIS, an incremental and adaptive sampling-based informative path planner
that can be run efficiently with onboard computation. Our approach leverages
past planning efforts through incremental refinement while continuously
adapting to updated world beliefs. We additionally present detailed
implementation and optimization insights to facilitate real-world deployment,
along with an array of reward functions tailored to specific missions and
behaviors. Extensive simulation results demonstrate IA-TIGRIS generates
higher-quality paths compared to baseline methods. We validate our planner on
two distinct hardware platforms: a hexarotor UAV and a fixed-wing UAV, each
having unique motion models and configuration spaces. Our results show up to a
41% improvement in information gain compared to baseline methods, suggesting
significant potential for deployment in real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15958v1' target='_blank'>Impact Analysis of Utility-Scale Energy Storage on the ERCOT Grid in
  Reducing Renewable Generation Curtailments and Emissions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cody Buehner, Sharaf K. Magableh, Oraib Dawaghreh, Caisheng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 21:40:16</h6>
<p class='card-text'>This paper explores the solutions for minimizing renewable energy (RE)
curtailment in the Texas Electric Reliability Council of Texas (ERCOT) grid. By
utilizing current and future planning data from ERCOT and the System Advisor
Model from the National Renewable Energy Laboratory, we examine how future
renewable energy (RE) initiatives, combined with utility-scale energy storage,
can reduce CO2 emissions while reshaping Texas's energy mix. The study projects
the energy landscape from 2023 to 2033, considering the planned phase-out of
fossil fuel plants and the integration of new wind/solar projects. By comparing
emissions under different load scenarios, with and without storage, we
demonstrate storage's role in optimizing RE utilization. The findings of this
paper provide actionable guidance for energy stakeholders, underscoring the
need to expand wind and solar projects with strategic storage solutions to
maximize Texas's RE capacity and substantially reduce CO2 emissions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15907v1' target='_blank'>Graph Attention Convolutional U-NET: A Semantic Segmentation Model for
  Identifying Flooded Areas</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Umair Danish, Madhushan Buwaneswaran, Tehara Fonseka, Katarina Grolinger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 19:50:13</h6>
<p class='card-text'>The increasing impact of human-induced climate change and unplanned urban
constructions has increased flooding incidents in recent years. Accurate
identification of flooded areas is crucial for effective disaster management
and urban planning. While few works have utilized convolutional neural networks
and transformer-based semantic segmentation techniques for identifying flooded
areas from aerial footage, recent developments in graph neural networks have
created improvement opportunities. This paper proposes an innovative approach,
the Graph Attention Convolutional U-NET (GAC-UNET) model, based on graph neural
networks for automated identification of flooded areas. The model incorporates
a graph attention mechanism and Chebyshev layers into the U-Net architecture.
Furthermore, this paper explores the applicability of transfer learning and
model reprogramming to enhance the accuracy of flood area segmentation models.
Empirical results demonstrate that the proposed GAC-UNET model, outperforms
other approaches with 91\% mAP, 94\% dice score, and 89\% IoU, providing
valuable insights for informed decision-making and better planning of future
infrastructures in flood-prone areas.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15657v2' target='_blank'>Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer
  a Safer Path?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yoshua Bengio, Michael Cohen, Damiano Fornasiere, Joumana Ghosn, Pietro Greiner, Matt MacDermott, Sören Mindermann, Adam Oberman, Jesse Richardson, Oliver Richardson, Marc-Antoine Rondeau, Pierre-Luc St-Charles, David Williams-King</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 18:28:36</h6>
<p class='card-text'>The leading AI companies are increasingly focused on building generalist AI
agents -- systems that can autonomously plan, act, and pursue goals across
almost all tasks that humans can perform. Despite how useful these systems
might be, unchecked AI agency poses significant risks to public safety and
security, ranging from misuse by malicious actors to a potentially irreversible
loss of human control. We discuss how these risks arise from current AI
training methods. Indeed, various scenarios and experiments have demonstrated
the possibility of AI agents engaging in deception or pursuing goals that were
not specified by human operators and that conflict with human interests, such
as self-preservation. Following the precautionary principle, we see a strong
need for safer, yet still useful, alternatives to the current agency-driven
trajectory. Accordingly, we propose as a core building block for further
advances the development of a non-agentic AI system that is trustworthy and
safe by design, which we call Scientist AI. This system is designed to explain
the world from observations, as opposed to taking actions in it to imitate or
please humans. It comprises a world model that generates theories to explain
data and a question-answering inference machine. Both components operate with
an explicit notion of uncertainty to mitigate the risks of overconfident
predictions. In light of these considerations, a Scientist AI could be used to
assist human researchers in accelerating scientific progress, including in AI
safety. In particular, our system can be employed as a guardrail against AI
agents that might be created despite the risks involved. Ultimately, focusing
on non-agentic AI may enable the benefits of AI innovation while avoiding the
risks associated with the current trajectory. We hope these arguments will
motivate researchers, developers, and policymakers to favor this safer path.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15635v2' target='_blank'>Para-Lane: Multi-Lane Dataset Registering Parallel Scans for
  Benchmarking Novel View Synthesis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziqian Ni, Sicong Du, Zhenghua Hou, Chenming Wu, Sheng Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 18:03:56</h6>
<p class='card-text'>To evaluate end-to-end autonomous driving systems, a simulation environment
based on Novel View Synthesis (NVS) techniques is essential, which synthesizes
photo-realistic images and point clouds from previously recorded sequences
under new vehicle poses, particularly in cross-lane scenarios. Therefore, the
development of a multi-lane dataset and benchmark is necessary. While recent
synthetic scene-based NVS datasets have been prepared for cross-lane
benchmarking, they still lack the realism of captured images and point clouds.
To further assess the performance of existing methods based on NeRF and 3DGS,
we present the first multi-lane dataset registering parallel scans specifically
for novel driving view synthesis dataset derived from real-world scans,
comprising 25 groups of associated sequences, including 16,000 front-view
images, 64,000 surround-view images, and 16,000 LiDAR frames. All frames are
labeled to differentiate moving objects from static elements. Using this
dataset, we evaluate the performance of existing approaches in various testing
scenarios at different lanes and distances. Additionally, our method provides
the solution for solving and assessing the quality of multi-sensor poses for
multi-modal data alignment for curating such a dataset in real-world. We plan
to continually add new sequences to test the generalization of existing methods
across different scenarios. The dataset is released publicly at the project
page: https://nizqleo.github.io/paralane-dataset/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15630v1' target='_blank'>Reduced-Order Model Guided Contact-Implicit Model Predictive Control for
  Humanoid Locomotion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sergio A. Esteban, Vince Kurtz, Adrian B. Ghansah, Aaron D. Ames</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 17:57:55</h6>
<p class='card-text'>Humanoid robots have great potential for real-world applications due to their
ability to operate in environments built for humans, but their deployment is
hindered by the challenge of controlling their underlying high-dimensional
nonlinear hybrid dynamics. While reduced-order models like the Hybrid Linear
Inverted Pendulum (HLIP) are simple and computationally efficient, they lose
whole-body expressiveness. Meanwhile, recent advances in Contact-Implicit Model
Predictive Control (CI-MPC) enable robots to plan through multiple hybrid
contact modes, but remain vulnerable to local minima and require significant
tuning. We propose a control framework that combines the strengths of HLIP and
CI-MPC. The reduced-order model generates a nominal gait, while CI-MPC manages
the whole-body dynamics and modifies the contact schedule as needed. We
demonstrate the effectiveness of this approach in simulation with a novel 24
degree-of-freedom humanoid robot: Achilles. Our proposed framework achieves
rough terrain walking, disturbance recovery, robustness under model and state
uncertainty, and allows the robot to interact with obstacles in the
environment, all while running online in real-time at 50 Hz.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15616v1' target='_blank'>Pastiche Novel Generation Creating: Fan Fiction You Love in Your
  Favorite Author's Style</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xueran Han, Yuhan Liu, Mingzhe Li, Wei Liu, Sen Hu, Rui Yan, Zhiqiang Xu, Xiuying Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 17:40:42</h6>
<p class='card-text'>Great novels create immersive worlds with rich character arcs,
well-structured plots, and nuanced writing styles. However, current novel
generation methods often rely on brief, simplistic story outlines and generate
details using plain, generic language. To bridge this gap, we introduce the
task of Pastiche Novel Generation, which requires the generated novels to
imitate the distinctive features of the original work, including understanding
character profiles, predicting plausible plot developments, and writing
concrete details using vivid, expressive language. To achieve this, we propose
WriterAgent, a novel generation system designed to master the core aspects of
literary pastiche. WriterAgent is trained through a curriculum learning
paradigm, progressing from low-level stylistic mastery to high-level narrative
coherence. Its key tasks include language style learning, character modeling,
plot planning, and stylish writing, ensuring comprehensive narrative control.
To support this, WriterAgent leverages the WriterLoRA framework, an extension
of LoRA with hierarchical and cumulative task-specific modules, each
specializing in a different narrative aspect. We evaluate WriterAgent on
multilingual classics like Harry Potter and Dream of the Red Chamber,
demonstrating its superiority over baselines in capturing the target author's
settings, character dynamics, and writing style to produce coherent, faithful
narratives.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15525v1' target='_blank'>Enhanced Probabilistic Collision Detection for Motion Planning Under
  Sensing Uncertainty</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaoli Wang, Sipu Ruan, Xin Meng, Gregory Chirikjian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 15:27:29</h6>
<p class='card-text'>Probabilistic collision detection (PCD) is essential in motion planning for
robots operating in unstructured environments, where considering sensing
uncertainty helps prevent damage. Existing PCD methods mainly used simplified
geometric models and addressed only position estimation errors. This paper
presents an enhanced PCD method with two key advancements: (a) using
superquadrics for more accurate shape approximation and (b) accounting for both
position and orientation estimation errors to improve robustness under sensing
uncertainty. Our method first computes an enlarged surface for each object that
encapsulates its observed rotated copies, thereby addressing the orientation
estimation errors. Then, the collision probability under the position
estimation errors is formulated as a chance-constraint problem that is solved
with a tight upper bound. Both the two steps leverage the recently developed
normal parameterization of superquadric surfaces. Results show that our PCD
method is twice as close to the Monte-Carlo sampled baseline as the best
existing PCD method and reduces path length by 30% and planning time by 37%,
respectively. A Real2Sim pipeline further validates the importance of
considering orientation estimation errors, showing that the collision
probability of executing the planned path in simulation is only 2%, compared to
9% and 29% when considering only position estimation errors or none at all.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15198v1' target='_blank'>Graph-Based Deep Learning on Stereo EEG for Predicting Seizure Freedom
  in Epilepsy Patients</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Artur Agaronyan, Syeda Abeera Amir, Nunthasiri Wittayanakorn, John Schreiber, Marius G. Linguraru, William Gaillard, Chima Oluigbo, Syed Muhammad Anwar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 04:24:34</h6>
<p class='card-text'>Predicting seizure freedom is essential for tailoring epilepsy treatment. But
accurate prediction remains challenging with traditional methods, especially
with diverse patient populations. This study developed a deep learning-based
graph neural network (GNN) model to predict seizure freedom from stereo
electroencephalography (sEEG) data in patients with refractory epilepsy. We
utilized high-quality sEEG data from 15 pediatric patients to train a deep
learning model that can accurately predict seizure freedom outcomes and advance
understanding of brain connectivity at the seizure onset zone. Our model
integrates local and global connectivity using graph convolutions with
multi-scale attention mechanisms to capture connections between
difficult-to-study regions such as the thalamus and motor regions. The model
achieved an accuracy of 92.4% in binary class analysis, 86.6% in patient-wise
analysis, and 81.4% in multi-class analysis. Node and edge-level feature
analysis highlighted the anterior cingulate and frontal pole regions as key
contributors to seizure freedom outcomes. The nodes identified by our model
were also more likely to coincide with seizure onset zones. Our findings
underscore the potential of new connectivity-based deep learning models such as
GNNs for enhancing the prediction of seizure freedom, predicting seizure onset
zones, connectivity analysis of the brain during seizure, as well as informing
AI-assisted personalized epilepsy treatment planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15181v1' target='_blank'>Debunking the Myth of Join Ordering: Toward Robust SQL Analytics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junyi Zhao, Kai Su, Yifei Yang, Xiangyao Yu, Paraschos Koutris, Huanchen Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 03:24:06</h6>
<p class='card-text'>Join order optimization is critical in achieving good query performance.
Despite decades of research and practice, modern query optimizers could still
generate inferior join plans that are orders of magnitude slower than optimal.
Existing research on robust query processing often lacks theoretical guarantees
on join-order robustness while sacrificing query performance. In this paper, we
rediscover the recent Predicate Transfer technique from a robustness point of
view. We introduce two new algorithms, LargestRoot and SafeSubjoin, and then
propose Robust Predicate Transfer (RPT) that is provably robust against
arbitrary join orders of an acyclic query. We integrated Robust Predicate
Transfer with DuckDB, a state-of-the-art analytical database, and evaluated
against all the queries in TPC-H, JOB, and TPC-DS benchmarks. Our experimental
results show that RPT improves join-order robustness by orders of magnitude
compared to the baseline. With RPT, the largest ratio between the maximum and
minimum execution time out of random join orders for a single acyclic query is
only 1.6x (the ratio is close to 1 for most evaluated queries). Meanwhile,
applying RPT also improves the end-to-end query performance by 1.5x (per-query
geometric mean). We hope that this work sheds light on solving the practical
join ordering problem.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15160v1' target='_blank'>GraphFuzz: Automated Testing of Graph Algorithm Implementations with
  Differential Fuzzing and Lightweight Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenqi Yan, Manuel Rigger, Anthony Wirth, Van-Thuan Pham</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 02:47:05</h6>
<p class='card-text'>Graph algorithms, such as shortest path finding, play a crucial role in
enabling essential applications and services like infrastructure planning and
navigation, making their correctness important. However, thoroughly testing
graph algorithm implementations poses several challenges, including their vast
input space (i.e., arbitrary graphs). Moreover, through our preliminary study,
we find that just a few automatically generated graphs (less than 10) could be
enough to cover the code of many graph algorithm implementations, rendering the
code coverage-guided fuzzing approach -- one of the state-of-the-art search
algorithms -- less efficient than expected.
  To tackle these challenges, we introduce GraphFuzz, the first automated
feedback-guided fuzzing framework for graph algorithm implementations. Our key
innovation lies in identifying lightweight and algorithm-specific feedback
signals to combine with or completely replace the code coverage feedback to
enhance the diversity of the test corpus, thereby speeding up the bug-finding
process. This novel idea also allows GraphFuzz to effectively work in both
black-box (i.e., no code coverage instrumentation/collection is required) and
grey-box setups. GraphFuzz applies differential testing to detect both
crash-triggering bugs and logic bugs. Our evaluation demonstrates the
effectiveness of GraphFuzz. The tool has successfully discovered 12 previously
unknown bugs, including 6 logic bugs, in 9 graph algorithm implementations in
two popular graph libraries, NetworkX and iGraph. All of them have been
confirmed and and 11 bugs have been rectified by the libraries' maintainers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17495v1' target='_blank'>Spatiotemporal Forecasting in Climate Data Using EOFs and Machine
  Learning Models: A Case Study in Chile</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mauricio Herrera, Francisca Kleisinger, Andrés Wilsón</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 01:34:38</h6>
<p class='card-text'>Effective resource management and environmental planning in regions with high
climatic variability, such as Chile, demand advanced predictive tools. This
study addresses this challenge by employing an innovative and computationally
efficient hybrid methodology that integrates machine learning (ML) methods for
time series forecasting with established statistical techniques. The
spatiotemporal data undergo decomposition using time-dependent Empirical
Orthogonal Functions (EOFs), denoted as \(\phi_{k}(t)\), and their
corresponding spatial coefficients, \(\alpha_{k}(s)\), to reduce
dimensionality. Wavelet analysis provides high-resolution time and frequency
information from the \(\phi_{k}(t)\) functions, while neural networks forecast
these functions within a medium-range horizon \(h\). By utilizing various ML
models, particularly a Wavelet - ANN hybrid model, we forecast
\(\phi_{k}(t+h)\) up to a time horizon \(h\), and subsequently reconstruct the
spatiotemporal data using these extended EOFs. This methodology is applied to a
grid of climate data covering the territory of Chile. It transitions from a
high-dimensional multivariate spatiotemporal data forecasting problem to a
low-dimensional univariate forecasting problem. Additionally, cluster analysis
with Dynamic Time Warping for defining similarities between rainfall time
series, along with spatial coherence and predictability assessments, has been
instrumental in identifying geographic areas where model performance is
enhanced. This approach also elucidates the reasons behind poor forecast
performance in regions or clusters with low spatial coherence and
predictability. By utilizing cluster medoids, the forecasting process becomes
more practical and efficient. This compound approach significantly reduces
computational complexity while generating forecasts of reasonable accuracy and
utility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15043v1' target='_blank'>DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot
  Trajectories</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jean-Baptiste Bouvier, Kanghyun Ryu, Kartik Nagpal, Qiayuan Liao, Koushil Sreenath, Negar Mehr</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 21:00:21</h6>
<p class='card-text'>Diffusion models excel at creating images and videos thanks to their
multimodal generative capabilities. These same capabilities have made diffusion
models increasingly popular in robotics research, where they are used for
generating robot motion. However, the stochastic nature of diffusion models is
fundamentally at odds with the precise dynamical equations describing the
feasible motion of robots. Hence, generating dynamically admissible robot
trajectories is a challenge for diffusion models. To alleviate this issue, we
introduce DDAT: Diffusion policies for Dynamically Admissible Trajectories to
generate provably admissible trajectories of black-box robotic systems using
diffusion models. A sequence of states is a dynamically admissible trajectory
if each state of the sequence belongs to the reachable set of its predecessor
by the robot's equations of motion. To generate such trajectories, our
diffusion policies project their predictions onto a dynamically admissible
manifold during both training and inference to align the objective of the
denoiser neural network with the dynamical admissibility constraint. The
auto-regressive nature of these projections along with the black-box nature of
robot dynamics render these projections immensely challenging. We thus enforce
admissibility by iteratively sampling a polytopic under-approximation of the
reachable set of a state onto which we project its predicted successor, before
iterating this process with the projected successor. By producing accurate
trajectories, this projection eliminates the need for diffusion models to
continually replan, enabling one-shot long-horizon trajectory planning. We
demonstrate that our framework generates higher quality dynamically admissible
robot trajectories through extensive simulations on a quadcopter and various
MuJoCo environments, along with real-world experiments on a Unitree GO1 and
GO2.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15037v2' target='_blank'>DEFT: Differentiable Branched Discrete Elastic Rods for Modeling
  Furcated DLOs in Real-Time</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yizhou Chen, Xiaoyue Wu, Yeheng Zong, Anran Li, Yuzhen Chen, Julie Wu, Bohao Zhang, Ram Vasudevan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 20:46:09</h6>
<p class='card-text'>Autonomous wire harness assembly requires robots to manipulate complex
branched cables with high precision and reliability. A key challenge in
automating this process is predicting how these flexible and branched
structures behave under manipulation. Without accurate predictions, it is
difficult for robots to reliably plan or execute assembly operations. While
existing research has made progress in modeling single-threaded Deformable
Linear Objects (DLOs), extending these approaches to Branched Deformable Linear
Objects (BDLOs) presents fundamental challenges. The junction points in BDLOs
create complex force interactions and strain propagation patterns that cannot
be adequately captured by simply connecting multiple single-DLO models. To
address these challenges, this paper presents Differentiable discrete branched
Elastic rods for modeling Furcated DLOs in real-Time (DEFT), a novel framework
that combines a differentiable physics-based model with a learning framework
to: 1) accurately model BDLO dynamics, including dynamic propagation at
junction points and grasping in the middle of a BDLO, 2) achieve efficient
computation for real-time inference, and 3) enable planning to demonstrate
dexterous BDLO manipulation. A comprehensive series of real-world experiments
demonstrates DEFT's efficacy in terms of accuracy, computational speed, and
generalizability compared to state-of-the-art alternatives. Project
page:https://roahmlab.github.io/DEFT/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15006v1' target='_blank'>Safe Beyond the Horizon: Efficient Sampling-based MPC with Neural
  Control Barrier Functions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ji Yin, Oswin So, Eric Yang Yu, Chuchu Fan, Panagiotis Tsiotras</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 19:59:11</h6>
<p class='card-text'>A common problem when using model predictive control (MPC) in practice is the
satisfaction of safety specifications beyond the prediction horizon. While
theoretical works have shown that safety can be guaranteed by enforcing a
suitable terminal set constraint or a sufficiently long prediction horizon,
these techniques are difficult to apply and thus are rarely used by
practitioners, especially in the case of general nonlinear dynamics. To solve
this problem, we impose a tradeoff between exact recursive feasibility,
computational tractability, and applicability to ''black-box'' dynamics by
learning an approximate discrete-time control barrier function and
incorporating it into a variational inference MPC (VIMPC), a sampling-based MPC
paradigm. To handle the resulting state constraints, we further propose a new
sampling strategy that greatly reduces the variance of the estimated optimal
control, improving the sample efficiency, and enabling real-time planning on a
CPU. The resulting Neural Shield-VIMPC (NS-VIMPC) controller yields substantial
safety improvements compared to existing sampling-based MPC controllers, even
under badly designed cost functions. We validate our approach in both
simulation and real-world hardware experiments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14995v1' target='_blank'>Reinforcement Learning for Ultrasound Image Analysis A Comprehensive
  Review of Advances and Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maha Ezzelarab, Midhila Madhusoodanan, Shrimanti Ghosh, Geetika Vadali, Jacob Jaremko, Abhilash Hareendranathan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 19:37:49</h6>
<p class='card-text'>Over the last decade, the use of machine learning (ML) approaches in
medicinal applications has increased manifold. Most of these approaches are
based on deep learning, which aims to learn representations from grid data
(like medical images). However, reinforcement learning (RL) applications in
medicine are relatively less explored. Medical applications often involve a
sequence of subtasks that form a diagnostic pipeline, and RL is uniquely suited
to optimize over such sequential decision-making tasks. Ultrasound (US) image
analysis is a quintessential example of such a sequential decision-making task,
where the raw signal captured by the US transducer undergoes a series of signal
processing and image post-processing steps, generally leading to a diagnostic
suggestion. The application of RL in US remains limited. Deep Reinforcement
Learning (DRL), that combines deep learning and RL, holds great promise in
optimizing these pipelines by enabling intelligent and sequential
decision-making. This review paper surveys the applications of RL in US over
the last decade. We provide a succinct overview of the theoretic framework of
RL and its application in US image processing and review existing work in each
aspect of the image analysis pipeline. A comprehensive search of Scopus
filtered on relevance yielded 14 papers most relevant to this topic. These
papers were further categorized based on their target applications image
classification, image segmentation, image enhancement, video summarization, and
auto navigation and path planning. We also examined the type of RL approach
used in each publication. Finally, we discuss key areas in healthcare where DRL
approaches in US could be used for sequential decision-making. We analyze the
opportunities, challenges, and limitations, providing insights into the future
potential of DRL in US image analysis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14819v1' target='_blank'>Learning from Reward-Free Offline Data: A Case for Planning with Latent
  Dynamics Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vlad Sobal, Wancong Zhang, Kynghyun Cho, Randall Balestriero, Tim G. J. Rudner, Yann LeCun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 18:39:41</h6>
<p class='card-text'>A long-standing goal in AI is to build agents that can solve a variety of
tasks across different environments, including previously unseen ones. Two
dominant approaches tackle this challenge: (i) reinforcement learning (RL),
which learns policies through trial and error, and (ii) optimal control, which
plans actions using a learned or known dynamics model. However, their relative
strengths and weaknesses remain underexplored in the setting where agents must
learn from offline trajectories without reward annotations. In this work, we
systematically analyze the performance of different RL and control-based
methods under datasets of varying quality. On the RL side, we consider
goal-conditioned and zero-shot approaches. On the control side, we train a
latent dynamics model using the Joint Embedding Predictive Architecture (JEPA)
and use it for planning. We study how dataset properties-such as data
diversity, trajectory quality, and environment variability-affect the
performance of these approaches. Our results show that model-free RL excels
when abundant, high-quality data is available, while model-based planning
excels in generalization to novel environment layouts, trajectory stitching,
and data-efficiency. Notably, planning with a latent dynamics model emerges as
a promising approach for zero-shot generalization from suboptimal data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14814v1' target='_blank'>VB-Com: Learning Vision-Blind Composite Humanoid Locomotion Against
  Deficient Perception</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junli Ren, Tao Huang, Huayi Wang, Zirui Wang, Qingwei Ben, Jiangmiao Pang, Ping Luo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 18:35:14</h6>
<p class='card-text'>The performance of legged locomotion is closely tied to the accuracy and
comprehensiveness of state observations. Blind policies, which rely solely on
proprioception, are considered highly robust due to the reliability of
proprioceptive observations. However, these policies significantly limit
locomotion speed and often require collisions with the terrain to adapt. In
contrast, Vision policies allows the robot to plan motions in advance and
respond proactively to unstructured terrains with an online perception module.
However, perception is often compromised by noisy real-world environments,
potential sensor failures, and the limitations of current simulations in
presenting dynamic or deformable terrains. Humanoid robots, with high degrees
of freedom and inherently unstable morphology, are particularly susceptible to
misguidance from deficient perception, which can result in falls or termination
on challenging dynamic terrains. To leverage the advantages of both vision and
blind policies, we propose VB-Com, a composite framework that enables humanoid
robots to determine when to rely on the vision policy and when to switch to the
blind policy under perceptual deficiency. We demonstrate that VB-Com
effectively enables humanoid robots to traverse challenging terrains and
obstacles despite perception deficiencies caused by dynamic terrains or
perceptual noise.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14807v1' target='_blank'>FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image
  Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fadillah Maani, Numan Saeed, Tausifa Saleem, Zaid Farooq, Hussain Alasmawi, Werner Diehl, Ameera Mohammad, Gareth Waring, Saudabi Valappi, Leanne Bricker, Mohammad Yaqub</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 18:30:34</h6>
<p class='card-text'>Foundation models are becoming increasingly effective in the medical domain,
offering pre-trained models on large datasets that can be readily adapted for
downstream tasks. Despite progress, fetal ultrasound images remain a
challenging domain for foundation models due to their inherent complexity,
often requiring substantial additional training and facing limitations due to
the scarcity of paired multimodal data. To overcome these challenges, here we
introduce FetalCLIP, a vision-language foundation model capable of generating
universal representation of fetal ultrasound images. FetalCLIP was pre-trained
using a multimodal learning approach on a diverse dataset of 210,035 fetal
ultrasound images paired with text. This represents the largest paired dataset
of its kind used for foundation model development to date. This unique training
approach allows FetalCLIP to effectively learn the intricate anatomical
features present in fetal ultrasound images, resulting in robust
representations that can be used for a variety of downstream applications. In
extensive benchmarking across a range of key fetal ultrasound applications,
including classification, gestational age estimation, congenital heart defect
(CHD) detection, and fetal structure segmentation, FetalCLIP outperformed all
baselines while demonstrating remarkable generalizability and strong
performance even with limited labeled data. We plan to release the FetalCLIP
model publicly for the benefit of the broader scientific community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14803v1' target='_blank'>Planning, scheduling, and execution on the Moon: the CADRE technology
  demonstration mission</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gregg Rabideau, Joseph Russino, Andrew Branch, Nihal Dhamani, Tiago Stegun Vaquero, Steve Chien, Jean-Pierre de la Croix, Federico Rossi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 18:26:39</h6>
<p class='card-text'>NASA's Cooperative Autonomous Distributed Robotic Exploration (CADRE)
mission, slated for flight to the Moon's Reiner Gamma region in 2025/2026, is
designed to demonstrate multi-agent autonomous exploration of the Lunar surface
and sub-surface. A team of three robots and a base station will autonomously
explore a region near the lander, collecting the data required for 3D
reconstruction of the surface with no human input; and then autonomously
perform distributed sensing with multi-static ground penetrating radars (GPR),
driving in formation while performing coordinated radar soundings to create a
map of the subsurface. At the core of CADRE's software architecture is a novel
autonomous, distributed planning, scheduling, and execution (PS&E) system. The
system coordinates the robots' activities, planning and executing tasks that
require multiple robots' participation while ensuring that each individual
robot's thermal and power resources stay within prescribed bounds, and
respecting ground-prescribed sleep-wake cycles. The system uses a
centralized-planning, distributed-execution paradigm, and a leader election
mechanism ensures robustness to failures of individual agents. In this paper,
we describe the architecture of CADRE's PS&E system; discuss its design
rationale; and report on verification and validation (V&V) testing of the
system on CADRE's hardware in preparation for deployment on the Moon.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14782v1' target='_blank'>A Neural Operator-Based Emulator for Regional Shallow Water Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peter Rivera-Casillas, Sourav Dutta, Shukai Cai, Mark Loveland, Kamaljyoti Nath, Khemraj Shukla, Corey Trahan, Jonghyun Lee, Matthew Farthing, Clint Dawson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 18:02:44</h6>
<p class='card-text'>Coastal regions are particularly vulnerable to the impacts of rising sea
levels and extreme weather events. Accurate real-time forecasting of
hydrodynamic processes in these areas is essential for infrastructure planning
and climate adaptation. In this study, we present the Multiple-Input Temporal
Operator Network (MITONet), a novel autoregressive neural emulator that employs
dimensionality reduction to efficiently approximate high-dimensional numerical
solvers for complex, nonlinear problems that are governed by time-dependent,
parameterized partial differential equations. Although MITONet is applicable to
a wide range of problems, we showcase its capabilities by forecasting regional
tide-driven dynamics described by the two-dimensional shallow-water equations,
while incorporating initial conditions, boundary conditions, and a varying
domain parameter. We demonstrate MITONet's performance in a real-world
application, highlighting its ability to make accurate predictions by
extrapolating both in time and parametric space.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14778v1' target='_blank'>Harnessing PDF Data for Improving Japanese Large Multimodal Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 17:59:59</h6>
<p class='card-text'>Large Multimodal Models (LMMs) have demonstrated strong performance in
English, but their effectiveness in Japanese remains limited due to the lack of
high-quality training data. Current Japanese LMMs often rely on translated
English datasets, restricting their ability to capture Japan-specific cultural
knowledge. To address this, we explore the potential of Japanese PDF data as a
training resource, an area that remains largely underutilized. We introduce a
fully automated pipeline that leverages pretrained models to extract image-text
pairs from PDFs through layout analysis, OCR, and vision-language pairing,
removing the need for manual annotation. Additionally, we construct instruction
data from extracted image-text pairs to enrich the training data. To evaluate
the effectiveness of PDF-derived data, we train Japanese LMMs and assess their
performance on the Japanese LMM Benchmark. Our results demonstrate substantial
improvements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench.
Further analysis highlights the impact of PDF-derived data on various factors,
such as model size and language models, reinforcing its value as a multimodal
resource for Japanese LMMs. We plan to make the source code and data publicly
available upon acceptance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14777v1' target='_blank'>Making Universal Policies Universal</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Niklas Höpner, David Kuric, Herke van Hoof</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 17:59:55</h6>
<p class='card-text'>The development of a generalist agent capable of solving a wide range of
sequential decision-making tasks remains a significant challenge. We address
this problem in a cross-agent setup where agents share the same observation
space but differ in their action spaces. Our approach builds on the universal
policy framework, which decouples policy learning into two stages: a
diffusion-based planner that generates observation sequences and an inverse
dynamics model that assigns actions to these plans. We propose a method for
training the planner on a joint dataset composed of trajectories from all
agents. This method offers the benefit of positive transfer by pooling data
from different agents, while the primary challenge lies in adapting shared
plans to each agent's unique constraints. We evaluate our approach on the
BabyAI environment, covering tasks of varying complexity, and demonstrate
positive transfer across agents. Additionally, we examine the planner's
generalisation ability to unseen agents and compare our method to traditional
imitation learning approaches. By training on a pooled dataset from multiple
agents, our universal policy achieves an improvement of up to $42.20\%$ in task
completion accuracy compared to a policy trained on a dataset from a single
agent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14585v1' target='_blank'>A Stackelberg Game Approach for Signal Temporal Logic Control Synthesis
  with Uncontrollable Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bohan Cui, Xinyi Yu, Alessandro Giua, Xiang Yin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 14:14:42</h6>
<p class='card-text'>In this paper, we investigate the control synthesis problem for Signal
Temporal Logic (STL) specifications in the presence of uncontrollable agents.
Existing works mainly address this problem in a robust control setting by
assuming the uncontrollable agents are adversarial and accounting for the
worst-case scenario. While this approach ensures safety, it can be overly
conservative in scenarios where uncontrollable agents have their own objectives
that are not entirely opposed to the system's goals. Motivated by this
limitation, we propose a new framework for STL control synthesis within the
Stackelberg game setting. Specifically, we assume that the system controller,
acting as the leader, first commits to a plan, after which the uncontrollable
agents, acting as followers, take a best response based on the committed plan
and their own objectives. Our goal is to synthesize a control sequence for the
leader such that, for any rational followers producing a best response, the
leader's STL task is guaranteed to be satisfied. We present an effective
solution to this problem by transforming it into a single-stage optimization
problem and leveraging counter-example guided synthesis techniques. We
demonstrate that the proposed approach is sound and identify conditions under
which it is optimal. Simulation results are also provided to illustrate the
effectiveness of the proposed framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14571v1' target='_blank'>Predicting Filter Medium Performances in Chamber Filter Presses with
  Digital Twins Using Neural Network Technologies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dennis Teutscher, Tyll Weber-Carstanjen, Stephan Simonis, Mathias J. Krause</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 13:55:53</h6>
<p class='card-text'>Efficient solid-liquid separation is crucial in industries like mining, but
traditional chamber filter presses depend heavily on manual monitoring, leading
to inefficiencies, downtime, and resource wastage. This paper introduces a
machine learning-powered digital twin framework to improve operational
flexibility and predictive control. A key challenge addressed is the
degradation of the filter medium due to repeated cycles and clogging, which
reduces filtration efficiency. To solve this, a neural network-based predictive
model was developed to forecast operational parameters, such as pressure and
flow rates, under various conditions. This predictive capability allows for
optimized filtration cycles, reduced downtime, and improved process efficiency.
Additionally, the model predicts the filter mediums lifespan, aiding in
maintenance planning and resource sustainability. The digital twin framework
enables seamless data exchange between filter press sensors and the predictive
model, ensuring continuous updates to the training data and enhancing accuracy
over time. Two neural network architectures, feedforward and recurrent, were
evaluated. The recurrent neural network outperformed the feedforward model,
demonstrating superior generalization. It achieved a relative $L^2$-norm error
of $5\%$ for pressure and $9.3\%$ for flow rate prediction on partially known
data. For completely unknown data, the relative errors were $18.4\%$ and
$15.4\%$, respectively. Qualitative analysis showed strong alignment between
predicted and measured data, with deviations within a confidence band of
$8.2\%$ for pressure and $4.8\%$ for flow rate predictions. This work
contributes an accurate predictive model, a new approach to predicting filter
medium cycle impacts, and a real-time interface for model updates, ensuring
adaptability to changing operational conditions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14528v1' target='_blank'>Dynamic Preference-based Multi-modal Trip Planning of Public Transport
  and Shared Mobility</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yimeng Zhang, Oded Cats, Shadi Sharif Azadeh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 13:01:51</h6>
<p class='card-text'>The shift from private vehicles to public and shared transport is crucial to
reducing emissions and meeting climate targets. Consequently, there is an
urgent need to develop a multimodal transport trip planning approach that
integrates public transport and shared mobility solutions, offering viable
alternatives to private vehicle use. To this end, we propose a preference-based
optimization framework for multi-modal trip planning with public transport,
ride-pooling services, and shared micro-mobility fleets. We introduce a
mixed-integer programming model that incorporates preferences into the
objective function of the mathematical model. We present a meta-heuristic
framework that incorporates a customized Adaptive Large Neighborhood Search
algorithm and other tailored algorithms, to effectively manage dynamic requests
through a rolling horizon approach. Numerical experiments are conducted using
real transport network data in a suburban area of Rotterdam, the Netherlands.
Model application results demonstrate that the proposed algorithm can
efficiently obtain near-optimal solutions. Managerial insights are gained from
comprehensive experiments that consider various passenger segments, costs of
micro-mobility vehicles, and availability fluctuation of shared mobility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14457v1' target='_blank'>Watch Less, Feel More: Sim-to-Real RL for Generalizable Articulated
  Object Manipulation via Motion Adaptation and Impedance Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tan-Dzung Do, Nandiraju Gireesh, Jilong Wang, He Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 11:18:35</h6>
<p class='card-text'>Articulated object manipulation poses a unique challenge compared to rigid
object manipulation as the object itself represents a dynamic environment. In
this work, we present a novel RL-based pipeline equipped with variable
impedance control and motion adaptation leveraging observation history for
generalizable articulated object manipulation, focusing on smooth and dexterous
motion during zero-shot sim-to-real transfer. To mitigate the sim-to-real gap,
our pipeline diminishes reliance on vision by not leveraging the vision data
feature (RGBD/pointcloud) directly as policy input but rather extracting useful
low-dimensional data first via off-the-shelf modules. Additionally, we
experience less sim-to-real gap by inferring object motion and its intrinsic
properties via observation history as well as utilizing impedance control both
in the simulation and in the real world. Furthermore, we develop a
well-designed training setting with great randomization and a specialized
reward system (task-aware and motion-aware) that enables multi-staged,
end-to-end manipulation without heuristic motion planning. To the best of our
knowledge, our policy is the first to report 84\% success rate in the real
world via extensive experiments with various unseen objects.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14456v2' target='_blank'>Narrative-Driven Travel Planning: Geoculturally-Grounded Script
  Generation with Evolutionary Itinerary Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ran Ding, Ziyu Zhang, Ying Zhu, Ziqian Kong, Peilan Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 11:15:23</h6>
<p class='card-text'>To enhance tourists' experiences and immersion, this paper proposes a
narrative-driven travel planning framework called NarrativeGuide, which
generates a geoculturally-grounded narrative script for travelers, offering a
novel, role-playing experience for their journey. In the initial stage,
NarrativeGuide constructs a knowledge graph for attractions within a city, then
configures the worldview, character setting, and exposition based on the
knowledge graph. Using this foundation, the knowledge graph is combined to
generate an independent scene unit for each attraction. During the itinerary
planning stage, NarrativeGuide models narrative-driven travel planning as an
optimization problem, utilizing a genetic algorithm (GA) to refine the
itinerary. Before evaluating the candidate itinerary, transition scripts are
generated for each pair of adjacent attractions, which, along with the scene
units, form a complete script. The weighted sum of script coherence, travel
time, and attraction scores is then used as the fitness value to update the
candidate solution set. Experimental results across four cities, i.e., Nanjing
and Yangzhou in China, Paris in France, and Berlin in Germany, demonstrate
significant improvements in narrative coherence and cultural fit, alongside a
notable reduction in travel time and an increase in the quality of visited
attractions. Our study highlights that incorporating external evolutionary
optimization effectively addresses the limitations of large language models in
travel planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14455v1' target='_blank'>An Efficient Ground-aerial Transportation System for Pest Control
  Enabled by AI-based Autonomous Nano-UAVs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luca Crupi, Luca Butera, Alberto Ferrante, Alessandro Giusti, Daniele Palossi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 11:14:55</h6>
<p class='card-text'>Efficient crop production requires early detection of pest outbreaks and
timely treatments; we consider a solution based on a fleet of multiple
autonomous miniaturized unmanned aerial vehicles (nano-UAVs) to visually detect
pests and a single slower heavy vehicle that visits the detected outbreaks to
deliver treatments. To cope with the extreme limitations aboard nano-UAVs,
e.g., low-resolution sensors and sub-100 mW computational power budget, we
design, fine-tune, and optimize a tiny image-based convolutional neural network
(CNN) for pest detection. Despite the small size of our CNN (i.e., 0.58
GOps/inference), on our dataset, it scores a mean average precision (mAP) of
0.79 in detecting harmful bugs, i.e., 14% lower mAP but 32x fewer operations
than the best-performing CNN in the literature. Our CNN runs in real-time at
6.8 frame/s, requiring 33 mW on a GWT GAP9 System-on-Chip aboard a Crazyflie
nano-UAV. Then, to cope with in-field unexpected obstacles, we leverage a
global+local path planner based on the A* algorithm. The global path planner
determines the best route for the nano-UAV to sweep the entire area, while the
local one runs up to 50 Hz aboard our nano-UAV and prevents collision by
adjusting the short-distance path. Finally, we demonstrate with in-simulator
experiments that once a 25 nano-UAVs fleet has combed a 200x200 m vineyard,
collected information can be used to plan the best path for the tractor,
visiting all and only required hotspots. In this scenario, our efficient
transportation system, compared to a traditional single-ground vehicle
performing both inspection and treatment, can save up to 20 h working time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14264v1' target='_blank'>SPRIG: Stackelberg Perception-Reinforcement Learning with Internal Game
  Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fernando Martinez-Lopez, Juntao Chen, Yingdong Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 05:02:29</h6>
<p class='card-text'>Deep reinforcement learning agents often face challenges to effectively
coordinate perception and decision-making components, particularly in
environments with high-dimensional sensory inputs where feature relevance
varies. This work introduces SPRIG (Stackelberg Perception-Reinforcement
learning with Internal Game dynamics), a framework that models the internal
perception-policy interaction within a single agent as a cooperative
Stackelberg game. In SPRIG, the perception module acts as a leader,
strategically processing raw sensory states, while the policy module follows,
making decisions based on extracted features. SPRIG provides theoretical
guarantees through a modified Bellman operator while preserving the benefits of
modern policy optimization. Experimental results on the Atari BeamRider
environment demonstrate SPRIG's effectiveness, achieving around 30% higher
returns than standard PPO through its game-theoretical balance of feature
extraction and decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15825v1' target='_blank'>Utilizing AI and Machine Learning for Predictive Analysis of
  Post-Treatment Cancer Recurrence</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Umer Qayyum, Muhammad Fahad, Nasrullah Abbasi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 03:54:12</h6>
<p class='card-text'>In oncology, recurrence after treatment is one of the major challenges,
related to patients' survival and quality of life. Conventionally, prediction
of cancer relapse has always relied on clinical observation with statistical
model support, which almost fails to explain the complex, multifactorial nature
of tumor recurrence. This research explores how AI and ML models may increase
the accuracy and reliability of recurrence prediction in cancer. Therefore, AI
and ML create new opportunities not only for personalized medicine but also for
proactive management of patients through analyzing large volumes of data on
genetics, clinical manifestations, and treatment. The paper describes the
various AI and ML techniques for pattern identification and outcome prediction
in cancer patients using supervised and unsupervised learning. Clinical
implications provide an opportunity to review how early interventions could
happen and the design of treatment planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15824v1' target='_blank'>Getting SMARTER for Motion Planning in Autonomous Driving Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Montgomery Alban, Ehsan Ahmadi, Randy Goebel, Amir Rasouli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 03:51:49</h6>
<p class='card-text'>Motion planning is a fundamental problem in autonomous driving and perhaps
the most challenging to comprehensively evaluate because of the associated
risks and expenses of real-world deployment. Therefore, simulations play an
important role in efficient development of planning algorithms. To be
effective, simulations must be accurate and realistic, both in terms of
dynamics and behavior modeling, and also highly customizable in order to
accommodate a broad spectrum of research frameworks. In this paper, we
introduce SMARTS 2.0, the second generation of our motion planning simulator
which, in addition to being highly optimized for large-scale simulation,
provides many new features, such as realistic map integration,
vehicle-to-vehicle (V2V) communication, traffic and pedestrian simulation, and
a broad variety of sensor models.
  Moreover, we present a novel benchmark suite for evaluating planning
algorithms in various highly challenging scenarios, including interactive
driving, such as turning at intersections, and adaptive driving, in which the
task is to closely follow a lead vehicle without any explicit knowledge of its
intention. Each scenario is characterized by a variety of traffic patterns and
road structures. We further propose a series of common and task-specific
metrics to effectively evaluate the performance of the planning algorithms. At
the end, we evaluate common motion planning algorithms using the proposed
benchmark and highlight the challenges the proposed scenarios impose. The new
SMARTS 2.0 features and the benchmark are publicly available at
github.com/huawei-noah/SMARTS.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14231v1' target='_blank'>Real-Time Sampling-based Online Planning for Drone Interception</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gilhyun Ryou, Lukas Lao Beyer, Sertac Karaman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 03:48:38</h6>
<p class='card-text'>This paper studies high-speed online planning in dynamic environments. The
problem requires finding time-optimal trajectories that conform to system
dynamics, meeting computational constraints for real-time adaptation, and
accounting for uncertainty from environmental changes. To address these
challenges, we propose a sampling-based online planning algorithm that
leverages neural network inference to replace time-consuming nonlinear
trajectory optimization, enabling rapid exploration of multiple trajectory
options under uncertainty. The proposed method is applied to the drone
interception problem, where a defense drone must intercept a target while
avoiding collisions and handling imperfect target predictions. The algorithm
efficiently generates trajectories toward multiple potential target drone
positions in parallel. It then assesses trajectory reachability by comparing
traversal times with the target drone's predicted arrival time, ultimately
selecting the minimum-time reachable trajectory. Through extensive validation
in both simulated and real-world environments, we demonstrate our method's
capability for high-rate online planning and its adaptability to unpredictable
movements in unstructured settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15820v1' target='_blank'>Universal AI maximizes Variational Empowerment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yusuke Hayashi, Koichi Takahashi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 02:58:44</h6>
<p class='card-text'>This paper presents a theoretical framework unifying AIXI -- a model of
universal AI -- with variational empowerment as an intrinsic drive for
exploration. We build on the existing framework of Self-AIXI -- a universal
learning agent that predicts its own actions -- by showing how one of its
established terms can be interpreted as a variational empowerment objective. We
further demonstrate that universal AI's planning process can be cast as
minimizing expected variational free energy (the core principle of active
Inference), thereby revealing how universal AI agents inherently balance
goal-directed behavior with uncertainty reduction curiosity). Moreover, we
argue that power-seeking tendencies of universal AI agents can be explained not
only as an instrumental strategy to secure future reward, but also as a direct
consequence of empowerment maximization -- i.e.\ the agent's intrinsic drive to
maintain or expand its own controllability in uncertain environments. Our main
contribution is to show how these intrinsic motivations (empowerment,
curiosity) systematically lead universal AI agents to seek and sustain
high-optionality states. We prove that Self-AIXI asymptotically converges to
the same performance as AIXI under suitable conditions, and highlight that its
power-seeking behavior emerges naturally from both reward maximization and
curiosity-driven exploration. Since AIXI can be view as a Bayes-optimal
mathematical formulation for Artificial General Intelligence (AGI), our result
can be useful for further discussion on AI safety and the controllability of
AGI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14147v1' target='_blank'>Learning the P2D Model for Lithium-Ion Batteries with SOH Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maricela Best McKay, Bhushan Gopaluni, Brian Wetton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 23:17:30</h6>
<p class='card-text'>Lithium ion batteries are widely used in many applications. Battery
management systems control their optimal use and charging and predict when the
battery will cease to deliver the required output on a planned duty or driving
cycle. Such systems use a simulation of a mathematical model of battery
performance. These models can be electrochemical or data-driven.
Electrochemical models for batteries running at high currents are
mathematically and computationally complex. In this work, we show that a
well-regarded electrochemical model, the Pseudo Two Dimensional (P2D) model,
can be replaced by a computationally efficient Convolutional Neural Network
(CNN) surrogate model fit to accurately simulated data from a class of random
driving cycles. We demonstrate that a CNN is an ideal choice for accurately
capturing Lithium ion concentration profiles. Additionally, we show how the
neural network model can be adjusted to correspond to battery changes in State
of Health (SOH).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14111v1' target='_blank'>Comprehensive Review on the Control of Heat Pumps for Energy Flexibility
  in Distribution Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gustavo L. Aschidamini, Mina Pavlovic, Bradley A. Reinholz, Malcolm S. Metcalfe, Taco Niet, Mariana Resener</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 21:29:07</h6>
<p class='card-text'>Decarbonization plans promote the transition to heat pumps (HPs), creating
new opportunities for their energy flexibility in demand response programs,
solar photovoltaic integration and optimization of distribution networks. This
paper reviews scheduling-based and real-time optimization methods for
controlling HPs with a focus on energy flexibility in distribution networks.
Scheduling-based methods fall into two categories: rule-based controllers
(RBCs), which rely on predefined control rules without explicitly seeking
optimal solutions, and optimization models, which are designed to determine the
optimal scheduling of operations. Real-time optimization is achieved through
model predictive control (MPC), which relies on a predictive model to optimize
decisions over a time horizon, and reinforcement learning (RL), which takes a
model-free approach by learning optimal strategies through direct interaction
with the environment. The paper also examines studies on the impact of HPs on
distribution networks, particularly those leveraging energy flexibility
strategies. Key takeaways suggest the need to validate control strategies for
extreme cold-weather regions that require backup heaters, as well as develop
approaches designed for demand charge schemes that integrate HPs with other
controllable loads. From a grid impact assessment perspective, studies have
focused primarily on RBCs for providing energy flexibility through HP
operation, without addressing more advanced methods such as real-time
optimization using MPC or RL-based algorithms. Incorporating these advanced
control strategies could help identify key limitations, including the impact of
varying user participation levels and the cost-benefit trade-offs associated
with their implementation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13852v1' target='_blank'>Minimally sufficient structures for information-feedback policies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Basak Sakcak, Vadim K. Weinstein, Kalle G. Timperi, Steven M. LaValle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 16:16:41</h6>
<p class='card-text'>In this paper, we consider robotic tasks which require a desirable outcome to
be achieved in the physical world that the robot is embedded in and interacting
with. Accomplishing this objective requires designing a filter that maintains a
useful representation of the physical world and a policy over the filter
states. A filter is seen as the robot's perspective of the physical world based
on limited sensing, memory, and computation and it is represented as a
transition system over a space of information states. To this end, the
interactions result from the coupling of an internal and an external system, a
filter, and the physical world, respectively, through a sensor mapping and an
information-feedback policy. Within this setup, we look for sufficient
structures, that is, sufficient internal systems and sensors, for accomplishing
a given task. We establish necessary and sufficient conditions for these
structures to satisfy for information-feedback policies that can be defined
over the states of an internal system to exist. We also show that under mild
assumptions, minimal internal systems that can represent a particular
plan/policy described over the action-observation histories exist and are
unique. Finally, the results are applied to determine sufficient structures for
distance-optimal navigation in a polygonal environment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13823v1' target='_blank'>An Online Optimization-Based Trajectory Planning Approach for
  Cooperative Landing Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jingshan Chen, Lihan Xu, Henrik Ebel, Peter Eberhard</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 15:36:01</h6>
<p class='card-text'>This paper presents a real-time trajectory planning scheme for a
heterogeneous multi-robot system (consisting of a quadrotor and a ground mobile
robot) for a cooperative landing task, where the landing position, landing
time, and coordination between the robots are determined autonomously under the
consideration of feasibility and user specifications. The proposed framework
leverages the potential of the complementarity constraint as a decision-maker
and an indicator for diverse cooperative tasks and extends it to the
collaborative landing scenario. In a potential application of the proposed
methodology, a ground mobile robot may serve as a mobile charging station and
coordinates in real-time with a quadrotor to be charged, facilitating a safe
and efficient rendezvous and landing. We verified the generated trajectories in
simulation and real-world applications, demonstrating the real-time
capabilities of the proposed landing planning framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13818v1' target='_blank'>Building Age Estimation: A New Multi-Modal Benchmark Dataset and
  Community Challenge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nikolaos Dionelis, Nicolas Longépé, Alessandra Feliciotti, Mattia Marconcini, Devis Peressutti, Nika Oman Kadunc, JaeWan Park, Hagai Raja Sinulingga, Steve Andreas Immanuel, Ba Tran, Caroline Arnold</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 15:31:13</h6>
<p class='card-text'>Estimating the construction year of buildings is of great importance for
sustainability. Sustainable buildings minimize energy consumption and are a key
part of responsible and sustainable urban planning and development to
effectively combat climate change. By using Artificial Intelligence (AI) and
recently proposed Transformer models, we are able to estimate the construction
epoch of buildings from a multi-modal dataset. In this paper, we introduce a
new benchmark multi-modal dataset, i.e. the Map your City Dataset (MyCD),
containing top-view Very High Resolution (VHR) images, Earth Observation (EO)
multi-spectral data from the Copernicus Sentinel-2 satellite constellation, and
street-view images in many different cities in Europe, co-localized with
respect to the building under study and labelled with the construction epoch.
We assess EO generalization performance on new/ previously unseen cities that
have been held-out from training and appear only during inference. In this
work, we present the community-based data challenge we organized based on MyCD.
The ESA AI4EO Challenge MapYourCity was opened in 2024 for 4 months. Here, we
present the Top-4 performing models, and the main evaluation results. During
inference, the performance of the models using both all three input modalities
and only the two top-view modalities, i.e. without the street-view images, is
examined. The evaluation results show that the models are effective and can
achieve good performance on this difficult real-world task of estimating the
age of buildings, even on previously unseen cities, as well as even using only
the two top-view modalities (i.e. VHR and Sentinel-2) during inference.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13805v1' target='_blank'>AnDB: Breaking Boundaries with an AI-Native Database for Universal
  Semantic Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianqing Wang, Xun Xue, Guoliang Li, Yong Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 15:15:59</h6>
<p class='card-text'>In this demonstration, we present AnDB, an AI-native database that supports
traditional OLTP workloads and innovative AI-driven tasks, enabling unified
semantic analysis across structured and unstructured data. While structured
data analytics is mature, challenges remain in bridging the semantic gap
between user queries and unstructured data. AnDB addresses these issues by
leveraging cutting-edge AI-native technologies, allowing users to perform
semantic queries using intuitive SQL-like statements without requiring AI
expertise. This approach eliminates the ambiguity of traditional text-to-SQL
systems and provides a seamless end-to-end optimization for analyzing all data
types. AnDB automates query processing by generating multiple execution plans
and selecting the optimal one through its optimizer, which balances accuracy,
execution time, and financial cost based on user policies and internal
optimizing mechanisms. AnDB future-proofs data management infrastructure,
empowering users to effectively and efficiently harness the full potential of
all kinds of data without starting from scratch.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13746v1' target='_blank'>A Digital Urban Twin Enabling Interactive Pollution Predictions and
  Enhanced Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dennis Teutscher, Fedor Bukreev, Adrian Kummerlaender, Stephan Simonis, Peter Baechler, Ashkan Rezaee, Mariusz Hermansdorfer, Mathias J. Krause</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 14:09:22</h6>
<p class='card-text'>Digital twin (DT) technology is increasingly used in urban planning,
leveraging real-time data integration for environmental monitoring. This paper
presents an urban-focused DT that combines computational fluid dynamics
simulations with live meteorological data to analyze pollution dispersion.
Addressing the health impacts of pollutants like particulate matter and
nitrogen dioxide, the DT provides real-time updates on air quality, wind speed,
and direction. Using OpenStreetMaps XML-based data, the model distinguishes
between porous elements like trees and solid structures, enhancing urban flow
analysis. The framework employs the lattice Boltzmann method (LBM) within the
open-source software OpenLB to simulate pollution transport. Nitrogen dioxide
and particulate matter concentrations are estimated based on traffic and
building emissions, enabling hot-spot identification. The DT was used from
November 7 to 23, 2024, with hourly updates, capturing pollution trends
influenced by wind patterns. Results show that alternating east-west winds
during this period create a dynamic pollution distribution, identifying
critical residential exposure areas. This work contributes a novel DT framework
that integrates real-time meteorological data, OpenStreetMap-based geometry,
and high-fidelity LBM simulations for urban wind and pollution modeling. Unlike
existing DTs, which focus on structural monitoring or large-scale environmental
factors, this approach enables fine-grained, dynamic analyses of urban airflow
and pollution dispersion. By allowing interactive modifications to urban
geometry and continuous data updates, the DT serves as a powerful tool for
adaptive urban planning, supporting evidence-based policy making to improve air
quality and public health.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13742v1' target='_blank'>Decentralized Annuity: A Quest for the Holy Grail of Lifetime Financial
  Security</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Feng Runhuan, Liang Zongxia, Song Yilun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 14:06:29</h6>
<p class='card-text'>This paper presents a novel framework for decentralized annuities, aiming to
address the limitations of traditional pension systems such as defined
contribution (DC) and defined benefit (DB) plans, while providing lifetime
financial support. It sheds light on often ignored pitfalls within current
retirement schemes and introduces individual rationality properties. The
research delves into various fairness concepts that underpin existing plans,
emphasizing that decentralized annuities, while meeting similar fairness
criteria, offer enhanced flexibility for individual rationality and improved
social welfare for all participants. Using theoretical models and examples, we
demonstrate the potential of decentralized annuities to outperform self-managed
plans (DC) and to produce effects comparable to defined benefit (DB) plans,
particularly within larger participant pools. The paper concludes by exploring
the managerial implications of decentralized annuities and laying the
groundwork for the further advancement of equitable and sustainable
decentralized annuity systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13677v1' target='_blank'>A Framework for Semantics-based Situational Awareness during Mobile
  Robot Deployments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianshu Ruan, Aniketh Ramesh, Hao Wang, Alix Johnstone-Morfoisse, Gokcenur Altindal, Paul Norman, Grigoris Nikolaou, Rustam Stolkin, Manolis Chiou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 12:37:23</h6>
<p class='card-text'>Deployment of robots into hazardous environments typically involves a
``Human-Robot Teaming'' (HRT) paradigm, in which a human supervisor interacts
with a remotely operating robot inside the hazardous zone. Situational
Awareness (SA) is vital for enabling HRT, to support navigation, planning, and
decision-making. This paper explores issues of higher-level ``semantic''
information and understanding in SA. In semi-autonomous, or variable-autonomy
paradigms, different types of semantic information may be important, in
different ways, for both the human operator and an autonomous agent controlling
the robot. We propose a generalizable framework for acquiring and combining
multiple modalities of semantic-level SA during remote deployments of mobile
robots. We demonstrate the framework with an example application of search and
rescue (SAR) in disaster response robotics. We propose a set of ``environment
semantic indicators" that can reflect a variety of different types of semantic
information, e.g. indicators of risk, or signs of human activity, as the robot
encounters different scenes. Based on these indicators, we propose a metric to
describe the overall situation of the environment called ``Situational Semantic
Richness (SSR)". This metric combines multiple semantic indicators to summarise
the overall situation. The SSR indicates if an information-rich and complex
situation has been encountered, which may require advanced reasoning for robots
and humans and hence the attention of the expert human operator. The framework
is tested on a Jackal robot in a mock-up disaster response environment.
Experimental results demonstrate that the proposed semantic indicators are
sensitive to changes in different modalities of semantic information in
different scenes, and the SSR metric reflects overall semantic changes in the
situations encountered.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13621v1' target='_blank'>Decentralized Planning Using Probabilistic Hyperproperties</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Francesco Pontiggia, Filip Macák, Roman Andriushchenko, Michele Chiari, Milan Češka</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 10:59:02</h6>
<p class='card-text'>Multi-agent planning under stochastic dynamics is usually formalised using
decentralized (partially observable) Markov decision processes ( MDPs) and
reachability or expected reward specifications. In this paper, we propose a
different approach: we use an MDP describing how a single agent operates in an
environment and probabilistic hyperproperties to capture desired temporal
objectives for a set of decentralized agents operating in the environment. We
extend existing approaches for model checking probabilistic hyperproperties to
handle temporal formulae relating paths of different agents, thus requiring the
self-composition between multiple MDPs. Using several case studies, we
demonstrate that our approach provides a flexible and expressive framework to
broaden the specification capabilities with respect to existing planning
techniques. Additionally, we establish a close connection between a subclass of
probabilistic hyperproperties and planning for a particular type of Dec-MDPs,
for both of which we show undecidability. This lays the ground for the use of
existing decentralized planning tools in the field of probabilistic
hyperproperty verification.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14917v1' target='_blank'>Sce2DriveX: A Generalized MLLM Framework for Scene-to-Drive Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rui Zhao, Qirui Yuan, Jinyu Li, Haofeng Hu, Yun Li, Chengyuan Zheng, Fei Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 09:50:44</h6>
<p class='card-text'>End-to-end autonomous driving, which directly maps raw sensor inputs to
low-level vehicle controls, is an important part of Embodied AI. Despite
successes in applying Multimodal Large Language Models (MLLMs) for high-level
traffic scene semantic understanding, it remains challenging to effectively
translate these conceptual semantics understandings into low-level motion
control commands and achieve generalization and consensus in cross-scene
driving. We introduce Sce2DriveX, a human-like driving chain-of-thought (CoT)
reasoning MLLM framework. Sce2DriveX utilizes multimodal joint learning from
local scene videos and global BEV maps to deeply understand long-range
spatiotemporal relationships and road topology, enhancing its comprehensive
perception and reasoning capabilities in 3D dynamic/static scenes and achieving
driving generalization across scenes. Building on this, it reconstructs the
implicit cognitive chain inherent in human driving, covering scene
understanding, meta-action reasoning, behavior interpretation analysis, motion
planning and control, thereby further bridging the gap between autonomous
driving and human thought processes. To elevate model performance, we have
developed the first extensive Visual Question Answering (VQA) driving
instruction dataset tailored for 3D spatial understanding and long-axis task
reasoning. Extensive experiments demonstrate that Sce2DriveX achieves
state-of-the-art performance from scene understanding to end-to-end driving, as
well as robust generalization on the CARLA Bench2Drive benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13443v1' target='_blank'>Physics-Aware Robotic Palletization with Online Masking Inference</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianqi Zhang, Zheng Wu, Yuxin Chen, Yixiao Wang, Boyuan Liang, Scott Moura, Masayoshi Tomizuka, Mingyu Ding, Wei Zhan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 05:39:41</h6>
<p class='card-text'>The efficient planning of stacking boxes, especially in the online setting
where the sequence of item arrivals is unpredictable, remains a critical
challenge in modern warehouse and logistics management. Existing solutions
often address box size variations, but overlook their intrinsic and physical
properties, such as density and rigidity, which are crucial for real-world
applications. We use reinforcement learning (RL) to solve this problem by
employing action space masking to direct the RL policy toward valid actions.
Unlike previous methods that rely on heuristic stability assessments which are
difficult to assess in physical scenarios, our framework utilizes online
learning to dynamically train the action space mask, eliminating the need for
manual heuristic design. Extensive experiments demonstrate that our proposed
method outperforms existing state-of-the-arts. Furthermore, we deploy our
learned task planner in a real-world robotic palletizer, validating its
practical applicability in operational settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13286v1' target='_blank'>BoundPlanner: A convex-set-based approach to bounded manipulator
  trajectory planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thies Oelerich, Christian Hartl-Nesic, Florian Beck, Andreas Kugi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 21:16:11</h6>
<p class='card-text'>Online trajectory planning enables robot manipulators to react quickly to
changing environments or tasks. Many robot trajectory planners exist for known
environments but are often too slow for online computations. Current methods in
online trajectory planning do not find suitable trajectories in challenging
scenarios that respect the limits of the robot and account for collisions. This
work proposes a trajectory planning framework consisting of the novel Cartesian
path planner based on convex sets, called BoundPlanner, and the online
trajectory planner BoundMPC. BoundPlanner explores and maps the collision-free
space using convex sets to compute a reference path with bounds. BoundMPC is
extended in this work to handle convex sets for path deviations, which allows
the robot to optimally follow the path within the bounds while accounting for
the robot's kinematics. Collisions of the robot's kinematic chain are
considered by a novel convex-set-based collision avoidance formulation
independent on the number of obstacles. Simulations and experiments with a
7-DoF manipulator show the performance of the proposed planner compared to
state-of-the-art methods. The source code is available at
github.com/Thieso/BoundPlanner and videos of the experiments can be found at
www.acin.tuwien.ac.at/42d4</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13130v1' target='_blank'>Magma: A Foundation Model for Multimodal AI Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jianwei Yang, Reuben Tan, Qianhui Wu, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Lars Liden, Jianfeng Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 18:55:21</h6>
<p class='card-text'>We present Magma, a foundation model that serves multimodal AI agentic tasks
in both the digital and physical worlds. Magma is a significant extension of
vision-language (VL) models in that it not only retains the VL understanding
ability (verbal intelligence) of the latter, but is also equipped with the
ability to plan and act in the visual-spatial world (spatial-temporal
intelligence) and complete agentic tasks ranging from UI navigation to robot
manipulation. To endow the agentic capabilities, Magma is pretrained on large
amounts of heterogeneous datasets spanning from images, videos to robotics
data, where the actionable visual objects (e.g., clickable buttons in GUI) in
images are labeled by Set-of-Mark (SoM) for action grounding, and the object
movements (e.g., the trace of human hands or robotic arms) in videos are
labeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show
that SoM and ToM reach great synergy and facilitate the acquisition of
spatial-temporal intelligence for our Magma model, which is fundamental to a
wide range of tasks as shown in Fig.1. In particular, Magma creates new
state-of-the-art results on UI navigation and robotic manipulation tasks,
outperforming previous models that are specifically tailored to these tasks. On
image and video-related multimodal tasks, Magma also compares favorably to
popular large multimodal models that are trained on much larger datasets. We
make our model and code public for reproducibility at
https://microsoft.github.io/Magma.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13006v1' target='_blank'>Integrating Reinforcement Learning, Action Model Learning, and Numeric
  Planning for Tackling Complex Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yarin Benyamin, Argaman Mordoch, Shahaf S. Shperberg, Roni Stern</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 16:26:21</h6>
<p class='card-text'>Automated Planning algorithms require a model of the domain that specifies
the preconditions and effects of each action. Obtaining such a domain model is
notoriously hard. Algorithms for learning domain models exist, yet it remains
unclear whether learning a domain model and planning is an effective approach
for numeric planning environments, i.e., where states include discrete and
numeric state variables. In this work, we explore the benefits of learning a
numeric domain model and compare it with alternative model-free solutions. As a
case study, we use two tasks in Minecraft, a popular sandbox game that has been
used as an AI challenge. First, we consider an offline learning setting, where
a set of expert trajectories are available to learn from. This is the standard
setting for learning domain models. We used the Numeric Safe Action Model
Learning (NSAM) algorithm to learn a numeric domain model and solve new
problems with the learned domain model and a numeric planner. We call this
model-based solution NSAM_(+p), and compare it to several model-free Imitation
Learning (IL) and Offline Reinforcement Learning (RL) algorithms. Empirical
results show that some IL algorithms can learn faster to solve simple tasks,
while NSAM_(+p) allows solving tasks that require long-term planning and
enables generalizing to solve problems in larger environments. Then, we
consider an online learning setting, where learning is done by moving an agent
in the environment. For this setting, we introduce RAMP. In RAMP, observations
collected during the agent's execution are used to simultaneously train an RL
policy and learn a planning domain action model. This forms a positive feedback
loop between the RL policy and the learned domain model. We demonstrate
experimentally the benefits of using RAMP, showing that it finds more efficient
plans and solves more problems than several RL baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12952v1' target='_blank'>Integrated demand-side management and timetabling for an urban transit
  system: A Benders decomposition approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lixing Yang, Yahan Lu, Jiateng Yin, Sh. Sharif Azadeh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 15:33:19</h6>
<p class='card-text'>The intelligent upgrading of metropolitan rail transit systems has made it
feasible to implement demand-side management policies that integrate multiple
operational strategies in practical operations. However, the tight
interdependence between supply and demand necessitates a coordinated approach
combining demand-side management policies and supply-side resource allocations
to enhance the urban rail transit ecosystem. In this study, we propose a
mathematical and computational framework that optimizes train timetables,
passenger flow control strategies, and trip-shifting plans through the pricing
policy. Our framework incorporates an emerging trip-booking approach that
transforms waiting at the stations into waiting at home, thereby mitigating
station overcrowding. Additionally, it ensures service fairness by maintaining
an equitable likelihood of delays across different stations. We formulate the
problem as an integer linear programming model, aiming to minimize passengers'
waiting time and government subsidies required to offset revenue losses from
fare discounts used to encourage trip shifting. To improve computational
efficiency, we develop a Benders decomposition-based algorithm within the
branch-and-cut method, which decomposes the model into train timetabling with
partial passenger assignment and passenger flow control subproblems. We propose
valid inequalities based on our model's properties to strengthen the linear
relaxation bounds at each node. Computational results from proof-of-concept and
real-world case studies on the Beijing metro show that our solution method
outperforms commercial solvers in terms of computational efficiency. We can
obtain high-quality solutions, including optimal ones, at the root node with
reduced branching requirements thanks to our novel decomposition framework and
valid inequalities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12890v1' target='_blank'>Testing and Combining Transient Spectral Classification Tools on
  4MOST-like Blended Spectra</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrew Milligan, Isobel Hook, Christopher Frohmaier, Mathew Smith, Georgios Dimitriadis, Young-Lo Kim, Kate Maguire, Anais Möller, Matt Nicholl, Stephen J. Smartt, Jesper Storm, Mark Sullivan, Elmo Tempel, Philip Wiseman, Letizia P. Cassarà, Ricardo Demarco, Alexander Fritz, Jiachen Jiang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 14:25:56</h6>
<p class='card-text'>With the 4-meter Multi-Object Spectroscopic Telescope (4MOST) expected to
provide an influx of transient spectra when it begins observations in early
2026 we consider the potential for real-time classification of these spectra.
We investigate three extant spectroscopic transient classifiers: the Deep
Automated Supernova and Host classifier (DASH), Next Generation SuperFit (NGSF)
and SuperNova IDentification (SNID), with a focus on comparing the efficiency
and purity of the transient samples they produce. We discuss our method for
simulating realistic, 4MOST-like, host-galaxy contaminated spectra and
determining quality cuts for each classifier used to ensure pure SN Ia samples
while maintaining efficient classification in other transient classes. We
investigate the classifiers individually and in combinations. We find that a
combination of DASH and NGSF can produce a SN Ia sample with a purity of 99.9%
while successfully classifying 70% of SNe Ia. However, it struggles to classify
non-SN Ia transients. We investigate photometric cuts to transient magnitude
and transient flux fraction, finding that both can be used to improve transient
classification efficiencies by 7--25% depending on the transient subclass.
Finally, we present an example classification plan for live classification and
the predicted purities and efficiencies across five transient classes: Ia, Ibc,
II, superluminous and non-supernova transients.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12862v1' target='_blank'>RobotIQ: Empowering Mobile Robots with Human-Level Planning for
  Real-World Execution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Emmanuel K. Raptis, Athanasios Ch. Kapoutsis, Elias B. Kosmatopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 13:49:28</h6>
<p class='card-text'>This paper introduces RobotIQ, a framework that empowers mobile robots with
human-level planning capabilities, enabling seamless communication via natural
language instructions through any Large Language Model. The proposed framework
is designed in the ROS architecture and aims to bridge the gap between humans
and robots, enabling robots to comprehend and execute user-expressed text or
voice commands. Our research encompasses a wide spectrum of robotic tasks,
ranging from fundamental logical, mathematical, and learning reasoning for
transferring knowledge in domains like navigation, manipulation, and object
localization, enabling the application of learned behaviors from simulated
environments to real-world operations. All encapsulated within a modular
crafted robot library suite of API-wise control functions, RobotIQ offers a
fully functional AI-ROS-based toolset that allows researchers to design and
develop their own robotic actions tailored to specific applications and robot
configurations. The effectiveness of the proposed system was tested and
validated both in simulated and real-world experiments focusing on a home
service scenario that included an assistive application designed for elderly
people. RobotIQ with an open-source, easy-to-use, and adaptable robotic library
suite for any robot can be found at https://github.com/emmarapt/RobotIQ.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12834v1' target='_blank'>NTP-INT: Network Traffic Prediction-Driven In-band Network Telemetry for
  High-load Switches</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Penghui Zhang, Hua Zhang, Yuqi Dai, Cheng Zeng, Jingyu Wang, Jianxin Liao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 13:00:52</h6>
<p class='card-text'>In-band network telemetry (INT) is essential to network management due to its
real-time visibility. However, because of the rapid increase in network devices
and services, it has become crucial to have targeted access to detailed network
information in a dynamic network environment. This paper proposes an
intelligent network telemetry system called NTP-INT to obtain more fine-grained
network information on high-load switches. Specifically, NTP-INT consists of
three modules: network traffic prediction module, network pruning module, and
probe path planning module. Firstly, the network traffic prediction module
adopts a Multi-Temporal Graph Neural Network (MTGNN) to predict future network
traffic and identify high-load switches. Then, we design the network pruning
algorithm to generate a subnetwork covering all high-load switches to reduce
the complexity of probe path planning. Finally, the probe path planning module
uses an attention-mechanism-based deep reinforcement learning (DEL) model to
plan efficient probe paths in the network slice. The experimental results
demonstrate that NTP-INT can acquire more precise network information on
high-load switches while decreasing the control overhead by 50\%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12816v1' target='_blank'>Preparing for the 2061 return of Halley's comet -- A rendezvous mission
  with an innovative imaging system</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cesare Barbieri, Alessandro Beolchi, Ivano Bertini, Vania Da Deppo, Elena Fantino, Roberto Flores, Claudio Pernechele, Chiara Pozzi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 12:22:28</h6>
<p class='card-text'>The return of Comet 1P/Halley will promote a wide interest for ground and
space observations of a celestial body of outstanding scientific and cultural
interest. In addition to remote observations, space will open the possibility
of in situ science similarly to the passage of 1986. In this paper, we first
discuss the scientific motivations for a rendezvous mission, capable to
overcome the limitations of the flyby missions that took place at that time. In
the second part, we describe an example of a rendezvous trajectory that can be
carried out with existing power and propulsion technologies. The transfer is
made possible by the gravitational assistance of a giant planet. The resulting
mission will be capable to reach the comet beyond the distance of Saturn, when
the sublimation of super-volatile species will be ongoing, and well before the
onset of the sublimation of water (4 AU). After rendezvous, the spacecraft will
accompany the comet for several years before, around and after perihelion (July
2061). Our concept mission does not foresee the implementation of solar panels.
In this way, operations can occur even inside the dense dust coma at short
distance from the nucleus. In the third part of the paper, an innovative
imaging system is proposed, with a very large field of view (100{\deg}) capable
to record on the same frame details on the surface and the surrounding space,
in order to follow for several degrees the trajectories of chunks and clouds
ejected by pits or fractures, crucial to the understanding of the cometary
activity. A concerted effort is needed in the current decade to plan and
approve a rendezvous mission to 1P. Indeed, the scenario here described
requires launching before 2040, less than 15 years from now. Later launches
imply a severe loss of scientific knowledge, because the spacecraft will not be
able to reach the comet before the onset of water sublimation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12766v1' target='_blank'>Efficient Individually Rational Recommender System under Stochastic
  Order</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gal Bahar, Omer Ben-Porat, Kevin Leyton-Brown, Moshe Tennenholtz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 11:31:49</h6>
<p class='card-text'>With the rise of online applications, recommender systems (RSs) often
encounter constraints in balancing exploration and exploitation. Such
constraints arise when exploration is carried out by agents whose individual
utility should be balanced with overall welfare. Recent work suggests that
recommendations should be individually rational. Specifically, if agents have a
default arm they would use, relying on the RS should yield each agent at least
the reward of the default arm, conditioned on the knowledge available to the
RS. Under this individual rationality constraint, striking a balance between
exploration and exploitation becomes a complex planning problem. We assume a
stochastic order of the rewards (e.g., Bernoulli, unit-variance Gaussian,
etc.), and derive an approximately optimal algorithm. Our technique is based on
an auxiliary Goal Markov Decision Process problem that is of independent
interest. Additionally, we present an incentive-compatible version of our
algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12756v2' target='_blank'>Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement
  Learning for Enabling Adaptive and Feasible Master Stowage Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jaike van Twiller, Yossiri Adulyasak, Erick Delage, Djordje Grbic, Rune Møller Jensen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 11:18:17</h6>
<p class='card-text'>Reinforcement learning (RL) has shown promise in solving various
combinatorial optimization problems. However, conventional RL faces challenges
when dealing with real-world constraints, especially when action space
feasibility is explicit and dependent on the corresponding state or trajectory.
In this work, we focus on using RL in container shipping, often considered the
cornerstone of global trade, by dealing with the critical challenge of master
stowage planning. The main objective is to maximize cargo revenue and minimize
operational costs while navigating demand uncertainty and various complex
operational constraints, namely vessel capacity and stability, which must be
dynamically updated along the vessel's voyage. To address this problem, we
implement a deep reinforcement learning framework with feasibility projection
to solve the master stowage planning problem (MPP) under demand uncertainty.
The experimental results show that our architecture efficiently finds adaptive,
feasible solutions for this multi-stage stochastic optimization problem,
outperforming traditional mixed-integer programming and RL with feasibility
regularization. Our AI-driven decision-support policy enables adaptive and
feasible planning under uncertainty, optimizing operational efficiency and
capacity utilization while contributing to sustainable and resilient global
supply chains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12723v1' target='_blank'>myEye2Wheeler: A Two-Wheeler Indian Driver Real-World Eye-Tracking
  Dataset</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bhaiya Vaibhaw Kumar, Deepti Rawat, Tanvi Kandalla, Aarnav Nagariya, Kavita Vemuri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 10:39:00</h6>
<p class='card-text'>This paper presents the myEye2Wheeler dataset, a unique resource of
real-world gaze behaviour of two-wheeler drivers navigating complex Indian
traffic. Most datasets are from four-wheeler drivers on well-planned roads and
homogeneous traffic. Our dataset offers a critical lens into the unique visual
attention patterns and insights into the decision-making of Indian two-wheeler
drivers. The analysis demonstrates that existing saliency models, like
TASED-Net, perform less effectively on the myEye-2Wheeler dataset compared to
when applied on the European 4-wheeler eye tracking datasets (DR(Eye)VE),
highlighting the need for models specifically tailored to the traffic
conditions. By introducing the dataset, we not only fill a significant gap in
two-wheeler driver behaviour research in India but also emphasise the critical
need for developing context-specific saliency models. The larger aim is to
improve road safety for two-wheeler users and lane-planning to support a
cost-effective mode of transport.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12680v1' target='_blank'>Introducing ROADS: A Systematic Comparison of Remote Control Interaction
  Concepts for Automated Vehicles at Road Works</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mark Colley, Jonathan Westhauser, Jonas Andersson, Alexander G. Mirnig, Enrico Rukzio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 09:37:25</h6>
<p class='card-text'>As vehicle automation technology continues to mature, there is a necessity
for robust remote monitoring and intervention features. These are essential for
intervening during vehicle malfunctions, challenging road conditions, or in
areas that are difficult to navigate. This evolution in the role of the human
operator - from a constant driver to an intermittent teleoperator -
necessitates the development of suitable interaction interfaces. While some
interfaces were suggested, a comparative study is missing. We designed,
implemented, and evaluated three interaction concepts (path planning,
trajectory guidance, and waypoint guidance) with up to four concurrent requests
of automated vehicles in a within-subjects study with N=23 participants. The
results showed a clear preference for the path planning concept. It also led to
the highest usability but lower satisfaction. With trajectory guidance, the
fewest requests were resolved. The study's findings contribute to the ongoing
development of HMIs focused on the remote assistance of automated vehicles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12631v2' target='_blank'>Score-Based Diffusion Policy Compatible with Reinforcement Learning via
  Optimal Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingyang Sun, Pengxiang Ding, Weinan Zhang, Donglin Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 08:22:20</h6>
<p class='card-text'>Diffusion policies have shown promise in learning complex behaviors from
demonstrations, particularly for tasks requiring precise control and long-term
planning. However, they face challenges in robustness when encountering
distribution shifts. This paper explores improving diffusion-based imitation
learning models through online interactions with the environment. We propose
OTPR (Optimal Transport-guided score-based diffusion Policy for Reinforcement
learning fine-tuning), a novel method that integrates diffusion policies with
RL using optimal transport theory. OTPR leverages the Q-function as a transport
cost and views the policy as an optimal transport map, enabling efficient and
stable fine-tuning. Moreover, we introduce masked optimal transport to guide
state-action matching using expert keypoints and a compatibility-based
resampling strategy to enhance training stability. Experiments on three
simulation tasks demonstrate OTPR's superior performance and robustness
compared to existing methods, especially in complex and sparse-reward
environments. In sum, OTPR provides an effective framework for combining IL and
RL, achieving versatile and reliable policy learning. The code will be released
at https://github.com/Sunmmyy/OTPR.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12481v1' target='_blank'>Predicate Hierarchies Improve Few-Shot State Classification</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Emily Jin, Joy Hsu, Jiajun Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 03:08:37</h6>
<p class='card-text'>State classification of objects and their relations is core to many
long-horizon tasks, particularly in robot planning and manipulation. However,
the combinatorial explosion of possible object-predicate combinations, coupled
with the need to adapt to novel real-world environments, makes it a desideratum
for state classification models to generalize to novel queries with few
examples. To this end, we propose PHIER, which leverages predicate hierarchies
to generalize effectively in few-shot scenarios. PHIER uses an object-centric
scene encoder, self-supervised losses that infer semantic relations between
predicates, and a hyperbolic distance metric that captures hierarchical
structure; it learns a structured latent space of image-predicate pairs that
guides reasoning over state classification queries. We evaluate PHIER in the
CALVIN and BEHAVIOR robotic environments and show that PHIER significantly
outperforms existing methods in few-shot, out-of-distribution state
classification, and demonstrates strong zero- and few-shot generalization from
simulated to real-world tasks. Our results demonstrate that leveraging
predicate hierarchies improves performance on state classification tasks with
limited data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12417v1' target='_blank'>Point source localisation with unbalanced optimal transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tuomo Valkonen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 01:31:50</h6>
<p class='card-text'>Replacing the quadratic proximal penalty familiar from Hilbert spaces by an
unbalanced optimal transport distance, we develop forward-backward type
optimisation methods in spaces of Radon measures. We avoid the actual
computation of the optimal transport distances through the use of transport
three-plans and the rough concept of transport subdifferentials. The resulting
algorithm has a step similar to the sliding heuristics previously introduced
for conditional gradient methods, however, now non-heuristically derived from
the geometry of the space. We demonstrate the improved numerical performance of
the approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12405v1' target='_blank'>An Investment Prioritization Model for Wildfire Risk Mitigation Through
  Power Line Undergrounding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saeed Nematshahi, Amin Khodaei, Ali Arabnya</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 00:39:46</h6>
<p class='card-text'>Grid-ignited wildfires are one of the most destructive catastrophic events,
profoundly affecting the built and natural environments. Burying power lines is
an effective solution for mitigating the risk of wildfire ignition. However, it
is a costly capital expenditure (CapEx) requiring meticulous planning and
investment prioritization. This paper proposes a systematic approach to
estimate the potential wildfire ignition damage associated with each
transmission line and accordingly offers a priority list for undergrounding.
The proposed approach allows electric utilities to make risk-informed decisions
for grid modernization and resiliency improvement against wildfires. As a case
study, we examine the likelihood of wildfire ignition for each line segment,
i.e., between two high-voltage towers, under diverse weather conditions
throughout the year. The studies on the standard IEEE 30-bus test system,
simulated on 43,712 scenarios, demonstrate the effectiveness of the proposed
approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12387v1' target='_blank'>Angular Resolution of Electrons in Gaseous Targets</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Majd Ghrear, Sven E. Vahsen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 23:54:36</h6>
<p class='card-text'>Low-energy electron recoils are of interest in several planned and proposed
future nuclear and particle physics experiments. The topology and directions of
such recoils provide important particle identification and kinematical
constraints, and are experimentally accessible in gaseous targets. Electron
recoils have complex trajectories, and the angular resolution that can be
achieved has not been well understood. We have developed a method for
estimating and optimizing this angular resolution, considering contributions
from both multiple scattering and detection. First, we clarify that the formula
commonly used for multiple scattering through small angles is actually a fit to
Moliere theory for heavy particles. We revise this formula so that it is
applicable to electrons in gas. Next, we combine this with an effective point
resolution contribution, which accounts for diffusion and detector effects, to
obtain an approximation for the angular resolution. We identify the optimal fit
length and the corresponding optimal angular resolution. The result is a simple
formula to estimate the best achievable angular resolution for electrons in
gaseous detectors, given the electron energy and basic gas and detector
properties. Our model's predictions show good agreement with simulations. This
approach can assist in the design of future experiments and the development of
analysis techniques. Given the widespread use of gaseous detectors, this work
is relevant to many scientific communities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12267v1' target='_blank'>NeuroStrata: Harnessing Neurosymbolic Paradigms for Improved Design,
  Testability, and Verifiability of Autonomous CPS</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xi Zheng, Ziyang Li, Ivan Ruchkin, Ruzica Piskac, Miroslav Pajic</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 19:07:41</h6>
<p class='card-text'>Autonomous cyber-physical systems (CPSs) leverage AI for perception,
planning, and control but face trust and safety certification challenges due to
inherent uncertainties. The neurosymbolic paradigm replaces stochastic layers
with interpretable symbolic AI, enabling determinism. While promising,
challenges like multisensor fusion, adaptability, and verification remain. This
paper introduces NeuroStrata, a neurosymbolic framework to enhance the testing
and verification of autonomous CPS. We outline its key components, present
early results, and detail future plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14895v1' target='_blank'>High-Dynamic Radar Sequence Prediction for Weather Nowcasting Using
  Spatiotemporal Coherent Gaussian Representation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziye Wang, Yiran Qin, Lin Zeng, Ruimao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 19:00:02</h6>
<p class='card-text'>Weather nowcasting is an essential task that involves predicting future radar
echo sequences based on current observations, offering significant benefits for
disaster management, transportation, and urban planning. Current prediction
methods are limited by training and storage efficiency, mainly focusing on 2D
spatial predictions at specific altitudes. Meanwhile, 3D volumetric predictions
at each timestamp remain largely unexplored. To address such a challenge, we
introduce a comprehensive framework for 3D radar sequence prediction in weather
nowcasting, using the newly proposed SpatioTemporal Coherent Gaussian Splatting
(STC-GS) for dynamic radar representation and GauMamba for efficient and
accurate forecasting. Specifically, rather than relying on a 4D Gaussian for
dynamic scene reconstruction, STC-GS optimizes 3D scenes at each frame by
employing a group of Gaussians while effectively capturing their movements
across consecutive frames. It ensures consistent tracking of each Gaussian over
time, making it particularly effective for prediction tasks. With the
temporally correlated Gaussian groups established, we utilize them to train
GauMamba, which integrates a memory mechanism into the Mamba framework. This
allows the model to learn the temporal evolution of Gaussian groups while
efficiently handling a large volume of Gaussian tokens. As a result, it
achieves both efficiency and accuracy in forecasting a wide range of dynamic
meteorological radar signals. The experimental results demonstrate that our
STC-GS can efficiently represent 3D radar sequences with over $16\times$ higher
spatial resolution compared with the existing 3D representation methods, while
GauMamba outperforms state-of-the-art methods in forecasting a broad spectrum
of high-dynamic weather conditions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12237v1' target='_blank'>Systematic biases from the exclusion of higher harmonics in parameter
  estimation on LISA binaries</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sophia Yi, Francesco Iacovelli, Sylvain Marsat, Digvijay Wadekar, Emanuele Berti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 19:00:01</h6>
<p class='card-text'>The remarkable sensitivity achieved by the planned Laser Interferometer Space
Antenna (LISA) will allow us to observe gravitational-wave signals from the
mergers of massive black hole binaries (MBHBs) with signal-to-noise ratio (SNR)
in the hundreds, or even thousands. At such high SNR, our ability to precisely
infer the parameters of an MBHB from the detected signal will be limited by the
accuracy of the waveform templates we use. In this paper, we explore the
systematic biases that arise in parameter estimation if we use waveform
templates that do not model radiation in higher-order multipoles. This is an
important consideration for the large fraction of high-mass events expected to
be observed with LISA. We examine how the biases change for MBHB events with
different total masses, mass ratios, and inclination angles. We find that
systematic biases due to insufficient mode content are severe for events with
total redshifted mass $\gtrsim10^6\,M_\odot$. We then compare several methods
of predicting such systematic biases without performing a full Bayesian
parameter estimation. In particular, we show that through direct likelihood
optimization it is possible to predict systematic biases with remarkable
computational efficiency and accuracy. Finally, we devise a method to construct
approximate waveforms including angular multipoles with $\ell\geq5$ to better
understand how many additional modes (beyond the ones available in current
approximants) might be required to perform unbiased parameter estimation on the
MBHB signals detected by LISA.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12058v1' target='_blank'>A survey about perceptions of mobility to inform an agent-based
  simulator of subjective modal choice</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Carole Adam, Benoit Gaudou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 17:25:18</h6>
<p class='card-text'>In order to adapt to the issues of climate change and public health, urban
policies are trying to encourage soft mobility, but the share of the car
remains significant. Beyond known constraints, we study here the impact of
perception biases on individual choices. We designed a multi-criteria decision
model, integrating the influence of habits and biases. We then conducted an
online survey, which received 650 responses. We used these to calculate
realistic mobility perception values, in order to initialise the environment
and the population of a modal choice simulator, implemented in Netlogo. This
allows us to visualize the adaptation of the modal distribution in reaction to
the evolution of urban planning, depending on whether or not we activate biases
and habits in individual reasoning.
  This is an extended and translated version of a demo paper published in
French at JFSMA-JFMS 2024 "Un simulateur multi-agent de choix modal subjectif"</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12035v1' target='_blank'>Planning minimum regret $CO_2$ pipeline networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stephan Bogs, Ali Abdelshafy, Grit Walther</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 17:05:41</h6>
<p class='card-text'>The transition to a low-carbon economy necessitates effective carbon capture
and storage (CCS) solutions, particularly for hard-to-abate sectors. Herein,
pipeline networks are indispensable for cost-efficient $CO_2$ transportation
over long distances. However, there is deep uncertainty regarding which
industrial sectors will participate in such systems. This poses a significant
challenge due to substantial investments as well as the lengthy planning and
development timelines required for $CO_2$ pipeline projects, which are further
constrained by limited upgrade options for already built infrastructure. The
economies of scale inherent in pipeline construction exacerbate these
challenges, leading to potential regret over earlier decisions. While numerous
models were developed to optimize the initial layout of pipeline infrastructure
based on known demand, a gap exists in addressing the incremental development
of infrastructure in conjunction with deep uncertainty. Hence, this paper
introduces a novel optimization model for $CO_2$ pipeline infrastructure
development, minimizing regret as its objective function and incorporating
various upgrade options, such as looping and pressure increases. The model's
effectiveness is also demonstrated by presenting a comprehensive case study of
Germany's cement and lime industries. The developed approach quantitatively
illustrates the trade-off between different options, which can help in deriving
effective strategies for $CO_2$ infrastructure development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12011v1' target='_blank'>Reconfigurable Intelligent Surfaces-Assisted Integrated Access and
  Backhaul</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Charitha Madapatha, Behrooz Makki, Hao Guo, Tommy Svensson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 16:46:15</h6>
<p class='card-text'>In this paper, we study the impact of reconfigurable intelligent surfaces
(RISs) on the coverage extension of integrated access and backhaul (IAB)
networks. Particularly, using a finite stochastic geometry model, with random
distributions of user equipments (UEs) in a finite region, and planned
hierachical architecture for IAB, we study the service coverage probability
defined as the probability of the event that the UEs' minimum rate requirements
are satisfied. We present comparisons between different cases including
IAB-only, IAB assisted with RIS for backhaul as well as IAB assisted by network
controlled repeaters (NCRs). Our investigations focus on wide-area IAB assisted
with RIS through the lens of different design architectures and deployments,
revealing both conflicts and synergies for minimizing the effect of tree
foliage over seasonal changes. Our simulation results reveal both opportunities
and challenges towards the implementation of RIS in IAB.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11990v1' target='_blank'>Unified Multivariate Ordinal Model for analysis of sensory attributes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Janaína Marques e Melo, João César Reis Alves, Gabriel Rodrigues Palma, Sílvia Maria de Freitas, Idemauro Antonio Rodrigues de Lara</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 16:31:24</h6>
<p class='card-text'>Experiments involving sensory analysis of foods and beverages are beneficial
for selecting healthy products and assessing the preferences of potential
consumers. They are generally planned in incomplete blocks, and their
attributes, such as aroma, colour, and flavour, are evaluated using a 9-point
hedonic scale, characterising an ordinal variable response. Also, the
generalised logit model with random effects for panellists is one of the
appropriate models to relate the multivariate response to the covariates. This
study aims to present a method for analysing sensory attributes through a
unified multivariate model. Due to the nature of the variable, each separate
model already corresponds to a multivariate analysis, so our proposal would
incorporate a complete analysis with solely one model. This proposal is based
on multivariate methods for categorical data and maximum likelihood theory. Our
method was evaluated through a simulation study, in which we consider three
distinct formulations with two attributes to represent various formulation
selection scenarios via mixed discrete models. The simulated results
demonstrated overall concordance rates exceeding 80\% for the unified model
compared to the separate models. Moreover, as motivation is presented, a study
of 13 prebiotic beverages based on cashew nut almonds added to grape juice,
with 130 potential consumers. The attributes evaluated were overall impression,
aroma, Body, sweetness and flavour, using a 9-point hedonic scale. The selected
unified model considering all attributes was the non-proportional odds
mixed-effect model. According to this model, the prebiotic beverage
formulations most likely to be accepted were: 8\% sugar and 40\% grape juice
($F_4$), 6\% sugar and 44\% grape juice ($F_6$), and 9\% sugar and 30\% grape
juice ($F_{13}$). The unified analysis and computational time showed the
advantages of this proposal.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11940v1' target='_blank'>The Dynamic Model of the UR10 Robot and its ROS2 Integration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vincenzo Petrone, Enrico Ferrentino, Pasquale Chiacchio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 15:51:57</h6>
<p class='card-text'>This paper presents the full dynamic model of the UR10 industrial robot. A
triple-stage identification approach is adopted to estimate the manipulator's
dynamic coefficients. First, linear parameters are computed using a standard
linear regression algorithm. Subsequently, nonlinear friction parameters are
estimated according to a sigmoidal model. Lastly, motor drive gains are devised
to map estimated joint currents to torques. The overall identified model can be
used for both control and planning purposes, as the accompanied ROS2 software
can be easily reconfigured to account for a generic payload. The estimated
robot model is experimentally validated against a set of exciting trajectories
and compared to the state-of-the-art model for the same manipulator, achieving
higher current prediction accuracy (up to a factor of 4.43) and more precise
motor gains. The related software is available at
https://codeocean.com/capsule/8515919/tree/v2.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11889v1' target='_blank'>MQG4AI Towards Responsible High-risk AI -- Illustrated for Transparency
  Focusing on Explainability Techniques</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Miriam Elia, Alba Maria Lopez, Katherin Alexandra Corredor, Bernhard Bauer, Esteban Garcia-Cuesta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 15:14:52</h6>
<p class='card-text'>As artificial intelligence (AI) systems become increasingly integrated into
critical domains, ensuring their responsible design and continuous development
is imperative. Effective AI quality management (QM) requires tools and
methodologies that address the complexities of the AI lifecycle. In this paper,
we propose an approach for AI lifecycle planning that bridges the gap between
generic guidelines and use case-specific requirements (MQG4AI). Our work aims
to contribute to the development of practical tools for implementing
Responsible AI (RAI) by aligning lifecycle planning with technical, ethical and
regulatory demands. Central to our approach is the introduction of a flexible
and customizable Methodology based on Quality Gates, whose building blocks
incorporate RAI knowledge through information linking along the AI lifecycle in
a continuous manner, addressing AIs evolutionary character. For our present
contribution, we put a particular emphasis on the Explanation stage during
model development, and illustrate how to align a guideline to evaluate the
quality of explanations with MQG4AI, contributing to overall Transparency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11752v1' target='_blank'>Early Detection of Human Handover Intentions in Human-Robot
  Collaboration: Comparing EEG, Gaze, and Hand Motion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Parag Khanna, Nona Rajabi, Sumeyra U. Demir Kanik, Danica Kragic, Mårten Björkman, Christian Smith</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 12:48:49</h6>
<p class='card-text'>Human-robot collaboration (HRC) relies on accurate and timely recognition of
human intentions to ensure seamless interactions. Among common HRC tasks,
human-to-robot object handovers have been studied extensively for planning the
robot's actions during object reception, assuming the human intention for
object handover. However, distinguishing handover intentions from other actions
has received limited attention. Most research on handovers has focused on
visually detecting motion trajectories, which often results in delays or false
detections when trajectories overlap. This paper investigates whether human
intentions for object handovers are reflected in non-movement-based
physiological signals. We conduct a multimodal analysis comparing three data
modalities: electroencephalogram (EEG), gaze, and hand-motion signals. Our
study aims to distinguish between handover-intended human motions and
non-handover motions in an HRC setting, evaluating each modality's performance
in predicting and classifying these actions before and after human movement
initiation. We develop and evaluate human intention detectors based on these
modalities, comparing their accuracy and timing in identifying handover
intentions. To the best of our knowledge, this is the first study to
systematically develop and test intention detectors across multiple modalities
within the same experimental context of human-robot handovers. Our analysis
reveals that handover intention can be detected from all three modalities.
Nevertheless, gaze signals are the earliest as well as the most accurate to
classify the motion as intended for handover or non-handover.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11744v2' target='_blank'>FUNCTO: Function-Centric One-Shot Imitation Learning for Tool
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chao Tang, Anxing Xiao, Yuhong Deng, Tianrun Hu, Wenlong Dong, Hanbo Zhang, David Hsu, Hong Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 12:34:42</h6>
<p class='card-text'>Learning tool use from a single human demonstration video offers a highly
intuitive and efficient approach to robot teaching. While humans can
effortlessly generalize a demonstrated tool manipulation skill to diverse tools
that support the same function (e.g., pouring with a mug versus a teapot),
current one-shot imitation learning (OSIL) methods struggle to achieve this. A
key challenge lies in establishing functional correspondences between
demonstration and test tools, considering significant geometric variations
among tools with the same function (i.e., intra-function variations). To
address this challenge, we propose FUNCTO (Function-Centric OSIL for Tool
Manipulation), an OSIL method that establishes function-centric correspondences
with a 3D functional keypoint representation, enabling robots to generalize
tool manipulation skills from a single human demonstration video to novel tools
with the same function despite significant intra-function variations. With this
formulation, we factorize FUNCTO into three stages: (1) functional keypoint
extraction, (2) function-centric correspondence establishment, and (3)
functional keypoint-based action planning. We evaluate FUNCTO against exiting
modular OSIL methods and end-to-end behavioral cloning methods through
real-robot experiments on diverse tool manipulation tasks. The results
demonstrate the superiority of FUNCTO when generalizing to novel tools with
intra-function geometric variations. More details are available at
https://sites.google.com/view/functo.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11721v1' target='_blank'>Enhancing Recommendation Explanations through User-Centric Refinement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jingsen Zhang, Zihang Tian, Xueyang Feng, Xu Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 12:08:18</h6>
<p class='card-text'>Generating natural language explanations for recommendations has become
increasingly important in recommender systems. Traditional approaches typically
treat user reviews as ground truth for explanations and focus on improving
review prediction accuracy by designing various model architectures. However,
due to limitations in data scale and model capability, these explanations often
fail to meet key user-centric aspects such as factuality, personalization, and
sentiment coherence, significantly reducing their overall helpfulness to users.
In this paper, we propose a novel paradigm that refines initial explanations
generated by existing explainable recommender models during the inference stage
to enhance their quality in multiple aspects. Specifically, we introduce a
multi-agent collaborative refinement framework based on large language models.
To ensure alignment between the refinement process and user demands, we employ
a plan-then-refine pattern to perform targeted modifications. To enable
continuous improvements, we design a hierarchical reflection mechanism that
provides feedback on the refinement process from both strategic and content
perspectives. Extensive experiments on three datasets demonstrate the
effectiveness of our framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11715v1' target='_blank'>Proactive Depot Discovery: A Generative Framework for Flexible
  Location-Routing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Site Qu, Guoqiang Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 12:00:28</h6>
<p class='card-text'>The Location-Routing Problem (LRP), which combines the challenges of facility
(depot) locating and vehicle route planning, is critically constrained by the
reliance on predefined depot candidates, limiting the solution space and
potentially leading to suboptimal outcomes. Previous research on LRP without
predefined depots is scant and predominantly relies on heuristic algorithms
that iteratively attempt depot placements across a planar area. Such approaches
lack the ability to proactively generate depot locations that meet specific
geographic requirements, revealing a notable gap in current research landscape.
To bridge this gap, we propose a data-driven generative DRL framework, designed
to proactively generate depots for LRP without predefined depot candidates,
solely based on customer requests data which include geographic and demand
information. It can operate in two distinct modes: direct generation of exact
depot locations, and the creation of a multivariate Gaussian distribution for
flexible depots sampling. By extracting depots' geographic pattern from
customer requests data, our approach can dynamically respond to logistical
needs, identifying high-quality depot locations that further reduce total
routing costs compared to traditional methods. Extensive experiments
demonstrate that, for a same group of customer requests, compared with those
depots identified through random attempts, our framework can proactively
generate depots that lead to superior solution routes with lower routing cost.
The implications of our framework potentially extend into real-world
applications, particularly in emergency medical rescue and disaster relief
logistics, where rapid establishment and adjustment of depot locations are
paramount, showcasing its potential in addressing LRP for dynamic and
unpredictable environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11694v1' target='_blank'>Connecting Earth and Moon via the L1 Lagrangian point</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:A. K. de Almeida Jr, V. M. de Oliveira, T. Vaillant, D. Maia, A. C. M. Correia, D. Barbosa, L. T. B. Santos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 11:32:02</h6>
<p class='card-text'>The renewed global interest in lunar exploration requires new orbital
strategies to ensure flight safety which can benefit extended lunar missions
and service a plethora of planned instruments in the lunar orbit and surface.
We investigate here the equivalent fuel consumption cost to transfer from (to)
a given orbit and enter (leave) at any point of an invariant manifold
associated with a Lyapunov orbit around the Earth-Moon $L_1$ Lagrangian point
using bi-impulsive maneuvers. Whereas solving this type of transfer is
generally computationally expensive, we simulate here tens of millions of
transfers orbits, for different times of flight, Jacobi constants and spatial
location on the manifold. We are able to reduce computational cost by taking
advantage of the efficient procedure given by the Theory of Functional
Connections for solving boundary value problems, represented with special
constraints created to the purposes of this work. We develop here the
methodology for constructing these transfers, and apply it to find a low-cost
transfer from an orbit around the Earth to a stable manifold and another
low-cost transfer from an unstable manifold to an orbit around the Moon. In the
end, we obtain an innovative Earth-to-Moon transfer that involves a gravity
assist maneuver with the Moon and allows a long stationed stage at the Lyapunov
orbit around $L_1$ which can be used for designing multi-purpose missions for
extended periods of time with low fuel costs. This is paramount to optimize new
exploration concepts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15782v1' target='_blank'>Model-free system identification of surface ships in waves via Hankel
  dynamic mode decomposition with control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Giorgio Palma, Andrea Serani, Shawn Aram, David W. Wundrow, David Drazen, Matteo Diez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 11:11:14</h6>
<p class='card-text'>This study introduces and compares the Hankel dynamic mode decomposition with
control (Hankel-DMDc) and a novel Bayesian extension of Hankel-DMDc as
model-free (i.e., data-driven and equation-free) approaches for system
identification and prediction of free-running ship motions in irregular waves.
The proposed DMDc methods create a reduced-order model using limited data from
the system state and incoming wave elevation histories, with the latter and
rudder angle serving as forcing inputs. The inclusion of delayed states of the
system as additional dimensions per the Hankel-DMDc improves the representation
of the underlying non-linear dynamics of the system by DMD. The approaches are
statistically assessed using data from free-running simulations of a 5415M
hull's course-keeping in irregular beam-quartering waves at sea state 7, a
highly severe condition characterized by nonlinear responses near
roll-resonance. The results demonstrate robust performance and remarkable
computational efficiency. The results indicate that the proposed methods
effectively identify the dynamic system in analysis. Furthermore, the Bayesian
formulation incorporates uncertainty quantification and enhances prediction
accuracy. Ship motions are predicted with good agreement with test data over a
15 encounter waves observation window. No significant accuracy degradation is
noted along the test sequences, suggesting the method can support accurate and
efficient maritime design and operational planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11626v1' target='_blank'>High-spatial-resolution simulations of Be star disks in binary systems:
  I. Structure and kinematics of coplanar disks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:A. C. Rubio, A. C. Carciofi, J. E. Bjorkman, T. H. de Amorim, A. T. Okazaki, M. W. Suffak, C. E. Jones, P. P. Candido</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 10:16:27</h6>
<p class='card-text'>Binarity in massive stars has proven to be an important aspect in the their
evolution. For Be stars, it might be the cause of their spin up, and thus part
of the mechanism behind the formation of their viscous decretion disks.
Detecting companions in systems with Be stars is challenging, making it
difficult to obtain observational constraints on their binary fraction. We
explore the effects of a binary companion in a system with a Be star, from disk
formation to quasi steady-state using smoothed particle hydrodynamics (SPH)
simulations of coplanar, circular binary systems. High spatial resolution is
achieved by adopting particle splitting in the SPH code, as well as a more
realistic description of the secondary star and the disk viscosity. The tidal
forces considerably affect the Be disk, forming distinct regions in the system,
with observational consequences that can be used to infer the presence of a
otherwise undetectable companion. With the upgraded code, we can probe a region
approximately 4 times larger than previously possible. We describe the
configuration and kinematics of each part of the system, and provide a summary
of their expected observational signals. Material that enters the Roche lobe of
the companion is partially captured by it, forming a rotationally supported,
disk-like structure. Material not accreted escapes and forms a circumbinary
disk around the system. This is the first work to describe the region beyond
the truncation region of the Be disk and its observational consequences with
detail. We argue that observational features of previously unclear origin, such
as the intermittent shell features and emission features of HR 2142 and HD
55606, originate in areas beyond the truncation region. This new understanding
of the behavior of disks in Be binaries will allow not just for better
interpretation of existing data, but also for the planning of future
observations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11537v2' target='_blank'>$\text{M}^{\text{3}}$: A Modular World Model over Streams of Tokens</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lior Cohen, Kaixin Wang, Bingyi Kang, Uri Gadot, Shie Mannor</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 08:06:10</h6>
<p class='card-text'>Token-based world models emerged as a promising modular framework, modeling
dynamics over token streams while optimizing tokenization separately. While
successful in visual environments with discrete actions (e.g., Atari games),
their broader applicability remains uncertain. In this paper, we introduce
$\text{M}^{\text{3}}$, a $\textbf{m}$odular $\textbf{w}$orld $\textbf{m}$odel
that extends this framework, enabling flexible combinations of observation and
action modalities through independent modality-specific components.
$\text{M}^{\text{3}}$ integrates several improvements from existing literature
to enhance agent performance. Through extensive empirical evaluation across
diverse benchmarks, $\text{M}^{\text{3}}$ achieves state-of-the-art sample
efficiency for planning-free world models. Notably, among these methods, it is
the first to reach a human-level median score on Atari 100K, with superhuman
performance on 13 games. Our code and model weights are publicly available at
https://github.com/leor-c/M3.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11536v2' target='_blank'>CSST Large Scale Structure Analysis Pipeline: III. Emission-line
  Redshift Measurement for Slitless Spectra</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jipeng Sui, Hu Zou, Xiaohu Yang, Xianzhong Zheng, Run Wen, Yizhou Gu, Weiyu Ding, Lu Feng, Hong Guo, Wei-Jian Guo, Yunkun Han, Yipeng Jing, Cheng Li, Wenxiong Li, Shufei Liu, Zhixia Shen, Gaurav Singh, Jiali Wang, Peng Wei, Yunao Xiao, Suijian Xue, Hu Zhan, Pengjie Zhang, Gongbo Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 08:05:39</h6>
<p class='card-text'>The China Space Station Telescope (CSST) is a forthcoming space-based optical
telescope designed to co-orbit with the Chinese Space Station. With a planned
slitless spectroscopic survey spanning a broad wavelength range of $255-1000$nm
and an average spectral resolution exceeding 200, the CSST holds significant
potential for cosmic large-scale structure analysis. In this study, we focus on
redshift determinations from slitless spectra through emission line analysis
within the CSST framework. Our tailored redshift measurement process involves
identifying emission lines in one-dimensional slitless spectra, aligning
observed wavelengths with their rest-frame counterparts from prominent galaxy
emissions, and calculating wavelength shifts to determine redshifts accurately.
To validate our redshift measurement algorithm, we leverage simulated spectra
generated by the CSST emulator for slitless spectroscopy. The outcomes
demonstrate a remarkable redshift completeness exceeding 95 per cent for
emission line galaxies (ELGs), alongside a purity surpassing 85 per cent. The
redshift uncertainty remains impressively below than $\sim 0.001$. Notably,
when concentrating on galaxies with more than three matched emission lines, the
completeness of ELGs and the purity of measurable galaxies can reach 98 per
cent and 97 per cent, respectively. Furthermore, we explore the influence of
parameters like magnitude, spectral signal-to-noise ratio, and redshift on
redshift completeness and purity. The discussion also delves into redshift
degeneracies stemming from emission-line matching confusion. Our developed
redshift measurement process will be applied to extensive simulated datasets
and forthcoming CSST slitless spectroscopic observations for further
cosmological and extragalactic analyses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11535v1' target='_blank'>Disentangled Iterative Surface Fitting for Contact-stable Grasp Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tomoya Yamanokuchi, Alberto Bacchin, Emilio Olivastri, Takamitsu Matsubara, Emanuele Menegatti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 08:05:36</h6>
<p class='card-text'>In this work, we address the limitation of surface fitting-based grasp
planning algorithm, which primarily focuses on geometric alignment between the
gripper and object surface while overlooking the stability of contact point
distribution, often resulting in unstable grasps due to inadequate contact
configurations. To overcome this limitation, we propose a novel surface fitting
algorithm that integrates contact stability while preserving geometric
compatibility. Inspired by human grasping behavior, our method disentangles the
grasp pose optimization into three sequential steps: (1) rotation optimization
to align contact normals, (2) translation refinement to improve Center of Mass
(CoM) alignment, and (3) gripper aperture adjustment to optimize contact point
distribution. We validate our approach through simulations on ten YCB dataset
objects, demonstrating an 80% improvement in grasp success over conventional
surface fitting methods that disregard contact stability. Further details can
be found on our project page:
https://tomoya-yamanokuchi.github.io/disf-project-page/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11518v1' target='_blank'>Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Di Wu, Xian Wei, Guang Chen, Hao Shen, Xiangfeng Wang, Wenhao Li, Bo Jin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 07:39:34</h6>
<p class='card-text'>Embodied multi-agent systems (EMAS) have attracted growing attention for
their potential to address complex, real-world challenges in areas such as
logistics and robotics. Recent advances in foundation models pave the way for
generative agents capable of richer communication and adaptive problem-solving.
This survey provides a systematic examination of how EMAS can benefit from
these generative capabilities. We propose a taxonomy that categorizes EMAS by
system architectures and embodiment modalities, emphasizing how collaboration
spans both physical and virtual contexts. Central building blocks, perception,
planning, communication, and feedback, are then analyzed to illustrate how
generative techniques bolster system robustness and flexibility. Through
concrete examples, we demonstrate the transformative effects of integrating
foundation models into embodied, multi-agent frameworks. Finally, we discuss
challenges and future directions, underlining the significant promise of EMAS
to reshape the landscape of AI-driven collaboration.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11359v1' target='_blank'>Simulation-Based Optimization for Policy Incentives and Planning of
  Hybrid Microgrids</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nanrui Gong, James C. Spall</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 02:16:45</h6>
<p class='card-text'>Transitioning to renewable power generation is often difficult for remote or
isolated communities, due to generation intermittency and high cost barriers.
Our paper presents a simulation-based optimization approach for the design of
policy incentives and planning of microgrids with renewable energy sources,
targeting isolated communities. We propose a novel framework that integrates
stochastic simulation to account for weather uncertainty and system
availability while optimizing microgrid configurations and policy incentives.
Utilizing the mixed-variable Simultaneous Perturbation Stochastic Approximation
(MSPSA) algorithm, our method demonstrates a significant reduction in Net
Present Cost (NPC) for microgrids, achieving a 68.1% reduction in total costs
in a case study conducted on Popova Island. The results indicate the
effectiveness of our approach in enhancing the economic viability of microgrids
while promoting cleaner energy solutions. Future research directions include
refining uncertainty models and exploring applications in grid-connected
microgrids.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11352v1' target='_blank'>A Framework for Learning Scoring Rules in Autonomous Driving Planning
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zikang Xiong, Joe Kurian Eappen, Suresh Jagannathan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 02:06:57</h6>
<p class='card-text'>In autonomous driving systems, motion planning is commonly implemented as a
two-stage process: first, a trajectory proposer generates multiple candidate
trajectories, then a scoring mechanism selects the most suitable trajectory for
execution. For this critical selection stage, rule-based scoring mechanisms are
particularly appealing as they can explicitly encode driving preferences,
safety constraints, and traffic regulations in a formalized,
human-understandable format. However, manually crafting these scoring rules
presents significant challenges: the rules often contain complex
interdependencies, require careful parameter tuning, and may not fully capture
the nuances present in real-world driving data. This work introduces FLoRA, a
novel framework that bridges this gap by learning interpretable scoring rules
represented in temporal logic. Our method features a learnable logic structure
that captures nuanced relationships across diverse driving scenarios,
optimizing both rules and parameters directly from real-world driving
demonstrations collected in NuPlan. Our approach effectively learns to evaluate
driving behavior even though the training data only contains positive examples
(successful driving demonstrations). Evaluations in closed-loop planning
simulations demonstrate that our learned scoring rules outperform existing
techniques, including expert-designed rules and neural network scoring models,
while maintaining interpretability. This work introduces a data-driven approach
to enhance the scoring mechanism in autonomous driving systems, designed as a
plug-in module to seamlessly integrate with various trajectory proposers. Our
video and code are available on xiong.zikang.me/FLoRA.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11312v1' target='_blank'>AI Generations: From AI 1.0 to AI 4.0</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiahao Wu, Hengxu You, Jing Du</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 23:19:44</h6>
<p class='card-text'>This paper proposes that Artificial Intelligence (AI) progresses through
several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),
AI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of
these AI generations is driven by shifting priorities among algorithms,
computing power, and data. AI 1.0 ushered in breakthroughs in pattern
recognition and information processing, fueling advances in computer vision,
natural language processing, and recommendation systems. AI 2.0 built on these
foundations through real-time decision-making in digital environments,
leveraging reinforcement learning and adaptive planning for agentic AI
applications. AI 3.0 extended intelligence into physical contexts, integrating
robotics, autonomous vehicles, and sensor-fused control systems to act in
uncertain real-world settings. Building on these developments, AI 4.0 puts
forward the bold vision of self-directed AI capable of setting its own goals,
orchestrating complex training regimens, and possibly exhibiting elements of
machine consciousness. This paper traces the historical foundations of AI
across roughly seventy years, mapping how changes in technological bottlenecks
from algorithmic innovation to high-performance computing to specialized data,
have spurred each generational leap. It further highlights the ongoing
synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,
regulatory, and philosophical challenges that arise when artificial systems
approach (or aspire to) human-like autonomy. Ultimately, understanding these
evolutions and their interdependencies is pivotal for guiding future research,
crafting responsible governance, and ensuring that AI transformative potential
benefits society as a whole.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11298v1' target='_blank'>Integrating Language Models for Enhanced Network State Monitoring in
  DRL-Based SFC Provisioning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Parisa Fard Moshiri, Murat Arda Onsu, Poonam Lohan, Burak Kantarci, Emil Janulewicz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 22:52:14</h6>
<p class='card-text'>Efficient Service Function Chain (SFC) provisioning and Virtual Network
Function (VNF) placement are critical for enhancing network performance in
modern architectures such as Software-Defined Networking (SDN) and Network
Function Virtualization (NFV). While Deep Reinforcement Learning (DRL) aids
decision-making in dynamic network environments, its reliance on structured
inputs and predefined rules limits adaptability in unforeseen scenarios.
Additionally, incorrect actions by a DRL agent may require numerous training
iterations to correct, potentially reinforcing suboptimal policies and
degrading performance. This paper integrates DRL with Language Models (LMs),
specifically Bidirectional Encoder Representations from Transformers (BERT) and
DistilBERT, to enhance network management. By feeding final VNF allocations
from DRL into the LM, the system can process and respond to queries related to
SFCs, DCs, and VNFs, enabling real-time insights into resource utilization,
bottleneck detection, and future demand planning. The LMs are fine-tuned to our
domain-specific dataset using Low-Rank Adaptation (LoRA). Results show that
BERT outperforms DistilBERT with a lower test loss (0.28 compared to 0.36) and
higher confidence (0.83 compared to 0.74), though BERT requires approximately
46% more processing time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11295v1' target='_blank'>Game-Of-Goals: Using adversarial games to achieve strategic resilience</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aditya Ghose, Asjad Khan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 22:34:59</h6>
<p class='card-text'>Our objective in this paper is to develop a machinery that makes a given
organizational strategic plan resilient to the actions of competitor agents
(adverse environmental actions). We assume that we are given a goal tree
representing strategic goals (can also be seen business requirements for a
software systems) with the assumption that competitor agents are behaving in a
maximally adversarial fashion(opposing actions against our sub goals or goals
in general). We use game tree search methods (such as minimax) to select an
optimal execution strategy(at a given point in time), such that it can maximize
our chances of achieving our (high level) strategic goals. Our machinery helps
us determine which path to follow(strategy selection) to achieve the best end
outcome. This is done by comparing alternative execution strategies available
to us via an evaluation function. Our evaluation function is based on the idea
that we want to make our execution plans defensible(future-proof) by selecting
execution strategies that make us least vulnerable to adversarial actions by
the competitor agents. i.e we want to select an execution strategy such that
its leaves minimum room(or options) for the adversary to cause
impediment/damage to our business goals/plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11213v1' target='_blank'>Stochastic Optimization of Inventory at Large-scale Supply Chains</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaoyang Larry Jin, Mehdi Maasoumy, Yimin Liu, Zeshi Zheng, Zizhuo Ren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 17:25:50</h6>
<p class='card-text'>Today's global supply chains face growing challenges due to rapidly changing
market conditions, increased network complexity and inter-dependency, and
dynamic uncertainties in supply, demand, and other factors. To combat these
challenges, organizations employ Material Requirements Planning (MRP) software
solutions to set inventory stock buffers - for raw materials, work-in-process
goods, and finished products - to help them meet customer service levels.
However, holding excess inventory further complicates operations and can lock
up millions of dollars of capital that could be otherwise deployed.
Furthermore, most commercially available MRP solutions fall short in
considering uncertainties and do not result in optimal solutions for modern
enterprises.
  At C3 AI, we fundamentally reformulate the inventory management problem as a
constrained stochastic optimization. We then propose a simulation-optimization
framework that minimizes inventory and related costs while maintaining desired
service levels. The framework's goal is to find the optimal reorder parameters
that minimize costs subject to a pre-defined service-level constraint and all
other real-world operational constraints. These optimal reorder parameters can
be fed back into an MRP system to drive optimal order placement, or used to
place optimal orders directly. This approach has proven successful in reducing
inventory levels by 10-35 percent, resulting in hundreds of millions of dollars
of economic benefit for major enterprises at a global scale.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11134v1' target='_blank'>Solving Online Resource-Constrained Scheduling for Follow-Up Observation
  in Astronomy: a Reinforcement Learning Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yajie Zhang, Ce Yu, Chao Sun, Jizeng Wei, Junhan Ju, Shanjiang Tang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 14:01:12</h6>
<p class='card-text'>In the astronomical observation field, determining the allocation of
observation resources of the telescope array and planning follow-up
observations for targets of opportunity (ToOs) are indispensable components of
astronomical scientific discovery. This problem is computationally challenging,
given the online observation setting and the abundance of time-varying factors
that can affect whether an observation can be conducted. This paper presents
ROARS, a reinforcement learning approach for online astronomical
resource-constrained scheduling. To capture the structure of the astronomical
observation scheduling, we depict every schedule using a directed acyclic graph
(DAG), illustrating the dependency of timing between different observation
tasks within the schedule. Deep reinforcement learning is used to learn a
policy that can improve the feasible solution by iteratively local rewriting
until convergence. It can solve the challenge of obtaining a complete solution
directly from scratch in astronomical observation scenarios, due to the high
computational complexity resulting from numerous spatial and temporal
constraints. A simulation environment is developed based on real-world
scenarios for experiments, to evaluate the effectiveness of our proposed
scheduling approach. The experimental results show that ROARS surpasses 5
popular heuristics, adapts to various observation scenarios and learns
effective strategies with hindsight.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12198v1' target='_blank'>Maximize Your Diffusion: A Study into Reward Maximization and Alignment
  for Diffusion-based Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dom Huh, Prasant Mohapatra</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 00:30:39</h6>
<p class='card-text'>Diffusion-based planning, learning, and control methods present a promising
branch of powerful and expressive decision-making solutions. Given the growing
interest, such methods have undergone numerous refinements over the past years.
However, despite these advancements, existing methods are limited in their
investigations regarding general methods for reward maximization within the
decision-making process. In this work, we study extensions of fine-tuning
approaches for control applications. Specifically, we explore extensions and
various design choices for four fine-tuning approaches: reward alignment
through reinforcement learning, direct preference optimization, supervised
fine-tuning, and cascading diffusion. We optimize their usage to merge these
independent efforts into one unified paradigm. We show the utility of such
propositions in offline RL settings and demonstrate empirical improvements over
a rich array of control tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10862v1' target='_blank'>Accelerated co-design of robots through morphological pretraining</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luke Strgar, Sam Kriegman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-15 17:20:56</h6>
<p class='card-text'>The co-design of robot morphology and neural control typically requires using
reinforcement learning to approximate a unique control policy gradient for each
body plan, demanding massive amounts of training data to measure the
performance of each design. Here we show that a universal, morphology-agnostic
controller can be rapidly and directly obtained by gradient-based optimization
through differentiable simulation. This process of morphological pretraining
allows the designer to explore non-differentiable changes to a robot's physical
layout (e.g. adding, removing and recombining discrete body parts) and
immediately determine which revisions are beneficial and which are deleterious
using the pretrained model. We term this process "zero-shot evolution" and
compare it with the simultaneous co-optimization of a universal controller
alongside an evolving design population. We find the latter results in
diversity collapse, a previously unknown pathology whereby the population --
and thus the controller's training data -- converges to similar designs that
are easier to steer with a shared universal controller. We show that zero-shot
evolution with a pretrained controller quickly yields a diversity of highly
performant designs, and by fine-tuning the pretrained controller on the current
population throughout evolution, diversity is not only preserved but
significantly increased as superior performance is achieved.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10787v1' target='_blank'>Modelling and short-term forecasting of seasonal mortality</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ainhoa-Elena Leger, Silvia Rizzi, Ugofilippo Basellini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-15 12:46:14</h6>
<p class='card-text'>Excess mortality, i.e. the difference between expected and observed
mortality, is used to quantify the death toll of mortality shocks, such as
infectious disease-related epidemics and pandemics. However, predictions of
expected mortality are sensitive to model assumptions. Among three
specifications of a Serfling-Poisson regression for seasonal mortality, we
analyse which one yields the most accurate predictions. We compare the
Serfling-Poisson models with: 1) parametric effect for the trend and
seasonality (SP), 2) non-parametric effect for the trend and seasonality
(SP-STSS), also known as modulation model, and 3) non-parametric effect for the
trend and parametric effect for the seasonality (SP-STFS). Forecasting is
achieved with P-splines smoothing. The SP-STFS model resulted in more accurate
historical forecasts of monthly rates from national statistical offices in 25
European countries. An application to the COVID-19 pandemic years illustrates
how excess mortality can be used to evaluate the vulnerability of populations
and aid public health planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10734v2' target='_blank'>Motion planning for highly-dynamic unconditioned reflexes based on
  chained Signed Distance Functions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ken Lin, Qi Ye, Tin Lun Lam, Zhibin Li, Jiming Chen, Gaofeng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-15 09:14:49</h6>
<p class='card-text'>The unconditioned reflex (e.g., protective reflex), which is the innate
reaction of the organism and usually performed through the spinal cord rather
than the brain, can enable organisms to escape harms from environments. In this
paper, we propose an online, highly-dynamic motion planning algorithm to endow
manipulators the highly-dynamic unconditioned reflexes to humans and/or
environments. Our method is based on a chained version of Signed Distance
Functions (SDFs), which can be pre-computed and stored. Our proposed algorithm
is divided into two stages. In the offline stage, we create 3 groups of local
SDFs to store the geometric information of the manipulator and its working
environment. In the online stage, the pre-computed local SDFs are chained
together according the configuration of the manipulator, to provide global
geometric information about the environment. While the point clouds of the
dynamic objects serve as query points to look up these local SDFs for quickly
generating escape velocity. Then we propose a modified geometric Jacobian
matrix and use the Jacobian-pseudo-inverse method to generate real-time reflex
behaviors to avoid the static and dynamic obstacles in the environment. The
benefits of our method are validated in both static and dynamic scenarios. In
the static scenario, our method identifies the path solutions with lower time
consumption and shorter trajectory length compared to existing solutions. In
the dynamic scenario, our method can reliably pursue the dynamic target point,
avoid dynamic obstacles, and react to these obstacles within 1ms, which
surpasses the unconditioned reflex reaction time of humans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10720v2' target='_blank'>NPSim: Nighttime Photorealistic Simulation From Daytime Images With
  Monocular Inverse Rendering and Ray Tracing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shutong Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-15 08:24:19</h6>
<p class='card-text'>Semantic segmentation is an important task for autonomous driving. A powerful
autonomous driving system should be capable of handling images under all
conditions, including nighttime. Generating accurate and diverse nighttime
semantic segmentation datasets is crucial for enhancing the performance of
computer vision algorithms in low-light conditions. In this thesis, we
introduce a novel approach named NPSim, which enables the simulation of
realistic nighttime images from real daytime counterparts with monocular
inverse rendering and ray tracing. NPSim comprises two key components: mesh
reconstruction and relighting. The mesh reconstruction component generates an
accurate representation of the scene structure by combining geometric
information extracted from the input RGB image and semantic information from
its corresponding semantic labels. The relighting component integrates
real-world nighttime light sources and material characteristics to simulate the
complex interplay of light and object surfaces under low-light conditions. The
scope of this thesis mainly focuses on the implementation and evaluation of the
mesh reconstruction component. Through experiments, we demonstrate the
effectiveness of the mesh reconstruction component in producing high-quality
scene meshes and their generality across different autonomous driving datasets.
We also propose a detailed experiment plan for evaluating the entire pipeline,
including both quantitative metrics in training state-of-the-art supervised and
unsupervised semantic segmentation approaches and human perceptual studies,
aiming to indicate the capability of our approach to generate realistic
nighttime images and the value of our dataset in steering future progress in
the field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10585v1' target='_blank'>Prediction uncertainty-aware planning using deep ensembles and
  trajectory optimisation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anshul Nayak, Azim Eskandarian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 22:29:19</h6>
<p class='card-text'>Human motion is stochastic and ensuring safe robot navigation in a
pedestrian-rich environment requires proactive decision-making. Past research
relied on incorporating deterministic future states of surrounding pedestrians
which can be overconfident leading to unsafe robot behaviour. The current paper
proposes a predictive uncertainty-aware planner that integrates neural network
based probabilistic trajectory prediction into planning. Our method uses a deep
ensemble based network for probabilistic forecasting of surrounding humans and
integrates the predictive uncertainty as constraints into the planner. We
compare numerous constraint satisfaction methods on the planner and evaluated
its performance on real world pedestrian datasets. Further, offline robot
navigation was carried out on out-of-distribution pedestrian trajectories
inside a narrow corridor</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13156v1' target='_blank'>Compositionally Grading Alloy Stacking Fault Energy using Autonomous
  Path Planning and Additive Manufacturing with Elemental Powders</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:James Hanagan, Nicole Person, Daniel Salas, Marshall Allen, Wenle Xu, Daniel Lewis, Brady Butler, James D. Paramore, George Pharr, Ibrahim Karaman, Raymundo Arroyave</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 22:02:02</h6>
<p class='card-text'>Compositionally graded alloys (CGAs) are often proposed for use in structural
components where the combination of two or more alloys within a single part can
yield substantial enhancement in performance and functionality. For these
applications, numerous design methodologies have been developed, one of the
most sophisticated being the application of path planning algorithms originally
designed for robotics to solve CGA design problems. In addition to the
traditional application to structural components, this work proposes and
demonstrates the application of this CGA design framework to rapid alloy
design, synthesis, and characterization. A composition gradient in the CoCrFeNi
alloy space was planned between the maximum and minimum stacking fault energy
(SFE) as predicted by a previously developed model in a face-centered cubic
(FCC) high entropy alloy (HEA) space. The path was designed to be monotonic in
SFE and avoid regions that did not meet FCC phase fraction and solidification
range constraints predicted by CALculation of PHAse Diagrams (CALPHAD).
Compositions from the path were selected to produce a linear gradient in SFE,
and the CGA was built using laser directed energy deposition (L-DED). The
resulting gradient was characterized for microstructure and mechanical
properties, including hardness, elastic modulus, and strain rate sensitivity.
Despite being predicted to contain a single FCC phase throughout the gradient,
part of the CGA underwent a martensitic transformation, thereby demonstrating a
limitation of using equilibrium CALPHAD calculations for phase stability
predictions. More broadly, this demonstrates the ability of the methods
employed to bring attention to blind spots in alloy models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10568v1' target='_blank'>Observer-Aware Probabilistic Planning Under Partial Observability</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Salomé Lepers, Vincent Thomas, Olivier Buffet</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 21:41:04</h6>
<p class='card-text'>In this article, we are interested in planning problems where the agent is
aware of the presence of an observer, and where this observer is in a partial
observability situation. The agent has to choose its strategy so as to optimize
the information transmitted by observations. Building on observer-aware Markov
decision processes (OAMDPs), we propose a framework to handle this type of
problems and thus formalize properties such as legibility, explicability and
predictability. This extension of OAMDPs to partial observability can not only
handle more realistic problems, but also permits considering dynamic hidden
variables of interest. These dynamic target variables allow, for instance,
working with predictability, or with legibility problems where the goal might
change during execution. We discuss theoretical properties of PO-OAMDPs and,
experimenting with benchmark problems, we analyze HSVI's convergence behavior
with dedicated initializations and study the resulting strategies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10519v1' target='_blank'>Customizable Contraction Hierarchies -- A Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thomas Bläsius, Valentin Buchhold, Dorothea Wagner, Tim Zeitz, Michael Zündorf</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 19:35:02</h6>
<p class='card-text'>This work establishes the technical fundamentals of a well-tuned Customizable
Contraction Hierarchies (CCH) implementation that is simple and elegant. We
give a detailed overview of the state of the art of CCH, review recent advances
on CCH and show how to combine them. Additionally, we propose further
refinements that improve the performance of CCH. An extensive evaluation
confirms that a CCH framework is not only comprehensive in supported features
but also competitive in performance to both Contraction Hierarchies (CH) and
Customizable Route Planning (CRP).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10515v1' target='_blank'>Distributed Application Provisioning over Ethereum based private and
  permissioned Blockchain: Availability modeling, capacity, and costs planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Carlos Melo, Jamilson Dantas, Paulo Pereira, Paulo Maciel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 19:24:06</h6>
<p class='card-text'>Blockchain and Cloud Computing are two of the main topics related to the
distributed computing paradigm, and in the last decade, they have seen
exponential growth in their adoption. Cloud computing has long been established
as the main mechanism to test, develop, and deliver new applications and
services in a distributed manner across the World Wide Web. Large data centers
host many services and store petabytes of user data. Infrastructure and
services owners rule the access to data and may even be able to change contents
and attest to its veracity. Blockchain is a step towards a future where the
user's data are considered safer, besides being public. Advances in
blockchain-based technologies, now, support service provisioning over
permissioned and private infrastructures. Therefore, organizations or groups of
individuals may share information, service even if they do not trust each
other, besides supporting infrastructure management tasks. This paper presents
and evaluates models for assessing the availability and capacity-oriented
availability of cloud computing infrastructures. It aims at running
Blockchain's distributed applications based on the Ethereum blockchain platform
and the required expenses to perform service delivery in public and private
infrastructures. Most of the obtained results also apply to other blockchains
based platforms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10509v1' target='_blank'>A Comprehensive Hyperledger Fabric Performance Evaluation based on
  Resources Capacity Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Carlos Melo, Glauber Gonçalves, Francisco A. Silva, André Soares</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 19:14:06</h6>
<p class='card-text'>Hyperledger Fabric is a platform for permissioned blockchain networks that
enables secure and auditable distributed data storage for enterprise
applications. There is a growing interest in applications based on this
platform, but its use requires the configuration of different blockchain
parameters. Various configurations impact the system's non-functional
qualities, especially performance and cost. In this article, we propose a
Stochastic Petri Net to model the performance of the Hyperledger Fabric
platform with different blockchain parameters, computer capacity, and
transaction rates. We also present a set of case studies to demonstrate the
feasibility of the proposed model. This model serves as a practical guide to
help administrators of permissioned blockchain networks find the best
performance for their applications. The proposed model allowed us to identify
the block size that leads to a high mean response time (ranging from 1 to 25
seconds) caused by a change in the arrival rate.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10365v2' target='_blank'>AffinityFlow: Guided Flows for Antibody Affinity Maturation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Can Chen, Karla-Luise Herpoldt, Chenchao Zhao, Zichen Wang, Marcus Collins, Shang Shang, Ron Benson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 18:43:22</h6>
<p class='card-text'>Antibodies are widely used as therapeutics, but their development requires
costly affinity maturation, involving iterative mutations to enhance binding
affinity.This paper explores a sequence-only scenario for affinity maturation,
using solely antibody and antigen sequences. Recently AlphaFlow wraps AlphaFold
within flow matching to generate diverse protein structures, enabling a
sequence-conditioned generative model of structure. Building on this, we
propose an alternating optimization framework that (1) fixes the sequence to
guide structure generation toward high binding affinity using a structure-based
affinity predictor, then (2) applies inverse folding to create sequence
mutations, refined by a sequence-based affinity predictor for post selection. A
key challenge is the lack of labeled data for training both predictors. To
address this, we develop a co-teaching module that incorporates valuable
information from noisy biophysical energies into predictor refinement. The
sequence-based predictor selects consensus samples to teach the structure-based
predictor, and vice versa. Our method, AffinityFlow, achieves state-of-the-art
performance in affinity maturation experiments. We plan to open-source our code
after acceptance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10279v1' target='_blank'>Emit As You Go: Enumerating Edges of a Spanning Tree</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Katrin Casel, Stefan Neubert</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 16:36:52</h6>
<p class='card-text'>Classically, planning tasks are studied as a two-step process: plan creation
and plan execution. In situations where plan creation is slow (for example, due
to expensive information access or complex constraints), a natural speed-up
tactic is interleaving planning and execution. We implement such an approach
with an enumeration algorithm that, after little preprocessing time, outputs
parts of a plan one by one with little delay in-between consecutive outputs. As
concrete planning task, we consider efficient connectivity in a network
formalized as the minimum spanning tree problem in all four standard variants:
(un)weighted (un)directed graphs. Solution parts to be emitted one by one for
this concrete task are the individual edges that form the final tree.
  We show with algorithmic upper bounds and matching unconditional adversary
lower bounds that efficient enumeration is possible for three of four problem
variants; specifically for undirected unweighted graphs (delay in the order of
the average degree), as well as graphs with either weights (delay in the order
of the maximum degree and the average runtime per emitted edge of a total-time
algorithm) or directions (delay in the order of the maximum degree). For graphs
with both weighted and directed edges, we show that no meaningful enumeration
is possible.
  Finally, with experiments on random undirected unweighted graphs, we show
that the theoretical advantage of little preprocessing and delay carries over
to practice.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10177v1' target='_blank'>STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingcong Lei, Yiming Zhao, Ge Wang, Zhixin Mai, Shuguang Cui, Yatong Han, Jinke Ren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 14:12:09</h6>
<p class='card-text'>A key objective of embodied intelligence is enabling agents to perform
long-horizon tasks in dynamic environments while maintaining robust
decision-making and adaptability. To achieve this goal, we propose the
Spatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task
planning and execution by integrating spatio-temporal memory. STMA is built
upon three critical components: (1) a spatio-temporal memory module that
captures historical and environmental changes in real time, (2) a dynamic
knowledge graph that facilitates adaptive spatial reasoning, and (3) a
planner-critic mechanism that iteratively refines task strategies. We evaluate
STMA in the TextWorld environment on 32 tasks, involving multi-step planning
and exploration under varying levels of complexity. Experimental results
demonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7%
increase in average score compared to the state-of-the-art model. The results
highlight the effectiveness of spatio-temporal memory in advancing the memory
capabilities of embodied agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10098v1' target='_blank'>Structuring the Environment Nudges Participants Toward Hierarchical Over
  Shortest Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Valeria Simonelli, Davide Nuzzi, Gian Luca Lancia, Giovanni Pezzulo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 11:45:46</h6>
<p class='card-text'>Effective planning is crucial for navigating complex environments and
achieving goals efficiently. In this study, we investigated how environmental
structure influences the selection of planning strategies. Participants
navigated a space station to collect colored spheres, with environments either
structured (spheres grouped by color) or unstructured (spheres scattered
randomly). We tested three types of plans: hierarchical (grouping spheres by
color), shortest path (minimizing travel distance), and neutral (none of the
above). By manipulating environmental structure, we were able to nudge
participants toward a preference for hierarchical planning in structured
environments, while shortest path plans were favored in unstructured
environments. A mismatch between self-reported preferences and actual choices
indicated that participants often adopted implicit strategies, unaware of their
decision-making processes. These findings highlight the powerful effect of
environmental cues on planning and suggest that even subtle changes in
structure can guide the selection of planning strategies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10090v1' target='_blank'>Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for
  Furniture Assembly Using Vision-Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenrui Tie, Shengxiang Sun, Jinxuan Zhu, Yiwei Liu, Jingxiang Guo, Yue Hu, Haonan Chen, Junting Chen, Ruihai Wu, Lin Shao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 11:25:24</h6>
<p class='card-text'>Humans possess an extraordinary ability to understand and execute complex
manipulation tasks by interpreting abstract instruction manuals. For robots,
however, this capability remains a substantial challenge, as they cannot
interpret abstract instructions and translate them into executable actions. In
this paper, we present Manual2Skill, a novel framework that enables robots to
perform complex assembly tasks guided by high-level manual instructions. Our
approach leverages a Vision-Language Model (VLM) to extract structured
information from instructional images and then uses this information to
construct hierarchical assembly graphs. These graphs represent parts,
subassemblies, and the relationships between them. To facilitate task
execution, a pose estimation model predicts the relative 6D poses of components
at each assembly step. At the same time, a motion planning module generates
actionable sequences for real-world robotic implementation. We demonstrate the
effectiveness of Manual2Skill by successfully assembling several real-world
IKEA furniture items. This application highlights its ability to manage
long-horizon manipulation tasks with both efficiency and precision,
significantly enhancing the practicality of robot learning from instruction
manuals. This work marks a step forward in advancing robotic systems capable of
understanding and executing complex manipulation tasks in a manner akin to
human capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10025v1' target='_blank'>What is a Feature, Really? Toward a Unified Understanding Across SE
  Disciplines</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nitish Patkar, Aimen Fahmi, Timo Kehrer, Norbert Seyff</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 09:08:53</h6>
<p class='card-text'>In software engineering, the concept of a ``feature'' is widely used but
inconsistently defined across disciplines such as requirements engineering (RE)
and software product lines (SPL). This lack of consistency often results in
communication gaps, rework, and inefficiencies in projects. To address these
challenges, this paper proposes an empirical, data-driven approach to explore
how features are described, implemented, and managed across real-world
projects, starting with open-source software (OSS). By analyzing
feature-related branches in OSS repositories, we identify patterns in
contributor behavior, feature implementation, and project management
activities. Our findings provide actionable insights to improve project
planning, resource allocation, and team coordination. Additionally, we outline
a roadmap to unify the understanding of features across software engineering
disciplines. This research aims to bridge gaps between academic inquiry and
practical strategies, fostering better feature planning and development
workflows in diverse project environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10012v1' target='_blank'>Dream to Drive: Model-Based Vehicle Control Using Analytic World Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Asen Nachkov, Danda Pani Paudel, Jan-Nico Zaech, Davide Scaramuzza, Luc Van Gool</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 08:46:49</h6>
<p class='card-text'>Differentiable simulators have recently shown great promise for training
autonomous vehicle controllers. Being able to backpropagate through them, they
can be placed into an end-to-end training loop where their known dynamics turn
into useful priors for the policy to learn, removing the typical black box
assumption of the environment. So far, these systems have only been used to
train policies. However, this is not the end of the story in terms of what they
can offer. Here, for the first time, we use them to train world models.
Specifically, we present three new task setups that allow us to learn next
state predictors, optimal planners, and optimal inverse states. Unlike analytic
policy gradients (APG), which requires the gradient of the next simulator state
with respect to the current actions, our proposed setups rely on the gradient
of the next state with respect to the current state. We call this approach
Analytic World Models (AWMs) and showcase its applications, including how to
use it for planning in the Waymax simulator. Apart from pushing the limits of
what is possible with such simulators, we offer an improved training recipe
that increases performance on the large-scale Waymo Open Motion dataset by up
to 12% compared to baselines at essentially no additional cost.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09918v1' target='_blank'>Dual Control for Interactive Autonomous Merging with Model Predictive
  Diffusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jacob Knaup, Jovin D'sa, Behdad Chalaki, Hossein Nourkhiz Mahjoub, Ehsan Moradi-Pari, Panagiotis Tsiotras</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 05:06:46</h6>
<p class='card-text'>Interactive decision-making is essential in applications such as autonomous
driving, where the agent must infer the behavior of nearby human drivers while
planning in real-time. Traditional predict-then-act frameworks are often
insufficient or inefficient because accurate inference of human behavior
requires a continuous interaction rather than isolated prediction. To address
this, we propose an active learning framework in which we rigorously derive
predicted belief distributions. Additionally, we introduce a novel model-based
diffusion solver tailored for online receding horizon control problems,
demonstrated through a complex, non-convex highway merging scenario. Our
approach extends previous high-fidelity dual control simulations to hardware
experiments, which may be viewed at https://youtu.be/Q_JdZuopGL4, and verifies
behavior inference in human-driven traffic scenarios, moving beyond idealized
models. The results show improvements in adaptive planning under uncertainty,
advancing the field of interactive decision-making for real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09916v1' target='_blank'>Surface dynamics and geophysical environment of asteroid (3200) Phaethon</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hangbin Jo, Masateru Ishiguro, Derek C. Richardson, Sean E. Marshall, Tomoko Arai, Ko Ishibashi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 05:03:21</h6>
<p class='card-text'>Context. (3200) Phaethon is a ~5-km-diameter near-Earth asteroid with a small
perihelion distance of 0.14 au and is the parent body of the Geminids. JAXA's
DESTINY+ mission will fly by Phaethon in the near future. Aims. We aim to
support the pre-flight planning for the DESTINY+ mission by performing a
geophysical analysis on Phaethon's surface and near-surface environment
utilizing the latest shape model from numerous observations. Methods. We
employed the soft-sphere discrete element method code PKDGRAV to construct a
"mascon" model of Phaethon and determine its gravity. We then computed the
geopotential on Phaethon and derived various physical quantities related to its
surface and near-surface dynamics. Results. We calculated geophysical
quantities for the surface, including surface acceleration and slope. To assess
whether surface objects could be launched off the surface, we computed the
escape speed, return speed, Jacobi speed, and the location and stability of
equilibrium points around Phaethon, and conducted a simple dynamical simulation
of launched particles. Conclusions. Our results suggest that a large depression
feature in the northern hemisphere could harbor exposed subsurface material and
the freshest material on Phaethon. We propose that this depression be
considered a key area for observation by the DESTINY+ mission</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09877v1' target='_blank'>Stretching Rubber, Not Budgets: Accurate Parking Utilization on a
  Shoestring</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christopher K. Allsup</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 03:06:35</h6>
<p class='card-text'>Effective parking management is essential for ensuring accessibility, safety,
and convenience in master-planned communities, particularly in active adult
neighborhoods experiencing rapid growth. Accurately assessing parking
utilization is a crucial first step in planning for future demand, but data
collection methods can be costly and labor-intensive. This paper presents a
low-cost yet highly accurate methodology for measuring parking utilization
using road tubes connected to portable traffic counters from JAMAR
Technologies, Inc. By integrating results from JAMAR's analysis tool with
custom Python scripting, the methodology enables precise parking lot counts
through parameter optimization and automated error correction. The system's
efficiency allows for scalable deployment without significant manual
observation, reducing both costs and disruptions to daily operations. Using
Tellico Village as a case study, this research demonstrates that community
planners can obtain actionable parking insights on a limited budget, empowering
them to make informed decisions about capacity expansion, traffic flow
improvements, and facility scheduling. The findings underscore the feasibility
of leveraging cost-effective technology to optimize infrastructure planning and
ensure long-term resident satisfaction as communities grow.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09855v1' target='_blank'>Prospects for observing chiral symmetry breaking in lepton colliders</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maurice H. P. M. van Putten, Maryam A. Abchouyeh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 01:40:24</h6>
<p class='card-text'>Weak interactions in neutron $\beta$-decay exhibit parity violation through
the preferential emission of right-handed antineutrinos. We identify this
symmetry breaking with a reduction of phase space due to the small neutrino
mass. During a brief interval of momentum exchange, a small mass neutrino puts
the emission process close to the bifurcation horizon of Rindler space, doubly
covered by Minkowski space ${\cal M}$ as dictated by the Equivalence Principle
of general relativity. In the limit of arbitrarily small mass, this two-sheet
covering effectively collapses into a single sheet, reducing the dimension of
Dirac spinors from four to two, leaving neutrinos single-handed. This predicts
a similar reduction to single-handed particle states in electrons created at
TeV energies, which may be tested with the planned linear leptonic colliders.
If confirmed, right-handed small mass neutrinos are expected to exist at
sufficiently low energies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09805v1' target='_blank'>Towards Patient-Specific Surgical Planning for Bicuspid Aortic Valve
  Repair: Fully Automated Segmentation of the Aortic Valve in 4D CT</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zaiyang Guo, Ningjun J Dong, Harold Litt, Natalie Yushkevich, Melanie Freas, Jessica Nunez, Victor Ferrari, Jilei Hao, Shir Goldfinger, Matthew A. Jolley, Joseph Bavaria, Nimesh Desai, Alison M. Pouch</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 22:43:43</h6>
<p class='card-text'>The bicuspid aortic valve (BAV) is the most prevalent congenital heart defect
and may require surgery for complications such as stenosis, regurgitation, and
aortopathy. BAV repair surgery is effective but challenging due to the
heterogeneity of BAV morphology. Multiple imaging modalities can be employed to
assist the quantitative assessment of BAVs for surgical planning.
Contrast-enhanced 4D computed tomography (CT) produces volumetric temporal
sequences with excellent contrast and spatial resolution. Segmentation of the
aortic cusps and root in these images is an essential step in creating patient
specific models for visualization and quantification. While deep learning-based
methods are capable of fully automated segmentation, no BAV-specific model
exists. Among valve segmentation studies, there has been limited quantitative
assessment of the clinical usability of the segmentation results. In this work,
we developed a fully automated multi-label BAV segmentation pipeline based on
nnU-Net. The predicted segmentations were used to carry out surgically relevant
morphological measurements including geometric cusp height, commissural angle
and annulus diameter, and the results were compared against manual
segmentation. Automated segmentation achieved average Dice scores of over 0.7
and symmetric mean distance below 0.7 mm for all three aortic cusps and the
root wall. Clinically relevant benchmarks showed good consistency between
manual and predicted segmentations. Overall, fully automated BAV segmentation
of 3D frames in 4D CT can produce clinically usable measurements for surgical
risk stratification, but the temporal consistency of segmentations needs to be
improved.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10477v1' target='_blank'>Knowledge Integration Strategies in Autonomous Vehicle Prediction and
  Planning: A Comprehensive Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kumar Manas, Adrian Paschke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 19:32:41</h6>
<p class='card-text'>This comprehensive survey examines the integration of knowledge-based
approaches into autonomous driving systems, with a focus on trajectory
prediction and planning. We systematically review methodologies for
incorporating domain knowledge, traffic rules, and commonsense reasoning into
these systems, spanning purely symbolic representations to hybrid
neuro-symbolic architectures. In particular, we analyze recent advancements in
formal logic and differential logic programming, reinforcement learning
frameworks, and emerging techniques that leverage large foundation models and
diffusion models for knowledge representation. Organized under a unified
literature survey section, our discussion synthesizes the state-of-the-art into
a high-level overview, supported by a detailed comparative table that maps key
works to their respective methodological categories. This survey not only
highlights current trends -- including the growing emphasis on interpretable
AI, formal verification in safety-critical systems, and the increased use of
generative models in prediction and planning -- but also outlines the
challenges and opportunities for developing robust, knowledge-enhanced
autonomous driving systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10476v1' target='_blank'>Multi-Objective Planning with Contextual Lexicographic Reward
  Preferences</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pulkit Rustagi, Yashwanthi Anand, Sandhya Saisubramanian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 19:04:22</h6>
<p class='card-text'>Autonomous agents are often required to plan under multiple objectives whose
preference ordering varies based on context. The agent may encounter multiple
contexts during its course of operation, each imposing a distinct lexicographic
ordering over the objectives, with potentially different reward functions
associated with each context. Existing approaches to multi-objective planning
typically consider a single preference ordering over the objectives, across the
state space, and do not support planning under multiple objective orderings
within an environment. We present Contextual Lexicographic Markov Decision
Process (CLMDP), a framework that enables planning under varying lexicographic
objective orderings, depending on the context. In a CLMDP, both the objective
ordering at a state and the associated reward functions are determined by the
context. We employ a Bayesian approach to infer a state-context mapping from
expert trajectories. Our algorithm to solve a CLMDP first computes a policy for
each objective ordering and then combines them into a single context-aware
policy that is valid and cycle-free. The effectiveness of the proposed approach
is evaluated in simulation and using a mobile robot.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09595v2' target='_blank'>BenchQC: A Benchmarking Toolkit for Quantum Computation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nia Pollard, Kamal Choudhary</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 18:51:08</h6>
<p class='card-text'>The Variational Quantum Eigensolver (VQE) is a promising algorithm for
quantum computing applications in chemistry and materials science, particularly
in addressing the limitations of classical methods for complex systems. This
study benchmarks the performance of the VQE for calculating ground-state
energies of aluminum clusters (Al$^-$, Al$_2$, and Al$_3^-$) within a
quantum-density functional theory (DFT) embedding framework, systematically
varying key parameters -- (I) classical optimizers, (II) circuit types, (III)
number of repetitions, (IV) simulator types, (V) basis sets, and (VI) noise
models. Our findings demonstrate that certain optimizers achieve efficient and
accurate convergence, while circuit choice and basis set selection
significantly impact accuracy, with higher-level basis sets closely matching
classical computation data from Numerical Python Solver (NumPy) and
Computational Chemistry Comparison and Benchmark DataBase (CCCBDB). To evaluate
the workflow under realistic conditions, we employed IBM noise models to
simulate the effects of hardware noise. The results showed close agreement with
CCCBDB benchmarks, with percent errors consistently below 0.2 percent. The
results establish VQE's capability for reliable energy estimations and
highlight the importance of optimizing quantum-DFT parameters to balance
computational cost and precision. This work paves the way for broader VQE
benchmarking on diverse chemical systems, with plans to make results accessible
on Joint Automated Repository for Various Integrated Simulations (JARVIS) and
develop a Python package to support the quantum chemistry and materials science
communities in advancing quantum-enhanced discovery.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09587v1' target='_blank'>Rolling Ahead Diffusion for Traffic Scene Simulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yunpeng Liu, Matthew Niedoba, William Harvey, Adam Scibior, Berend Zwartsenberg, Frank Wood</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 18:45:56</h6>
<p class='card-text'>Realistic driving simulation requires that NPCs not only mimic natural
driving behaviors but also react to the behavior of other simulated agents.
Recent developments in diffusion-based scenario generation focus on creating
diverse and realistic traffic scenarios by jointly modelling the motion of all
the agents in the scene. However, these traffic scenarios do not react when the
motion of agents deviates from their modelled trajectories. For example, the
ego-agent can be controlled by a stand along motion planner. To produce
reactive scenarios with joint scenario models, the model must regenerate the
scenario at each timestep based on new observations in a Model Predictive
Control (MPC) fashion. Although reactive, this method is time-consuming, as one
complete possible future for all NPCs is generated per simulation step.
Alternatively, one can utilize an autoregressive model (AR) to predict only the
immediate next-step future for all NPCs. Although faster, this method lacks the
capability for advanced planning. We present a rolling diffusion based traffic
scene generation model which mixes the benefits of both methods by predicting
the next step future and simultaneously predicting partially noised further
future steps at the same time. We show that such model is efficient compared to
diffusion model based AR, achieving a beneficial compromise between reactivity
and computational efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09561v1' target='_blank'>Enhancing Traffic Safety Analysis with Digital Twin Technology:
  Integrating Vehicle Dynamics and Environmental Factors into Microscopic
  Traffic Simulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guanhao Xu, Jianfei Chen, Zejiang Wang, Anye Zhou, Max Schrader, Joshua Bittle, Yunli Shao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 18:11:49</h6>
<p class='card-text'>Traffic safety is a critical concern in transportation engineering and urban
planning. Traditional traffic safety analysis requires trained observers to
collect data in the field, which is time-consuming, labor-intensive, and
sometimes inaccurate. In recent years, microscopic traffic simulation, which
simulates individual vehicles' movements within a transportation network, have
been utilized to study traffic safety. However, microscopic traffic simulation
only focuses on traffic-related factors, such as traffic volume, traffic
signals, and lane configurations, neglecting vehicle dynamics and
environment-related factors like weather and lighting conditions, which can
significantly impact traffic safety. In light of this, this paper explores the
application of digital twin technology in traffic safety analysis, integrating
vehicle simulators, which consider vehicle dynamics and environmental factors,
and microscopic traffic simulators, which simulate the operations of traffic
flow, for enhanced safety evaluations. Various scenarios, including different
weather conditions and visibility levels, are simulated using a digital twin of
a road segment in Tuscaloosa, Alabama. The simulations employ Surrogate Safety
Measures (SSMs) like Time to Collision (TTC) and Deceleration Rate to Avoid a
Crash (DRAC) to assess safety under varying conditions. The results demonstrate
that traffic digital twin can identify potential safety issues that traditional
microscopic simulation cannot, providing insights for improving traffic control
strategies and transportation infrastructure to enhance traffic safety.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09560v2' target='_blank'>EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language
  Models for Vision-Driven Embodied Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, Tong Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 18:11:34</h6>
<p class='card-text'>Leveraging Multi-modal Large Language Models (MLLMs) to create embodied
agents offers a promising avenue for tackling real-world tasks. While
language-centric embodied agents have garnered substantial attention,
MLLM-based embodied agents remain underexplored due to the lack of
comprehensive evaluation frameworks. To bridge this gap, we introduce
EmbodiedBench, an extensive benchmark designed to evaluate vision-driven
embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing
tasks across four environments, ranging from high-level semantic tasks (e.g.,
household) to low-level tasks involving atomic actions (e.g., navigation and
manipulation); and (2) six meticulously curated subsets evaluating essential
agent capabilities like commonsense reasoning, complex instruction
understanding, spatial awareness, visual perception, and long-term planning.
Through extensive experiments, we evaluated 19 leading proprietary and
open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel
at high-level tasks but struggle with low-level manipulation, with the best
model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a
multifaceted standardized evaluation platform that not only highlights existing
challenges but also offers valuable insights to advance MLLM-based embodied
agents. Our code is available at https://embodiedbench.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09556v1' target='_blank'>Real-Time Fast Marching Tree for Mobile Robot Motion Planning in Dynamic
  Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jefferson Silveira, Kleber Cabral, Sidney Givigi, Joshua A. Marshall</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 18:08:17</h6>
<p class='card-text'>This paper proposes the Real-Time Fast Marching Tree (RT-FMT), a real-time
planning algorithm that features local and global path generation,
multiple-query planning, and dynamic obstacle avoidance. During the search,
RT-FMT quickly looks for the global solution and, in the meantime, generates
local paths that can be used by the robot to start execution faster. In
addition, our algorithm constantly rewires the tree to keep branches from
forming inside the dynamic obstacles and to maintain the tree root near the
robot, which allows the tree to be reused multiple times for different goals.
Our algorithm is based on the planners Fast Marching Tree (FMT*) and Real-time
Rapidly-Exploring Random Tree (RT-RRT*). We show via simulations that RT-FMT
outperforms RT- RRT* in both execution cost and arrival time, in most cases.
Moreover, we also demonstrate via simulation that it is worthwhile taking the
local path before the global path is available in order to reduce arrival time,
even though there is a small possibility of taking an inferior path.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09527v1' target='_blank'>Project portfolio planning in the pharmaceutical industry -- strategic
  objectives and quantitative optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stig Johan Wiklund, Magnus Ytterstad, Frank Miller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 17:39:28</h6>
<p class='card-text'>Many pharmaceutical companies face concerns with the maintenance of desired
revenue levels. Sales forecasts for the current portfolio of products and
projects may indicate a decline in revenue as the marketed products approach
patent expiry. To counteract the potential downturn in revenue, and to
establish revenue growth, an in-flow of new projects into the development
phases is required. In this article, we devise an approach with which the
in-flow of new projects could be optimized, while adhering to the objectives
and constraints set on revenue targets, budget limitations and strategic
considerations on the composition of the company's portfolio.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19430v1' target='_blank'>A systematic literature review on the application of analytical
  approaches and mathematical programming in public bus transit network design
  and operations planning: Part II</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Reza Mahmoudi, Saeid Saidi, S. Chan Wirasinghe</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 17:26:32</h6>
<p class='card-text'>Among all public transit modes, bus transit systems stand out as the most
prevalent and popular. This prominence has spurred a significant body of
research addressing various aspects of bus systems. In the literature,
analytical approaches and mathematical programming are predominantly used to
explore the Public Bus Transit Network Design Problem and Operations Planning
(PBTNDP&OP). Part I of our study presented statistical analyses of literature
applying these methodologies to PBTNDP&OP, along with a comprehensive review of
analytical papers, highlighting the strengths and weaknesses of each approach.
In Part II, we delve into the applications of mathematical programming within
PBTNDP&OP, building upon the 15 major sub-categories identified in Part I. We
have critically analyzed the identified papers within these sub-categories from
various perspectives, including the problems investigated, modeling methods
employed, decision variables, network structures, and key findings. This
critical review highlights selected papers in each category. Finally,
acknowledging existing research gaps, we propose potential extensions for
future research. Despite the extensive array of publications, numerous topics
still warrant further exploration. Notably, sustainable PBTNDP&OP and
challenges associated with integrating emerging technologies are poised to
dominate future research agendas.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09508v1' target='_blank'>A systematic literature review on the application of analytical
  approaches and mathematical programming in public bus transit network design
  and operations planning: Part I</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Reza Mahmoudi, Saeid Saidi, S. Chan Wirasinghe</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 17:21:39</h6>
<p class='card-text'>The Public Bus Transit Network Design Problem and Operations Planning
(PBTNDP&OP) remains a core research area within transportation, in particular,
because of the emergence of new transit technologies and services. Analytical
approaches and mathematical programming are the most commonly applied
methodologies to study this problem. Many studies utilize either of these two
methods, often viewed as competing due to the unique benefits each provides
that the other does not. This two-part paper systematically reviews the
application of analytical approaches and mathematical programming in PBTNDP&OP,
analyzing publications from 1968 to 2021. It begins by comparing analytical
methods and mathematical programming through various statistical analyses,
including the number of published papers, the most active journals and authors,
keyword frequencies, keyword co-occurrence maps, and co-authorship maps.
Subsequent analysis of the identified papers includes examinations from
multiple perspectives: the problems investigated, modeling methods used,
decision variables considered, network structures, and key findings. This is
followed by a critical review of selected papers. The paper concludes by
discussing the advantages and disadvantages of each approach and suggests
potential extensions for future research based on identified gaps in existing
studies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09468v1' target='_blank'>Speed planning by minimizing travel time and energy consumption</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stefano Ardizzoni, Luca Consolini, Mattia Laurini, Marco Locatelli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 16:31:57</h6>
<p class='card-text'>In this paper we address the speed planning problem for a vehicle over an
assigned path with the aim of minimizing a weighted sum of travel time and
energy consumption under suitable constraints (maximum allowed speed, maximum
traction or braking force, maximum power consumption). The resulting
mathematical model is a non--convex optimization problem. We prove that, under
some mild assumptions, a convex reformulation of the non--convex problem is
exact. In particular, the convex reformulation is a Second Order Cone
Programming (SOCP) problem, for which efficient solvers exist. Through the
numerical experiments we confirm that the convex relaxation can be solved very
efficiently and, moreover, we also provide the Pareto front of the trade-off
between the two objectives (travel time and energy consumption).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09393v1' target='_blank'>Generalizable Reinforcement Learning with Biologically Inspired
  Hyperdimensional Occupancy Grid Maps for Exploration and Goal-Directed Path
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shay Snyder, Ryan Shea, Andrew Capodieci, David Gorsich, Maryam Parsa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 15:10:45</h6>
<p class='card-text'>Real-time autonomous systems utilize multi-layer computational frameworks to
perform critical tasks such as perception, goal finding, and path planning.
Traditional methods implement perception using occupancy grid mapping (OGM),
segmenting the environment into discretized cells with probabilistic
information. This classical approach is well-established and provides a
structured input for downstream processes like goal finding and path planning
algorithms. Recent approaches leverage a biologically inspired mathematical
framework known as vector symbolic architectures (VSA), commonly known as
hyperdimensional computing, to perform probabilistic OGM in hyperdimensional
space. This approach, VSA-OGM, provides native compatibility with spiking
neural networks, positioning VSA-OGM as a potential neuromorphic alternative to
conventional OGM. However, for large-scale integration, it is essential to
assess the performance implications of VSA-OGM on downstream tasks compared to
established OGM methods. This study examines the efficacy of VSA-OGM against a
traditional OGM approach, Bayesian Hilbert Maps (BHM), within reinforcement
learning based goal finding and path planning frameworks, across a controlled
exploration environment and an autonomous driving scenario inspired by the
F1-Tenth challenge. Our results demonstrate that VSA-OGM maintains comparable
learning performance across single and multi-scenario training configurations
while improving performance on unseen environments by approximately 47%. These
findings highlight the increased generalizability of policy networks trained
with VSA-OGM over BHM, reinforcing its potential for real-world deployment in
diverse environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09379v2' target='_blank'>TRIFFID: Autonomous Robotic Aid For Increasing First Responders
  Efficiency</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jorgen Cani, Panagiotis Koletsis, Konstantinos Foteinos, Ioannis Kefaloukos, Lampros Argyriou, Manolis Falelakis, Iván Del Pino, Angel Santamaria-Navarro, Martin Čech, Ondřej Severa, Alessandro Umbrico, Francesca Fracasso, AndreA Orlandini, Dimitrios Drakoulis, Evangelos Markakis, Iraklis Varlamis, Georgios Th. Papadopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 14:46:40</h6>
<p class='card-text'>The increasing complexity of natural disaster incidents demands innovative
technological solutions to support first responders in their efforts. This
paper introduces the TRIFFID system, a comprehensive technical framework that
integrates unmanned ground and aerial vehicles with advanced artificial
intelligence functionalities to enhance disaster response capabilities across
wildfires, urban floods, and post-earthquake search and rescue missions. By
leveraging state-of-the-art autonomous navigation, semantic perception, and
human-robot interaction technologies, TRIFFID provides a sophisticated system
composed of the following key components: hybrid robotic platform, centralized
ground station, custom communication infrastructure, and smartphone
application. The defined research and development activities demonstrate how
deep neural networks, knowledge graphs, and multimodal information fusion can
enable robots to autonomously navigate and analyze disaster environments,
reducing personnel risks and accelerating response times. The proposed system
enhances emergency response teams by providing advanced mission planning,
safety monitoring, and adaptive task execution capabilities. Moreover, it
ensures real-time situational awareness and operational support in complex and
risky situations, facilitating rapid and precise information collection and
coordinated actions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09303v1' target='_blank'>Towards Seamless Hierarchical Federated Learning under Intermittent
  Client Participation: A Stagewise Decision-Making Methodology</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minghong Wu, Minghui Liwang, Yuhan Su, Li Li, Seyyedali Hosseinalipour, Xianbin Wang, Huaiyu Dai, Zhenzhen Jiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 13:16:10</h6>
<p class='card-text'>Federated Learning (FL) offers a pioneering distributed learning paradigm
that enables devices/clients to build a shared global model. This global model
is obtained through frequent model transmissions between clients and a central
server, which may cause high latency, energy consumption, and congestion over
backhaul links. To overcome these drawbacks, Hierarchical Federated Learning
(HFL) has emerged, which organizes clients into multiple clusters and utilizes
edge nodes (e.g., edge servers) for intermediate model aggregations between
clients and the central server. Current research on HFL mainly focus on
enhancing model accuracy, latency, and energy consumption in scenarios with a
stable/fixed set of clients. However, addressing the dynamic availability of
clients -- a critical aspect of real-world scenarios -- remains underexplored.
This study delves into optimizing client selection and client-to-edge
associations in HFL under intermittent client participation so as to minimize
overall system costs (i.e., delay and energy), while achieving fast model
convergence. We unveil that achieving this goal involves solving a complex
NP-hard problem. To tackle this, we propose a stagewise methodology that splits
the solution into two stages, referred to as Plan A and Plan B. Plan A focuses
on identifying long-term clients with high chance of participation in
subsequent model training rounds. Plan B serves as a backup, selecting
alternative clients when long-term clients are unavailable during model
training rounds. This stagewise methodology offers a fresh perspective on
client selection that can enhance both HFL and conventional FL via enabling
low-overhead decision-making processes. Through evaluations on MNIST and
CIFAR-10 datasets, we show that our methodology outperforms existing benchmarks
in terms of model accuracy and system costs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09280v1' target='_blank'>Adaptive Multi-Objective Bayesian Optimization for Capacity Planning of
  Hybrid Heat Sources in Electric-Heat Coupling Systems of Cold Regions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruizhe Yang, Zhongkai Yi, Ying Xu, Guiyu Chen, Haojie Yang, Rong Yi, Tongqing Li, Miaozhe ShenJin Li, Haoxiang Gao, Hongyu Duan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 12:50:43</h6>
<p class='card-text'>The traditional heat-load generation pattern of combined heat and power
generators has become a problem leading to renewable energy source (RES) power
curtailment in cold regions, motivating the proposal of a planning model for
alternative heat sources. The model aims to identify non-dominant capacity
allocation schemes for heat pumps, thermal energy storage, electric boilers,
and combined storage heaters to construct a Pareto front, considering both
economic and sustainable objectives. The integration of various heat sources
from both generation and consumption sides enhances flexibility in utilization.
The study introduces a novel optimization algorithm, the adaptive
multi-objective Bayesian optimization (AMBO). Compared to other widely used
multi-objective optimization algorithms, AMBO eliminates predefined parameters
that may introduce subjectivity from planners. Beyond the algorithm, the
proposed model incorporates a noise term to account for inevitable simulation
deviations, enabling the identification of better-performing planning results
that meet the unique requirements of cold regions. What's more, the
characteristics of electric-thermal coupling scenarios are captured and
reflected in the operation simulation model to make sure the simulation is
close to reality. Numerical simulation verifies the superiority of the proposed
approach in generating a more diverse and evenly distributed Pareto front in a
sample-efficient manner, providing comprehensive and objective planning
choices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09268v2' target='_blank'>GEVRM: Goal-Expressive Video Generation Model For Robust Visual
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongyin Zhang, Pengxiang Ding, Shangke Lyu, Ying Peng, Donglin Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 12:29:50</h6>
<p class='card-text'>With the rapid development of embodied artificial intelligence, significant
progress has been made in vision-language-action (VLA) models for general robot
decision-making. However, the majority of existing VLAs fail to account for the
inevitable external perturbations encountered during deployment. These
perturbations introduce unforeseen state information to the VLA, resulting in
inaccurate actions and consequently, a significant decline in generalization
performance. The classic internal model control (IMC) principle demonstrates
that a closed-loop system with an internal model that includes external input
signals can accurately track the reference input and effectively offset the
disturbance. We propose a novel closed-loop VLA method GEVRM that integrates
the IMC principle to enhance the robustness of robot visual manipulation. The
text-guided video generation model in GEVRM can generate highly expressive
future visual planning goals. Simultaneously, we evaluate perturbations by
simulating responses, which are called internal embeddings and optimized
through prototype contrastive learning. This allows the model to implicitly
infer and distinguish perturbations from the external environment. The proposed
GEVRM achieves state-of-the-art performance on both standard and perturbed
CALVIN benchmarks and shows significant improvements in realistic robot tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09256v1' target='_blank'>DynSegNet:Dynamic Architecture Adjustment for Adversarial Learning in
  Segmenting Hemorrhagic Lesions from Fundus Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zesheng Li, Minwen Liao, Haoran Chen, Yan Su, Chengchang Pan, Honggang Qi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 12:11:58</h6>
<p class='card-text'>The hemorrhagic lesion segmentation plays a critical role in ophthalmic
diagnosis, directly influencing early disease detection, treatment planning,
and therapeutic efficacy evaluation. However, the task faces significant
challenges due to lesion morphological variability, indistinct boundaries, and
low contrast with background tissues. To improve diagnostic accuracy and
treatment outcomes, developing advanced segmentation techniques remains
imperative. This paper proposes an adversarial learning-based dynamic
architecture adjustment approach that integrates hierarchical U-shaped
encoder-decoder, residual blocks, attention mechanisms, and ASPP modules. By
dynamically optimizing feature fusion, our method enhances segmentation
performance. Experimental results demonstrate a Dice coefficient of 0.6802, IoU
of 0.5602, Recall of 0.766, Precision of 0.6525, and Accuracy of 0.9955,
effectively addressing the challenges in fundus image hemorrhage
segmentation.[* Corresponding author.]</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09227v1' target='_blank'>Bridging Logic Programming and Deep Learning for Explainability through
  ILASP</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Talissa Dreossi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 11:52:09</h6>
<p class='card-text'>My research explores integrating deep learning and logic programming to set
the basis for a new generation of AI systems. By combining neural networks with
Inductive Logic Programming (ILP), the goal is to construct systems that make
accurate predictions and generate comprehensible rules to validate these
predictions. Deep learning models process and analyze complex data, while ILP
techniques derive logical rules to prove the network's conclusions. Explainable
AI methods, like eXplainable Answer Set Programming (XASP), elucidate the
reasoning behind these rules and decisions. The focus is on applying ILP
frameworks, specifically ILASP and FastLAS, to enhance explainability in
various domains. My test cases span weather prediction, the legal field, and
image recognition. In weather forecasting, the system will predict events and
provides explanations using FastLAS, with plans to integrate recurrent neural
networks in the future. In the legal domain, the research focuses on
interpreting vague decisions and assisting legal professionals by encoding
Italian legal articles and learning reasoning patterns from Court of Cassation
decisions using ILASP. For biological laboratories, we will collaborate with a
research group to automate spermatozoa morphology classification for Bull
Breeding Soundness Evaluation using YOLO networks and ILP to explain
classification outcomes. This hybrid approach aims to bridge the gap between
the high performance of deep learning models and the transparency of symbolic
reasoning, advancing AI by providing interpretable and trustworthy
applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09215v1' target='_blank'>Architecture for Simulating Behavior Mode Changes in Norm-Aware
  Autonomous Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sean Glaze, Daniela Inclezan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 11:49:02</h6>
<p class='card-text'>This paper presents an architecture for simulating the actions of a
norm-aware intelligent agent whose behavior with respect to norm compliance is
set, and can later be changed, by a human controller. Updating an agent's
behavior mode from a norm-abiding to a riskier one may be relevant when the
agent is involved in time-sensitive rescue operations, for example. We base our
work on the Authorization and Obligation Policy Language AOPL designed by
Gelfond and Lobo for the specification of norms. We introduce an architecture
and a prototype software system that can be used to simulate an agent's plans
under different behavior modes that can later be changed by the controller. We
envision such software to be useful to policy makers, as they can more readily
understand how agents may act in certain situations based on the agents'
attitudes towards norm-compliance. Policy makers may then refine their policies
if simulations show unwanted consequences.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09208v1' target='_blank'>Autonomous Task Completion Based on Goal-directed Answer Set Programming</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexis R. Tudor</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 11:46:56</h6>
<p class='card-text'>Task planning for autonomous agents has typically been done using deep
learning models and simulation-based reinforcement learning. This research
proposes combining inductive learning techniques with goal-directed answer set
programming to increase the explainability and reliability of systems for task
breakdown and completion. Preliminary research has led to the creation of a
Python harness that utilizes s(CASP) to solve task problems in a
computationally efficient way. Although this research is in the early stages,
we are exploring solutions to complex problems in simulated task completion.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09205v1' target='_blank'>Counterfactual Explanations as Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vaishak Belle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 11:45:54</h6>
<p class='card-text'>There has been considerable recent interest in explainability in AI,
especially with black-box machine learning models. As correctly observed by the
planning community, when the application at hand is not a single-shot decision
or prediction, but a sequence of actions that depend on observations, a richer
notion of explanations are desirable.
  In this paper, we look to provide a formal account of ``counterfactual
explanations," based in terms of action sequences. We then show that this
naturally leads to an account of model reconciliation, which might take the
form of the user correcting the agent's model, or suggesting actions to the
agent's plan. For this, we will need to articulate what is true versus what is
known, and we appeal to a modal fragment of the situation calculus to formalise
these intuitions. We consider various settings: the agent knowing partial
truths, weakened truths and having false beliefs, and show that our definitions
easily generalize to these different settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09170v1' target='_blank'>LimSim Series: An Autonomous Driving Simulation Platform for Validation
  and Enhancement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daocheng Fu, Naiting Zhong, Xu Han, Pinlong Cai, Licheng Wen, Song Mao, Botian Shi, Yu Qiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 10:53:38</h6>
<p class='card-text'>Closed-loop simulation environments play a crucial role in the validation and
enhancement of autonomous driving systems (ADS). However, certain challenges
warrant significant attention, including balancing simulation accuracy with
duration, reconciling functionality with practicality, and establishing
comprehensive evaluation mechanisms. This paper addresses these challenges by
introducing the LimSim Series, a comprehensive simulation platform designed to
support the rapid deployment and efficient iteration of ADS. The LimSim Series
integrates multi-type information from road networks, employs human-like
decision-making and planning algorithms for background vehicles, and introduces
the concept of the Area of Interest (AoI) to optimize computational resources.
The platform offers a variety of baseline algorithms and user-friendly
interfaces, facilitating flexible validation of multiple technical pipelines.
Additionally, the LimSim Series incorporates multi-dimensional evaluation
metrics, delivering thorough insights into system performance, thus enabling
researchers to promptly identify issues for further improvements. Experiments
demonstrate that the LimSim Series is compatible with modular, end-to-end, and
VLM-based knowledge-driven systems. It can assist in the iteration and updating
of ADS by evaluating performance across various scenarios. The code of the
LimSim Series is released at: https://github.com/PJLab-ADG/LimSim.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09102v2' target='_blank'>Sum-of-Squares Hierarchy for the Gromov Wasserstein Problem</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hoang Anh Tran, Binh Tuan Nguyen, Yong Sheng Soh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 09:21:53</h6>
<p class='card-text'>The Gromov-Wasserstein (GW) problem is a variant of the classical optimal
transport problem that allows one to compute meaningful transportation plans
between incomparable spaces. At an intuitive level, it seeks plans that
minimize the discrepancy between metric evaluations of pairs of points. The GW
problem is typically cast as an instance of a non-convex quadratic program that
is, unfortunately, intractable to solve. In this paper, we describe tractable
semidefinite relaxations of the GW problem based on the Sum-of-Squares (SOS)
hierarchy. We describe how the Putinar-type and the Schm\"udgen-type moment
hierarchies can be simplified using marginal constraints, and we prove
convergence rates for these hierarchies towards computing global optimal
solutions to the GW problem. The proposed SOS hierarchies naturally induce a
distance measure analogous to the distortion metrics, and we show that these
are genuine distances in that they satisfy the triangle inequality. In
particular, the proposed SOS hierarchies provide computationally tractable
proxies of the GW distance and the associated distortion distances (over metric
measure spaces) that are otherwise intractable to compute.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08995v1' target='_blank'>PixLift: Accelerating Web Browsing via AI Upscaling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yonas Atinafu, Sarthak Malla, HyunSeok Daniel Jang, Nouar Aldahoul, Matteo Varvello, Yasir Zaki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 06:14:59</h6>
<p class='card-text'>Accessing the internet in regions with expensive data plans and limited
connectivity poses significant challenges, restricting information access and
economic growth. Images, as a major contributor to webpage sizes, exacerbate
this issue, despite advances in compression formats like WebP and AVIF. The
continued growth of complex and curated web content, coupled with suboptimal
optimization practices in many regions, has prevented meaningful reductions in
web page sizes. This paper introduces PixLift, a novel solution to reduce
webpage sizes by downscaling their images during transmission and leveraging AI
models on user devices to upscale them. By trading computational resources for
bandwidth, PixLift enables more affordable and inclusive web access. We address
key challenges, including the feasibility of scaled image requests on popular
websites, the implementation of PixLift as a browser extension, and its impact
on user experience. Through the analysis of 71.4k webpages, evaluations of
three mainstream upscaling models, and a user study, we demonstrate PixLift's
ability to significantly reduce data usage without compromising image quality,
fostering a more equitable internet.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08992v1' target='_blank'>Some problems of developing astrophysical equipment and combining it
  with optical telescopes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Edward Emelianov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 06:09:54</h6>
<p class='card-text'>The results of a study of the accuracy characteristics and image quality on
the SAO RAS optical telescopes, Zeiss-1000 and BTA, using the recently
developed "Telescope Analyzer" device are described: a method for determining
the coefficients of the pointing correction system, the position of the
aberration axis along the coma in images of star fields, natural frequencies of
vibrations of mechanical systems, prospects for the development of the device.
Attention is paid to the thermal deformations of the BTA main mirror and
measures to reduce them. Mention is made of systems being developed for partial
correction of wavefront aberrations due to imperfect mechanics, and plans to
modernize the control system of the BTA. The complex of 0.5-meter telescopes
"Astro-M" has not been forgotten: hardware and software solutions for
automating the first and second telescopes, plans for commissioning of
telescopes No 3-5 are described. Links to repositories with developed software
and hardware products are provided.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08987v2' target='_blank'>Neural Force Field: Learning Generalized Physical Representation from a
  Few Examples</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shiqian Li, Ruihong Shen, Chi Zhang, Yixin Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 05:50:13</h6>
<p class='card-text'>Physical reasoning is a remarkable human ability that enables rapid learning
and generalization from limited experience. Current AI models, despite
extensive training, still struggle to achieve similar generalization,
especially in Out-of-distribution (OOD) settings. This limitation stems from
their inability to abstract core physical principles from observations. A key
challenge is developing representations that can efficiently learn and
generalize physical dynamics from minimal data. Here we present Neural Force
Field (NFF) a modeling framework built on Neural Ordinary Differential Equation
(NODE) that learns interpretable force field representations which can be
efficiently integrated through an Ordinary Differential Equation ( ODE) solver
to predict object trajectories. Unlike existing approaches that rely on
high-dimensional latent spaces, NFF captures fundamental physical concepts such
as gravity, support, and collision in an interpretable manner. Experiments on
two challenging physical reasoning tasks demonstrate that NFF, trained with
only a few examples, achieves strong generalization to unseen scenarios. This
physics-grounded representation enables efficient forward-backward planning and
rapid adaptation through interactive refinement. Our work suggests that
incorporating physics-inspired representations into learning systems can help
bridge the gap between artificial and human physical reasoning capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08974v1' target='_blank'>Topo2Seq: Enhanced Topology Reasoning via Topology Sequence Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiming Yang, Yueru Luo, Bingkun He, Erlong Li, Zhipeng Cao, Chao Zheng, Shuqi Mei, Zhen Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 05:21:02</h6>
<p class='card-text'>Extracting lane topology from perspective views (PV) is crucial for planning
and control in autonomous driving. This approach extracts potential drivable
trajectories for self-driving vehicles without relying on high-definition (HD)
maps. However, the unordered nature and weak long-range perception of the
DETR-like framework can result in misaligned segment endpoints and limited
topological prediction capabilities. Inspired by the learning of contextual
relationships in language models, the connectivity relations in roads can be
characterized as explicit topology sequences. In this paper, we introduce
Topo2Seq, a novel approach for enhancing topology reasoning via topology
sequences learning. The core concept of Topo2Seq is a randomized order
prompt-to-sequence learning between lane segment decoder and topology sequence
decoder. The dual-decoder branches simultaneously learn the lane topology
sequences extracted from the Directed Acyclic Graph (DAG) and the lane graph
containing geometric information. Randomized order prompt-to-sequence learning
extracts unordered key points from the lane graph predicted by the lane segment
decoder, which are then fed into the prompt design of the topology sequence
decoder to reconstruct an ordered and complete lane graph. In this way, the
lane segment decoder learns powerful long-range perception and accurate
topological reasoning from the topology sequence decoder. Notably, topology
sequence decoder is only introduced during training and does not affect the
inference efficiency. Experimental evaluations on the OpenLane-V2 dataset
demonstrate the state-of-the-art performance of Topo2Seq in topology reasoning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08950v1' target='_blank'>Single-Agent Planning in a Multi-Agent System: A Unified Framework for
  Type-Based Planners</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fengming Zhu, Fangzhen Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 04:17:43</h6>
<p class='card-text'>We consider a general problem where an agent is in a multi-agent environment
and must plan for herself without any prior information about her opponents. At
each moment, this pivotal agent is faced with a trade-off between exploiting
her currently accumulated information about the other agents and exploring
further to improve future (re-)planning. We propose a theoretic framework that
unifies a spectrum of planners for the pivotal agent to address this trade-off.
The planner at one end of this spectrum aims to find exact solutions, while
those towards the other end yield approximate solutions as the problem scales
up. Beyond theoretical analysis, we also implement \textbf{13} planners and
conduct experiments in a specific domain called \textit{multi-agent route
planning} with the number of agents \textbf{up to~50}, to compare their
performaces in various scenarios. One interesting observation comes from a
class of planners that we call \textit{safe-agents} and their enhanced variants
by incorporating domain-specific knowledge, which is a simple special case
under the proposed general framework, but performs sufficiently well in most
cases. Our unified framework, as well as those induced planners, provides new
insights on multi-agent decision-making, with potential applications to related
areas such as mechanism design.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08903v1' target='_blank'>3D-Grounded Vision-Language Framework for Robotic Task Planning:
  Automated Prompt Synthesis and Supervised Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guoqin Tang, Qingxuan Jia, Zeyuan Huang, Gang Chen, Ning Ji, Zhipeng Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 02:40:19</h6>
<p class='card-text'>Vision-language models (VLMs) have achieved remarkable success in scene
understanding and perception tasks, enabling robots to plan and execute actions
adaptively in dynamic environments. However, most multimodal large language
models lack robust 3D scene localization capabilities, limiting their
effectiveness in fine-grained robotic operations. Additionally, challenges such
as low recognition accuracy, inefficiency, poor transferability, and
reliability hinder their use in precision tasks. To address these limitations,
we propose a novel framework that integrates a 2D prompt synthesis module by
mapping 2D images to point clouds, and incorporates a small language model
(SLM) for supervising VLM outputs. The 2D prompt synthesis module enables VLMs,
trained on 2D images and text, to autonomously extract precise 3D spatial
information without manual intervention, significantly enhancing 3D scene
understanding. Meanwhile, the SLM supervises VLM outputs, mitigating
hallucinations and ensuring reliable, executable robotic control code
generation. Our framework eliminates the need for retraining in new
environments, thereby improving cost efficiency and operational robustness.
Experimental results that the proposed framework achieved a 96.0\% Task Success
Rate (TSR), outperforming other methods. Ablation studies demonstrated the
critical role of both the 2D prompt synthesis module and the output supervision
module (which, when removed, caused a 67\% TSR drop). These findings validate
the framework's effectiveness in improving 3D recognition, task planning, and
robotic task execution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09672v1' target='_blank'>IMM-MOT: A Novel 3D Multi-object Tracking Framework with Interacting
  Multiple Model Filter</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaohong Liu, Xulong Zhao, Gang Liu, Zili Wu, Tao Wang, Lei Meng, Yuhan Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 01:55:32</h6>
<p class='card-text'>3D Multi-Object Tracking (MOT) provides the trajectories of surrounding
objects, assisting robots or vehicles in smarter path planning and obstacle
avoidance. Existing 3D MOT methods based on the Tracking-by-Detection framework
typically use a single motion model to track an object throughout its entire
tracking process. However, objects may change their motion patterns due to
variations in the surrounding environment. In this paper, we introduce the
Interacting Multiple Model filter in IMM-MOT, which accurately fits the complex
motion patterns of individual objects, overcoming the limitation of
single-model tracking in existing approaches. In addition, we incorporate a
Damping Window mechanism into the trajectory lifecycle management, leveraging
the continuous association status of trajectories to control their creation and
termination, reducing the occurrence of overlooked low-confidence true targets.
Furthermore, we propose the Distance-Based Score Enhancement module, which
enhances the differentiation between false positives and true positives by
adjusting detection scores, thereby improving the effectiveness of the Score
Filter. On the NuScenes Val dataset, IMM-MOT outperforms most other
single-modal models using 3D point clouds, achieving an AMOTA of 73.8%. Our
project is available at https://github.com/Ap01lo/IMM-MOT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08856v1' target='_blank'>A Systematic Evaluation of Generative Models on Tabular Transportation
  Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chengen Wang, Alvaro Cardenas, Gurcan Comert, Murat Kantarcioglu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 00:14:55</h6>
<p class='card-text'>The sharing of large-scale transportation data is beneficial for
transportation planning and policymaking. However, it also raises significant
security and privacy concerns, as the data may include identifiable personal
information, such as individuals' home locations. To address these concerns,
synthetic data generation based on real transportation data offers a promising
solution that allows privacy protection while potentially preserving data
utility. Although there are various synthetic data generation techniques, they
are often not tailored to the unique characteristics of transportation data,
such as the inherent structure of transportation networks formed by all trips
in the datasets. In this paper, we use New York City taxi data as a case study
to conduct a systematic evaluation of the performance of widely used tabular
data generative models. In addition to traditional metrics such as distribution
similarity, coverage, and privacy preservation, we propose a novel graph-based
metric tailored specifically for transportation data. This metric evaluates the
similarity between real and synthetic transportation networks, providing
potentially deeper insights into their structural and functional alignment. We
also introduced an improved privacy metric to address the limitations of the
commonly-used one. Our experimental results reveal that existing tabular data
generative models often fail to perform as consistently as claimed in the
literature, particularly when applied to transportation data use cases.
Furthermore, our novel graph metric reveals a significant gap between synthetic
and real data. This work underscores the potential need to develop generative
models specifically tailored to take advantage of the unique characteristics of
emerging domains, such as transportation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08814v1' target='_blank'>Mortality simulations for insured and general populations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Asmik Nalmpatian, Christian Heumann</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 22:01:55</h6>
<p class='card-text'>This study presents a framework for high-resolution mortality simulations
tailored to insured and general populations. Due to the scarcity of detailed
demographic-specific mortality data, we leverage Iterative Proportional Fitting
(IPF) and Monte Carlo simulations to generate refined mortality tables that
incorporate age, gender, smoker status, and regional distributions. This
methodology enhances public health planning and actuarial analysis by providing
enriched datasets for improved life expectancy projections and insurance
product development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08813v1' target='_blank'>Measuring Anxiety Levels with Head Motion Patterns in Severe Depression
  Population</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fouad Boualeb, Emery Pierson, Nicolas Doudeau, Clémence Nineuil, Ali Amad, Mohamed Daoudi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 21:55:26</h6>
<p class='card-text'>Depression and anxiety are prevalent mental health disorders that frequently
cooccur, with anxiety significantly influencing both the manifestation and
treatment of depression. An accurate assessment of anxiety levels in
individuals with depression is crucial to develop effective and personalized
treatment plans. This study proposes a new noninvasive method for quantifying
anxiety severity by analyzing head movements -- specifically speed,
acceleration, and angular displacement -- during video-recorded interviews with
patients suffering from severe depression. Using data from a new CALYPSO
Depression Dataset, we extracted head motion characteristics and applied
regression analysis to predict clinically evaluated anxiety levels. Our results
demonstrate a high level of precision, achieving a mean absolute error (MAE) of
0.35 in predicting the severity of psychological anxiety based on head movement
patterns. This indicates that our approach can enhance the understanding of
anxiety's role in depression and assist psychiatrists in refining treatment
strategies for individuals.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08794v1' target='_blank'>Spectral Journey: How Transformers Predict the Shortest Path</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrew Cohen, Andrey Gromov, Kaiyu Yang, Yuandong Tian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 21:17:30</h6>
<p class='card-text'>Decoder-only transformers lead to a step-change in capability of large
language models. However, opinions are mixed as to whether they are really
planning or reasoning. A path to making progress in this direction is to study
the model's behavior in a setting with carefully controlled data. Then
interpret the learned representations and reverse-engineer the computation
performed internally. We study decoder-only transformer language models trained
from scratch to predict shortest paths on simple, connected and undirected
graphs. In this setting, the representations and the dynamics learned by the
model are interpretable. We present three major results: (1) Two-layer
decoder-only language models can learn to predict shortest paths on simple,
connected graphs containing up to 10 nodes. (2) Models learn a graph embedding
that is correlated with the spectral decomposition of the line graph. (3)
Following the insights, we discover a novel approximate path-finding algorithm
Spectral Line Navigator (SLN) that finds shortest path by greedily selecting
nodes in the space of spectral embedding of the line graph.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08791v1' target='_blank'>ClipRover: Zero-shot Vision-Language Exploration and Target Discovery by
  Mobile Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxuan Zhang, Adnan Abdullah, Sanjeev J. Koppal, Md Jahidul Islam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 21:07:10</h6>
<p class='card-text'>Vision-language navigation (VLN) has emerged as a promising paradigm,
enabling mobile robots to perform zero-shot inference and execute tasks without
specific pre-programming. However, current systems often separate map
exploration and path planning, with exploration relying on inefficient
algorithms due to limited (partially observed) environmental information. In
this paper, we present a novel navigation pipeline named ''ClipRover'' for
simultaneous exploration and target discovery in unknown environments,
leveraging the capabilities of a vision-language model named CLIP. Our approach
requires only monocular vision and operates without any prior map or knowledge
about the target. For comprehensive evaluations, we design the functional
prototype of a UGV (unmanned ground vehicle) system named ''Rover Master'', a
customized platform for general-purpose VLN tasks. We integrate and deploy the
ClipRover pipeline on Rover Master to evaluate its throughput, obstacle
avoidance capability, and trajectory performance across various real-world
scenarios. Experimental results demonstrate that ClipRover consistently
outperforms traditional map traversal algorithms and achieves performance
comparable to path-planning methods that depend on prior map and target
knowledge. Notably, ClipRover offers real-time active navigation without
requiring pre-captured candidate images or pre-built node graphs, addressing
key limitations of existing VLN pipelines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08754v1' target='_blank'>HistoSmith: Single-Stage Histology Image-Label Generation via
  Conditional Latent Diffusion for Enhanced Cell Segmentation and
  Classification</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Valentina Vadori, Jean-Marie Graïc, Antonella Peruffo, Livio Finos, Ujwala Kiran Chaudhari, Enrico Grisan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 19:51:41</h6>
<p class='card-text'>Precise segmentation and classification of cell instances are vital for
analyzing the tissue microenvironment in histology images, supporting medical
diagnosis, prognosis, treatment planning, and studies of brain
cytoarchitecture. However, the creation of high-quality annotated datasets for
training remains a major challenge. This study introduces a novel single-stage
approach (HistoSmith) for generating image-label pairs to augment histology
datasets. Unlike state-of-the-art methods that utilize diffusion models with
separate components for label and image generation, our approach employs a
latent diffusion model to learn the joint distribution of cellular layouts,
classification masks, and histology images. This model enables tailored data
generation by conditioning on user-defined parameters such as cell types,
quantities, and tissue types. Trained on the Conic H&E histopathology dataset
and the Nissl-stained CytoDArk0 dataset, the model generates realistic and
diverse labeled samples. Experimental results demonstrate improvements in cell
instance segmentation and classification, particularly for underrepresented
cell types like neutrophils in the Conic dataset. These findings underscore the
potential of our approach to address data scarcity challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08697v2' target='_blank'>Bilevel Learning for Bilevel Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bowen Li, Tom Silver, Sebastian Scherer, Alexander Gray</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 18:59:56</h6>
<p class='card-text'>A robot that learns from demonstrations should not just imitate what it sees
-- it should understand the high-level concepts that are being demonstrated and
generalize them to new tasks. Bilevel planning is a hierarchical model-based
approach where predicates (relational state abstractions) can be leveraged to
achieve compositional generalization. However, previous bilevel planning
approaches depend on predicates that are either hand-engineered or restricted
to very simple forms, limiting their scalability to sophisticated,
high-dimensional state spaces. To address this limitation, we present IVNTR,
the first bilevel planning approach capable of learning neural predicates
directly from demonstrations. Our key innovation is a neuro-symbolic bilevel
learning framework that mirrors the structure of bilevel planning. In IVNTR,
symbolic learning of the predicate "effects" and neural learning of the
predicate "functions" alternate, with each providing guidance for the other. We
evaluate IVNTR in six diverse robot planning domains, demonstrating its
effectiveness in abstracting various continuous and high-dimensional states.
While most existing approaches struggle to generalize (with <35% success rate),
our IVNTR achieves an average of 77% success rate on unseen tasks.
Additionally, we showcase IVNTR on a mobile manipulator, where it learns to
perform real-world mobile manipulation tasks and generalizes to unseen test
scenarios that feature new objects, new states, and longer task horizons. Our
findings underscore the promise of learning and planning with abstractions as a
path towards high-level generalization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08504v1' target='_blank'>MoDitector: Module-Directed Testing for Autonomous Driving Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Renzhi Wang, Mingfei Cheng, Xiaofei Xie, Yuan Zhou, Lei Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 15:35:11</h6>
<p class='card-text'>Testing Autonomous Driving Systems (ADS) is crucial for ensuring their
safety, reliability, and performance. Despite numerous testing methods
available that can generate diverse and challenging scenarios to uncover
potential vulnerabilities, these methods often treat ADS as a black-box,
primarily focusing on identifying system failures like collisions or
near-misses without pinpointing the specific modules responsible for these
failures. Understanding the root causes of failures is essential for effective
debugging and subsequent system repair. We observed that existing methods also
fall short in generating diverse failures that adequately test the distinct
modules of an ADS, such as perception, prediction, planning and control. To
bridge this gap, we introduce MoDitector, the first root-cause-aware testing
method for ADS. Unlike previous approaches, MoDitector not only generates
scenarios leading to collisions but also showing which specific module
triggered the failure. This method targets specific modules, creating test
scenarios that highlight the weaknesses of these given modules. Specifically,
our approach involves designing module-specific oracles to ascertain module
failures and employs a module-directed testing strategy that includes
module-specific feedback, adaptive seed selection, and mutation. This strategy
guides the generation of tests that effectively provoke module-specific
failures. We evaluated MoDitector across four critical ADS modules and four
testing scenarios. Our approach represents a significant innovation in ADS
testing by focusing on identifying and rectifying module-specific errors within
the system, moving beyond conventional black-box failure detection.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08493v1' target='_blank'>DUNE: science and status</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Francisco Martínez López</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 15:29:11</h6>
<p class='card-text'>The Deep Underground Neutrino Experiment (DUNE) is a next-generation
long-baseline neutrino oscillation experiment. Its primary goal is the
determination of the neutrino mass hierarchy and the CP-violating phase. The
DUNE physics program also includes the detection of astrophysical neutrinos and
the search for beyond the Standard Model phenomena, such as nucleon decays.
DUNE will consist of a near detector complex placed at Fermilab, several
hundred meters downstream of the neutrino production point, and 17-kton Liquid
Argon Time Projection Chamber (LArTPC) far detector modules to be built in the
Sanford Underground Research Facility (SURF), approximately 1.5 km underground
and 1300 km away. The detectors will be exposed to a wide-band neutrino beam
generated by a 1.2 MW proton beam, with a planned upgrade to 2.4 MW. Two
prototypes of the FD technology, the ProtoDUNE 700 ton LArTPCs, have been
operated at CERN for over 2 years, and have been recently optimized to take new
data in 2024-2025. Additionally, the 2x2 Demonstrator, a prototype of the LAr
component of the near detector, has recently started operations in the NuMI
beam at Fermilab. This talk will present the science programme, as well as
recent progress, of DUNE and its different prototyping efforts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08486v1' target='_blank'>Referring Remote Sensing Image Segmentation via Bidirectional Alignment
  Guided Joint Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianxiang Zhang, Zhaokun Wen, Bo Kong, Kecheng Liu, Yisi Zhang, Peixian Zhuang, Jiangyun Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 15:21:18</h6>
<p class='card-text'>Referring Remote Sensing Image Segmentation (RRSIS) is critical for
ecological monitoring, urban planning, and disaster management, requiring
precise segmentation of objects in remote sensing imagery guided by textual
descriptions. This task is uniquely challenging due to the considerable
vision-language gap, the high spatial resolution and broad coverage of remote
sensing imagery with diverse categories and small targets, and the presence of
clustered, unclear targets with blurred edges. To tackle these issues, we
propose \ours, a novel framework designed to bridge the vision-language gap,
enhance multi-scale feature interaction, and improve fine-grained object
differentiation. Specifically, \ours introduces: (1) the Bidirectional Spatial
Correlation (BSC) for improved vision-language feature alignment, (2) the
Target-Background TwinStream Decoder (T-BTD) for precise distinction between
targets and non-targets, and (3) the Dual-Modal Object Learning Strategy
(D-MOLS) for robust multimodal feature reconstruction. Extensive experiments on
the benchmark datasets RefSegRS and RRSIS-D demonstrate that \ours achieves
state-of-the-art performance. Specifically, \ours improves the overall IoU
(oIoU) by 3.76 percentage points (80.57) and 1.44 percentage points (79.23) on
the two datasets, respectively. Additionally, it outperforms previous methods
in the mean IoU (mIoU) by 5.37 percentage points (67.95) and 1.84 percentage
points (66.04), effectively addressing the core challenges of RRSIS with
enhanced precision and robustness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08386v1' target='_blank'>Accelerating Stable Matching between Workers and Time-Dependent Tasks
  for Dynamic MCS: A Stagewise Service Trading Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Houyi Qi, Minghui Liwang, Xianbin Wang, Liqun Fu, Yiguang Hong, Li Li, Zhipeng Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 13:19:12</h6>
<p class='card-text'>Designing proper incentives in mobile crowdsensing (MCS) networks represents
a critical mechanism in engaging distributed mobile users (workers) to
contribute heterogeneous data for diverse applications (tasks). We develop a
novel stagewise trading framework to reach efficient and stable matching
between tasks and workers, upon considering the diversity of tasks and the
dynamism of MCS networks. This framework integrates futures and spot trading
stages, where in the former, we propose futures trading-driven stable matching
and pre-path-planning (FT-SMP^3) for long-term task-worker assignment and
pre-planning of workers' paths based on historical statistics and risk
analysis. While in the latter, we investigate spot trading-driven DQN path
planning and onsite worker recruitment (ST-DP^2WR) mechanism to enhance
workers' and tasks' practical utilities by facilitating temporary worker
recruitment. We prove that our proposed mechanisms support crucial properties
such as stability, individual rationality, competitive equilibrium, and weak
Pareto optimality theoretically. Also, comprehensive evaluations confirm the
satisfaction of these properties in practical network settings, demonstrating
our commendable performance in terms of service quality, running time, and
decision-making overheads.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08376v1' target='_blank'>Enhanced Load Forecasting with GAT-LSTM: Leveraging Grid and Temporal
  Features</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ugochukwu Orji, Çiçek Güven, Dan Stowell</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 13:07:18</h6>
<p class='card-text'>Accurate power load forecasting is essential for the efficient operation and
planning of electrical grids, particularly given the increased variability and
complexity introduced by renewable energy sources. This paper introduces
GAT-LSTM, a hybrid model that combines Graph Attention Networks (GAT) and Long
Short-Term Memory (LSTM) networks. A key innovation of the model is the
incorporation of edge attributes, such as line capacities and efficiencies,
into the attention mechanism, enabling it to dynamically capture spatial
relationships grounded in grid-specific physical and operational constraints.
Additionally, by employing an early fusion of spatial graph embeddings and
temporal sequence features, the model effectively learns and predicts complex
interactions between spatial dependencies and temporal patterns, providing a
realistic representation of the dynamics of power grids. Experimental
evaluations on the Brazilian Electricity System dataset demonstrate that the
GAT-LSTM model significantly outperforms state-of-the-art models, achieving
reductions of 21. 8% in MAE, 15. 9% in RMSE and 20. 2% in MAPE. These results
underscore the robustness and adaptability of the GAT-LSTM model, establishing
it as a powerful tool for applications in grid management and energy planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08684v1' target='_blank'>Self-Evaluation for Job-Shop Scheduling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Imanol Echeverria, Maialen Murua, Roberto Santana</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 11:22:33</h6>
<p class='card-text'>Combinatorial optimization problems, such as scheduling and route planning,
are crucial in various industries but are computationally intractable due to
their NP-hard nature. Neural Combinatorial Optimization methods leverage
machine learning to address these challenges but often depend on sequential
decision-making, which is prone to error accumulation as small mistakes
propagate throughout the process. Inspired by self-evaluation techniques in
Large Language Models, we propose a novel framework that generates and
evaluates subsets of assignments, moving beyond traditional stepwise
approaches. Applied to the Job-Shop Scheduling Problem, our method integrates a
heterogeneous graph neural network with a Transformer to build a policy model
and a self-evaluation function. Experimental validation on challenging,
well-known benchmarks demonstrates the effectiveness of our approach,
surpassing state-of-the-art methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08303v1' target='_blank'>Lattice gauge ensembles and data management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yasumichi Aoki, Ed Bennett, Ryan Bignell, Kadir Utku Can, Takumi Doi, Steven Gottlieb, Rajan Gupta, Georg von Hippel, Issaku Kanamori, Andrey Kotov, Giannis Koutsou, Agostino Patella, Giovanni Pederiva, Christian Schmidt, Takeshi Yamazaki, Yi-Bo Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 11:04:04</h6>
<p class='card-text'>We summarize the status of lattice QCD ensemble generation efforts and their
data management characteristics. Namely, these proceedings combine the
contributions to a dedicated parallel session during the 41st International
Symposium on Lattice Field Theory (Lattice 2024), during which representatives
of 16 lattice QCD collaborations provided details on their simulation program,
with focus on plans for publication, data management, and storage requirements.
The parallel session was organized by the International Lattice Data Grid
(ILDG), following an open call to the lattice QCD community for participation
in the session.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08279v3' target='_blank'>What Is That Talk About? A Video-to-Text Summarization Dataset for
  Scientific Presentations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 10:36:55</h6>
<p class='card-text'>Transforming recorded videos into concise and accurate textual summaries is a
growing challenge in multimodal learning. This paper introduces VISTA, a
dataset specifically designed for video-to-text summarization in scientific
domains. VISTA contains 18,599 recorded AI conference presentations paired with
their corresponding paper abstracts. We benchmark the performance of
state-of-the-art large models and apply a plan-based framework to better
capture the structured nature of abstracts. Both human and automated
evaluations confirm that explicit planning enhances summary quality and factual
consistency. However, a considerable gap remains between models and human
performance, highlighting the challenges of scientific video summarization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08260v1' target='_blank'>FixDrive: Automatically Repairing Autonomous Vehicle Driving Behaviour
  for $0.08 per Violation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Sun, Christopher M. Poskitt, Kun Wang, Jun Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 10:07:56</h6>
<p class='card-text'>Autonomous Vehicles (AVs) are advancing rapidly, with Level-4 AVs already
operating in real-world conditions. Current AVs, however, still lag behind
human drivers in adaptability and performance, often exhibiting overly
conservative behaviours and occasionally violating traffic laws. Existing
solutions, such as runtime enforcement, mitigate this by automatically
repairing the AV's planned trajectory at runtime, but such approaches lack
transparency and should be a measure of last resort. It would be preferable for
AV repairs to generalise beyond specific incidents and to be interpretable for
users. In this work, we propose FixDrive, a framework that analyses driving
records from near-misses or law violations to generate AV driving strategy
repairs that reduce the chance of such incidents occurring again. These repairs
are captured in {\mu}Drive, a high-level domain-specific language for
specifying driving behaviours in response to event-based triggers. Implemented
for the state-of-the-art autonomous driving system Apollo, FixDrive identifies
and visualises critical moments from driving records, then uses a Multimodal
Large Language Model (MLLM) with zero-shot learning to generate {\mu}Drive
programs. We tested FixDrive on various benchmark scenarios, and found that the
generated repairs improved the AV's performance with respect to following
traffic laws, avoiding collisions, and successfully reaching destinations.
Furthermore, the direct costs of repairing an AV -- 15 minutes of offline
analysis and $0.08 per violation -- are reasonable in practice.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08228v1' target='_blank'>Fare Structure Design in Public Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anita Schöbel, Reena Urban</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 09:16:17</h6>
<p class='card-text'>Fare planning is one among several steps in public transport planning. Fares
are relevant for the covering of costs of the public transport operator, but
also affect the ridership and the passenger satisfaction. A fare structure is
the assignment of prices to all paths in a network. In practice, often a given
fare structure shall be changed to fulfill new requirements, meaning that a new
fare strategy is desired. This motivates the usage of prices of the former fare
structure or other desirable prices as reference prices. In this paper, we
investigate the fare structure design problem that aims to determine fares such
that the sum of absolute deviations between the new fares and the reference
prices is minimized. Fare strategies that are considered here are flat tariffs,
affine distance tariffs and zone tariffs. Additionally, we regard constraints
that ensure that it is not beneficial to buy a ticket for a longer journey than
actually traveled (no-elongation property) or to split a ticket into several
sub-tickets to cover a journey (no-stopover property). Our literature review
provides an overview of the research on fare planning. We analyze the fare
structure design problem for flat, distance and zone tariffs, pointing out
connections to median problems. Further, we study its complexity which ranges
from linear-time solvability to NP-complete cases.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08217v1' target='_blank'>Investigating Vulnerabilities of GPS Trip Data to Trajectory-User
  Linking Attacks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benedikt Ströbl, Alexandra Kapp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 08:54:49</h6>
<p class='card-text'>Open human mobility data is considered an essential basis for the profound
research and analysis required for the transition to sustainable mobility and
sustainable urban planning. Cycling data has especially been the focus of data
collection endeavors in recent years. Although privacy risks regarding location
data are widely known, practitioners often refrain from advanced privacy
mechanisms to prevent utility losses. Removing user identifiers from trips is
thereby deemed a major privacy gain, as it supposedly prevents linking single
trips to obtain entire movement patterns. In this paper, we propose a novel
attack to reconstruct user identifiers in GPS trip datasets consisting of
single trips, unlike previous ones that are dedicated to evaluating
trajectory-user linking in the context of check-in data. We evaluate the
remaining privacy risk for users in such datasets and our empirical findings
from two real-world datasets show that the risk of re-identification is
significant even when personal identifiers have been removed, and that
truncation as a simple additional privacy mechanism may not be effective in
protecting user privacy. Further investigations indicate that users who
frequently visit locations that are only visited by a small number of others,
tend to be more vulnerable to re-identification.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08169v1' target='_blank'>CoDynTrust: Robust Asynchronous Collaborative Perception via Dynamic
  Feature Trust Modulus</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yunjiang Xu, Lingzhi Li, Jin Wang, Benyuan Yang, Zhiwen Wu, Xinhong Chen, Jianping Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 07:23:26</h6>
<p class='card-text'>Collaborative perception, fusing information from multiple agents, can extend
perception range so as to improve perception performance. However, temporal
asynchrony in real-world environments, caused by communication delays, clock
misalignment, or sampling configuration differences, can lead to information
mismatches. If this is not well handled, then the collaborative performance is
patchy, and what's worse safety accidents may occur. To tackle this challenge,
we propose CoDynTrust, an uncertainty-encoded asynchronous fusion perception
framework that is robust to the information mismatches caused by temporal
asynchrony. CoDynTrust generates dynamic feature trust modulus (DFTM) for each
region of interest by modeling aleatoric and epistemic uncertainty as well as
selectively suppressing or retaining single-vehicle features, thereby
mitigating information mismatches. We then design a multi-scale fusion module
to handle multi-scale feature maps processed by DFTM. Compared to existing
works that also consider asynchronous collaborative perception, CoDynTrust
combats various low-quality information in temporally asynchronous scenarios
and allows uncertainty to be propagated to downstream tasks such as planning
and control. Experimental results demonstrate that CoDynTrust significantly
reduces performance degradation caused by temporal asynchrony across multiple
datasets, achieving state-of-the-art detection performance even with temporal
asynchrony. The code is available at https://github.com/CrazyShout/CoDynTrust.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08158v1' target='_blank'>Open-Source Factor Graph Optimization Package for GNSS: Examples and
  Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Taro Suzuki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 06:51:42</h6>
<p class='card-text'>State estimation methods using factor graph optimization (FGO) have garnered
significant attention in global navigation satellite system (GNSS) research.
FGO exhibits superior estimation accuracy compared with traditional state
estimation methods that rely on least-squares or Kalman filters. However, only
a few FGO libraries are specialized for GNSS observations. This paper
introduces an open-source GNSS FGO package named gtsam\_gnss, which has a
simple structure and can be easily applied to GNSS research and development.
This package separates the preprocessing of GNSS observations from factor
optimization. Moreover, it describes the error function of the GNSS factor in a
straightforward manner, allowing for general-purpose inputs. This design
facilitates the transition from ordinary least-squares-based positioning to FGO
and supports user-specific GNSS research. In addition, gtsam\_gnss includes
analytical examples involving various factors using GNSS data in real urban
environments. This paper presents three application examples: the use of a
robust error model, estimation of integer ambiguity in the carrier phase, and
combination of GNSS and inertial measurements from smartphones. The proposed
framework demonstrates excellent state estimation performance across all use
cases.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09657v1' target='_blank'>Integrating Spatiotemporal Vision Transformer into Digital Twins for
  High-Resolution Heat Stress Forecasting in Campus Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenjing Gong, Xinyue Ye, Keshu Wu, Suphanut Jamonnak, Wenyu Zhang, Yifan Yang, Xiao Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 05:27:16</h6>
<p class='card-text'>Extreme heat events exacerbated by climate change pose significant challenges
to urban resilience and planning. This study introduces a climate-responsive
digital twin framework integrating the Spatiotemporal Vision Transformer
(ST-ViT) model to enhance heat stress forecasting and decision-making. Using a
Texas campus as a testbed, we synthesized high-resolution physical model
simulations with spatial and meteorological data to develop fine-scale human
thermal predictions. The ST-ViT-powered digital twin enables efficient,
data-driven insights for planners, policymakers, and campus stakeholders,
supporting targeted heat mitigation strategies and advancing climate-adaptive
urban design.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08102v1' target='_blank'>Resampling Methods that Generate Time Series Data to Enable Sensitivity
  and Model Analysis in Energy Modeling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kelly Wang, Steven O. Kimbrough</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 03:59:18</h6>
<p class='card-text'>Energy systems modeling frequently relies on time series data, whether
observed or forecast. This is particularly the case, for example, in capacity
planning models that use hourly production and load data forecast to occur over
the coming several decades. This paper addresses the attendant problem of
performing sensitivity, robustness, and other post-solution analyses using time
series data. We explore two efficient and relatively simple, non-parametric,
bootstrapping methods for generating arbitrary numbers of time series from a
single observed or forecast series. The paper presents and assesses each
method. We find that the generated series are both visually and by statistical
summary measures close to the original observational data. In consequence these
series are credibly taken as stochastic instances from a common distribution,
that of the original series of observations. With climate change in mind, the
paper further proposes and explores two general techniques for systematically
altering (increasing or decreasing) time series. Both for the perturbed and
unperturbed synthetic series data, we find that the generated series induce
variability in properties of the series that are important for energy modeling,
in particular periods of under- and over-production, and periods of increased
ramping rates. In consequence, series produced in this way are apt for use in
robustness, sensitivity, and in general post-solution analysis of energy
planning models. These validity factors auger well for applications beyond
energy modeling.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08047v2' target='_blank'>WorldGUI: Dynamic Testing for Comprehensive Desktop GUI Automation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Henry Hengyuan Zhao, Difei Gao, Mike Zheng Shou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 01:06:10</h6>
<p class='card-text'>Current GUI agents have achieved outstanding performance in GUI element
grounding. However, planning remains highly challenging, especially due to
sensitivity to the initial state of the environment. Specifically, slight
differences in the initial state-such as the target software not being open or
the interface not being in its default state-often lead to planning errors.
This issue is widespread in real user scenarios, but existing benchmarks fail
to evaluate it. In this paper, we present WorldGUI, a novel GUI benchmark that
designs GUI tasks with various initial states to simulate real computer-user
interactions. The benchmark spans a wide range of tasks across 10 popular
software applications, including PowerPoint, VSCode, and Adobe Acrobat. In
addition, to address the challenges of dynamic GUI automation tasks, we propose
GUI-Thinker, a holistic framework, leveraging a critique mechanism, that
effectively manages the unpredictability and complexity of GUI interactions.
Experimental results demonstrate that GUI-Thinker significantly outperforms
Claude-3.5 (Computer Use) by 14.9% in success rate on WorldGUI tasks. This
improvement underscores the effectiveness of our critical-thinking-based
framework in enhancing GUI automation. The code is available at
https://github.com/showlab/WorldGUI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08033v1' target='_blank'>End-to-End Predictive Planner for Autonomous Driving with Consistency
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anjian Li, Sangjae Bae, David Isele, Ryne Beeson, Faizan M. Tariq</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 00:26:01</h6>
<p class='card-text'>Trajectory prediction and planning are fundamental components for autonomous
vehicles to navigate safely and efficiently in dynamic environments.
Traditionally, these components have often been treated as separate modules,
limiting the ability to perform interactive planning and leading to
computational inefficiency in multi-agent scenarios. In this paper, we present
a novel unified and data-driven framework that integrates prediction and
planning with a single consistency model. Trained on real-world human driving
datasets, our consistency model generates samples from high-dimensional,
multimodal joint trajectory distributions of the ego and multiple surrounding
agents, enabling end-to-end predictive planning. It effectively produces
interactive behaviors, such as proactive nudging and yielding to ensure both
safe and efficient interactions with other road users. To incorporate
additional planning constraints on the ego vehicle, we propose an alternating
direction method for multi-objective guidance in online guided sampling.
Compared to diffusion models, our consistency model achieves better performance
with fewer sampling steps, making it more suitable for real-time deployment.
Experimental results on Waymo Open Motion Dataset (WOMD) demonstrate our
method's superiority in trajectory quality, constraint satisfaction, and
interactive behavior compared to various existing approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08019v1' target='_blank'>Connectivity of LEO Satellite Mega Constellations: An Application of
  Percolation Theory on a Sphere</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hao Lin, Mustafa A. Kishk, Mohamed-Slim Alouini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 23:33:41</h6>
<p class='card-text'>With the advent of the 6G era, global connectivity has become a common goal
in the evolution of communications, aiming to bring Internet services to more
unconnected regions. Additionally, the rise of applications such as the
Internet of Everything and remote education also requires global connectivity.
Non-terrestrial networks (NTN), particularly low earth orbit (LEO) satellites,
play a crucial role in this future vision. Although some literature already
analyze the coverage performance using stochastic geometry, the ability of
generating large-scale continuous service area is still expected to analyze.
Therefore, in this paper, we mainly investigate the necessary conditions of LEO
satellite deployment for large-scale continuous service coverage on the earth.
Firstly, we apply percolation theory to a closed spherical surface and define
the percolation on a sphere for the first time. We introduce the sub-critical
and super-critical cases to prove the existence of the phase transition of
percolation probability. Then, through stereographic projection, we introduce
the tight bounds and closed-form expression of the critical number of LEO
satellites on the same constellation. In addition, we also investigate how the
altitude and maximum slant range of LEO satellites affect percolation
probability, and derive the critical values of them. Based on our findings, we
provide useful recommendations for companies planning to deploy LEO satellite
networks to enhance connectivity.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07970v2' target='_blank'>Ly-$α$ processing of solid-state Ethanolamine: Potential Precursors
  to Sugar and Peptide Derivatives</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:T. Suhasaria, S. M. Wee, R. Basalgète, S. Krasnokutski, C. Jäger, K. Schwarz, Th. Henning</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 21:29:56</h6>
<p class='card-text'>Ethanolamine (EA), a key component of phospholipids, has recently been
detected in the interstellar medium within molecular clouds. To understand this
observation, laboratory studies of its formation and destruction are essential
and should be complemented by astrochemical models. This study investigates the
photostability of EA ice under Lyman (Ly)-$\alpha$ (10.2 eV) irradiation at 10
K, and explores its potential role in the formation of simple and complex
organic molecules in molecular clouds. The UV destruction cross section of EA
was estimated to be ($4.7\pm0.3)\times10^{-18}$ cm$^2$, providing insight into
its half-life of $6.5\times10^{7}$ yr in dense interstellar clouds. Fourier
transform infrared spectroscopy and quadrupole mass spectrometry were used to
identify various photoproducts, with their formation pathways discussed.
Ethylene glycol and serine were tentatively detected during the warming up
process following irradiation, suggesting that EA could contribute to the
formation of prebiotic molecules such as sugars, peptides and their
derivatives. High mass signals detected in the mass spectrometer suggest the
presence of several complex organic molecules, and further analysis of residues
at room temperature is planned for future work. The results suggest that EA
could contribute to the formation of prebiotic molecules in space, with
implications for the origin of life.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07962v1' target='_blank'>ESPFormer: Doubly-Stochastic Attention with Expected Sliced Transport
  Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ashkan Shahbazi, Elaheh Akbari, Darian Salehi, Xinran Liu, Navid Naderializadeh, Soheil Kolouri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 21:20:48</h6>
<p class='card-text'>While self-attention has been instrumental in the success of Transformers, it
can lead to over-concentration on a few tokens during training, resulting in
suboptimal information flow. Enforcing doubly-stochastic constraints in
attention matrices has been shown to improve structure and balance in attention
distributions. However, existing methods rely on iterative Sinkhorn
normalization, which is computationally costly. In this paper, we introduce a
novel, fully parallelizable doubly-stochastic attention mechanism based on
sliced optimal transport, leveraging Expected Sliced Transport Plans (ESP).
Unlike prior approaches, our method enforces double stochasticity without
iterative Sinkhorn normalization, significantly enhancing efficiency. To ensure
differentiability, we incorporate a temperature-based soft sorting technique,
enabling seamless integration into deep learning models. Experiments across
multiple benchmark datasets, including image classification, point cloud
classification, sentiment analysis, and neural machine translation, demonstrate
that our enhanced attention regularization consistently improves performance
across diverse applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07950v1' target='_blank'>Embracing Experiential Learning: Hackathons as an Educational Strategy
  for Shaping Soft Skills in Software Engineering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Allysson Allex Araújo, Marcos Kalinowski, Maria Teresa Baldassarre</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 20:58:33</h6>
<p class='card-text'>In recent years, Software Engineering (SE) scholars and practitioners have
emphasized the importance of integrating soft skills into SE education.
However, teaching and learning soft skills are complex, as they cannot be
acquired passively through raw knowledge acquisition. On the other hand,
hackathons have attracted increasing attention due to their experiential,
collaborative, and intensive nature, which certain tasks could be similar to
real-world software development. This paper aims to discuss the idea of
hackathons as an educational strategy for shaping SE students' soft skills in
practice. Initially, we overview the existing literature on soft skills and
hackathons in SE education. Then, we report preliminary empirical evidence from
a seven-day hybrid hackathon involving 40 students. We assess how the hackathon
experience promoted innovative and creative thinking, collaboration and
teamwork, and knowledge application among participants through a structured
questionnaire designed to evaluate students' self-awareness. Lastly, our
findings and new directions are analyzed through the lens of Self-Determination
Theory, which offers a psychological lens to understand human behavior. This
paper contributes to academia by advocating the potential of hackathons in SE
education and proposing concrete plans for future research within SDT. For
industry, our discussion has implications around developing soft skills in
future SE professionals, thereby enhancing their employability and readiness in
the software market.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07731v1' target='_blank'>Online matching and market imbalance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benjamin Barrientos, Daniel Freund, Daniela Saban</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 17:50:49</h6>
<p class='card-text'>Our work introduces the effect of supply/demand imbalances into the
literature on online matching with stochastic rewards in bipartite graphs. We
provide a parameterized definition that characterizes instances as over- or
undersupplied (or balanced), and show that higher competitive ratios against an
offline clairvoyant algorithm are achievable, for both adversarial and
stochastic arrivals, when instances are more imbalanced. The competitive ratio
guarantees we obtain are the best-possible for the class of delayed algorithms
we focus on (such algorithms may adapt to the history of arrivals and the
algorithm's own decisions, but not to the stochastic realization of each
potential match).
  We then explore the real-world implications of our improved competitive
ratios. First, we demonstrate analytically that the improved competitive ratios
under imbalanced instances is not a one-way street by showing that a platform
that conducts effective supply- and demand management should incorporate the
effect of imbalance on its matching performance on its supply planning in order
to create imbalanced instances. Second, we empirically study the relationship
between achieved competitive ratios and imbalance using the data of a volunteer
matching platform.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07631v1' target='_blank'>Divide and Merge: Motion and Semantic Learning in End-to-End Autonomous
  Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yinzhe Shen, Ömer Şahin Taş, Kaiwen Wang, Royden Wagner, Christoph Stiller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 15:21:31</h6>
<p class='card-text'>Perceiving the environment and its changes over time corresponds to two
fundamental yet heterogeneous types of information: semantics and motion.
Previous end-to-end autonomous driving works represent both types of
information in a single feature vector. However, including motion tasks, such
as prediction and planning, always impairs detection and tracking performance,
a phenomenon known as negative transfer in multi-task learning. To address this
issue, we propose Neural-Bayes motion decoding, a novel parallel detection,
tracking, and prediction method separating semantic and motion learning,
similar to the Bayes filter. Specifically, we employ a set of learned motion
queries that operate in parallel with the detection and tracking queries,
sharing a unified set of recursively updated reference points. Moreover, we
employ interactive semantic decoding to enhance information exchange in
semantic tasks, promoting positive transfer. Experiments on the nuScenes
dataset show improvements of 5% in detection and 11% in tracking. Our method
achieves state-of-the-art collision rates in open-loop planning evaluation
without any modifications to the planning module.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07600v1' target='_blank'>PlaySlot: Learning Inverse Latent Dynamics for Controllable
  Object-Centric Video Prediction and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Angel Villar-Corrales, Sven Behnke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 14:50:10</h6>
<p class='card-text'>Predicting future scene representations is a crucial task for enabling robots
to understand and interact with the environment. However, most existing methods
rely on video sequences and simulations with precise action annotations,
limiting their ability to leverage the large amount of available unlabeled
video data. To address this challenge, we propose PlaySlot, an object-centric
video prediction model that infers object representations and latent actions
from unlabeled video sequences. It then uses these representations to forecast
future object states and video frames. PlaySlot allows to generate multiple
possible futures conditioned on latent actions, which can be inferred from
video dynamics, provided by a user, or generated by a learned action policy,
thus enabling versatile and interpretable world modeling. Our results show that
PlaySlot outperforms both stochastic and object-centric baselines for video
prediction across different environments. Furthermore, we show that our
inferred latent actions can be used to learn robot behaviors sample-efficiently
from unlabeled video demonstrations. Videos and code are available at
https://play-slot.github.io/PlaySlot/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07591v1' target='_blank'>DMWM: Dual-Mind World Model with Long-Term Imagination</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lingyi Wang, Rashed Shelim, Walid Saad, Naren Ramakrishnan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 14:40:57</h6>
<p class='card-text'>Imagination in world models is crucial for enabling agents to learn
long-horizon policy in a sample-efficient manner. Existing recurrent
state-space model (RSSM)-based world models depend on single-step statistical
inference to capture the environment dynamics, and, hence, they are unable to
perform long-term imagination tasks due to the accumulation of prediction
errors. Inspired by the dual-process theory of human cognition, we propose a
novel dual-mind world model (DMWM) framework that integrates logical reasoning
to enable imagination with logical consistency. DMWM is composed of two
components: an RSSM-based System 1 (RSSM-S1) component that handles state
transitions in an intuitive manner and a logic-integrated neural network-based
System 2 (LINN-S2) component that guides the imagination process through
hierarchical deep logical reasoning. The inter-system feedback mechanism is
designed to ensure that the imagination process follows the logical rules of
the real environment. The proposed framework is evaluated on benchmark tasks
that require long-term planning from the DMControl suite. Extensive
experimental results demonstrate that the proposed framework yields significant
improvements in terms of logical coherence, trial efficiency, data efficiency
and long-term imagination over the state-of-the-art world models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12164v1' target='_blank'>Scalable and Robust Physics-Informed Graph Neural Networks for Water
  Distribution Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Inaam Ashraf, André Artelt, Barbara Hammer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 13:38:14</h6>
<p class='card-text'>Water distribution systems (WDSs) are an important part of critical
infrastructure becoming increasingly significant in the face of climate change
and urban population growth. We propose a robust and scalable surrogate deep
learning (DL) model to enable efficient planning, expansion, and rehabilitation
of WDSs. Our approach incorporates an improved graph neural network
architecture, an adapted physics-informed algorithm, an innovative training
scheme, and a physics-preserving data normalization method. Evaluation results
on a number of WDSs demonstrate that our model outperforms the current
state-of-the-art DL model. Moreover, our method allows us to scale the model to
bigger and more realistic WDSs. Furthermore, our approach makes the model more
robust to out-of-distribution input features (demands, pipe diameters). Hence,
our proposed method constitutes a significant step towards bridging the
simulation-to-real gap in the use of artificial intelligence for WDSs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07486v1' target='_blank'>Automated Road Extraction and Centreline Fitting in LiDAR Point Clouds</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyu Wang, Muhammad Ibrahim, Atif Mansoor, Hasnein Tareque, Ajmal Mian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 11:45:52</h6>
<p class='card-text'>Road information extraction from 3D point clouds is useful for urban planning
and traffic management. Existing methods often rely on local features and the
refraction angle of lasers from kerbs, which makes them sensitive to variable
kerb designs and issues in high-density areas due to data homogeneity. We
propose an approach for extracting road points and fitting centrelines using a
top-down view of LiDAR based ground-collected point clouds. This prospective
view reduces reliance on specific kerb design and results in better road
extraction. We first perform statistical outlier removal and density-based
clustering to reduce noise from 3D point cloud data. Next, we perform ground
point filtering using a grid-based segmentation method that adapts to diverse
road scenarios and terrain characteristics. The filtered points are then
projected onto a 2D plane, and the road is extracted by a skeletonisation
algorithm. The skeleton is back-projected onto the 3D point cloud with
calculated normals, which guide a region growing algorithm to find nearby road
points. The extracted road points are then smoothed with the Savitzky-Golay
filter to produce the final centreline. Our initial approach without
post-processing of road skeleton achieved 67% in IoU by testing on the Perth
CBD dataset with different road types. Incorporating the post-processing of the
road skeleton improved the extraction of road points around the smoothed
skeleton. The refined approach achieved a higher IoU value of 73% and with 23%
reduction in the processing time. Our approach offers a generalised and
computationally efficient solution that combines 3D and 2D processing
techniques, laying the groundwork for future road reconstruction and 3D-to-2D
point cloud alignment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07316v3' target='_blank'>CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junlong Li, Daya Guo, Dejian Yang, Runxin Xu, Yu Wu, Junxian He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 07:26:50</h6>
<p class='card-text'>Reasoning is a fundamental capability of Large Language Models. While prior
research predominantly focuses on enhancing narrow skills like math or code
generation, improving performance on many other reasoning tasks remains
challenging due to sparse and fragmented training data. To address this issue,
we propose CodeI/O, a novel approach that systematically condenses diverse
reasoning patterns inherently embedded in contextually-grounded codes, through
transforming the original code into a code input-output prediction format. By
training models to predict inputs/outputs given code and test cases entirely in
natural language as Chain-of-Thought (CoT) rationales, we expose them to
universal reasoning primitives -- like logic flow planning, state-space
searching, decision tree traversal, and modular decomposition -- while
decoupling structured reasoning from code-specific syntax and preserving
procedural rigor. Experimental results demonstrate CodeI/O leads to consistent
improvements across symbolic, scientific, logic, math & numerical, and
commonsense reasoning tasks. By matching the existing ground-truth outputs or
re-executing the code with predicted inputs, we can verify each prediction and
further enhance the CoTs through multi-turn revision, resulting in CodeI/O++
and achieving higher performance. Our data and models are available at
https://github.com/hkust-nlp/CodeIO.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07309v1' target='_blank'>Semi-Supervised Vision-Centric 3D Occupancy World Model for Autonomous
  Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiang Li, Pengfei Li, Yupeng Zheng, Wei Sun, Yan Wang, Yilun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 07:12:26</h6>
<p class='card-text'>Understanding world dynamics is crucial for planning in autonomous driving.
Recent methods attempt to achieve this by learning a 3D occupancy world model
that forecasts future surrounding scenes based on current observation. However,
3D occupancy labels are still required to produce promising results.
Considering the high annotation cost for 3D outdoor scenes, we propose a
semi-supervised vision-centric 3D occupancy world model, PreWorld, to leverage
the potential of 2D labels through a novel two-stage training paradigm: the
self-supervised pre-training stage and the fully-supervised fine-tuning stage.
Specifically, during the pre-training stage, we utilize an attribute projection
head to generate different attribute fields of a scene (e.g., RGB, density,
semantic), thus enabling temporal supervision from 2D labels via volume
rendering techniques. Furthermore, we introduce a simple yet effective
state-conditioned forecasting module to recursively forecast future occupancy
and ego trajectory in a direct manner. Extensive experiments on the nuScenes
dataset validate the effectiveness and scalability of our method, and
demonstrate that PreWorld achieves competitive performance across 3D occupancy
prediction, 4D occupancy forecasting and motion planning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07202v1' target='_blank'>Monte Carlo Tree Diffusion for System 2 Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jaesik Yoon, Hyeonseo Cho, Doojin Baek, Yoshua Bengio, Sungjin Ahn</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 02:51:42</h6>
<p class='card-text'>Diffusion models have recently emerged as a powerful tool for planning.
However, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally
improves with additional test-time computation (TTC), standard diffusion-based
planners offer only limited avenues for TTC scalability. In this paper, we
introduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates
the generative strength of diffusion models with the adaptive search
capabilities of MCTS. Our method reconceptualizes denoising as a
tree-structured process, allowing partially denoised plans to be iteratively
evaluated, pruned, and refined. By selectively expanding promising trajectories
while retaining the flexibility to revisit and improve suboptimal branches,
MCTD achieves the benefits of MCTS such as controlling exploration-exploitation
trade-offs within the diffusion framework. Empirical results on challenging
long-horizon tasks show that MCTD outperforms diffusion baselines, yielding
higher-quality solutions as TTC increases.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07120v1' target='_blank'>Is Long Range Sequential Modeling Necessary For Colorectal Tumor
  Segmentation?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhishek Srivastava, Koushik Biswas, Gorkem Durak, Gulsah Ozden, Mustafa Adli, Ulas Bagci</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 23:24:01</h6>
<p class='card-text'>Segmentation of colorectal cancer (CRC) tumors in 3D medical imaging is both
complex and clinically critical, providing vital support for effective
radiation therapy planning and survival outcome assessment. Recently, 3D
volumetric segmentation architectures incorporating long-range sequence
modeling mechanisms, such as Transformers and Mamba, have gained attention for
their capacity to achieve high accuracy in 3D medical image segmentation. In
this work, we evaluate the effectiveness of these global token modeling
techniques by pitting them against our proposed MambaOutUNet within the context
of our newly introduced colorectal tumor segmentation dataset (CTS-204). Our
findings suggest that robust local token interactions can outperform long-range
modeling techniques in cases where the region of interest is small and
anatomically complex, proposing a potential shift in 3D tumor segmentation
research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07106v1' target='_blank'>Towards MatCore: A Unified Metadata Standard for Materials Science</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jane Greenberg, Pamela Boveda-Aguirre, John Allison, Pietro Asinari, Maria Chan, Anand Chandrasekaran, Elif Ertekin, Emmanouel Garoufallou, Giulia Galli, Paolo Giannozzi, Feliciano Giustino, Gerhard Goldbeck, Hendrik Heinz, Arthi Jayaraman, Vincenzo Lordi, Kristin A. Persson, Gian-Marco Rignanese, Aidan Thompson, Eric Toberer, Scott McClellan, Ellad B. Tadmor</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 23:00:04</h6>
<p class='card-text'>The materials science community seeks to support the FAIR principles for
computational simulation research. The MatCore Project was recently launched to
address this need, with the goal of developing an overall metadata framework
and accompanying guidelines. This paper reports on the MatCore goals and
overall progress. Historical background context is provided, including a review
of the principles underlying successful core metadata standards. The paper also
presents selected MatCore examples and discusses future plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07096v1' target='_blank'>Lotus: Creating Short Videos From Long Videos With Abstractive and
  Extractive Summarization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aadit Barua, Karim Benharrak, Meng Chen, Mina Huh, Amy Pavel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 22:40:34</h6>
<p class='card-text'>Short-form videos are popular on platforms like TikTok and Instagram as they
quickly capture viewers' attention. Many creators repurpose their long-form
videos to produce short-form videos, but creators report that planning,
extracting, and arranging clips from long-form videos is challenging.
Currently, creators make extractive short-form videos composed of existing
long-form video clips or abstractive short-form videos by adding newly recorded
narration to visuals. While extractive videos maintain the original connection
between audio and visuals, abstractive videos offer flexibility in selecting
content to be included in a shorter time. We present Lotus, a system that
combines both approaches to balance preserving the original content with
flexibility over the content. Lotus first creates an abstractive short-form
video by generating both a short-form script and its corresponding speech, then
matching long-form video clips to the generated narration. Creators can then
add extractive clips with an automated method or Lotus's editing interface.
Lotus's interface can be used to further refine the short-form video. We
compare short-form videos generated by Lotus with those using an extractive
baseline method. In our user study, we compare creating short-form videos using
Lotus to participants' existing practice.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07008v1' target='_blank'>Early Operative Difficulty Assessment in Laparoscopic Cholecystectomy
  via Snapshot-Centric Video Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saurav Sharma, Maria Vannucci, Leonardo Pestana Legori, Mario Scaglia, Giovanni Guglielmo Laracca, Didier Mutter, Sergio Alfieri, Pietro Mascagni, Nicolas Padoy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 20:14:01</h6>
<p class='card-text'>Purpose: Laparoscopic cholecystectomy (LC) operative difficulty (LCOD) is
highly variable and influences outcomes. Despite extensive LC studies in
surgical workflow analysis, limited efforts explore LCOD using intraoperative
video data. Early recognition of LCOD could allow prompt review by expert
surgeons, enhance operating room (OR) planning, and improve surgical outcomes.
  Methods: We propose the clinical task of early LCOD assessment using limited
video observations. We design SurgPrOD, a deep learning model to assess LCOD by
analyzing features from global and local temporal resolutions (snapshots) of
the observed LC video. Also, we propose a novel snapshot-centric attention
(SCA) module, acting across snapshots, to enhance LCOD prediction. We introduce
the CholeScore dataset, featuring video-level LCOD labels to validate our
method.
  Results: We evaluate SurgPrOD on 3 LCOD assessment scales in the CholeScore
dataset. On our new metric assessing early and stable correct predictions,
SurgPrOD surpasses baselines by at least 0.22 points. SurgPrOD improves over
baselines by at least 9 and 5 percentage points in F1 score and top1-accuracy,
respectively, demonstrating its effectiveness in correct predictions.
  Conclusion: We propose a new task for early LCOD assessment and a novel
model, SurgPrOD analyzing surgical video from global and local perspectives.
Our results on the CholeScore dataset establishes a new benchmark to study LCOD
using intraoperative video data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06996v1' target='_blank'>A view on learning robust goal-conditioned value functions: Interplay
  between RL and MPC</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nathan P. Lawrence, Philip D. Loewen, Michael G. Forbes, R. Bhushan Gopaluni, Ali Mesbah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 19:45:06</h6>
<p class='card-text'>Reinforcement learning (RL) and model predictive control (MPC) offer a wealth
of distinct approaches for automatic decision-making. Given the impact both
fields have had independently across numerous domains, there is growing
interest in combining the general-purpose learning capability of RL with the
safety and robustness features of MPC. To this end, this paper presents a
tutorial-style treatment of RL and MPC, treating them as alternative approaches
to solving Markov decision processes. In our formulation, RL aims to learn a
global value function through offline exploration in an uncertain environment,
whereas MPC constructs a local value function through online optimization. This
local-global perspective suggests new ways to design policies that combine
robustness and goal-conditioned learning. Robustness is incorporated into the
RL and MPC pipelines through a scenario-based approach. Goal-conditioned
learning aims to alleviate the burden of engineering a reward function for RL.
Combining the two leads to a single policy that unites a robust, high-level RL
terminal value function with short-term, scenario-based MPC planning for
reliable constraint satisfaction. This approach leverages the benefits of both
RL and MPC, the effectiveness of which is demonstrated on classical control
benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06768v1' target='_blank'>Train for the Worst, Plan for the Best: Understanding Token Ordering in
  Masked Diffusions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jaeyeon Kim, Kulin Shah, Vasilis Kontonis, Sham Kakade, Sitan Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 18:47:21</h6>
<p class='card-text'>In recent years, masked diffusion models (MDMs) have emerged as a promising
alternative approach for generative modeling over discrete domains. Compared to
autoregressive models (ARMs), MDMs trade off complexity at training time with
flexibility at inference time. At training time, they must learn to solve an
exponentially large number of infilling problems, but at inference time, they
can decode tokens in essentially arbitrary order. In this work, we closely
examine these two competing effects. On the training front, we theoretically
and empirically demonstrate that MDMs indeed train on computationally
intractable subproblems compared to their autoregressive counterparts. On the
inference front, we show that a suitable strategy for adaptively choosing the
token decoding order significantly enhances the capabilities of MDMs, allowing
them to sidestep hard subproblems. On logic puzzles like Sudoku, we show that
adaptive inference can boost solving accuracy in pretrained MDMs from $<7$% to
$\approx 90$%, even outperforming ARMs with $7\times$ as many parameters and
that were explicitly trained via teacher forcing to learn the right order of
decoding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06725v1' target='_blank'>AgilePilot: DRL-Based Drone Agent for Real-Time Motion Planning in
  Dynamic Environments by Leveraging Object Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Roohan Ahmed Khan, Valerii Serpiva, Demetros Aschalew, Aleksey Fedoseev, Dzmitry Tsetserukou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 17:54:30</h6>
<p class='card-text'>Autonomous drone navigation in dynamic environments remains a critical
challenge, especially when dealing with unpredictable scenarios including
fast-moving objects with rapidly changing goal positions. While traditional
planners and classical optimisation methods have been extensively used to
address this dynamic problem, they often face real-time, unpredictable changes
that ultimately leads to sub-optimal performance in terms of adaptiveness and
real-time decision making. In this work, we propose a novel motion planner,
AgilePilot, based on Deep Reinforcement Learning (DRL) that is trained in
dynamic conditions, coupled with real-time Computer Vision (CV) for object
detections during flight. The training-to-deployment framework bridges the
Sim2Real gap, leveraging sophisticated reward structures that promotes both
safety and agility depending upon environment conditions. The system can
rapidly adapt to changing environments, while achieving a maximum speed of 3.0
m/s in real-world scenarios. In comparison, our approach outperforms classical
algorithms such as Artificial Potential Field (APF) based motion planner by 3
times, both in performance and tracking accuracy of dynamic targets by using
velocity predictions while exhibiting 90% success rate in 75 conducted
experiments. This work highlights the effectiveness of DRL in tackling
real-time dynamic navigation challenges, offering intelligent safety and
agility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06715v1' target='_blank'>HoneyComb: A Parallel Worst-Case Optimal Join on Multicores</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiacheng Wu, Dan Suciu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 17:47:32</h6>
<p class='card-text'>To achieve true scalability on massive datasets, a modern query engine needs
to be able to take advantage of large, shared-memory, multicore systems. Binary
joins are conceptually easy to parallelize on a multicore system; however,
several applications require a different approach to query evaluation, using a
Worst-Case Optimal Join (WCOJ) algorithm. WCOJ is known to outperform
traditional query plans for cyclic queries. However, there is no obvious
adaptation of WCOJ to parallel architectures. The few existing systems that
parallelize WCOJ do this by partitioning only the top variable of the WCOJ
algorithm. This leads to work skew (since some relations end up being read
entirely by every thread), possible contention between threads (when the
hierarchical trie index is built lazily, which is the case on most recent WCOJ
systems), and exacerbates the redundant computations already existing in WCOJ.
  We introduce HoneyComb, a parallel version of WCOJ, optimized for large
multicore, shared-memory systems. HoneyComb partitions the domains of all query
variables, not just that of the top loop. We adapt the partitioning idea from
the HyperCube algorithm, developed by the theory community for computing
multi-join queries on a massively parallel shared-nothing architecture, and
introduce new methods for computing the shares, optimized for a shared-memory
architecture. To avoid the contention created by the lazy construction of the
trie-index, we introduce CoCo, a new and very simple index structure, which we
build eagerly, by sorting the entire relation. Finally, in order to remove some
of the redundant computations of WCOJ, we introduce a rewriting technique of
the WCOJ plan that factors out some of these redundant computations. Our
experimental evaluation compares HoneyComb with several recent implementations
of WCOJ.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06656v3' target='_blank'>A Frontier AI Risk Management Framework: Bridging the Gap Between
  Current AI Practices and Established Risk Management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simeon Campos, Henry Papadatos, Fabien Roger, Chloé Touzet, Otter Quarks, Malcolm Murray</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 16:47:00</h6>
<p class='card-text'>The recent development of powerful AI systems has highlighted the need for
robust risk management frameworks in the AI industry. Although companies have
begun to implement safety frameworks, current approaches often lack the
systematic rigor found in other high-risk industries. This paper presents a
comprehensive risk management framework for the development of frontier AI that
bridges this gap by integrating established risk management principles with
emerging AI-specific practices. The framework consists of four key components:
(1) risk identification (through literature review, open-ended red-teaming, and
risk modeling), (2) risk analysis and evaluation using quantitative metrics and
clearly defined thresholds, (3) risk treatment through mitigation measures such
as containment, deployment controls, and assurance processes, and (4) risk
governance establishing clear organizational structures and accountability.
Drawing from best practices in mature industries such as aviation or nuclear
power, while accounting for AI's unique challenges, this framework provides AI
developers with actionable guidelines for implementing robust risk management.
The paper details how each component should be implemented throughout the
life-cycle of the AI system - from planning through deployment - and emphasizes
the importance and feasibility of conducting risk management work prior to the
final training run to minimize the burden associated with it.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06623v1' target='_blank'>Deferred-Decision Trajectory Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Purnanand Elango, Selahattin Burak Sarsilmaz, Behcet Acikmese</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 16:19:09</h6>
<p class='card-text'>We present DDTO--deferred-decision trajectory optimization--a framework for
trajectory generation with resilience to unmodeled uncertainties and
contingencies. The key idea is to ensure that a collection of candidate targets
is reachable for as long as possible while satisfying constraints, which
provides time to quantify the uncertainties. We propose optimization-based
constrained reachability formulations and construct equivalent cardinality
minimization problems, which then inform the design of computationally
tractable and efficient solution methods that leverage state-of-the-art convex
solvers and sequential convex programming (SCP) algorithms. The goal of
establishing the equivalence between constrained reachability and cardinality
minimization is to provide theoretically-sound underpinnings for the proposed
solution methods. We demonstrate the solution methods on real-world optimal
control applications encountered in quadrotor motion planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06615v1' target='_blank'>Multi-Scale Feature Fusion with Image-Driven Spatial Integration for
  Left Atrium Segmentation from Cardiac MRI Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bipasha Kundu, Zixin Yang, Richard Simon, Cristian Linte</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 16:12:46</h6>
<p class='card-text'>Accurate segmentation of the left atrium (LA) from late gadolinium-enhanced
magnetic resonance imaging plays a vital role in visualizing diseased atrial
structures, enabling the diagnosis and management of cardiovascular diseases.
It is particularly essential for planning treatment with ablation therapy, a
key intervention for atrial fibrillation (AF). However, manual segmentation is
time-intensive and prone to inter-observer variability, underscoring the need
for automated solutions. Class-agnostic foundation models like DINOv2 have
demonstrated remarkable feature extraction capabilities in vision tasks.
However, their lack of domain specificity and task-specific adaptation can
reduce spatial resolution during feature extraction, impacting the capture of
fine anatomical detail in medical imaging. To address this limitation, we
propose a segmentation framework that integrates DINOv2 as an encoder with a
UNet-style decoder, incorporating multi-scale feature fusion and input image
integration to enhance segmentation accuracy. The learnable weighting mechanism
dynamically prioritizes hierarchical features from different encoder blocks of
the foundation model, optimizing feature selection for task relevance.
Additionally, the input image is reintroduced during the decoding stage to
preserve high-resolution spatial details, addressing limitations of
downsampling in the encoder. We validate our approach on the LAScarQS 2022
dataset and demonstrate improved performance with a 92.3% Dice and 84.1% IoU
score for giant architecture compared to the nnUNet baseline model. These
findings emphasize the efficacy of our approach in advancing the field of
automated left atrium segmentation from cardiac MRI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06427v1' target='_blank'>Hybrid State-Space and GRU-based Graph Tokenization Mamba for
  Hyperspectral Image Classification</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Ahmad, Muhammad Hassaan Farooq Butt, Muhammad Usama, Manuel Mazzara, Salvatore Distefano, Adil Mehmood Khan, Danfeng Hong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 13:02:19</h6>
<p class='card-text'>Hyperspectral image (HSI) classification plays a pivotal role in domains such
as environmental monitoring, agriculture, and urban planning. However, it faces
significant challenges due to the high-dimensional nature of the data and the
complex spectral-spatial relationships inherent in HSI. Traditional methods,
including conventional machine learning and convolutional neural networks
(CNNs), often struggle to effectively capture these intricate spectral-spatial
features and global contextual information. Transformer-based models, while
powerful in capturing long-range dependencies, often demand substantial
computational resources, posing challenges in scenarios where labeled datasets
are limited, as is commonly seen in HSI applications. To overcome these
challenges, this work proposes GraphMamba, a hybrid model that combines
spectral-spatial token generation, graph-based token prioritization, and
cross-attention mechanisms. The model introduces a novel hybridization of
state-space modeling and Gated Recurrent Units (GRU), capturing both linear and
nonlinear spatial-spectral dynamics. GraphMamba enhances the ability to model
complex spatial-spectral relationships while maintaining scalability and
computational efficiency across diverse HSI datasets. Through comprehensive
experiments, we demonstrate that GraphMamba outperforms existing
state-of-the-art models, offering a scalable and robust solution for complex
HSI classification tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06401v1' target='_blank'>Habitizing Diffusion Planning for Efficient and Effective Decision
  Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haofei Lu, Yifei Shen, Dongsheng Li, Junliang Xing, Dongqi Han</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 12:40:32</h6>
<p class='card-text'>Diffusion models have shown great promise in decision-making, also known as
diffusion planning. However, the slow inference speeds limit their potential
for broader real-world applications. Here, we introduce Habi, a general
framework that transforms powerful but slow diffusion planning models into fast
decision-making models, which mimics the cognitive process in the brain that
costly goal-directed behavior gradually transitions to efficient habitual
behavior with repetitive practice. Even using a laptop CPU, the habitized model
can achieve an average 800+ Hz decision-making frequency (faster than previous
diffusion planners by orders of magnitude) on standard offline reinforcement
learning benchmarks D4RL, while maintaining comparable or even higher
performance compared to its corresponding diffusion planner. Our work proposes
a fresh perspective of leveraging powerful diffusion models for real-world
decision-making tasks. We also provide robust evaluations and analysis,
offering insights from both biological and engineering perspectives for
efficient and effective decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06359v1' target='_blank'>Occlusion-Aware Contingency Safety-Critical Planning for Autonomous
  Vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lei Zheng, Rui Yang, Minzhe Zheng, Zengqi Peng, Michael Yu Wang, Jun Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 11:20:14</h6>
<p class='card-text'>Ensuring safe driving while maintaining travel efficiency for autonomous
vehicles in dynamic and occluded environments is a critical challenge. This
paper proposes an occlusion-aware contingency safety-critical planning approach
for real-time autonomous driving in such environments. Leveraging reachability
analysis for risk assessment, forward reachable sets of occluded phantom
vehicles are computed to quantify dynamic velocity boundaries. These velocity
boundaries are incorporated into a biconvex nonlinear programming (NLP)
formulation, enabling simultaneous optimization of exploration and fallback
trajectories within a receding horizon planning framework. To facilitate
real-time optimization and ensure coordination between trajectories, we employ
the consensus alternating direction method of multipliers (ADMM) to decompose
the biconvex NLP problem into low-dimensional convex subproblems. The
effectiveness of the proposed approach is validated through simulation studies
and real-world experiments in occluded intersections. Experimental results
demonstrate enhanced safety and improved travel efficiency, enabling real-time
safe trajectory generation in dynamic occluded intersections under varying
obstacle conditions. A video showcasing the experimental results is available
at https://youtu.be/CHayG7NChqM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06221v1' target='_blank'>Interaction-aware Conformal Prediction for Crowd Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhe Huang, Tianchen Ji, Heling Zhang, Fatemeh Cheraghi Pouria, Katherine Driggs-Campbell, Roy Dong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 07:53:04</h6>
<p class='card-text'>During crowd navigation, robot motion plan needs to consider human motion
uncertainty, and the human motion uncertainty is dependent on the robot motion
plan. We introduce Interaction-aware Conformal Prediction (ICP) to alternate
uncertainty-aware robot motion planning and decision-dependent human motion
uncertainty quantification. ICP is composed of a trajectory predictor to
predict human trajectories, a model predictive controller to plan robot motion
with confidence interval radii added for probabilistic safety, a human
simulator to collect human trajectory calibration dataset conditioned on the
planned robot motion, and a conformal prediction module to quantify trajectory
prediction error on the decision-dependent calibration dataset. Crowd
navigation simulation experiments show that ICP strikes a good balance of
performance among navigation efficiency, social awareness, and uncertainty
quantification compared to previous works. ICP generalizes well to navigation
tasks under various crowd densities. The fast runtime and efficient memory
usage make ICP practical for real-world applications. Code is available at
https://github.com/tedhuang96/icp.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06212v1' target='_blank'>AVSim -- Realistic Simulation Framework for Airborne and Vector-Borne
  Disease Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pandula Thennakoon, Mario De Silva, M. Mahesha Viduranga, Sashini Liyanage, Roshan Godaliyadda, Mervyn Parakrama Ekanayake, Vijitha Herath, Anuruddhika Rathnayake, Ganga Thilakarathne, Janaka Ekanayake, Samath Dharmarathne</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 07:31:27</h6>
<p class='card-text'>The COVID-19 pandemic underscored the critical need for rapid epidemic trend
identification and effective intervention strategies to mitigate disease
progression and its socio-economic impact. Concurrent with emerging threats,
endemic diseases like dengue continue to strain healthcare systems,
particularly in populous, economically challenged nations. This paper
introduces AVSim (Airborne and Vectorborne Simulator), an agent-based model
designed to provide granular insights for optimizing resource allocation within
existing healthcare management frameworks. AVSim leverages realistic human
mobility and behavioral patterns to simulate disease propagation within a
detailed, scalable environment encompassing homes, schools, hospitals, and
commercial venues. Human movement is modeled based on occupational and
behavioral patterns, including age-specific activities. The simulator
incorporates age- and environment-specific disease outcomes, host-host and
host-vector interactions, and multiple disease stages, including mild, severe,
and critical phases. Immunity, quarantine, and hospitalization are also
modeled. Furthermore, AVSim supports tracing the path of disease spread,
providing micro-level insights into transmission dynamics. Implemented in
Python, AVSim offers flexibility and extensibility, enabling users to create
highly customized scenarios for airborne and vector-borne disease modeling.
Case studies demonstrating AVSim's application to COVID-19 and dengue
illustrate its potential for generating actionable epidemic insights, thereby
enhancing public health planning and response.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06194v1' target='_blank'>Multimodal Task Representation Memory Bank vs. Catastrophic Forgetting
  in Anomaly Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:You Zhou, Jiangshan Zhao, Deyu Zeng, Zuo Zuo, Weixiang Liu, Zongze Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 06:49:54</h6>
<p class='card-text'>Unsupervised Continuous Anomaly Detection (UCAD) faces significant challenges
in multi-task representation learning, with existing methods suffering from
incomplete representation and catastrophic forgetting. Unlike supervised
models, unsupervised scenarios lack prior information, making it difficult to
effectively distinguish redundant and complementary multimodal features. To
address this, we propose the Multimodal Task Representation Memory Bank (MTRMB)
method through two key technical innovations: A Key-Prompt-Multimodal Knowledge
(KPMK) mechanism that uses concise key prompts to guide cross-modal feature
interaction between BERT and ViT. Refined Structure-based Contrastive Learning
(RSCL) leveraging Grounding DINO and SAM to generate precise segmentation
masks, pulling features of the same structural region closer while pushing
different structural regions apart. Experiments on MVtec AD and VisA datasets
demonstrate MTRMB's superiority, achieving an average detection accuracy of
0.921 at the lowest forgetting rate, significantly outperforming
state-of-the-art methods. We plan to open source on GitHub.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06155v2' target='_blank'>Efficient-vDiT: Efficient Video Diffusion Transformers With Attention
  Tile</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hangliang Ding, Dacheng Li, Runlong Su, Peiyuan Zhang, Zhijie Deng, Ion Stoica, Hao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 05:00:56</h6>
<p class='card-text'>Despite the promise of synthesizing high-fidelity videos, Diffusion
Transformers (DiTs) with 3D full attention suffer from expensive inference due
to the complexity of attention computation and numerous sampling steps. For
example, the popular Open-Sora-Plan model consumes more than 9 minutes for
generating a single video of 29 frames. This paper addresses the inefficiency
issue from two aspects: 1) Prune the 3D full attention based on the redundancy
within video data; We identify a prevalent tile-style repetitive pattern in the
3D attention maps for video data, and advocate a new family of sparse 3D
attention that holds a linear complexity w.r.t. the number of video frames. 2)
Shorten the sampling process by adopting existing multi-step consistency
distillation; We split the entire sampling trajectory into several segments and
perform consistency distillation within each one to activate few-step
generation capacities. We further devise a three-stage training pipeline to
conjoin the low-complexity attention and few-step generation capacities.
Notably, with 0.1% pretraining data, we turn the Open-Sora-Plan-1.2 model into
an efficient one that is 7.4x -7.8x faster for 29 and 93 frames 720p video
generation with a marginal performance trade-off in VBench. In addition, we
demonstrate that our approach is amenable to distributed inference, achieving
an additional 3.91x speedup when running on 4 GPUs with sequence parallelism.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06149v1' target='_blank'>Reward-Based Collision-Free Algorithm for Trajectory Planning of
  Autonomous Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jose D. Hoyos, Tianyu Zhou, Zehui Lu, Shaoshuai Mou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 04:30:30</h6>
<p class='card-text'>This paper introduces a new mission planning algorithm for autonomous robots
that enables the reward-based selection of an optimal waypoint sequence from a
predefined set. The algorithm computes a feasible trajectory and corresponding
control inputs for a robot to navigate between waypoints while avoiding
obstacles, maximizing the total reward, and adhering to constraints on state,
input and its derivatives, mission time window, and maximum distance. This also
solves a generalized prize-collecting traveling salesman problem. The proposed
algorithm employs a new genetic algorithm that evolves solution candidates
toward the optimal solution based on a fitness function and crossover. During
fitness evaluation, a penalty method enforces constraints, and the differential
flatness property with clothoid curves efficiently penalizes infeasible
trajectories. The Euler spiral method showed promising results for trajectory
parameterization compared to minimum snap and jerk polynomials. Due to the
discrete exploration space, crossover is performed using a dynamic
time-warping-based method and extended convex combination with projection. A
mutation step enhances exploration. Results demonstrate the algorithm's ability
to find the optimal waypoint sequence, fulfill constraints, avoid infeasible
waypoints, and prioritize high-reward ones. Simulations and experiments with a
ground vehicle, quadrotor, and quadruped are presented, complemented by
benchmarking and a time-complexity analysis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06146v1' target='_blank'>Guided Exploration for Efficient Relational Model Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Annie Feng, Nishanth Kumar, Tomas Lozano-Perez, Leslie Pack-Kaelbling</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 04:23:01</h6>
<p class='card-text'>Efficient exploration is critical for learning relational models in
large-scale environments with complex, long-horizon tasks. Random exploration
methods often collect redundant or irrelevant data, limiting their ability to
learn accurate relational models of the environment. Goal-literal babbling
(GLIB) improves upon random exploration by setting and planning to novel goals,
but its reliance on random actions and random novel goal selection limits its
scalability to larger domains. In this work, we identify the principles
underlying efficient exploration in relational domains: (1) operator
initialization with demonstrations that cover the distinct lifted effects
necessary for planning and (2) refining preconditions to collect maximally
informative transitions by selecting informative goal-action pairs and
executing plans to them. To demonstrate these principles, we introduce
Baking-Large, a challenging domain with extensive state-action spaces and
long-horizon tasks. We evaluate methods using oracle-driven demonstrations for
operator initialization and precondition-targeting guidance to efficiently
gather critical transitions. Experiments show that both the oracle
demonstrations and precondition-targeting oracle guidance significantly improve
sample efficiency and generalization, paving the way for future methods to use
these principles to efficiently learn accurate relational models in complex
domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06113v1' target='_blank'>Towards Bio-inspired Heuristically Accelerated Reinforcement Learning
  for Adaptive Underwater Multi-Agents Behaviour</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Antoine Vivien, Thomas Chaffre, Matthew Stephenson, Eva Artusi, Paulo Santos, Benoit Clement, Karl Sammut</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 02:47:33</h6>
<p class='card-text'>This paper describes the problem of coordination of an autonomous Multi-Agent
System which aims to solve the coverage planning problem in a complex
environment. The considered applications are the detection and identification
of objects of interest while covering an area. These tasks, which are highly
relevant for space applications, are also of interest among various domains
including the underwater context, which is the focus of this study. In this
context, coverage planning is traditionally modelled as a Markov Decision
Process where a coordinated MAS, a swarm of heterogeneous autonomous underwater
vehicles, is required to survey an area and search for objects. This MDP is
associated with several challenges: environment uncertainties, communication
constraints, and an ensemble of hazards, including time-varying and
unpredictable changes in the underwater environment. MARL algorithms can solve
highly non-linear problems using deep neural networks and display great
scalability against an increased number of agents. Nevertheless, most of the
current results in the underwater domain are limited to simulation due to the
high learning time of MARL algorithms. For this reason, a novel strategy is
introduced to accelerate this convergence rate by incorporating biologically
inspired heuristics to guide the policy during training. The PSO method, which
is inspired by the behaviour of a group of animals, is selected as a heuristic.
It allows the policy to explore the highest quality regions of the action and
state spaces, from the beginning of the training, optimizing the
exploration/exploitation trade-off. The resulting agent requires fewer
interactions to reach optimal performance. The method is applied to the MSAC
algorithm and evaluated for a 2D covering area mission in a continuous control
environment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06076v1' target='_blank'>A Planning Framework for Adaptive Labeling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daksh Mittal, Yuanzhe Ma, Shalmali Joshi, Hongseok Namkoong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 00:01:08</h6>
<p class='card-text'>Ground truth labels/outcomes are critical for advancing scientific and
engineering applications, e.g., evaluating the treatment effect of an
intervention or performance of a predictive model. Since randomly sampling
inputs for labeling can be prohibitively expensive, we introduce an adaptive
labeling framework where measurement effort can be reallocated in batches. We
formulate this problem as a Markov decision process where posterior beliefs
evolve over time as batches of labels are collected (state transition), and
batches (actions) are chosen to minimize uncertainty at the end of data
collection. We design a computational framework that is agnostic to different
uncertainty quantification approaches including those based on deep learning,
and allows a diverse array of policy gradient approaches by relying on
continuous policy parameterizations. On real and synthetic datasets, we
demonstrate even a one-step lookahead policy can substantially outperform
common adaptive labeling heuristics, highlighting the virtue of planning. On
the methodological side, we note that standard REINFORCE-style policy gradient
estimators can suffer high variance since they rely only on zeroth order
information. We propose a direct backpropagation-based approach,
Smoothed-Autodiff, based on a carefully smoothed version of the original
non-differentiable MDP. Our method enjoys low variance at the price of
introducing bias, and we theoretically and empirically show that this trade-off
can be favorable.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06052v1' target='_blank'>A Comprehensive Energy Management Application Method considering Smart
  Home Occupant Behavior using IoT and Real Big Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:S. Saba Rafiei, Mahdi S. Naderi, Mehrdad Abedi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 22:17:54</h6>
<p class='card-text'>One of the most far-reaching use cases of the internet of things is in smart
grid and smart home operation. The smart home concept allows residents to
control, monitor, and manage their energy consumption with minimum loss and
self-involvement. Since each household's lifestyle and energy consumption is
unique, the management system needs background knowledge about residents'
energy consumption behavioral patterns for more accurate planning. To obtain
this information, data related to residents' consumption records must be
processed. This research has attempted to provide an optimal decentralized
management system consisting of interoperable sections to forecast, optimize,
schedule, and implement load management in a smart home. Comparing different
prediction models using 4 years of 1-min interval real data of a smart home
with photovoltaic generation (PV) and electric vehicle (EV), forecasting
non-controllable loads and taking a deterministic approach in different
scenarios, the system uses mixed integer linear programming (MILP) to provide
load scheduling with the objective of an optimal total energy cost reduction
with minimum changes in the household's desired consumption compared to the
initial state. The results have shown that the proposed system has reliable
performance due to the high precision of the forecast and has led to increased
energy efficiency, reduced energy cost (up to 62. 05\%), reduced
peak-to-average ratio (PAR) (up to 44. 19\%) and reduced standard deviation
(SD) (up to 19. 70\%) in net consumption.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06036v2' target='_blank'>An assessment of observational coverage and gaps for robust Sun to
  heliosphere integrated science</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yeimy J. Rivera, Samuel T. Badman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 21:21:44</h6>
<p class='card-text'>Understanding the generation and development of the continuous outflow from
the Sun requires tracing the physical conditions from deep in the corona to the
heliosphere. Detailed global observations of plasma state variables and the
magnetic field are needed to provide critical constraints to the underlying
physics driving models of the corona and solar wind. Key diagnostics of the
solar wind require measurements at its formation site and during its outflow to
continuously track it across rapidly changing regions of space. A unified view
of the solar wind is only possible through coordinated remote and in situ
observations that probe these different regions. Here, we discuss current
observational coverage and gaps of different plasma properties and review
recent coordinated studies. We highlight how these efforts may become more
routine with the launch of upcoming and planned missions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05938v1' target='_blank'>Energy-Efficient Autonomous Aerial Navigation with Dynamic Vision
  Sensors: A Physics-Guided Neuromorphic Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sourav Sanyal, Amogh Joshi, Manish Nagaraj, Rohan Kumar Manna, Kaushik Roy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 15:40:18</h6>
<p class='card-text'>Vision-based object tracking is a critical component for achieving autonomous
aerial navigation, particularly for obstacle avoidance. Neuromorphic Dynamic
Vision Sensors (DVS) or event cameras, inspired by biological vision, offer a
promising alternative to conventional frame-based cameras. These cameras can
detect changes in intensity asynchronously, even in challenging lighting
conditions, with a high dynamic range and resistance to motion blur. Spiking
neural networks (SNNs) are increasingly used to process these event-based
signals efficiently and asynchronously. Meanwhile, physics-based artificial
intelligence (AI) provides a means to incorporate system-level knowledge into
neural networks via physical modeling. This enhances robustness, energy
efficiency, and provides symbolic explainability. In this work, we present a
neuromorphic navigation framework for autonomous drone navigation. The focus is
on detecting and navigating through moving gates while avoiding collisions. We
use event cameras for detecting moving objects through a shallow SNN
architecture in an unsupervised manner. This is combined with a lightweight
energy-aware physics-guided neural network (PgNN) trained with depth inputs to
predict optimal flight times, generating near-minimum energy paths. The system
is implemented in the Gazebo simulator and integrates a sensor-fused
vision-to-planning neuro-symbolic framework built with the Robot Operating
System (ROS) middleware. This work highlights the future potential of
integrating event-based vision with physics-guided planning for
energy-efficient autonomous navigation, particularly for low-latency
decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05916v2' target='_blank'>Adaptive Grasping of Moving Objects in Dense Clutter via Global-to-Local
  Detection and Static-to-Dynamic Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hao Chen, Takuya Kiyokawa, Weiwei Wan, Kensuke Harada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 14:24:30</h6>
<p class='card-text'>Robotic grasping is facing a variety of real-world uncertainties caused by
non-static object states, unknown object properties, and cluttered object
arrangements. The difficulty of grasping increases with the presence of more
uncertainties, where commonly used learning-based approaches struggle to
perform consistently across varying conditions. In this study, we integrate the
idea of similarity matching to tackle the challenge of grasping novel objects
that are simultaneously in motion and densely cluttered using a single RGBD
camera, where multiple uncertainties coexist. We achieve this by shifting
visual detection from global to local states and operating grasp planning from
static to dynamic scenes. Notably, we introduce optimization methods to enhance
planning efficiency for this time-sensitive task. Our proposed system can adapt
to various object types, arrangements and movement speeds without the need for
extensive training, as demonstrated by real-world experiments. Videos are
available at https://youtu.be/sdC50dx-xp8?si=27oVr4dhG0rqN_tT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05912v1' target='_blank'>LpBound: Pessimistic Cardinality Estimation using $\ell_p$-Norms of
  Degree Sequences</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haozhe Zhang, Christoph Mayer, Mahmoud Abo Khamis, Dan Olteanu, Dan Suciu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 14:13:51</h6>
<p class='card-text'>Cardinality estimation is the problem of estimating the size of the output of
a query, without actually evaluating the query. The cardinality estimator is a
critical piece of a query optimizer, and is often the main culprit when the
optimizer chooses a poor plan.
  This paper introduces LpBound, a pessimistic cardinality estimator for
multijoin queries (acyclic or cyclic) with selection predicates and group-by
clauses. LpBound computes a guaranteed upper bound on the size of the query
output using simple statistics on the input relations, consisting of
$\ell_p$-norms of degree sequences. The bound is the optimal solution of a
linear program whose constraints encode data statistics and Shannon
inequalities. We introduce two optimizations that exploit the structure of the
query in order to speed up the estimation time and make LpBound practical.
  We experimentally evaluate LpBound against a range of traditional,
pessimistic, and machine learning-based estimators on the JOB, STATS, and
subgraph matching benchmarks. Our main finding is that LpBound can be orders of
magnitude more accurate than traditional estimators used in mainstream
open-source and commercial database systems. Yet it has comparable low
estimation time and space requirements. When injected the estimates of LpBound,
Postgres derives query plans at least as good as those derived using the true
cardinalities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06895v1' target='_blank'>A Comprehensive Review of U-Net and Its Variants: Advances and
  Applications in Medical Image Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wang Jiangtao, Nur Intan Raihana Ruhaiyem, Fu Panpan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 13:11:51</h6>
<p class='card-text'>Medical images often exhibit low and blurred contrast between lesions and
surrounding tissues, with considerable variation in lesion edges and shapes
even within the same disease, leading to significant challenges in
segmentation. Therefore, precise segmentation of lesions has become an
essential prerequisite for patient condition assessment and formulation of
treatment plans. Significant achievements have been made in research related to
the U-Net model in recent years. It improves segmentation performance and is
extensively applied in the semantic segmentation of medical images to offer
technical support for consistent quantitative lesion analysis methods. First,
this paper classifies medical image datasets on the basis of their imaging
modalities and then examines U-Net and its various improvement models from the
perspective of structural modifications. The research objectives, innovative
designs, and limitations of each approach are discussed in detail. Second, we
summarize the four central improvement mechanisms of the U-Net and U-Net
variant algorithms: the jump-connection mechanism, residual-connection
mechanism, 3D-UNet, and transformer mechanism. Finally, we examine the
relationships among the four core enhancement mechanisms and commonly utilized
medical datasets and propose potential avenues and strategies for future
advancements. This paper provides a systematic summary and reference for
researchers in related fields, and we look forward to designing more efficient
and stable medical image segmentation network models based on the U-Net
network.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05792v2' target='_blank'>AToM: Adaptive Theory-of-Mind-Based Human Motion Prediction in Long-Term
  Human-Robot Interactions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuwen Liao, Muqing Cao, Xinhang Xu, Lihua Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 06:48:16</h6>
<p class='card-text'>Humans learn from observations and experiences to adjust their behaviours
towards better performance. Interacting with such dynamic humans is
challenging, as the robot needs to predict the humans accurately for safe and
efficient operations. Long-term interactions with dynamic humans have not been
extensively studied by prior works. We propose an adaptive human prediction
model based on the Theory-of-Mind (ToM), a fundamental social-cognitive ability
that enables humans to infer others' behaviours and intentions. We formulate
the human internal belief about others using a game-theoretic model, which
predicts the future motions of all agents in a navigation scenario. To estimate
an evolving belief, we use an Unscented Kalman Filter to update the behavioural
parameters in the human internal model. Our formulation provides unique
interpretability to dynamic human behaviours by inferring how the human
predicts the robot. We demonstrate through long-term experiments in both
simulations and real-world settings that our prediction effectively promotes
safety and efficiency in downstream robot planning. Code will be available at
https://github.com/centiLinda/AToM-human-prediction.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05769v2' target='_blank'>Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual
  Descriptions Using Gaussian Splatting, ChatGPT/Deepseek, and Google Maps
  Platform</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 04:06:07</h6>
<p class='card-text'>Urban digital twins are virtual replicas of cities that use multi-source data
and data analytics to optimize urban planning, infrastructure management, and
decision-making. Towards this, we propose a framework focused on the
single-building scale. By connecting to cloud mapping platforms such as Google
Map Platforms APIs, by leveraging state-of-the-art multi-agent Large Language
Models data analysis using ChatGPT(4o) and Deepseek-V3/R1, and by using our
Gaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildings
framework can retrieve a building's 3D model, visual descriptions, and achieve
cloud-based mapping integration with large language model-based data analytics
using a building's address, postal code, or geographic coordinates.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05713v1' target='_blank'>4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised
  Disease Progression Modelling of Idiopathic Pulmonary Fibrosis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:An Zhao, Moucheng Xu, Ahmed H. Shahin, Wim Wuyts, Mark G. Jones, Joseph Jacob, Daniel C. Alexander</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 22:25:53</h6>
<p class='card-text'>Understanding the progression trajectories of diseases is crucial for early
diagnosis and effective treatment planning. This is especially vital for
life-threatening conditions such as Idiopathic Pulmonary Fibrosis (IPF), a
chronic, progressive lung disease with a prognosis comparable to many cancers.
Computed tomography (CT) imaging has been established as a reliable diagnostic
tool for IPF. Accurately predicting future CT scans of early-stage IPF patients
can aid in developing better treatment strategies, thereby improving survival
outcomes. In this paper, we propose 4D Vector Quantised Generative Adversarial
Networks (4D-VQ-GAN), a model capable of generating realistic CT volumes of IPF
patients at any time point. The model is trained using a two-stage approach. In
the first stage, a 3D-VQ-GAN is trained to reconstruct CT volumes. In the
second stage, a Neural Ordinary Differential Equation (ODE) based temporal
model is trained to capture the temporal dynamics of the quantised embeddings
generated by the encoder in the first stage. We evaluate different
configurations of our model for generating longitudinal CT scans and compare
the results against ground truth data, both quantitatively and qualitatively.
For validation, we conduct survival analysis using imaging biomarkers derived
from generated CT scans and achieve a C-index comparable to that of biomarkers
derived from the real CT scans. The survival analysis results demonstrate the
potential clinical utility inherent to generated longitudinal CT scans, showing
that they can reliably predict survival outcomes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05710v1' target='_blank'>SSDD-GAN: Single-Step Denoising Diffusion GAN for Cochlear Implant
  Surgical Scene Completion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yike Zhang, Eduardo Davalos, Jack Noble</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 22:04:22</h6>
<p class='card-text'>Recent deep learning-based image completion methods, including both
inpainting and outpainting, have demonstrated promising results in restoring
corrupted images by effectively filling various missing regions. Among these,
Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic
Models (DDPMs) have been employed as key generative image completion
approaches, excelling in the field of generating high-quality restorations with
reduced artifacts and improved fine details. In previous work, we developed a
method aimed at synthesizing views from novel microscope positions for
mastoidectomy surgeries; however, that approach did not have the ability to
restore the surrounding surgical scene environment. In this paper, we propose
an efficient method to complete the surgical scene of the synthetic
postmastoidectomy dataset. Our approach leverages self-supervised learning on
real surgical datasets to train a Single-Step Denoising Diffusion-GAN
(SSDD-GAN), combining the advantages of diffusion models with the adversarial
optimization of GANs for improved Structural Similarity results of 6%. The
trained model is then directly applied to the synthetic postmastoidectomy
dataset using a zero-shot approach, enabling the generation of realistic and
complete surgical scenes without the need for explicit ground-truth labels from
the synthetic postmastoidectomy dataset. This method addresses key limitations
in previous work, offering a novel pathway for full surgical microscopy scene
completion and enhancing the usability of the synthetic postmastoidectomy
dataset in surgical preoperative planning and intraoperative navigation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05702v1' target='_blank'>Graph Neural Networks for Efficient AC Power Flow Prediction in Power
  Grids</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seyedamirhossein Talebi, Kaixiong Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 21:42:47</h6>
<p class='card-text'>This paper proposes a novel approach using Graph Neural Networks (GNNs) to
solve the AC Power Flow problem in power grids. AC OPF is essential for
minimizing generation costs while meeting the operational constraints of the
grid. Traditional solvers struggle with scalability, especially in large
systems with renewable energy sources. Our approach models the power grid as a
graph, where buses are nodes and transmission lines are edges. We explore
different GNN architectures, including GCN, GAT, SAGEConv, and GraphConv to
predict AC power flow solutions efficiently. Our experiments on IEEE test
systems show that GNNs can accurately predict power flow solutions and scale to
larger systems, outperforming traditional solvers in terms of computation time.
This work highlights the potential of GNNs for real-time power grid management,
with future plans to apply the model to even larger grid systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05692v1' target='_blank'>Variational integrators for optimal control of foldable drones</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:L. Colombo, J. Giribet, D. Martín de Diego</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 20:47:54</h6>
<p class='card-text'>Numerical methods that preserves geometric invariants of the system such as
energy, momentum and symplectic form, are called geometric integrators. These
include variational integrators as an important subclass of geometric
integrators. The general idea for those variational integrators is to
discretize Hamilton's principle rather than the equations of motion and as a
consequence these methods preserves some of the invariants of the original
system (symplecticity, symmetry, good behavior of energy,...). In this paper,
we construct variational integrators for control-dependent Lagrangian systems
on Lie groups. These integrators are derived via a discrete-time variational
principle for discrete-time control-dependent reduced Lagrangians. We employ
the variational integrator into optimal control problems for path planning of
foldable unmanned aerial vehicles (UAVs). Simulation are shown to validate the
performance of the geometric integrator.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05683v2' target='_blank'>Characterisation of optimal solutions to second-order Beckmann problem
  through bimartingale couplings and leaf decompositions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Krzysztof J. Ciosmak</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 20:30:14</h6>
<p class='card-text'>We completely characterise the optimal solutions for the three-marginal
optimal transport problem - introduced in [K. Bolbotowski, G. Bouchitt\'e,
Kantorovich-Rubinstein duality theory for the Hessian, 2024, preprint], and
whose relaxation is the second-order Beckmann problem - for arbitrary pairs
$\mu,\nu\in\mathcal{P}_2(\mathbb{R}^n)$ of absolutely continuous measures with
common barycentre such that there exists an optimal plan with absolutely
continuous third marginal.
  In our work, we define the concept of bimartingale couplings for a pair of
measures and establish several equivalent conditions that ensure such couplings
exist. One of these conditions is that the pair is ordered according to the
convex-concave order, thereby generalising the classical Strassen theorem.
Another equivalent condition is that the dual problem associated with the
second-order Beckmann problem attains its optimum at a
$\mathcal{C}^{1,1}(\mathbb{R}^n)$ function with isometric derivative.
  We prove that the problem for $\mu,\nu$ completely decomposes into a
collection of simpler problems on the leaves of the $1$-Lipschitz derivative
$Du$ of an optimal solution $u\in\mathcal{C}^{1,1}(\mathbb{R}^n)$ for the dual
problem. On each such, leaf the solution is expressed in terms of bimartingale
couplings between conditional measures of $\mu,\nu$, where the conditioning is
defined relative to the foliation induced by $Du$.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05652v1' target='_blank'>An inpainting approach to manipulate asymmetry in pre-operative breast
  images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Helena Montenegro, Maria J. Cardoso, Jaime S. Cardoso</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 17:54:11</h6>
<p class='card-text'>One of the most frequent modalities of breast cancer treatment is surgery.
Breast surgery can cause visual alterations to the breasts, due to scars and
asymmetries. To enable an informed choice of treatment, the patient must be
adequately informed of the aesthetic outcomes of each treatment plan. In this
work, we propose an inpainting approach to manipulate breast shape and nipple
position in breast images, for the purpose of predicting the aesthetic outcomes
of breast cancer treatment. We perform experiments with various model
architectures for the inpainting task, including invertible networks capable of
manipulating breasts in the absence of ground-truth breast contour and nipple
annotations. Experiments on two breast datasets show the proposed models'
ability to realistically alter a patient's breasts, enabling a faithful
reproduction of breast asymmetries of post-operative patients in pre-operative
images.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05641v1' target='_blank'>Generating Physically Realistic and Directable Human Motions from
  Multi-Modal Inputs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aayam Shrestha, Pan Liu, German Ros, Kai Yuan, Alan Fern</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 17:02:11</h6>
<p class='card-text'>This work focuses on generating realistic, physically-based human behaviors
from multi-modal inputs, which may only partially specify the desired motion.
For example, the input may come from a VR controller providing arm motion and
body velocity, partial key-point animation, computer vision applied to videos,
or even higher-level motion goals. This requires a versatile low-level humanoid
controller that can handle such sparse, under-specified guidance, seamlessly
switch between skills, and recover from failures. Current approaches for
learning humanoid controllers from demonstration data capture some of these
characteristics, but none achieve them all. To this end, we introduce the
Masked Humanoid Controller (MHC), a novel approach that applies multi-objective
imitation learning on augmented and selectively masked motion demonstrations.
The training methodology results in an MHC that exhibits the key capabilities
of catch-up to out-of-sync input commands, combining elements from multiple
motion sequences, and completing unspecified parts of motions from sparse
multimodal input. We demonstrate these key capabilities for an MHC learned over
a dataset of 87 diverse skills and showcase different multi-modal use cases,
including integration with planning frameworks to highlight MHC's ability to
solve new user-defined tasks without any finetuning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05595v1' target='_blank'>Data efficient Robotic Object Throwing with Model-Based Reinforcement
  Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Niccolò Turcato, Giulio Giacomuzzo, Matteo Terreran, Davide Allegro, Ruggero Carli, Alberto Dalla Libera</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 14:43:42</h6>
<p class='card-text'>Pick-and-place (PnP) operations, featuring object grasping and trajectory
planning, are fundamental in industrial robotics applications. Despite many
advancements in the field, PnP is limited by workspace constraints, reducing
flexibility. Pick-and-throw (PnT) is a promising alternative where the robot
throws objects to target locations, leveraging extrinsic resources like gravity
to improve efficiency and expand the workspace. However, PnT execution is
complex, requiring precise coordination of high-speed movements and object
dynamics. Solutions to the PnT problem are categorized into analytical and
learning-based approaches. Analytical methods focus on system modeling and
trajectory generation but are time-consuming and offer limited generalization.
Learning-based solutions, in particular Model-Free Reinforcement Learning
(MFRL), offer automation and adaptability but require extensive interaction
time. This paper introduces a Model-Based Reinforcement Learning (MBRL)
framework, MC-PILOT, which combines data-driven modeling with policy
optimization for efficient and accurate PnT tasks. MC-PILOT accounts for model
uncertainties and release errors, demonstrating superior performance in
simulations and real-world tests with a Franka Emika Panda manipulator. The
proposed approach generalizes rapidly to new targets, offering advantages over
analytical and Model-Free methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05526v1' target='_blank'>Towards Learning Scalable Agile Dynamic Motion Planning for Robosoccer
  Teams with Policy Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Brandon Ho, Batuhan Altundas, Matthew Gombolay</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 11:13:07</h6>
<p class='card-text'>In fast-paced, ever-changing environments, dynamic Motion Planning for
Multi-Agent Systems in the presence of obstacles is a universal and unsolved
problem. Be it from path planning around obstacles to the movement of robotic
arms, or in planning navigation of robot teams in settings such as Robosoccer,
dynamic motion planning is needed to avoid collisions while reaching the
targeted destination when multiple agents occupy the same area. In continuous
domains where the world changes quickly, existing classical Motion Planning
algorithms such as RRT* and A* become computationally expensive to rerun at
every time step. Many variations of classical and well-formulated non-learning
path-planning methods have been proposed to solve this universal problem but
fall short due to their limitations of speed, smoothness, optimally, etc. Deep
Learning models overcome their challenges due to their ability to adapt to
varying environments based on past experience. However, current learning motion
planning models use discretized environments, do not account for heterogeneous
agents or replanning, and build up to improve the classical motion planners'
efficiency, leading to issues with scalability. To prevent collisions between
heterogenous team members and collision to obstacles while trying to reach the
target location, we present a learning-based dynamic navigation model and show
our model working on a simple environment in the concept of a simple Robosoccer
Game.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05479v1' target='_blank'>Model Validity in Observers: When to Increase the Complexity of Your
  Model?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Agapius Bou Ghosn, Philip Polack, Arnaud de La Fortelle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 07:40:30</h6>
<p class='card-text'>Model validity is key to the accurate and safe behavior of autonomous
vehicles. Using invalid vehicle models in the different plan and control
vehicle frameworks puts the stability of the vehicle, and thus its safety at
stake. In this work, we analyze the validity of several popular vehicle models
used in the literature with respect to a real vehicle and we prove that serious
accuracy issues are encountered beyond a specific lateral acceleration point.
We set a clear lateral acceleration domain in which the used models are an
accurate representation of the behavior of the vehicle. We then target the
necessity of using learned methods to model the vehicle's behavior. The effects
of model validity on state observers are investigated. The performance of
model-based observers is compared to learning-based ones. Overall, the
presented work emphasizes the validity of vehicle models and presents clear
operational domains in which models could be used safely.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05476v1' target='_blank'>Convolutional Neural Network Segmentation for Satellite Imagery Data to
  Identify Landforms Using U-Net Architecture</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mitul Goswami, Sainath Dey, Aniruddha Mukherjee, Suneeta Mohanty, Prasant Kumar Pattnaik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 07:27:12</h6>
<p class='card-text'>This study demonstrates a novel use of the U-Net architecture in the field of
semantic segmentation to detect landforms using preprocessed satellite imagery.
The study applies the U-Net model for effective feature extraction by using
Convolutional Neural Network (CNN) segmentation techniques. Dropout is
strategically used for regularization to improve the model's perseverance, and
the Adam optimizer is used for effective training. The study thoroughly
assesses the performance of the U-Net architecture utilizing a large sample of
preprocessed satellite topographical images. The model excels in semantic
segmentation tasks, displaying high-resolution outputs, quick feature
extraction, and flexibility to a wide range of applications. The findings
highlight the U-Net architecture's substantial contribution to the advancement
of machine learning and image processing technologies. The U-Net approach,
which emphasizes pixel-wise categorization and comprehensive segmentation map
production, is helpful in practical applications such as autonomous driving,
disaster management, and land use planning. This study not only investigates
the complexities of U-Net architecture for semantic segmentation, but also
highlights its real-world applications in image classification, analysis, and
landform identification. The study demonstrates the U-Net model's key
significance in influencing the environment of modern technology.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05462v1' target='_blank'>Motion Planning of Nonholonomic Cooperative Mobile Manipulators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Keshab Patra, Arpita Sinha, Anirban Guha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 06:05:43</h6>
<p class='card-text'>We propose a real-time implementable motion planning technique for
cooperative object transportation by nonholonomic mobile manipulator robots
(MMRs) in an environment with static and dynamic obstacles. The proposed motion
planning technique works in two steps. A novel visibility vertices-based path
planning algorithm computes a global piece-wise linear path between the start
and the goal location in the presence of static obstacles offline. It defines
the static obstacle free space around the path with a set of convex polygons
for the online motion planner. We employ a Nonliner Model Predictive Control
(NMPC) based online motion planning technique for nonholonomic MMRs that
jointly plans for the mobile base and the manipulators arm. It efficiently
utilizes the locomotion capability of the mobile base and the manipulation
capability of the arm. The motion planner plans feasible motion for the MMRs
and generates trajectory for object transportation considering the kinodynamic
constraints and the static and dynamic obstacles. The efficiency of our
approach is validated by numerical simulation and hardware experiments in
varied environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05454v2' target='_blank'>Temporal Representation Alignment: Successor Features Enable Emergent
  Compositionality in Robot Instruction Following</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vivek Myers, Bill Chunyuan Zheng, Anca Dragan, Kuan Fang, Sergey Levine</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 05:26:29</h6>
<p class='card-text'>Effective task representations should facilitate compositionality, such that
after learning a variety of basic tasks, an agent can perform compound tasks
consisting of multiple steps simply by composing the representations of the
constituent steps together. While this is conceptually simple and appealing, it
is not clear how to automatically learn representations that enable this sort
of compositionality. We show that learning to associate the representations of
current and future states with a temporal alignment loss can improve
compositional generalization, even in the absence of any explicit subtask
planning or reinforcement learning. We evaluate our approach across diverse
robotic manipulation tasks as well as in simulation, showing substantial
improvements for tasks specified with either language or goal images.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05396v1' target='_blank'>A Novel Convolutional-Free Method for 3D Medical Imaging Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Canxuan Gang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 00:52:45</h6>
<p class='card-text'>Segmentation of 3D medical images is a critical task for accurate diagnosis
and treatment planning. Convolutional neural networks (CNNs) have dominated the
field, achieving significant success in 3D medical image segmentation. However,
CNNs struggle with capturing long-range dependencies and global context,
limiting their performance, particularly for fine and complex structures.
Recent transformer-based models, such as TransUNet and nnFormer, have
demonstrated promise in addressing these limitations, though they still rely on
hybrid CNN-transformer architectures. This paper introduces a novel, fully
convolutional-free model based on transformer architecture and self-attention
mechanisms for 3D medical image segmentation. Our approach focuses on improving
multi-semantic segmentation accuracy and addressing domain adaptation
challenges between thick and thin slice CT images. We propose a joint loss
function that facilitates effective segmentation of thin slices based on thick
slice annotations, overcoming limitations in dataset availability. Furthermore,
we present a benchmark dataset for multi-semantic segmentation on thin slices,
addressing a gap in current medical imaging research. Our experiments
demonstrate the superiority of the proposed model over traditional and hybrid
architectures, offering new insights into the future of convolution-free
medical image segmentation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05378v1' target='_blank'>NextBestPath: Efficient 3D Mapping of Unseen Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shiyao Li, Antoine Guédon, Clémentin Boittiaux, Shizhe Chen, Vincent Lepetit</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 23:18:08</h6>
<p class='card-text'>This work addresses the problem of active 3D mapping, where an agent must
find an efficient trajectory to exhaustively reconstruct a new scene. Previous
approaches mainly predict the next best view near the agent's location, which
is prone to getting stuck in local areas. Additionally, existing indoor
datasets are insufficient due to limited geometric complexity and inaccurate
ground truth meshes. To overcome these limitations, we introduce a novel
dataset AiMDoom with a map generator for the Doom video game, enabling to
better benchmark active 3D mapping in diverse indoor environments. Moreover, we
propose a new method we call next-best-path (NBP), which predicts long-term
goals rather than focusing solely on short-sighted views. The model jointly
predicts accumulated surface coverage gains for long-term goals and obstacle
maps, allowing it to efficiently plan optimal paths with a unified model. By
leveraging online data collection, data augmentation and curriculum learning,
NBP significantly outperforms state-of-the-art methods on both the existing
MP3D dataset and our AiMDoom dataset, achieving more efficient mapping in
indoor environments of varying complexity.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05330v1' target='_blank'>Multi-Class Segmentation of Aortic Branches and Zones in Computed
  Tomography Angiography: The AortaSeg24 Challenge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Imran, Jonathan R. Krebs, Vishal Balaji Sivaraman, Teng Zhang, Amarjeet Kumar, Walker R. Ueland, Michael J. Fassler, Jinlong Huang, Xiao Sun, Lisheng Wang, Pengcheng Shi, Maximilian Rokuss, Michael Baumgartner, Yannick Kirchhof, Klaus H. Maier-Hein, Fabian Isensee, Shuolin Liu, Bing Han, Bong Thanh Nguyen, Dong-jin Shin, Park Ji-Woo, Mathew Choi, Kwang-Hyun Uhm, Sung-Jea Ko, Chanwoong Lee, Jaehee Chun, Jin Sung Kim, Minghui Zhang, Hanxiao Zhang, Xin You, Yun Gu, Zhaohong Pan, Xuan Liu, Xiaokun Liang, Markus Tiefenthaler, Enrique Almar-Munoz, Matthias Schwab, Mikhail Kotyushev, Rostislav Epifanov, Marek Wodzinski, Henning Muller, Abdul Qayyum, Moona Mazher, Steven A. Niederer, Zhiwei Wang, Kaixiang Yang, Jintao Ren, Stine Sofia Korreman, Yuchong Gao, Hongye Zeng, Haoyu Zheng, Rui Zheng, Jinghua Yue, Fugen Zhou, Bo Liu, Alexander Cosman, Muxuan Liang, Chang Zhao, Gilbert R. Upchurch Jr., Jun Ma, Yuyin Zhou, Michol A. Cooper, Wei Shao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 21:09:05</h6>
<p class='card-text'>Multi-class segmentation of the aorta in computed tomography angiography
(CTA) scans is essential for diagnosing and planning complex endovascular
treatments for patients with aortic dissections. However, existing methods
reduce aortic segmentation to a binary problem, limiting their ability to
measure diameters across different branches and zones. Furthermore, no
open-source dataset is currently available to support the development of
multi-class aortic segmentation methods. To address this gap, we organized the
AortaSeg24 MICCAI Challenge, introducing the first dataset of 100 CTA volumes
annotated for 23 clinically relevant aortic branches and zones. This dataset
was designed to facilitate both model development and validation. The challenge
attracted 121 teams worldwide, with participants leveraging state-of-the-art
frameworks such as nnU-Net and exploring novel techniques, including cascaded
models, data augmentation strategies, and custom loss functions. We evaluated
the submitted algorithms using the Dice Similarity Coefficient (DSC) and
Normalized Surface Distance (NSD), highlighting the approaches adopted by the
top five performing teams. This paper presents the challenge design, dataset
details, evaluation metrics, and an in-depth analysis of the top-performing
algorithms. The annotated dataset, evaluation code, and implementations of the
leading methods are publicly available to support further research. All
resources can be accessed at https://aortaseg24.grand-challenge.org.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05161v1' target='_blank'>Estimated Roadway Segment Traffic Data by Vehicle Class for the United
  States: A Machine Learning Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Brittany Antonczak, Meg Fay, Aviral Chawla, Gregory Rowangould</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 18:42:33</h6>
<p class='card-text'>The Highway Performance Monitoring System, managed by the Federal Highway
Administration, provides essential data on average annual daily traffic across
U.S. roadways, but it has limited representation of medium- and heavy-duty
vehicles on non-interstate roads. This gap limits research and policy analysis
on the impacts of truck traffic, especially concerning air quality and public
health. To address this, we use random forest regression to estimate medium-
and heavy-duty vehicle traffic volumes in areas with sparse data. This results
in a more comprehensive dataset, which enables the estimation of traffic
density at the census block level as a proxy for traffic-related air pollution
exposure. Our high-resolution spatial data products, rigorously validated,
provide a more accurate representation of truck traffic and its environmental
and health impacts. These datasets are valuable for transportation planning,
public health research, and policy decisions aimed at mitigating the effects of
truck traffic on vulnerable communities exposed to air pollution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05152v1' target='_blank'>Extreme-Scale EV Charging Infrastructure Planning for Last-Mile Delivery
  Using High-Performance Parallel Computing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Waquar Kaleem, Taner Cokyasar, Jeffrey Larson, Omer Verbas, Tanveer Hossain Bhuiyan, Anirudh Subramanyam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 18:30:21</h6>
<p class='card-text'>This paper addresses stochastic charger location and allocation (SCLA)
problems under queue congestion for last-mile delivery using electric vehicles
(EVs). The objective is to decide where to open charging stations and how many
chargers of each type to install, subject to budgetary and waiting-time
constraints. We formulate the problem as a mixed-integer non-linear program,
where each station-charger pair is modeled as a multiserver queue with
stochastic arrivals and service times to capture the notion of waiting in fleet
operations. The model is extremely large, with billions of variables and
constraints for a typical metropolitan area; and even loading the model in
solver memory is difficult, let alone solving it. To address this challenge, we
develop a Lagrangian-based dual decomposition framework that decomposes the
problem by station and leverages parallelization on high-performance computing
systems, where the subproblems are solved by using a cutting plane method and
their solutions are collected at the master level. We also develop a three-step
rounding heuristic to transform the fractional subproblem solutions into
feasible integral solutions. Computational experiments on data from the Chicago
metropolitan area with hundreds of thousands of households and thousands of
candidate stations show that our approach produces high-quality solutions in
cases where existing exact methods cannot even load the model in memory. We
also analyze various policy scenarios, demonstrating that combining existing
depots with newly built stations under multiagency collaboration substantially
reduces costs and congestion. These findings offer a scalable and efficient
framework for developing sustainable large-scale EV charging networks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05256v1' target='_blank'>Learned Offline Query Planning via Bayesian Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jeffrey Tao, Natalie Maus, Haydn Jones, Yimeng Zeng, Jacob R. Gardner, Ryan Marcus</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 18:20:19</h6>
<p class='card-text'>Analytics database workloads often contain queries that are executed
repeatedly. Existing optimization techniques generally prioritize keeping
optimization cost low, normally well below the time it takes to execute a
single instance of a query. If a given query is going to be executed thousands
of times, could it be worth investing significantly more optimization time? In
contrast to traditional online query optimizers, we propose an offline query
optimizer that searches a wide variety of plans and incorporates query
execution as a primitive. Our offline query optimizer combines variational
auto-encoders with Bayesian optimization to find optimized plans for a given
query. We compare our technique to the optimal plans possible with PostgreSQL
and recent RL-based systems over several datasets, and show that our technique
finds faster query plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06856v1' target='_blank'>A physical model approach to order lot sizing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tania Daiana Tobares, Margarita Miguelina Mieras, Fabricio Orlando Sanchez Varretti, José Luis Iguain, Antonio José Ramirez-Pastor</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 18:08:10</h6>
<p class='card-text'>The growing need for companies to reduce costs and maximize profits has led
to an increased focus on logistics activities. Among these, inventory
management plays a crucial role in minimizing organizational expenses by
optimizing the storage and transportation of materials. In this context, this
study introduces an optimization model for the lot-sizing problem based on a
physical system approach. By establishing that the material supply problem is
isomorphic to a one-dimensional mechanical system of point particles connected
by elastic elements, we leverage this analogy to derive cost optimization
conditions naturally and obtain an exact solution. This approach determines lot
sizes that minimize the combined ordering and inventory holding costs in a
significantly shorter time, eliminating the need for heuristic methods. The
optimal lot sizes are defined in terms of the parameter $ \gamma = 2C_O / C_H
$, which represents the relationship between the ordering cost per order ($ C_O
$) and the holding cost per period for the material required in one period ($
C_H $). This parameter fully dictates the system's behavior: when $ \gamma \leq
1 $, the optimal strategy is to place one order per period, whereas for $
\gamma > 1 $, the number of orders $ N $ is reduced relative to the planning
horizon $ M $, meaning $ N < M $. By formulating the total cost function in
terms of the intensive variable $ N/M $, we consolidate the entire optimization
problem into a single function of $ \gamma $. This eliminates the need for
complex algorithms, enabling faster and more precise purchasing decisions. The
proposed model was validated through a real-world case study and benchmarked
against classical algorithms, demonstrating superior cost optimization and
reduced execution time. These findings underscore the potential of this
approach for improving material lot-sizing strategies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05108v1' target='_blank'>Towards Emotionally Intelligent Software Engineers: Understanding
  Students' Self-Perceptions After a Cooperative Learning Experience</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Allysson Allex Araújo, Marcos Kalinowski, Matheus Paixao, Daniel Graziotin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 17:29:08</h6>
<p class='card-text'>[Background] Emotional Intelligence (EI) can impact Software Engineering (SE)
outcomes through improved team communication, conflict resolution, and stress
management. SE workers face increasing pressure to develop both technical and
interpersonal skills, as modern software development emphasizes collaborative
work and complex team interactions. Despite EI's documented importance in
professional practice, SE education continues to prioritize technical knowledge
over emotional and social competencies. [Objective] This paper analyzes SE
students' self-perceptions of their EI after a two-month cooperative learning
project, using Mayer and Salovey's four-ability model to examine how students
handle emotions in collaborative development. [Method] We conducted a case
study with 29 SE students organized into four squads within a project-based
learning course, collecting data through questionnaires and focus groups that
included brainwriting and sharing circles, then analyzing the data using
descriptive statistics and open coding. [Results] Students demonstrated
stronger abilities in managing their own emotions compared to interpreting
others' emotional states. Despite limited formal EI training, they developed
informal strategies for emotional management, including structured planning and
peer support networks, which they connected to improved productivity and
conflict resolution. [Conclusion] This study shows how SE students perceive EI
in a collaborative learning context and provides evidence-based insights into
the important role of emotional competencies in SE education.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05104v1' target='_blank'>Leveraging Hypernetworks and Learnable Kernels for Consumer Energy
  Forecasting Across Diverse Consumer Types</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Umair Danish, Katarina Grolinger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 17:25:54</h6>
<p class='card-text'>Consumer energy forecasting is essential for managing energy consumption and
planning, directly influencing operational efficiency, cost reduction,
personalized energy management, and sustainability efforts. In recent years,
deep learning techniques, especially LSTMs and transformers, have been greatly
successful in the field of energy consumption forecasting. Nevertheless, these
techniques have difficulties in capturing complex and sudden variations, and,
moreover, they are commonly examined only on a specific type of consumer (e.g.,
only offices, only schools). Consequently, this paper proposes HyperEnergy, a
consumer energy forecasting strategy that leverages hypernetworks for improved
modeling of complex patterns applicable across a diversity of consumers.
Hypernetwork is responsible for predicting the parameters of the primary
prediction network, in our case LSTM. A learnable adaptable kernel, comprised
of polynomial and radial basis function kernels, is incorporated to enhance
performance. The proposed HyperEnergy was evaluated on diverse consumers
including, student residences, detached homes, a home with electric vehicle
charging, and a townhouse. Across all consumer types, HyperEnergy consistently
outperformed 10 other techniques, including state-of-the-art models such as
LSTM, AttentionLSTM, and transformer.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05050v1' target='_blank'>Calibration of a $Δ$E-E telescope based on CeBr$_3$ scintillator
  for secondary charged particles measurements in hadron therapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:L. Gesson, J. Gross, C. Mozzi, C. Reibel, Ch. Finck, S. Higueret, T. D. Le, E. Traykov, J. C. Thomas, N. Arbor, M. Pullia, G. Harmant, M. Vanstalle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 16:14:43</h6>
<p class='card-text'>Hadrontherapy is a promising cancer treatment method that offers better dose
conformity and reduces damage to healthy tissues compared to conventional
radiotherapy. However, one major challenge remaining is the precise
characterization of secondary particles generated by nuclear interactions of
the primary beam with tissues. Current data on secondary charged particles,
such as protons and light ions, remain insufficient, particularly in the
clinically relevant energy ranges. This lack of experimental data introduces
uncertainties in treatment planning softwares and Monte Carlo calculations,
thus compromising the accuracy of dose delivery to the patients. This work
consists in the characterization of secondary charged particles generated in
hadron therapy using a $\Delta$E-E telescope comprising a CeBr$_3$ crystal
scintillator and a plastic scintillator. The calibration and response of this
telescope to ions commonly used in clinical settings is presented in this work,
highlighting adherence to Birks law for accurate energy measurements. This
study is the first to optimize a $\Delta$E-E telescope combining CeBr$_3$ and
plastic scintillators specifically for secondary particle detection in
hadrontherapy. This represents an important step in the exploitation of the
system for nuclear data acquisition, as it enables both the measurement of
energy and the discrimination of secondary particles. The objective is to
develop a system compatible with clinical use, allowing for the most precise
possible comparison with treatment planning software calculations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05028v1' target='_blank'>Near-Optimal Online Learning for Multi-Agent Submodular Coordination:
  Tight Approximation and Communication Efficiency</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qixin Zhang, Zongqi Wan, Yu Yang, Li Shen, Dacheng Tao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 15:57:56</h6>
<p class='card-text'>Coordinating multiple agents to collaboratively maximize submodular functions
in unpredictable environments is a critical task with numerous applications in
machine learning, robot planning and control. The existing approaches, such as
the OSG algorithm, are often hindered by their poor approximation guarantees
and the rigid requirement for a fully connected communication graph. To address
these challenges, we firstly present a $\textbf{MA-OSMA}$ algorithm, which
employs the multi-linear extension to transfer the discrete submodular
maximization problem into a continuous optimization, thereby allowing us to
reduce the strict dependence on a complete graph through consensus techniques.
Moreover, $\textbf{MA-OSMA}$ leverages a novel surrogate gradient to avoid
sub-optimal stationary points. To eliminate the computationally intensive
projection operations in $\textbf{MA-OSMA}$, we also introduce a
projection-free $\textbf{MA-OSEA}$ algorithm, which effectively utilizes the KL
divergence by mixing a uniform distribution. Theoretically, we confirm that
both algorithms achieve a regret bound of
$\widetilde{O}(\sqrt{\frac{C_{T}T}{1-\beta}})$ against a
$(\frac{1-e^{-c}}{c})$-approximation to the best comparator in hindsight, where
$C_{T}$ is the deviation of maximizer sequence, $\beta$ is the spectral gap of
the network and $c$ is the joint curvature of submodular objectives. This
result significantly improves the $(\frac{1}{1+c})$-approximation provided by
the state-of-the-art OSG algorithm. Finally, we demonstrate the effectiveness
of our proposed algorithms through simulation-based multi-target tracking.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05024v1' target='_blank'>Prospects for detecting generic fast-time features in the neutrino
  lightcurve of nearby supernovae in neutrino telescopes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jakob Beise, Segev BenZvi, Spencer Griswold, Nora Valtonen-Mattila, Erin O'Sullivan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 15:55:01</h6>
<p class='card-text'>Neutrino emission offers a direct probe into the hydrodynamics and energy
transport processes within a supernova. Fast-time variations in the neutrino
luminosity and mean energy can provide insights into phenomena like turbulence,
convection, and shock revival. In this paper, we explore the detection
capabilities of large-volume neutrino telescopes such as the IceCube Neutrino
Observatory and the planned IceCube-Gen2 detector in identifying generic
fast-time features in the neutrino light curve. We also investigate the
potential enhancement in detection sensitivity using wavelength shifters, which
can improve light collection efficiency. By employing a Short-Time Fourier
Transform analysis, we quantify the excess power in the frequency spectrum
arising from fast-time modulations and compute the detection horizon for a
range of generic models. We find that with IceCube we can already see the
strongest modulation models (>50% amplitude) for progenitors located anywhere
in the Milky Way. Sensitivity to weaker modulations (>20% amplitude) is
possible in future detectors like IceCube-Gen2, in particular with the use of
wavelength shifters. For all detector configurations, the frequency and central
time of the fast-time feature at the 5$\sigma$ detection horizon can be
measured with a resolution of 7.0 Hz and 17 ms respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05014v1' target='_blank'>Seasonal Station-Keeping of Short Duration High Altitude Balloons using
  Deep Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tristan K. Schuler, Chinthan Prasad, Georgiy Kiselev, Donald Sofge</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 15:42:26</h6>
<p class='card-text'>Station-Keeping short-duration high-altitude balloons (HABs) in a region of
interest is a challenging path-planning problem due to partially observable,
complex, and dynamic wind flows. Deep reinforcement learning is a popular
strategy for solving the station-keeping problem. A custom simulation
environment was developed to train and evaluate Deep Q-Learning (DQN) for
short-duration HAB agents in the simulation. To train the agents on realistic
winds, synthetic wind forecasts were generated from aggregated historical
radiosonde data to apply horizontal kinematics to simulated agents. The
synthetic forecasts were closely correlated with ECWMF ERA5 Reanalysis
forecasts, providing a realistic simulated wind field and seasonal and
altitudinal variances between the wind models. DQN HAB agents were then trained
and evaluated across different seasonal months. To highlight differences and
trends in months with vastly different wind fields, a Forecast Score algorithm
was introduced to independently classify forecasts based on wind diversity, and
trends between station-keeping success and the Forecast Score were evaluated
across all seasons.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04998v1' target='_blank'>On Sequential Fault-Intolerant Process Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrzej Kaczmarczyk, Davin Choo, Niclas Boehmer, Milind Tambe, Haifeng Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 15:20:35</h6>
<p class='card-text'>We propose and study a planning problem we call Sequential Fault-Intolerant
Process Planning (SFIPP). SFIPP captures a reward structure common in many
sequential multi-stage decision problems where the planning is deemed
successful only if all stages succeed. Such reward structures are different
from classic additive reward structures and arise in important applications
such as drug/material discovery, security, and quality-critical product design.
We design provably tight online algorithms for settings in which we need to
pick between different actions with unknown success chances at each stage. We
do so both for the foundational case in which the behavior of actions is
deterministic, and the case of probabilistic action outcomes, where we
effectively balance exploration for learning and exploitation for planning
through the usage of multi-armed bandit algorithms. In our empirical
evaluations, we demonstrate that the specialized algorithms we develop, which
leverage additional information about the structure of the SFIPP instance,
outperform our more general algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04941v1' target='_blank'>Detection efficiency and spatial resolution of Monolithic Active Pixel
  Sensors bent to different radii</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anton Andronic, Pascal Becht, Mihail Bogdan Blidaru, Giuseppe Eugenio Bruno, Francesca Carnesecchi, Emma Chizzali, Domenico Colella, Manuel Colocci, Giacomo Contin, Laura Fabbietti, Roman Gernhäuser, Hartmut Hillemanns, Nicolo Jacazio, Alexander Philipp Kalweit, Alex Kluge, Artem Kotliarov, Filip Křížek, Lukas Lautner, Magnus Mager, Paolo Martinengo, Silvia Masciocchi, Marius Wilm Menzel, Alice Mulliri, Felix Reidt, Riccardo Ricci, Roberto Russo, David Schledewitz, Gilda Scioli, Serhiy Senyukov, Sabyasachi Siddhanta, Jory Sonneveld, Johanna Stachel, Miljenko Šuljić, Nicolas Tiltmann, Arianna Grisel Torres Ramos, Berkin Ulukutlu, Gianluca Usai, Jacob Bastiaan Van Beelen, Yitao Wu, Alperen Yüncü</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 14:03:44</h6>
<p class='card-text'>Bent monolithic active pixel sensors are the basis for the planned fully
cylindrical ultra low material budget tracking detector ITS3 of the ALICE
experiment. This paper presents results from testbeam campaigns using
high-energy particles to verify the performance of 50 um thick bent ALPIDE
chips in terms of efficiency and spatial resolution. The sensors were bent to
radii of 18, 24 and 30 mm, slightly smaller than the foreseen bending radii of
the future ALICE ITS3 layers. An efficiency larger than $99.9\%$ and a spatial
resolution of approximately 5 um, in line with the nominal operation of flat
ALPIDE sensors, is obtained at nominal operating conditions. These values are
found to be independent of the bending radius and thus constitute an additional
milestone in the demonstration of the feasibility of the planned ITS3 detector.
In addition, a special geometry in which the beam particles graze the chip and
traverse it laterally over distances of up to 3 mm is investigated.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04908v1' target='_blank'>Effective Sampling for Robot Motion Planning Through the Lens of
  Lattices</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Itai Panasoff, Kiril Solovey</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 13:26:53</h6>
<p class='card-text'>Sampling-based methods for motion planning, which capture the structure of
the robot's free space via (typically random) sampling, have gained popularity
due to their scalability, simplicity, and for offering global guarantees, such
as probabilistic completeness and asymptotic optimality. Unfortunately, the
practicality of those guarantees remains limited as they do not provide
insights into the behavior of motion planners for a finite number of samples
(i.e., a finite running time). In this work, we harness lattice theory and the
concept of $(\delta,\epsilon)$-completeness by Tsao et al. (2020) to construct
deterministic sample sets that endow their planners with strong finite-time
guarantees while minimizing running time. In particular, we introduce a
highly-efficient deterministic sampling approach based on the $A_d^*$ lattice,
which is the best-known geometric covering in dimensions $\leq 21$. Using our
new sampling approach, we obtain at least an order-of-magnitude speedup over
existing deterministic and uniform random sampling methods for complex
motion-planning problems. Overall, our work provides deep mathematical insights
while advancing the practical applicability of sampling-based motion planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04837v1' target='_blank'>Online Robot Motion Planning Methodology Guided by Group Social
  Proxemics Feature</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuan Mu, Xiaorui Liu, Shuai Guo, Wenzheng Chi, Wei Wang, Shuzhi Sam Ge</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 11:10:42</h6>
<p class='card-text'>Nowadays robot is supposed to demonstrate human-like perception, reasoning
and behavior pattern in social or service application. However, most of the
existing motion planning methods are incompatible with above requirement. A
potential reason is that the existing navigation algorithms usually intend to
treat people as another kind of obstacle, and hardly take the social principle
or awareness into consideration. In this paper, we attempt to model the
proxemics of group and blend it into the scenario perception and navigation of
robot. For this purpose, a group clustering method considering both social
relevance and spatial confidence is introduced. It can enable robot to identify
individuals and divide them into groups. Next, we propose defining the
individual proxemics within magnetic dipole model, and further established the
group proxemics and scenario map through vector-field superposition. On the
basis of the group clustering and proxemics modeling, we present the method to
obtain the optimal observation positions (OOPs) of group. Once the OOPs grid
and scenario map are established, a heuristic path is employed to generate path
that guide robot cruising among the groups for interactive purpose. A series of
experiments are conducted to validate the proposed methodology on the practical
robot, the results have demonstrated that our methodology has achieved
promising performance on group recognition accuracy and path-generation
efficiency. This concludes that the group awareness evolved as an important
module to make robot socially behave in the practical scenario.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04745v1' target='_blank'>Overview of EXL-50 Research Progress and Future Plan</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuejiang Shi, Yumin Wang, Bing Liu, Xianming Song, Shaodong Song, Xinchen Jiang, Dong Guo, Di Luo, Xiang Gu, Tiantian Sun, Xianli Huang, Zhi Li, Lili Dong, Xueyun Wang, Gang Yin, Mingyuan Wang, Wenjun Liu, Hanyue Zhao, Huasheng Xie, Yong, Liu, Dongkai Qi, Bo Xing, Jiangbo Ding, Chao Wu, Lei Li, Haijun Zhang, Yuanming Yang, Xin Zhao, Enwu Yang, Wenwu Luo, Peihai Zhou, Lei Han, Qing Zhou, Hanqing Wang, Jiaqi Dong, Baoshan Yuan, Y. -K. Martin. Peng, Minsheng Liu, the EXL-50 Team</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 08:27:10</h6>
<p class='card-text'>XuanLong-50 (EXL-50) is the first medium-size spherical torus (ST) in China,
with the toroidal field at major radius at 50 cm around 0.5T. CS-free and
non-inductive current drive via electron cyclotron resonance heating (ECRH) was
the main physics research issue for EXL-50. Discharges with plasma currents of
50 kA - 180 kA were routinely obtained in EXL-50, with the current flattop
sustained for up to or beyond 2 s. The current drive effectiveness on EXL-50
was as high as 1 A/W for low-density discharges using 28GHz ECRH alone for
heating power less than 200 kW. The plasma current reached Ip>80 kA for
high-density (5*10e18m-2) discharges with 150 kW 28GHz ECRH. Higher performance
discharge (Ip of about 120 kA and core density of about 1*10e19m-3) was
achieved with 150 kW 50GHz ECRH. The plasma current in EXL-50 was mainly
carried by the energetic electrons.Multi-fluid equilibrium model has been
successfully applied to reconstruct the magnetic flux surface and the measured
plasma parameters of the EXL-50 equilibrium. The physics mechanisms for the
solenoid-free ECRH current drive and the energetic electrons has also been
investigated. Preliminary experimental results show that 100 kW of lower hybrid
current drive (LHCD) waves can drive 20 kA of plasma current. Several boron
injection systems were installed and tested in EXL-50, including B2H6 gas
puffing, boron powder injection, boron pellet injection. The research plan of
EXL-50U, which is the upgrade machine of EXL-50, is also presented.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04733v1' target='_blank'>Lepton flavor violation in the Majorana and Dirac scotogenic models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Raghavendra Srikanth Hundi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 08:02:54</h6>
<p class='card-text'>In this work we have considered two minimal versions of scotogenic models,
where neutrinos acquire masses through a radiative mechanism. We call these two
models as Majorana and Dirac scotogenic models. In the former model, neutrinos
have Majorana nature, and in the later one, neutrinos are Dirac particles.
These two models are related to each other in terms of additional fields and
symmetries of the model. Hence, to compare these two models in future
experiments, we have analyzed lepton flavor violating (LFV) processes in both
of them, in the charged lepton sector. We have found that the 3-body LFV decays
in both these models can get different contributions. Among all the LFV decays
and after satisfying relevant constraints, we have found that $\tau\to3\mu$ can
have a branching ratio as high as $10^{-10}(10^{-11})$ in the Majorana(Dirac)
scotogenic model. This branching ratio can be probed in the future planned
experiments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04586v1' target='_blank'>Automatic Ply Partitioning for Laminar Composite Process Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eric Garner, Amir Mirzendehdel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 00:44:52</h6>
<p class='card-text'>This work introduces an automated ply partitioning strategy for large-scale
laminar composite manufacturing. It specifically targets the problem of
fabricating large plies from available spooled materials, while minimizing the
adverse effects on part quality. The proposed method inserts fiber-aligned
seams sequentially until each resulting sub-ply can be manufactured from
available materials, while simultaneously enforcing constraints to avoid
quality issues induced by the stacking of seams across multiple plies.
Leveraging the developable nature of individual plies, the partitioning problem
is cast as a sequence of one-dimensional piecewise linear optimization
problems, thus allowing for efficient local optimization via linear
programming. We experimentally demonstrate that coupling the local search with
a greedy global search produces the same results as an exhaustive search. The
resulting automated method provides an efficient and robust alternative to the
existing trial-and-error approach, and can be readily integrated into
state-of-the-art composite design workflows. In addition, this formulation
enables the inclusion of common constraints regarding laminate thickness
tolerance, sub-ply geometry, stay-out zones, material wastage, etc. The
efficacy of the proposed method is demonstrated through its application to the
surface of an airplane wing and to the body panels of an armored vehicle, each
subject to various performance and manufacturing-related geometric constraints.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04583v1' target='_blank'>Overcoming Fake Solutions in Semi-Dual Neural Optimal Transport: A
  Smoothing Approach for Learning the Optimal Transport Plan</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jaemoo Choi, Jaewoong Choi, Dohyun Kwon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 00:37:12</h6>
<p class='card-text'>We address the convergence problem in learning the Optimal Transport (OT)
map, where the OT Map refers to a map from one distribution to another while
minimizing the transport cost. Semi-dual Neural OT, a widely used approach for
learning OT Maps with neural networks, often generates fake solutions that fail
to transfer one distribution to another accurately. We identify a sufficient
condition under which the max-min solution of Semi-dual Neural OT recovers the
true OT Map. Moreover, to address cases when this sufficient condition is not
satisfied, we propose a novel method, OTP, which learns both the OT Map and the
Optimal Transport Plan, representing the optimal coupling between two
distributions. Under sharp assumptions on the distributions, we prove that our
model eliminates the fake solution issue and correctly solves the OT problem.
Our experiments show that the OTP model recovers the optimal transport map
where existing methods fail and outperforms current OT-based models in
image-to-image translation tasks. Notably, the OTP model can learn stochastic
transport maps when deterministic OT Maps do not exist, such as one-to-many
tasks like colorization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04493v1' target='_blank'>LUND-PROBE -- LUND Prostate Radiotherapy Open Benchmarking and
  Evaluation dataset</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Viktor Rogowski, Lars E Olsson, Jonas Scherman, Emilia Persson, Mustafa Kadhim, Sacha af Wetterstedt, Adalsteinn Gunnlaugsson, Martin P. Nilsson, Nandor Vass, Mathieu Moreau, Maria Gebre Medhin, Sven Bäck, Per Munck af Rosenschöld, Silke Engelholm, Christian Jamtheim Gustafsson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 20:44:42</h6>
<p class='card-text'>Radiotherapy treatment for prostate cancer relies on computed tomography (CT)
and/or magnetic resonance imaging (MRI) for segmentation of target volumes and
organs at risk (OARs). Manual segmentation of these volumes is regarded as the
gold standard for ground truth in machine learning applications but to acquire
such data is tedious and time-consuming. A publicly available clinical dataset
is presented, comprising MRI- and synthetic CT (sCT) images, target and OARs
segmentations, and radiotherapy dose distributions for 432 prostate cancer
patients treated with MRI-guided radiotherapy. An extended dataset with 35
patients is also included, with the addition of deep learning (DL)-generated
segmentations, DL segmentation uncertainty maps, and DL segmentations manually
adjusted by four radiation oncologists. The publication of these resources aims
to aid research within the fields of automated radiotherapy treatment planning,
segmentation, inter-observer analyses, and DL model uncertainty investigation.
The dataset is hosted on the AIDA Data Hub and offers a free-to-use resource
for the scientific community, valuable for the advancement of medical imaging
and prostate cancer radiotherapy research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04482v1' target='_blank'>Gig2Gether: Data-sharing to Empower, Unify and Demystify Gig Work</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jane Hsieh, Angie Zhang, Sajel Surati, Sijia Xie, Yeshua Ayala, Nithila Sathiya, Tzu-Sheng Kuo, Min Kyung Lee, Haiyi Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 20:14:39</h6>
<p class='card-text'>The wide adoption of platformized work has generated remarkable advancements
in the labor patterns and mobility of modern society. Underpinning such
progress, gig workers are exposed to unprecedented challenges and
accountabilities: lack of data transparency, social and physical isolation, as
well as insufficient infrastructural safeguards. Gig2Gether presents a space
designed for workers to engage in an initial experience of voluntarily
contributing anecdotal and statistical data to affect policy and build
solidarity across platforms by exchanging unifying and diverse experiences. Our
7-day field study with 16 active workers from three distinct platforms and work
domains showed existing affordances of data-sharing: facilitating mutual
support across platforms, as well as enabling financial reflection and
planning. Additionally, workers envisioned future use cases of data-sharing for
collectivism (e.g., collaborative examinations of algorithmic speculations) and
informing policy (e.g., around safety and pay), which motivated (latent) worker
desiderata of additional capabilities and data metrics. Based on these
findings, we discuss remaining challenges to address and how data-sharing tools
can complement existing structures to maximize worker empowerment and policy
impact.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04471v1' target='_blank'>Identifying Flaky Tests in Quantum Code: A Machine Learning Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Khushdeep Kaur, Dongchan Kim, Ainaz Jamshidi, Lei Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 19:43:51</h6>
<p class='card-text'>Testing and debugging quantum software pose significant challenges due to the
inherent complexities of quantum mechanics, such as superposition and
entanglement. One challenge is indeterminacy, a fundamental characteristic of
quantum systems, which increases the likelihood of flaky tests in quantum
programs. To the best of our knowledge, there is a lack of comprehensive
studies on quantum flakiness in the existing literature. In this paper, we
present a novel machine learning platform that leverages multiple machine
learning models to automatically detect flaky tests in quantum programs. Our
evaluation shows that the extreme gradient boosting and decision tree-based
models outperform other models (i.e., random forest, k-nearest neighbors, and
support vector machine), achieving the highest F1 score and Matthews
Correlation Coefficient in a balanced dataset and an imbalanced dataset,
respectively. Furthermore, we expand the currently limited dataset for
researchers interested in quantum flaky tests. In the future, we plan to
explore the development of unsupervised learning techniques to detect and
classify quantum flaky tests more effectively. These advancements aim to
improve the reliability and robustness of quantum software testing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04467v1' target='_blank'>Efficient variable-length hanging tether parameterization for marsupial
  robot planning in 3D environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:S. Martínez-Rozas, D. Alejo, F. Caballero, L. Merino, M. A. Pérez-Cutiño, F. Rodriguez, V. Sánchez-Canales, I. Ventura, J. M. Díaz-Bañez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 19:37:06</h6>
<p class='card-text'>This paper presents a novel approach to efficiently parameterize and estimate
the state of a hanging tether for path and trajectory planning of a UGV tied to
a UAV in a marsupial configuration. Most implementations in the state of the
art assume a taut tether or make use of the catenary curve to model the shape
of the hanging tether. The catenary model is complex to compute and must be
instantiated thousands of times during the planning process, becoming a
time-consuming task, while the taut tether assumption simplifies the problem,
but might overly restrict the movement of the platforms. In order to accelerate
the planning process, this paper proposes defining an analytical model to
efficiently compute the hanging tether state, and a method to get a tether
state parameterization free of collisions. We exploit the existing similarity
between the catenary and parabola curves to derive analytical expressions of
the tether state.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04455v1' target='_blank'>Momentum and Matter Matter for Axion Dark Matter Matters on Earth</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhishek Banerjee, Itay M. Bloch, Quentin Bonnefoy, Sebastian A. R. Ellis, Gilad Perez, Inbar Savoray, Konstantin Springmann, Yevgeny V. Stadnik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 19:02:02</h6>
<p class='card-text'>We investigate the implications of matter effects to searches for axion Dark
Matter on Earth. The finite momentum of axion Dark Matter is crucial to
elucidating the effects of Earth on both the axion Dark Matter field value and
its gradient. We find that experiments targeting axion couplings compatible
with canonical solutions of the strong CP puzzle are likely not affected by
Earth's matter effects. However, experiments sensitive to lighter axions with
stronger couplings can be significantly affected, with a significant part of
the parameter space suffering from a reduced axion field value, and therefore
decreased experimental sensitivity. In contrast, the spatial gradient of the
axion field can be enhanced along Earth's radial direction, with important
implications for ongoing and planned experiments searching for axion Dark
Matter.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04300v1' target='_blank'>CMB-S4: Foreground-Cleaning Pipeline Comparison for Measuring Primordial
  Gravitational Waves</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Federico Bianchini, Dominic Beck, W. L. Kimmy Wu, Zeeshan Ahmed, Sebastian Belkner, Julien Carron, Brandon S. Hensley, Clement L. Pryke, Caterina Umilta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 18:42:21</h6>
<p class='card-text'>We compare multiple foreground-cleaning pipelines for estimating the
tensor-to-scalar ratio, $r$, using simulated maps of the planned CMB-S4
experiment within the context of the South Pole Deep Patch. To evaluate
robustness, we analyze bias and uncertainty on $r$ across various foreground
suites using map-based simulations. The foreground-cleaning methods include: a
parametric maximum likelihood approach applied to auto- and cross-power spectra
between frequency maps; a map-based parametric maximum-likelihood method; and a
harmonic-space internal linear combination using frequency maps. We summarize
the conceptual basis of each method to highlight their similarities and
differences. To better probe the impact of foreground residuals, we implement
an iterative internal delensing step, leveraging a map-based pipeline to
generate a lensing $B$-mode template from the Large Aperture Telescope
frequency maps. Our results show that the performance of the three approaches
is comparable for simple and intermediate-complexity foregrounds, with
$\sigma(r)$ ranging from 3 to 5 $\times 10^{-4}$. However, biases at the
$1-2\sigma$ level appear when analyzing more complex forms of foreground
emission. By extending the baseline pipelines to marginalize over foreground
residuals, we demonstrate that contamination can be reduced to within
statistical uncertainties, albeit with a pipeline-dependent impact on
$\sigma(r)$, which translates to a detection significance between 2 and
4$\sigma$ for an input value of $r = 0.003$. These findings suggest varying
levels of maturity among the tested pipelines, with the auto- and
cross-spectra-based approach demonstrating the best stability and overall
performance. Moreover, given the extremely low noise levels, mutual validation
of independent foreground-cleaning pipelines is essential to ensure the
robustness of any potential detection.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04299v1' target='_blank'>MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinbo Xing, Long Mai, Cusuh Ham, Jiahui Huang, Aniruddha Mahapatra, Chi-Wing Fu, Tien-Tsin Wong, Feng Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 18:41:04</h6>
<p class='card-text'>This paper presents a method that allows users to design cinematic video
shots in the context of image-to-video generation. Shot design, a critical
aspect of filmmaking, involves meticulously planning both camera movements and
object motions in a scene. However, enabling intuitive shot design in modern
image-to-video generation systems presents two main challenges: first,
effectively capturing user intentions on the motion design, where both camera
movements and scene-space object motions must be specified jointly; and second,
representing motion information that can be effectively utilized by a video
diffusion model to synthesize the image animations. To address these
challenges, we introduce MotionCanvas, a method that integrates user-driven
controls into image-to-video (I2V) generation models, allowing users to control
both object and camera motions in a scene-aware manner. By connecting insights
from classical computer graphics and contemporary video generation techniques,
we demonstrate the ability to achieve 3D-aware motion control in I2V synthesis
without requiring costly 3D-related training data. MotionCanvas enables users
to intuitively depict scene-space motion intentions, and translates them into
spatiotemporal motion-conditioning signals for video diffusion models. We
demonstrate the effectiveness of our method on a wide range of real-world image
content and shot-design scenarios, highlighting its potential to enhance the
creative workflows in digital content creation and adapt to various image and
video editing applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04289v2' target='_blank'>Retro-Rank-In: A Ranking-Based Approach for Inorganic Materials
  Synthesis Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thorben Prein, Elton Pan, Sami Haddouti, Marco Lorenz, Janik Jehkul, Tymoteusz Wilk, Cansu Moran, Menelaos Panagiotis Fotiadis, Artur P. Toshev, Elsa Olivetti, Jennifer L. M. Rupp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 18:34:37</h6>
<p class='card-text'>Retrosynthesis strategically plans the synthesis of a chemical target
compound from simpler, readily available precursor compounds. This process is
critical for synthesizing novel inorganic materials, yet traditional methods in
inorganic chemistry continue to rely on trial-and-error experimentation.
Emerging machine-learning approaches struggle to generalize to entirely new
reactions due to their reliance on known precursors, as they frame
retrosynthesis as a multi-label classification task. To address these
limitations, we propose Retro-Rank-In, a novel framework that reformulates the
retrosynthesis problem by embedding target and precursor materials into a
shared latent space and learning a pairwise ranker on a bipartite graph of
inorganic compounds. We evaluate Retro-Rank-In's generalizability on
challenging retrosynthesis dataset splits designed to mitigate data duplicates
and overlaps. For instance, for Cr2AlB2, it correctly predicts the verified
precursor pair CrB + Al despite never seeing them in training, a capability
absent in prior work. Extensive experiments show that Retro-Rank-In sets a new
state-of-the-art, particularly in out-of-distribution generalization and
candidate set ranking, offering a powerful tool for accelerating inorganic
material synthesis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04287v1' target='_blank'>Breaking the Vault: A Case Study of the 2022 LastPass Data Breach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jessica Gentles, Mason Fields, Garrett Goodman, Suman Bhunia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 18:33:57</h6>
<p class='card-text'>Managing the security of employee work computers has become increasingly
important as today's work model shifts to remote and hybrid work plans. In this
paper, we explore the recent 2022 LastPass data breach, in which the attacker
obtained sensitive customer data by exploiting a software vulnerability on a
DevSecOps engineer's computer. We discuss the methodology of the attacker as
well as the impact this incident had on LastPass and its customers. Next, we
expand upon the impact the breach had on LastPass as well as its customers.
From this, we propose solutions for preparing for and mitigating similar
attacks in the future. The aim of this paper is to shed light on the LastPass
incident and provide methods for companies to secure their employee base, both
nationally and internationally. With a strong security structure, companies can
vastly reduce the chances of falling victim to a similar attack.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04423v1' target='_blank'>Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical
  Interventions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Khushboo Verma, Alan Michels, Ergi Gumusaneli, Shilpa Chitnis, Smita Sinha Kumar, Christopher Thompson, Lena Esmail, Guruprasath Srinivasan, Chandini Panchada, Sushovan Guha, Satwant Kumar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 17:15:12</h6>
<p class='card-text'>Referral workflow inefficiencies, including misaligned referrals and delays,
contribute to suboptimal patient outcomes and higher healthcare costs. In this
study, we investigated the possibility of predicting procedural needs based on
primary care diagnostic entries, thereby improving referral accuracy,
streamlining workflows, and providing better care to patients. A de-identified
dataset of 2,086 orthopedic referrals from the University of Texas Health at
Tyler was analyzed using machine learning models built on Base General
Embeddings (BGE) for semantic extraction. To ensure real-world applicability,
noise tolerance experiments were conducted, and oversampling techniques were
employed to mitigate class imbalance. The selected optimum and parsimonious
embedding model demonstrated high predictive accuracy (ROC-AUC: 0.874, Matthews
Correlation Coefficient (MCC): 0.540), effectively distinguishing patients
requiring surgical intervention. Dimensionality reduction techniques confirmed
the model's ability to capture meaningful clinical relationships. A threshold
sensitivity analysis identified an optimal decision threshold (0.30) to balance
precision and recall, maximizing referral efficiency. In the predictive
modeling analysis, the procedure rate increased from 11.27% to an optimal
60.1%, representing a 433% improvement with significant implications for
operational efficiency and healthcare revenue.
  The results of our study demonstrate that referral optimization can enhance
primary and surgical care integration. Through this approach, precise and
timely predictions of procedural requirements can be made, thereby minimizing
delays, improving surgical planning, and reducing administrative burdens. In
addition, the findings highlight the potential of clinical decision support as
a scalable solution for improving patient outcomes and the efficiency of the
healthcare system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04174v2' target='_blank'>Dense Fixed-Wing Swarming using Receding-Horizon NMPC</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Varun Madabushi, Yocheved Kopel, Adam Polevoy, Joseph Moore</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 16:07:06</h6>
<p class='card-text'>In this paper, we present an approach for controlling a team of agile
fixed-wing aerial vehicles in close proximity to one another. Our approach
relies on receding-horizon nonlinear model predictive control (NMPC) to plan
maneuvers across an expanded flight envelope to enable inter-agent collision
avoidance. To facilitate robust collision avoidance and characterize the
likelihood of inter-agent collisions, we compute a statistical bound on the
probability of the system leaving a tube around the planned nominal trajectory.
Finally, we propose a metric for evaluating highly dynamic swarms and use this
metric to evaluate our approach. We successfully demonstrated our approach
through both simulation and hardware experiments, and to our knowledge, this
the first time close-quarters swarming has been achieved with physical
aerobatic fixed-wing vehicles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04170v1' target='_blank'>From Configuration-Space Clearance to Feature-Space Margin: Sample
  Complexity in Learning-Based Collision Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sapir Tubul, Aviv Tamar, Kiril Solovey, Oren Salzman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 15:58:30</h6>
<p class='card-text'>Motion planning is a central challenge in robotics, with learning-based
approaches gaining significant attention in recent years. Our work focuses on a
specific aspect of these approaches: using machine-learning techniques,
particularly Support Vector Machines (SVM), to evaluate whether robot
configurations are collision free, an operation termed ``collision detection''.
Despite the growing popularity of these methods, there is a lack of theory
supporting their efficiency and prediction accuracy. This is in stark contrast
to the rich theoretical results of machine-learning methods in general and of
SVMs in particular. Our work bridges this gap by analyzing the sample
complexity of an SVM classifier for learning-based collision detection in
motion planning. We bound the number of samples needed to achieve a specified
accuracy at a given confidence level. This result is stated in terms relevant
to robot motion-planning such as the system's clearance. Building on these
theoretical results, we propose a collision-detection algorithm that can also
provide statistical guarantees on the algorithm's error in classifying robot
configurations as collision-free or not.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04155v1' target='_blank'>User-Friendly Game-Theoretic Modeling and Analysis of Multi-Modal
  Transportation Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Margarita Zambrano, Xinling Li, Riccardo Fiorista, Gioele Zardini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 15:40:24</h6>
<p class='card-text'>The evolution of existing transportation systems, mainly driven by
urbanization and increased availability of mobility options, such as private,
profit-maximizing ride-hailing companies, calls for tools to reason about their
design and regulation. To study this complex socio-technical problem, one needs
to account for the strategic interactions of the stakeholders involved in the
mobility ecosystem. In this paper, we present a game-theoretic framework to
model multi-modal mobility systems, focusing on municipalities, service
providers, and travelers. Through a user-friendly, Graphical User Interface,
one can visualize system dynamics and compute equilibria for various scenarios.
The framework enables stakeholders to assess the impact of local decisions
(e.g., fleet size for services or taxes for private companies) on the full
mobility system. Furthermore, this project aims to foster STEM interest among
high school students (e.g., in the context of prior activities in Switzerland,
and planned activities with the MIT museum). This initiative combines
theoretical advancements, practical applications, and educational outreach to
improve mobility system design.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04071v2' target='_blank'>The vertexing challenge at FCC-ee</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Armin Ilg, Anna Macchiolo, Fabrizio Palla</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 13:30:43</h6>
<p class='card-text'>Following in the footsteps of the LHC, the Future Circular Collider (FCC)
plans to be the next multi-generational collider project. In the first stage,
FCC-ee will collide intense beams of electrons and positrons at centre of mass
energies between 88 and 365 GeV, making it an electroweak, flavour, Higgs and
top factory. The unprecedented statistical precision requires FCC-ee
experiments to limit their systematic uncertainties to the very minimum.
  The precise reconstruction of the interaction vertices is central to most
measurements at FCC-ee, such as rare flavour physics processes and the
measurement of Higgs and Z decays to bottom and charm quarks and taus. This
contribution will discuss the requirements of FCC-ee vertex detectors, from the
necessary impact parameter resolution via the challenging collision environment
at the Z pole to the tight requirement on the material budget, which should be
kept below 0.3% of a radiation length per detection layer. Next, the proposed
vertex detector designs for FCC-ee are shortly presented, and an outlook is
given on novel detector designs and features.
  The requirements for the vertexing performance translate into requirements
for the sensors used for the vertex detector. As discussed in this
contribution, they need to feature a spatial resolution of about 3 $\mu$m and
provide timing information of O($\mu$s-ns) while keeping power consumption
minimal to allow for air-cooling of the detector - minimising the detector
material budget.
  The only type of sensor capable of aiming to fulfil such requirements are
CMOS Monolithic Active Pixel Sensors (MAPS), which combine signal generation,
amplification and readout into a single silicon die. Therefore, the rest of
this contribution will present an overview of existing and planned MAPS
technologies and prototypes aiming to fulfil the stringent FCC-ee vertex
detector requirements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04068v1' target='_blank'>Fundamental Oscillations of Massive Boson Stars -- II</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Swarnim Shirke, Bikram Keshari Pradhan, Debarati Chatterjee, Laura Sagunski, Jürgen Schaffner-Bielich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 13:25:09</h6>
<p class='card-text'>Boson Stars (BSs) are macroscopic self-gravitating configurations made of
complex scalar fields. These exotic compact objects (ECO) would manifest as
dark Boson stars and can contribute to a certain fraction of the dark matter
(DM) in the universe. In this work, we study the fundamental non-radial
oscillations ($f$-modes) of massive BSs and the associated gravitational wave
(GW) emission. We consider massive scalar BSs having the potential of the form
$V(\phi) = \frac{1}{2}m^2|\phi|^2 + \frac{1}{4}\lambda |\phi|^4$, restricting
to the strong-coupling regime ($\lambda \gg m^2/M_{Pl}^2$) where solutions
resembling fermionic stars are known to exist. We first review the available
parameter space for scalar DM that can form massive BSs and enlist various
constraints. We fit and provide simple analytical relations connecting various
macroscopic observables for BSs, which can be directly incorporated into future
studies of massive BSs throughout the strong coupling regime without requiring
any numerical computation. We then solve for the non-radial $l=2$ fundamental
quasinormal modes ($f$-modes) for massive BSs. Scaling relations for $f$-mode
equations have been reported in another work. Using these, we perform a
complete study of these oscillations spanning the entire available parameter
space of massive BSs and provide analytical fits for the $f$-mode
characteristics. We further study the universal relations for BSs and reveal
the parameter space that is sensitive to the current and future planned GW
detectors. We find that different parts of the parameters space can, in
principle, be probed by the LISA, LIGO, and NEMO detectors. Finally, we briefly
discuss the detectability of $f$-modes from BSs that have not been explored
before.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03999v1' target='_blank'>A Self-supervised Multimodal Deep Learning Approach to Differentiate
  Post-radiotherapy Progression from Pseudoprogression in Glioblastoma</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ahmed Gomaa, Yixing Huang, Pluvio Stephan, Katharina Breininger, Benjamin Frey, Arnd Dörfler, Oliver Schnell, Daniel Delev, Roland Coras, Charlotte Schmitter, Jenny Stritzelberger, Sabine Semrau, Andreas Maier, Siming Bayer, Stephan Schönecker, Dieter H Heiland, Peter Hau, Udo S. Gaipl, Christoph Bert, Rainer Fietkau, Manuel A. Schmidt, Florian Putz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 11:57:57</h6>
<p class='card-text'>Accurate differentiation of pseudoprogression (PsP) from True Progression
(TP) following radiotherapy (RT) in glioblastoma (GBM) patients is crucial for
optimal treatment planning. However, this task remains challenging due to the
overlapping imaging characteristics of PsP and TP. This study therefore
proposes a multimodal deep-learning approach utilizing complementary
information from routine anatomical MR images, clinical parameters, and RT
treatment planning information for improved predictive accuracy. The approach
utilizes a self-supervised Vision Transformer (ViT) to encode multi-sequence MR
brain volumes to effectively capture both global and local context from the
high dimensional input. The encoder is trained in a self-supervised upstream
task on unlabeled glioma MRI datasets from the open BraTS2021, UPenn-GBM, and
UCSF-PDGM datasets to generate compact, clinically relevant representations
from FLAIR and T1 post-contrast sequences. These encoded MR inputs are then
integrated with clinical data and RT treatment planning information through
guided cross-modal attention, improving progression classification accuracy.
This work was developed using two datasets from different centers: the Burdenko
Glioblastoma Progression Dataset (n = 59) for training and validation, and the
GlioCMV progression dataset from the University Hospital Erlangen (UKER) (n =
20) for testing. The proposed method achieved an AUC of 75.3%, outperforming
the current state-of-the-art data-driven approaches. Importantly, the proposed
approach relies on readily available anatomical MRI sequences, clinical data,
and RT treatment planning information, enhancing its clinical feasibility. The
proposed approach addresses the challenge of limited data availability for PsP
and TP differentiation and could allow for improved clinical decision-making
and optimized treatment plans for GBM patients.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03976v1' target='_blank'>Small Signal Stability Analysis of Kurdistan Regional Power System</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ibrahim Ismael Hamarash</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 11:14:10</h6>
<p class='card-text'>This paper presents for the first time a mathematical model for evaluating
the Planned Kurdistan Regional Power System (KRPS) for its ability to maintain
stability under small disturbances and fluctuations during normal operating
conditions. To achieve this objective, practical field data, manufacture's
datasheets, related IEEE task force reports have been used to build a complete
mathematical model in MATLAB/SIMULINK/SimPowerSystem environment. New modules
have been established and added to the platform wherever it does not support
special type of elements. The model represents accurately all the power system
components involved in physical phenomena of system dynamic oscillations. The
model consists of 53 transmission lines, 35 nodes and 6 generating stations.
The system is simulated under different configurations and settings; the
dynamic behaviors associated with each configuration are recorded and analyzed
accordingly.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03960v1' target='_blank'>Bilevel Multi-Armed Bandit-Based Hierarchical Reinforcement Learning for
  Interaction-Aware Self-Driving at Unsignalized Intersections</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zengqi Peng, Yubin Wang, Lei Zheng, Jun Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 10:50:59</h6>
<p class='card-text'>In this work, we present BiM-ACPPO, a bilevel multi-armed bandit-based
hierarchical reinforcement learning framework for interaction-aware
decision-making and planning at unsignalized intersections. Essentially, it
proactively takes the uncertainties associated with surrounding vehicles (SVs)
into consideration, which encompass those stemming from the driver's intention,
interactive behaviors, and the varying number of SVs. Intermediate decision
variables are introduced to enable the high-level RL policy to provide an
interaction-aware reference, for guiding low-level model predictive control
(MPC) and further enhancing the generalization ability of the proposed
framework. By leveraging the structured nature of self-driving at unsignalized
intersections, the training problem of the RL policy is modeled as a bilevel
curriculum learning task, which is addressed by the proposed Exp3.S-based BiMAB
algorithm. It is noteworthy that the training curricula are dynamically
adjusted, thereby facilitating the sample efficiency of the RL training
process. Comparative experiments are conducted in the high-fidelity CARLA
simulator, and the results indicate that our approach achieves superior
performance compared to all baseline methods. Furthermore, experimental results
in two new urban driving scenarios clearly demonstrate the commendable
generalization performance of the proposed method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04408v1' target='_blank'>Transforming Multimodal Models into Action Models for Radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Matteo Ferrante, Alessandra Carosi, Rolando Maria D Angelillo, Nicola Toschi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 09:51:28</h6>
<p class='card-text'>Radiotherapy is a crucial cancer treatment that demands precise planning to
balance tumor eradication and preservation of healthy tissue. Traditional
treatment planning (TP) is iterative, time-consuming, and reliant on human
expertise, which can potentially introduce variability and inefficiency. We
propose a novel framework to transform a large multimodal foundation model
(MLM) into an action model for TP using a few-shot reinforcement learning (RL)
approach. Our method leverages the MLM's extensive pre-existing knowledge of
physics, radiation, and anatomy, enhancing it through a few-shot learning
process. This allows the model to iteratively improve treatment plans using a
Monte Carlo simulator. Our results demonstrate that this method outperforms
conventional RL-based approaches in both quality and efficiency, achieving
higher reward scores and more optimal dose distributions in simulations on
prostate cancer data. This proof-of-concept suggests a promising direction for
integrating advanced AI models into clinical workflows, potentially enhancing
the speed, quality, and standardization of radiotherapy treatment planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03918v1' target='_blank'>Adaptation of Task Goal States from Prior Knowledge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrei Costinescu, Darius Burschka</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 09:51:04</h6>
<p class='card-text'>This paper presents a framework to define a task with freedom and variability
in its goal state. A robot could use this to observe the execution of a task
and target a different goal from the observed one; a goal that is still
compatible with the task description but would be easier for the robot to
execute. We define the model of an environment state and an environment
variation, and present experiments on how to interactively create the variation
from a single task demonstration and how to use this variation to create an
execution plan for bringing any environment into the goal state.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04407v1' target='_blank'>Illuminating Spaces: Deep Reinforcement Learning and Laser-Wall
  Partitioning for Architectural Layout Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Reza Kakooee, Benjamin Dillenburger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 09:35:24</h6>
<p class='card-text'>Space layout design (SLD), occurring in the early stages of the design
process, nonetheless influences both the functionality and aesthetics of the
ultimate architectural outcome. The complexity of SLD necessitates innovative
approaches to efficiently explore vast solution spaces. While image-based
generative AI has emerged as a potential solution, they often rely on
pixel-based space composition methods that lack intuitive representation of
architectural processes. This paper leverages deep Reinforcement Learning (RL),
as it offers a procedural approach that intuitively mimics the process of human
designers. Effectively using RL for SLD requires an explorative space composing
method to generate desirable design solutions. We introduce "laser-wall", a
novel space partitioning method that conceptualizes walls as emitters of
imaginary light beams to partition spaces. This approach bridges vector-based
and pixel-based partitioning methods, offering both flexibility and exploratory
power in generating diverse layouts. We present two planning strategies:
one-shot planning, which generates entire layouts in a single pass, and dynamic
planning, which allows for adaptive refinement by continuously transforming
laser-walls. Additionally, we introduce on-light and off-light wall
transformations for smooth and fast layout refinement, as well as identity-less
and identity-full walls for versatile room assignment. We developed
SpaceLayoutGym, an open-source OpenAI Gym compatible simulator for generating
and evaluating space layouts. The RL agent processes the input design scenarios
and generates solutions following a reward function that balances geometrical
and topological requirements. Our results demonstrate that the RL-based
laser-wall approach can generate diverse and functional space layouts that
satisfy both geometric constraints and topological requirements and is
architecturally intuitive.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03906v1' target='_blank'>Developing a Climate Litigation Framework: China's Contribution to
  International Environmental Law</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yedong Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 09:29:39</h6>
<p class='card-text'>Although "climate litigation" is not an indigenous term in China, localizing
it is essential to support the development of an independent environmental
legal knowledge system in China. Rooted in China's judicial tradition, which
emphasizes substantive rationality, traditional legal theories have primarily
focused on environmental law. However, the contemporary practices in the rule
of law have created an unclear trajectory for climate litigation. Research in
this area has long been trapped in a paradigm that relies on lawsuits for
ecological environmental damage compensation and environmental public interest
litigation, leading to a significant disconnect between theoretical frameworks
and practical application. With the advancement of the "dual carbon" strategic
goals-carbon peaking and carbon neutrality-it has become imperative to redefine
the concept of climate litigation within the Chinese context. We need to
establish a theoretical framework that aligns with the "dual carbon" objectives
while providing theoretical and institutional support for climate litigation,
ultimately contributing to the international discourse on climate justice.
Additionally, Hong Kong's proactive climate governance and robust ESG
(Environmental, Social, and Governance) practices provide valuable insights for
developing comprehensive climate litigation mechanisms. Based on this analysis,
we propose concrete plans for building a climate litigation system in China,
establishing a preventive relief system and a multi-source legal framework at
the substantive level and developing climate judicial mechanisms for mitigation
and adaptation at the procedural level.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03903v1' target='_blank'>Caribou -- A versatile data acquisition system for silicon pixel
  detector prototyping</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Younes Otarid, Mathieu Benoit, Eric Buschmann, Hucheng Chen, Dominik Dannheim, Thomas Koffas, Ryan St-Jean, Simon Spannagel, Shaochun Tang, Tomas Vanat</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 09:25:28</h6>
<p class='card-text'>Caribou is a versatile data acquisition system used in multiple collaborative
frameworks (CERN EP R&D, DRD3, AIDAinnova, Tangerine) for laboratory and
test-beam qualification of novel silicon pixel detector prototypes. The system
is built around a common hardware, firmware and software stack shared accross
different projects, thereby drastically reducing the development effort and
cost. It consists of a custom Control and Readout (CaR) board and a commercial
Xilinx Zynq System-on-Chip (SoC) platform. The SoC platform runs a full Yocto
distribution integrating the custom software framework (Peary) and a custom
FPGA firmware built within a common firmware infrastructure (Boreal). The CaR
board provides a hardware environment featuring various services such as
powering, slow-control, and high-speed data links for the target detector
prototype. Boreal and Peary, in turn, offer firmware and software architectures
that enable seamless integration of control and readout for new devices. While
the first version of the system used a SoC platform based on the ZC706
evaluation board, migration to a Zynq UltraScale+ architecture is progressing
towards the support of the ZCU102 board and the ultimate objective of
integrating the SoC functionality directly into the CaR board, eliminating the
need for separate evaluation boards. This paper describes the Caribou system,
focusing on the latest project developments and showcasing progress and future
plans across its hardware, firmware, and software components.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03831v1' target='_blank'>Optimizing Bayesian model selection for equation of state of cold
  neutron stars</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rahul Kashyap, Ish Gupta, Arnab Dhani, Monica Bapna, Bangalore Sathyaprakash</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 07:31:18</h6>
<p class='card-text'>We introduce a computational framework, Bayesian Evidence calculation fOr
Model Selection (BEOMS) to evaluate multiple Bayesian model selection methods
in the context of determining the equation of state (EOS) for cold neutron star
(NS), focusing on their performance with current and next-generation
gravitational wave (GW) observatories. We conduct a systematic comparison of
various EOS models by using posterior distributions obtained from EOS-agnostic
Bayesian inference of binary parameters applied to GWs from a population of
binary neutron star (BNS) mergers. The cumulative evidence for each model is
calculated in a multi-dimensional parameter space characterized by neutron star
masses and tidal deformabilities. Our findings indicate that Bayesian model
selection is most effective when performed in the two-dimensional subspace of
component mass and tidal deformability, requiring fewer events to distinguish
between EOS models with high confidence. Furthermore, we establish a
relationship between the precision of tidal deformability measurements and the
accuracy of model selection, taking into account the evolving sensitivities of
current and planned GW observatories. BEOMS offers computational efficiency and
can be adapted to execute model selection for gravitational wave data from
other sources.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04399v1' target='_blank'>Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks
  of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bokeng Zheng, Bo Rao, Tianxiang Zhu, Chee Wei Tan, Jingpu Duan, Zhi Zhou, Xu Chen, Xiaoxi Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 07:23:40</h6>
<p class='card-text'>Advances in artificial intelligence (AI) including foundation models (FMs),
are increasingly transforming human society, with smart city driving the
evolution of urban living.Meanwhile, vehicle crowdsensing (VCS) has emerged as
a key enabler, leveraging vehicles' mobility and sensor-equipped capabilities.
In particular, ride-hailing vehicles can effectively facilitate flexible data
collection and contribute towards urban intelligence, despite resource
limitations. Therefore, this work explores a promising scenario, where
edge-assisted vehicles perform joint tasks of order serving and the emerging
foundation model fine-tuning using various urban data. However, integrating the
VCS AI task with the conventional order serving task is challenging, due to
their inconsistent spatio-temporal characteristics: (i) The distributions of
ride orders and data point-of-interests (PoIs) may not coincide in geography,
both following a priori unknown patterns; (ii) they have distinct forms of
temporal effects, i.e., prolonged waiting makes orders become instantly invalid
while data with increased staleness gradually reduces its utility for model
fine-tuning.To overcome these obstacles, we propose an online framework based
on multi-agent reinforcement learning (MARL) with careful augmentation. A new
quality-of-service (QoS) metric is designed to characterize and balance the
utility of the two joint tasks, under the effects of varying data volumes and
staleness. We also integrate graph neural networks (GNNs) with MARL to enhance
state representations, capturing graph-structured, time-varying dependencies
among vehicles and across locations. Extensive experiments on our testbed
simulator, utilizing various real-world foundation model fine-tuning tasks and
the New York City Taxi ride order dataset, demonstrate the advantage of our
proposed method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03695v1' target='_blank'>Reduce Lap Time for Autonomous Racing with Curvature-Integrated MPCC
  Local Trajectory Planning Method</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhouheng Li, Lei Xie, Cheng Hu, Hongye Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 01:03:54</h6>
<p class='card-text'>The widespread application of autonomous driving technology has significantly
advanced the field of autonomous racing. Model Predictive Contouring Control
(MPCC) is a highly effective local trajectory planning method for autonomous
racing. However, the traditional MPCC method struggles with racetracks that
have significant curvature changes, limiting the performance of the vehicle
during autonomous racing. To address this issue, we propose a
curvature-integrated MPCC (CiMPCC) local trajectory planning method for
autonomous racing. This method optimizes the velocity of the local trajectory
based on the curvature of the racetrack centerline. The specific implementation
involves mapping the curvature of the racetrack centerline to a reference
velocity profile, which is then incorporated into the cost function for
optimizing the velocity of the local trajectory. This reference velocity
profile is created by normalizing and mapping the curvature of the racetrack
centerline, thereby ensuring efficient and performance-oriented local
trajectory planning in racetracks with significant curvature. The proposed
CiMPCC method has been experimented on a self-built 1:10 scale F1TENTH racing
vehicle deployed with ROS platform. The experimental results demonstrate that
the proposed method achieves outstanding results on a challenging racetrack
with sharp curvature, improving the overall lap time by 11.4%-12.5% compared to
other autonomous racing trajectory planning methods. Our code is available at
https://github.com/zhouhengli/CiMPCC.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03676v1' target='_blank'>Anytime Planning for End-Effector Trajectory Tracking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yeping Wang, Michael Gleicher</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 23:49:45</h6>
<p class='card-text'>End-effector trajectory tracking algorithms find joint motions that drive
robot manipulators to track reference trajectories. In practical scenarios,
anytime algorithms are preferred for their ability to quickly generate initial
motions and continuously refine them over time. In this paper, we present an
algorithmic framework that adapts common graph-based trajectory tracking
algorithms to be anytime and enhances their efficiency and effectiveness. Our
key insight is to identify guide paths that approximately track the reference
trajectory and strategically bias sampling toward the guide paths. We
demonstrate the effectiveness of the proposed framework by restructuring two
existing graph-based trajectory tracking algorithms and evaluating the updated
algorithms in three experiments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03607v1' target='_blank'>Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinhao Liang, Jacob K Christopher, Sven Koenig, Ferdinando Fioretto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 20:51:28</h6>
<p class='card-text'>Recent advances in diffusion models hold significant potential in robotics,
enabling the generation of diverse and smooth trajectories directly from raw
representations of the environment. Despite this promise, applying diffusion
models to motion planning remains challenging due to their difficulty in
enforcing critical constraints, such as collision avoidance and kinematic
feasibility. These limitations become even more pronounced in Multi-Robot
Motion Planning (MRMP), where multiple robots must coordinate in shared spaces.
To address this challenge, this work proposes Simultaneous MRMP Diffusion
(SMD), a novel approach integrating constrained optimization into the diffusion
sampling process to produce collision-free, kinematically feasible
trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark
to evaluate trajectory planning algorithms across scenarios with varying robot
densities, obstacle complexities, and motion constraints. Experimental results
show SMD consistently outperforms classical and learning-based motion planners,
achieving higher success rates and efficiency in complex multi-robot
environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03550v1' target='_blank'>TD-M(PC)$^2$: Improving Temporal Difference MPC Through Policy
  Constraint</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haotian Lin, Pengcheng Wang, Jeff Schneider, Guanya Shi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 19:08:42</h6>
<p class='card-text'>Model-based reinforcement learning algorithms that combine model-based
planning and learned value/policy prior have gained significant recognition for
their high data efficiency and superior performance in continuous control.
However, we discover that existing methods that rely on standard SAC-style
policy iteration for value learning, directly using data generated by the
planner, often result in \emph{persistent value overestimation}. Through
theoretical analysis and experiments, we argue that this issue is deeply rooted
in the structural policy mismatch between the data generation policy that is
always bootstrapped by the planner and the learned policy prior. To mitigate
such a mismatch in a minimalist way, we propose a policy regularization term
reducing out-of-distribution (OOD) queries, thereby improving value learning.
Our method involves minimum changes on top of existing frameworks and requires
no additional computation. Extensive experiments demonstrate that the proposed
approach improves performance over baselines such as TD-MPC2 by large margins,
particularly in 61-DoF humanoid tasks. View qualitative results at
https://darthutopian.github.io/tdmpc_square/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03547v1' target='_blank'>The Proper Motion of Strongly Lensed Binary Neutron Star Mergers in
  LIGO/Virgo/Kagra can be Constrained by Measuring Doppler Induced
  Gravitational Wave Dephasing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lorenz Zwick, Johan Samsing</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 19:03:02</h6>
<p class='card-text'>Strongly lensed binary neutron star (NS-NS) mergers are expected to be
observed once LIGO/Virgo/Kagra reaches the planned A+ or proposed A\#
sensitivity. We demonstrate that the relative transverse velocity of the
source-lens system can be constrained by comparing the phase of the two
associated gravitational wave (GW) images, using both semi-analytical and
numerical Bayesian methods. For A+ sensitivity, a one-sigma NS-NS merger signal
in magnification $(\mu=200)$ and redshift $(z_{\rm S}=1)$ will carry a
marginally detectable dephasing signature for a source transverse velocity of
$\sim 1800$ km/s. This is comparable to the velocity dispersion of large galaxy
clusters. Assuming the same population distribution, the most likely source
parameters of $\mu=100$ and $z_{\rm S}=1.4$ are always expected to showcase
detectable dephasing imprints for A\# sensitivity, provided they are moving
with transverse velocities larger than $\sim 2000$ km/s. We conclude that a
first measurement of the relative transverse velocity of a source via GW
dephasing methods is likely only a few years away.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03540v3' target='_blank'>Path Planning for Masked Diffusion Model Sampling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fred Zhangzhi Peng, Zachary Bezemek, Sawan Patel, Jarrid Rector-Brooks, Sherwood Yao, Alexander Tong, Pranam Chatterjee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 19:00:52</h6>
<p class='card-text'>In this paper, we explore how token unmasking order influences generative
quality in masked diffusion models (MDMs). We derive an expanded evidence lower
bound (ELBO) that introduces a planner to select which tokens to unmask at each
step. Our analysis reveals that alternative unmasking strategies can enhance
generation performance. Building on this, we propose Path Planning (P2), a
sampling framework that uses a pre-trained BERT model or the denoiser itself to
guide unmasking decisions. P2 generalizes all known MDM sampling strategies and
significantly improves performance across diverse domains, including language
generation (in-context learning, code generation, story infilling, mathematical
reasoning, reverse curse correction) and biological sequence generation
(protein and RNA sequences).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03454v1' target='_blank'>Kineto-Dynamical Planning and Accurate Execution of Minimum-Time
  Maneuvers on Three-Dimensional Circuits</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mattia Piccinini, Sebastiano Taddei, Johannes Betz, Francesco Biral</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 18:53:50</h6>
<p class='card-text'>Online planning and execution of minimum-time maneuvers on three-dimensional
(3D) circuits is an open challenge in autonomous vehicle racing. In this paper,
we present an artificial race driver (ARD) to learn the vehicle dynamics, plan
and execute minimum-time maneuvers on a 3D track. ARD integrates a novel
kineto-dynamical (KD) vehicle model for trajectory planning with economic
nonlinear model predictive control (E-NMPC). We use a high-fidelity vehicle
simulator (VS) to compare the closed-loop ARD results with a minimum-lap-time
optimal control problem (MLT-VS), solved offline with the same VS. Our ARD sets
lap times close to the MLT-VS, and the new KD model outperforms a literature
benchmark. Finally, we study the vehicle trajectories, to assess the
re-planning capabilities of ARD under execution errors. A video with the main
results is available as supplementary material.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03412v1' target='_blank'>Deep Reinforcement Learning-Based Optimization of Second-Life Battery
  Utilization in Electric Vehicles Charging Stations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rouzbeh Haghighi, Ali Hassan, Van-Hai Bui, Akhtar Hussain, Wencong Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 17:50:53</h6>
<p class='card-text'>The rapid rise in electric vehicle (EV) adoption presents significant
challenges in managing the vast number of retired EV batteries. Research
indicates that second-life batteries (SLBs) from EVs typically retain
considerable residual capacity, offering extended utility. These batteries can
be effectively repurposed for use in EV charging stations (EVCS), providing a
cost-effective alternative to new batteries and reducing overall planning
costs. Integrating battery energy storage systems (BESS) with SLBs into EVCS is
a promising strategy to alleviate system overload. However, efficient operation
of EVCS with integrated BESS is hindered by uncertainties such as fluctuating
EV arrival and departure times and variable power prices from the grid. This
paper presents a deep reinforcement learning-based (DRL) planning framework for
EV charging stations with BESS, leveraging SLBs. We employ the advanced soft
actor-critic (SAC) approach, training the model on a year's worth of data to
account for seasonal variations, including weekdays and holidays. A tailored
reward function enables effective offline training, allowing real-time
optimization of EVCS operations under uncertainty.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03360v1' target='_blank'>A Beam's Eye View to Fluence Maps 3D Network for Ultra Fast VMAT
  Radiotherapy Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simon Arberet, Florin C. Ghesu, Riqiang Gao, Martin Kraus, Jonathan Sackett, Esa Kuusela, Ali Kamen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 16:56:17</h6>
<p class='card-text'>Volumetric Modulated Arc Therapy (VMAT) revolutionizes cancer treatment by
precisely delivering radiation while sparing healthy tissues. Fluence maps
generation, crucial in VMAT planning, traditionally involves complex and
iterative, and thus time consuming processes. These fluence maps are
subsequently leveraged for leaf-sequence. The deep-learning approach presented
in this article aims to expedite this by directly predicting fluence maps from
patient data. We developed a 3D network which we trained in a supervised way
using a combination of L1 and L2 losses, and RT plans generated by Eclipse and
from the REQUITE dataset, taking the RT dose map as input and the fluence maps
computed from the corresponding RT plans as target. Our network predicts
jointly the 180 fluence maps corresponding to the 180 control points (CP) of
single arc VMAT plans. In order to help the network, we pre-process the input
dose by computing the projections of the 3D dose map to the beam's eye view
(BEV) of the 180 CPs, in the same coordinate system as the fluence maps. We
generated over 2000 VMAT plans using Eclipse to scale up the dataset size.
Additionally, we evaluated various network architectures and analyzed the
impact of increasing the dataset size. We are measuring the performance in the
2D fluence maps domain using image metrics (PSNR, SSIM), as well as in the 3D
dose domain using the dose-volume histogram (DVH) on a validation dataset. The
network inference, which does not include the data loading and processing, is
less than 20ms. Using our proposed 3D network architecture as well as
increasing the dataset size using Eclipse improved the fluence map
reconstruction performance by approximately 8 dB in PSNR compared to a U-Net
architecture trained on the original REQUITE dataset. The resulting DVHs are
very close to the one of the input target dose.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03322v1' target='_blank'>An efficient end-to-end computational framework for the generation of
  ECG calibrated volumetric models of human atrial electrophysiology</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Elena Zappon, Luca Azzolin, Matthias A. F. Gsell, Franz Thaler, Anton J. Prassl, Robert Arnold, Karli Gillette, Mohammadreza Kariman, Martin Manninger-Wünscher, Daniel Scherr, Aurel Neic, Martin Urschler, Christoph M. Augustin, Edward J. Vigmond, Gernot Plank</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 16:21:37</h6>
<p class='card-text'>Computational models of atrial electrophysiology (EP) are increasingly
utilized for applications such as the development of advanced mapping systems,
personalized clinical therapy planning, and the generation of virtual cohorts
and digital twins. These models have the potential to establish robust causal
links between simulated in silico behaviors and observed human atrial EP,
enabling safer, cost-effective, and comprehensive exploration of atrial
dynamics. However, current state-of-the-art approaches lack the fidelity and
scalability required for regulatory-grade applications, particularly in
creating high-quality virtual cohorts or patient-specific digital twins.
Challenges include anatomically accurate model generation, calibration to
sparse and uncertain clinical data, and computational efficiency within a
streamlined workflow. This study addresses these limitations by introducing
novel methodologies integrated into an automated end-to-end workflow for
generating high-fidelity digital twin snapshots and virtual cohorts of atrial
EP. These innovations include: (i) automated multi-scale generation of
volumetric biatrial models with detailed anatomical structures and fiber
architecture; (ii) a robust method for defining space-varying atrial parameter
fields; (iii) a parametric approach for modeling inter-atrial conduction
pathways; and (iv) an efficient forward EP model for high-fidelity
electrocardiogram computation. We evaluated this workflow on a cohort of 50
atrial fibrillation patients, producing high-quality meshes suitable for
reaction-eikonal and reaction-diffusion models and demonstrating the ability to
simulate atrial ECGs under parametrically controlled conditions. These
advancements represent a critical step toward scalable, precise, and clinically
applicable digital twin models and virtual cohorts, enabling enhanced
patient-specific predictions and therapeutic planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03317v1' target='_blank'>Contact-Aware Motion Planning Among Movable Objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haokun Wang, Qianhao Wang, Fei Gao, Shaojie Shen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 16:15:46</h6>
<p class='card-text'>Most existing methods for motion planning of mobile robots involve generating
collision-free trajectories. However, these methods focusing solely on contact
avoidance may limit the robots' locomotion and can not be applied to tasks
where contact is inevitable or intentional. To address these issues, we propose
a novel contact-aware motion planning (CAMP) paradigm for robotic systems. Our
approach incorporates contact between robots and movable objects as
complementarity constraints in optimization-based trajectory planning. By
leveraging augmented Lagrangian methods (ALMs), we efficiently solve the
optimization problem with complementarity constraints, producing
spatial-temporal optimal trajectories of the robots. Simulations demonstrate
that, compared to the state-of-the-art method, our proposed CAMP method expands
the reachable space of mobile robots, resulting in a significant improvement in
the success rate of two types of fundamental tasks: navigation among movable
objects (NAMO) and rearrangement of movable objects (RAMO). Real-world
experiments show that the trajectories generated by our proposed method are
feasible and quickly deployed in different tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03305v1' target='_blank'>HEP High Power Targetry Roadmap -- Workshop Report</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:F. Pellemoine, K. Ammigan, C. Barbier, S. Bidhar, A. Casella, M. Calviani, C. Densham, P. Hurh, D. Kim, D. Liu, K. Lynch, S. Makimura, D. Senor, V. Shiltsev, D. Stratakis, J. Terry, K. Yonehara</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 16:04:49</h6>
<p class='card-text'>Designing a reliable target is already a challenge for MW-class facilities
today and has led several major accelerator facilities to operate at lower than
design power due to target concerns. With present plans to increase beam power
for next generation accelerator facilities in the next decade, timely R and D
in support of robust high power targets is critical to secure the full physics
benefits of ambitious accelerator power upgrades. A comprehensive R and D
program must be implemented to address the many complex challenges faced by
multi MW beam intercepting devices. This roadmap is envisioned to be helpful to
the DOE-OHEP office when planning and prioritizing future R and D activities as
well as leveraging synergies across the Office of Science. The roadmap will be
extremely beneficial to the broader (external to DOE HEP) HPT community by
communicating OHEP s high level strategy and objectives for HPT R and D and
highlighting possible opportunities for collaboration.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03286v1' target='_blank'>Conditional Prediction by Simulation for Automated Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fabian Konstantinidis, Moritz Sackmann, Ulrich Hofmann, Christoph Stiller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 15:44:06</h6>
<p class='card-text'>Modular automated driving systems commonly handle prediction and planning as
sequential, separate tasks, thereby prohibiting cooperative maneuvers. To
enable cooperative planning, this work introduces a prediction model that
models the conditional dependencies between trajectories. For this, predictions
are generated by a microscopic traffic simulation, with the individual traffic
participants being controlled by a realistic behavior model trained via
Adversarial Inverse Reinforcement Learning. By assuming various candidate
trajectories for the automated vehicle, we generate predictions conditioned on
each of them. Furthermore, our approach allows the candidate trajectories to
adapt dynamically during the prediction rollout. Several example scenarios are
available at https://conditionalpredictionbysimulation.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18476v1' target='_blank'>AI's Impact on Traditional Software Development</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bhanuprakash Madupati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 14:58:09</h6>
<p class='card-text'>The application of artificial intelligence (AI) has brought key shifts in
conventional tactical software development, including code generation, testing
and debugging, and deployment. Waterfall and Agile development approaches,
which have been used for a long time, also widely employ manual and
well-planned steps. However, with the help of automated tools and models such
as OpenAI Codex and GPT-4, many aspects of the Software Development Life Cycle
(SDLC) have been made possible. This paper examines the technical aspect of
integrating AI into prior traditional software development life cycle
methodologies, emphasizing code automation, intelligent testing frameworks,
AI-based debugging, and continuous integration and deployment pipelines. The
analysis is also based on the advantages of utilizing AI for optimizations in
efficiency, accuracy, and development speed alongside issues like
over-dependence on AI, ethical questions, and technical constraints. Based on
the case and example given in this paper, it is clearly shown that the
self-improvement of AI in software development makes the process more dynamic,
autonomous, and optimized.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03214v1' target='_blank'>iVISPAR -- An Interactive Visual-Spatial Reasoning Benchmark for VLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Julius Mayer, Mohamad Ballout, Serwan Jassim, Farbod Nosrat Nezami, Elia Bruni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 14:29:01</h6>
<p class='card-text'>Vision-Language Models (VLMs) are known to struggle with spatial reasoning
and visual alignment. To help overcome these limitations, we introduce iVISPAR,
an interactive multi-modal benchmark designed to evaluate the spatial reasoning
capabilities of VLMs acting as agents. iVISPAR is based on a variant of the
sliding tile puzzle-a classic problem that demands logical planning, spatial
awareness, and multi-step reasoning. The benchmark supports visual 2D, 3D, and
text-based input modalities, enabling comprehensive assessments of VLMs'
planning and reasoning skills. We evaluate a broad suite of state-of-the-art
open-source and closed-source VLMs, comparing their performance while also
providing optimal path solutions and a human baseline to assess the task's
complexity and feasibility for humans. Results indicate that while some VLMs
perform well on simple spatial tasks, they encounter difficulties with more
complex configurations and problem properties. Notably, while VLMs generally
perform better in 2D vision compared to 3D or text-based representations, they
consistently fall short of human performance, illustrating the persistent
challenge of visual alignment. This highlights critical gaps in current VLM
capabilities, highlighting their limitations in achieving human-level
cognition.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03144v1' target='_blank'>Group Trip Planning Query Problem with Multimodal Journey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dildar Ali, Suman Banerjee, Yamuna Prasad</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 13:13:41</h6>
<p class='card-text'>In Group Trip Planning (GTP) Query Problem, we are given a city road network
where a number of Points of Interest (PoI) have been marked with their
respective categories (e.g., Cafeteria, Park, Movie Theater, etc.). A group of
agents want to visit one PoI from every category from their respective starting
location and once finished, they want to reach their respective destinations.
This problem asks which PoI from every category should be chosen so that the
aggregated travel cost of the group is minimized. This problem has been studied
extensively in the last decade, and several solution approaches have been
proposed. However, to the best of our knowledge, none of the existing studies
have considered the different modalities of the journey, which makes the
problem more practical. To bridge this gap, we introduce and study the GTP
Query Problem with Multimodal Journey in this paper. Along with the other
inputs of the GTP Query Problem, we are also given the different modalities of
the journey that are available and their respective cost. Now, the problem is
not only to select the PoIs from respective categories but also to select the
modality of the journey. For this problem, we have proposed an efficient
solution approach, which has been analyzed to understand their time and space
requirements. A large number of experiments have been conducted using real-life
datasets and the results have been reported. From the results, we observe that
the PoIs and modality of journey recommended by the proposed solution approach
lead to much less time and cost than the baseline methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04367v1' target='_blank'>Hybrid Deep Learning Framework for Classification of Kidney CT Images:
  Diagnosis of Stones, Cysts, and Tumors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kiran Sharma, Ziya Uddin, Adarsh Wadal, Dhruv Gupta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 08:38:35</h6>
<p class='card-text'>Medical image classification is a vital research area that utilizes advanced
computational techniques to improve disease diagnosis and treatment planning.
Deep learning models, especially Convolutional Neural Networks (CNNs), have
transformed this field by providing automated and precise analysis of complex
medical images. This study introduces a hybrid deep learning model that
integrates a pre-trained ResNet101 with a custom CNN to classify kidney CT
images into four categories: normal, stone, cyst, and tumor. The proposed model
leverages feature fusion to enhance classification accuracy, achieving 99.73%
training accuracy and 100% testing accuracy. Using a dataset of 12,446 CT
images and advanced feature mapping techniques, the hybrid CNN model
outperforms standalone ResNet101. This architecture delivers a robust and
efficient solution for automated kidney disease diagnosis, providing improved
precision, recall, and reduced testing time, making it highly suitable for
clinical applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02829v2' target='_blank'>Global Contact-Rich Planning with Sparsity-Rich Semidefinite Relaxations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shucheng Kang, Guorui Liu, Heng Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 02:13:51</h6>
<p class='card-text'>We show that contact-rich motion planning is also sparsity-rich when viewed
as polynomial optimization (POP). We can exploit not only the correlative and
term sparsity patterns that are general to all POPs, but also specialized
sparsity patterns from the robot kinematic structure and the separability of
contact modes. Such sparsity enables the design of high-order but sparse
semidefinite programming (SDPs) relaxations--building upon Lasserre's moment
and sums of squares hierarchy--that (i) can be solved in seconds by
off-the-shelf SDP solvers, and (ii) compute near globally optimal solutions to
the nonconvex contact-rich planning problems with small certified
suboptimality. Through extensive experiments both in simulation (Push Bot, Push
Box, Push Box with Obstacles, and Planar Hand) and real world (Push T), we
demonstrate the power of using convex SDP relaxations to generate global
contact-rich motion plans. As a contribution of independent interest, we
release the Sparse Polynomial Optimization Toolbox (SPOT)--implemented in C++
with interfaces to both Python and Matlab--that automates sparsity exploitation
for robotics and beyond.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02802v1' target='_blank'>Consistent Client Simulation for Motivational Interviewing-based
  Counseling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, John Pinto, Jenny Giam, Kit Phey Leng, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Ee-peng Lim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 00:58:30</h6>
<p class='card-text'>Simulating human clients in mental health counseling is crucial for training
and evaluating counselors (both human or simulated) in a scalable manner.
Nevertheless, past research on client simulation did not focus on complex
conversation tasks such as mental health counseling. In these tasks, the
challenge is to ensure that the client's actions (i.e., interactions with the
counselor) are consistent with with its stipulated profiles and negative
behavior settings. In this paper, we propose a novel framework that supports
consistent client simulation for mental health counseling. Our framework tracks
the mental state of a simulated client, controls its state transitions, and
generates for each state behaviors consistent with the client's motivation,
beliefs, preferred plan to change, and receptivity. By varying the client
profile and receptivity, we demonstrate that consistent simulated clients for
different counseling scenarios can be effectively created. Both our automatic
and expert evaluations on the generated counseling sessions also show that our
client simulation method achieves higher consistency than previous methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02783v1' target='_blank'>Runway capacity expansion planning for public airports under demand
  uncertainty</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziyue Li, Joseph Y. J. Chow, Qianwen Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 23:59:33</h6>
<p class='card-text'>Flight delay is a significant issue affecting air travel. The runway system,
frequently falling short of demand, serves as a bottleneck. As demand
increases, runway capacity expansion becomes imperative to mitigate congestion.
However, the decision to expand runway capacity is challenging due to inherent
uncertainties in demand forecasts. This paper presents a novel approach to
modeling air traffic demand growth as a jump diffusion process, incorporating
two layers of uncertainty: Geometric Brownian Motion (GBM) for continuous
variability and a Poisson process to capture the impact of crisis events, such
as natural disasters or public health emergencies, on decision-making. We
propose a real options model to jointly evaluate the interrelated factors of
optimal runway capacity and investment timing under uncertainty, with
investment timing linked to trigger demand. The findings suggest that increased
uncertainty indicates more conservative decision-making. Furthermore, the
relationship between optimal investment timing and expansion size is complex:
if the expansion size remains unchanged, the trigger demand decreases as the
demand growth rate increases; if the expansion size experiences a jump, the
trigger demand also exhibits a sharp rise. This work provides valuable insights
for airport authorities for informed capacity expansion decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02768v1' target='_blank'>Planning with affordances: Integrating learned affordance models and
  symbolic planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rajesh Mangannavar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 23:15:38</h6>
<p class='card-text'>Intelligent agents working in real-world environments must be able to learn
about the environment and its capabilities which enable them to take actions to
change to the state of the world to complete a complex multi-step task in a
photorealistic environment. Learning about the environment is especially
important to perform various multiple-step tasks without having to redefine an
agent's action set for different tasks or environment settings. In our work, we
augment an existing task and motion planning framework with learned affordance
models of objects in the world to enable planning and executing multi-step
tasks using learned models. Each task can be seen as changing the current state
of the world to a given goal state. The affordance models provide us with what
actions are possible and how to perform those actions in any given state. A
symbolic planning algorithm uses this information and the starting and goal
state to create a feasible plan to reach the desired goal state to complete a
given task. We demonstrate our approach in a virtual 3D photorealistic
environment, AI2-Thor, and evaluate it on real-world tasks. Our results show
that our agent quickly learns how to interact with the environment and is well
prepared to perform tasks such as "Moving an object out of the way to reach the
desired location."</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02677v1' target='_blank'>Quality assurance and reporting for FLASH clinical trials:the experience
  of the FEATHER trial</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Isabella Colizzi, Robert Schaefer, Jonas Brueckner, Gaia Dellepiane, Martin Grossmann, Maximilan Koerner, Antony John Lomax, David Meer, Benno Rohrer, Carla Rohrer Bley, Michele Togno, Serena Psoroulas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 19:36:54</h6>
<p class='card-text'>Research on ultra-high dose rate (UHDR) radiation therapy has indicated its
potential to spare normal tissue while maintaining equivalent tumor control
compared to conventional treatments. First clinical trials are underway. The
randomized phase II/III FEATHER clinical trial at the Paul Scherrer Institute
in collaboration with the University of Zurich Animal Hospital is one of the
first curative domestic animal trials to be attempted, and it is designed to
provide a good example for human trials. However, the lack of standardized
quality assurance (QA) guidelines for FLASH clinical trials presents a
significant challenge in trial design. This work aims to demonstrate the
development and testing of QA and reporting procedures implemented in the
FEATHER clinical trial. We have expanded the clinical QA program to include
UHDR-specific QA and additional patient-specific QA. Furthermore, we have
modified the monitor readout to enable time-resolved measurements, allowing
delivery log files to be used for dose and dose rate recalculations. Finally,
we developed a reporting strategy encompassing relevant parameters for
retrospective studies. We evaluated our QA and reporting procedures with
simulated treatments. This testing confirmed that our QA procedures effectively
ensure the correct and safe delivery of the planned dose. Additionally, we
demonstrated that we could reconstruct the delivered dose and dose rate using
the delivery log files. We developed and used in practice a comprehensive QA
and reporting protocol for a FLASH clinical trial at the Paul Scherrer
Institute. This work aims to establish guidelines and standardize reporting
practices for future advancements in the FLASH-RT field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02666v1' target='_blank'>Deep Reinforcement Learning Enabled Persistent Surveillance with
  Energy-Aware UAV-UGV Systems for Disaster Management Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md Safwan Mondal, Subramanian Ramasamy, Pranav Bhounsule</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 19:11:02</h6>
<p class='card-text'>Integrating Unmanned Aerial Vehicles (UAVs) with Unmanned Ground Vehicles
(UGVs) provides an effective solution for persistent surveillance in disaster
management. UAVs excel at covering large areas rapidly, but their range is
limited by battery capacity. UGVs, though slower, can carry larger batteries
for extended missions. By using UGVs as mobile recharging stations, UAVs can
extend mission duration through periodic refueling, leveraging the
complementary strengths of both systems. To optimize this energy-aware UAV-UGV
cooperative routing problem, we propose a planning framework that determines
optimal routes and recharging points between a UAV and a UGV. Our solution
employs a deep reinforcement learning (DRL) framework built on an
encoder-decoder transformer architecture with multi-head attention mechanisms.
This architecture enables the model to sequentially select actions for visiting
mission points and coordinating recharging rendezvous between the UAV and UGV.
The DRL model is trained to minimize the age periods (the time gap between
consecutive visits) of mission points, ensuring effective surveillance. We
evaluate the framework across various problem sizes and distributions,
comparing its performance against heuristic methods and an existing
learning-based model. Results show that our approach consistently outperforms
these baselines in both solution quality and runtime. Additionally, we
demonstrate the DRL policy's applicability in a real-world disaster scenario as
a case study and explore its potential for online mission planning to handle
dynamic changes. Adapting the DRL policy for priority-driven surveillance
highlights the model's generalizability for real-time disaster response.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02664v1' target='_blank'>Differentiable Composite Neural Signed Distance Fields for Robot
  Navigation in Dynamic Indoor Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:S. Talha Bukhari, Daniel Lawson, Ahmed H. Qureshi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 19:07:29</h6>
<p class='card-text'>Neural Signed Distance Fields (SDFs) provide a differentiable environment
representation to readily obtain collision checks and well-defined gradients
for robot navigation tasks. However, updating neural SDFs as the scene evolves
entails re-training, which is tedious, time consuming, and inefficient, making
it unsuitable for robot navigation with limited field-of-view in dynamic
environments. Towards this objective, we propose a compositional framework of
neural SDFs to solve robot navigation in indoor environments using only an
onboard RGB-D sensor. Our framework embodies a dual mode procedure for
trajectory optimization, with different modes using complementary methods of
modeling collision costs and collision avoidance gradients. The primary stage
queries the robot body's SDF, swept along the route to goal, at the obstacle
point cloud, enabling swift local optimization of trajectories. The secondary
stage infers the visible scene's SDF by aligning and composing the SDF
representations of its constituents, providing better informed costs and
gradients for trajectory optimization. The dual mode procedure combines the
best of both stages, achieving a success rate of 98%, 14.4% higher than
baseline with comparable amortized plan time on iGibson 2.0. We also
demonstrate its effectiveness in adapting to real-world indoor scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02578v1' target='_blank'>Innovating the software engineering class through multi-team development</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Allan Brockenbrough</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 18:54:43</h6>
<p class='card-text'>Often software engineering classes have the student concentrate on designing
and planning the project but stop short of actual student team development of
code. This leads to criticism by employers of new graduates that they are
missing skills in working in teams and coordinating multiple overlapping
changes to a code base. Additionally, students that are not actively
experiencing team development are unprepared to understand and modify existing
legacy-code bases written by others. This paper presents a new approach to
teaching undergraduate software engineering that emphasizes not only software
engineering methodology but also experiencing development as a member of a team
and modifying a legacy code base. Our innovative software engineering course
begins with learning the fundamentals of software engineering, followed by
examining an existing framework of a social media application. The students are
then grouped into multiple software teams, each focusing on a different aspect
of the app. The separate teams must define requirements, design, and provide
documentation on the services. Using an Agile development approach, the teams
incrementally add to the code base and demonstrate features as the application
evolves. Subsequent iterations of the class pick up the prior students code
base, providing experience working with a legacy code base. Preliminary results
of using this approach at the university are presented in this paper including
quantitative analysis. Analysis of student software submissions to the
cloud-based code repository shows student engagement and contributions over the
span of the course. Positive student evaluations show the effectiveness of
applying the principles of software engineering to the development of a complex
solution in a team environment. Keywords: Software engineering, teaching,
college computer science, innovative methods, agile.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02550v1' target='_blank'>Reachability-Based Contingency Planning against Multi-Modal Predictions
  with Branch MPC</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohamed-Khalil Bouzidi, Bojan Derajic, Daniel Goehring, Joerg Reichardt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 18:20:31</h6>
<p class='card-text'>This paper presents a novel contingency planning framework that integrates
learning-based multi-modal predictions of traffic participants into Branch
Model Predictive Control (MPC). Leveraging reachability analysis, we address
the computational challenges associated with Branch MPC by organizing the
multitude of predictions into driving corridors. Analyzing the overlap between
these corridors, their number can be reduced through pruning and clustering
while ensuring safety since all prediction modes are preserved. These processed
corridors directly correspond to the distinct branches of the scenario tree and
provide an efficient constraint representation for the Branch MPC. We further
utilize the reachability for determining maximum feasible decision postponing
times, ensuring that branching decisions remain executable. Qualitative and
quantitative evaluations demonstrate significantly reduced computational
complexity and enhanced safety and comfort.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02549v1' target='_blank'>Anytime Incremental $ρ$POMDP Planning in Continuous Spaces</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ron Benchetrit, Idan Lev-Yehudi, Andrey Zhitnikov, Vadim Indelman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 18:19:40</h6>
<p class='card-text'>Partially Observable Markov Decision Processes (POMDPs) provide a robust
framework for decision-making under uncertainty in applications such as
autonomous driving and robotic exploration. Their extension, $\rho$POMDPs,
introduces belief-dependent rewards, enabling explicit reasoning about
uncertainty. Existing online $\rho$POMDP solvers for continuous spaces rely on
fixed belief representations, limiting adaptability and refinement - critical
for tasks such as information-gathering. We present $\rho$POMCPOW, an anytime
solver that dynamically refines belief representations, with formal guarantees
of improvement over time. To mitigate the high computational cost of updating
belief-dependent rewards, we propose a novel incremental computation approach.
We demonstrate its effectiveness for common entropy estimators, reducing
computational cost by orders of magnitude. Experimental results show that
$\rho$POMCPOW outperforms state-of-the-art solvers in both efficiency and
solution quality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02520v1' target='_blank'>Privacy by Design for Self-Sovereign Identity Systems: An in-depth
  Component Analysis completed by a Design Assistance Dashboard</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Montassar Naghmouchi, Maryline Laurent</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 17:42:29</h6>
<p class='card-text'>The use of Self-Sovereign Identity (SSI) systems for digital identity
management is gaining traction and interest. Countries such as Bhutan have
already implemented an SSI infrastructure to manage the identity of their
citizens. The EU, thanks to the revised eIDAS regulation, is opening the door
for SSI vendors to develop SSI systems for the planned EU digital identity
wallet. These developments, which fall within the sovereign domain, raise
questions about individual privacy.
  The purpose of this article is to help SSI solution designers make informed
choices to ensure that the designed solution is privacy-friendly. The
observation is that the range of possible solutions is very broad, from DID and
DID resolution methods to verifiable credential types, publicly available
information (e.g. in a blockchain), type of infrastructure, etc. As a result,
the article proposes (1) to group the elementary building blocks of a SSI
system into 5 structuring layers, (2) to analyze for each layer the privacy
implications of using the chosen building block, and (3) to provide a design
assistance dashboard that gives the complete picture of the SSI, and shows the
interdependencies between architectural choices and technical building blocks,
allowing designers to make informed choices and graphically achieve a SSI
solution that meets their need for privacy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02207v1' target='_blank'>Human-Aided Trajectory Planning for Automated Vehicles through
  Teleoperation and Arbitration Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nick Le Large, David Brecht, Willi Poh, Jan-Hendrik Pauls, Martin Lauer, Frank Diermeyer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 10:45:52</h6>
<p class='card-text'>Teleoperation enables remote human support of automated vehicles in scenarios
where the automation is not able to find an appropriate solution. Remote
assistance concepts, where operators provide discrete inputs to aid specific
automation modules like planning, is gaining interest due to its reduced
workload on the human remote operator and improved safety. However, these
concepts are challenging to implement and maintain due to their deep
integration and interaction with the automated driving system. In this paper,
we propose a solution to facilitate the implementation of remote assistance
concepts that intervene on planning level and extend the operational design
domain of the vehicle at runtime. Using arbitration graphs, a modular
decision-making framework, we integrate remote assistance into an existing
automated driving system without modifying the original software components.
Our simulative implementation demonstrates this approach in two use cases,
allowing operators to adjust planner constraints and enable trajectory
generation beyond nominal operational design domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02179v1' target='_blank'>Deep Ensemble approach for Enhancing Brain Tumor Segmentation in
  Resource-Limited Settings</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jeremiah Fadugba, Isabel Lieberman, Olabode Ajayi, Mansour Osman, Solomon Oluwole Akinola, Tinashe Mustvangwa, Dong Zhang, Udunna C Anazondo, Raymond Confidence</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 09:53:09</h6>
<p class='card-text'>Segmentation of brain tumors is a critical step in treatment planning, yet
manual segmentation is both time-consuming and subjective, relying heavily on
the expertise of radiologists. In Sub-Saharan Africa, this challenge is
magnified by overburdened medical systems and limited access to advanced
imaging modalities and expert radiologists. Automating brain tumor segmentation
using deep learning offers a promising solution. Convolutional Neural Networks
(CNNs), especially the U-Net architecture, have shown significant potential.
However, a major challenge remains: achieving generalizability across different
datasets. This study addresses this gap by developing a deep learning ensemble
that integrates UNet3D, V-Net, and MSA-VNet models for the semantic
segmentation of gliomas. By initially training on the BraTS-GLI dataset and
fine-tuning with the BraTS-SSA dataset, we enhance model performance. Our
ensemble approach significantly outperforms individual models, achieving DICE
scores of 0.8358 for Tumor Core, 0.8521 for Whole Tumor, and 0.8167 for
Enhancing Tumor. These results underscore the potential of ensemble methods in
improving the accuracy and reliability of automated brain tumor segmentation,
particularly in resource-limited settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02174v1' target='_blank'>The TechDebt Game -- Enabling Discussions about Technical Debt</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marion Wiese, Angelina Heinrichs, Nino Rusieshvili, Rodrigo Rebouças de Almeida, Klara Borowa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 09:48:02</h6>
<p class='card-text'>Context. Technical Debt (TD), defined as software constructs that are
beneficial in the short term but may hinder future change, is a frequently used
term in software development practice. Nevertheless, practitioners do not
always fully understand its definition and, in particular, conceptual model.
Previous research highlights that communication about TD is challenging,
especially with non-technical stakeholders. Discussions on this topic often
cause conflicts due to misunderstandings related to other stakeholders'
perspectives. Goal. We designed a board game to emulate TD concepts to make
them tangible to all stakeholders, including non-technical ones. The game aims
to encourage discussions about TD in an emulated and safe environment, thereby
avoiding real-life conflicts. Method. To evaluate the game's effectiveness, we
surveyed 46 practitioners from diverse domains, positions, and experience
levels who played the game in 13 sessions following extensive testing during
its development. In addition to the players' general feedback, we examined
situations where players recognized new insights about TD or connected game
scenarios to real-life experiences. Results. Overall, the feedback on the game
and its enjoyment factor were highly positive. While developers and software
architects often connected game situations to their real-world experiences,
non-technical stakeholders, such as scrum masters, product owners, and less
experienced developers, encountered multiple new insights on TD. Numerous
players have shifted their attitudes toward TD and have outlined a plan to
modify their behavior regarding TD management. Conclusions. Although the game
may not lead to long-term behavior change among stakeholders, participants'
feedback provides evidence that it might serve as a valuable starting point for
team discussions on technical debt management.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02097v1' target='_blank'>VerteNet -- A Multi-Context Hybrid CNN Transformer for Accurate
  Vertebral Landmark Localization in Lateral Spine DXA Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zaid Ilyas, Arooba Maqsood, Afsah Saleem, Erchuan Zhang, David Suter, Parminder Raina, Jonathan M. Hodgson, John T. Schousboe, William D. Leslie, Joshua R. Lewis, Syed Zulqarnain Gilani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 08:27:51</h6>
<p class='card-text'>Lateral Spine Image (LSI) analysis is important for medical diagnosis,
treatment planning, and detailed spinal health assessments. Although modalities
like Computed Tomography and Digital X-ray Imaging are commonly used, Dual
Energy X-ray Absorptiometry (DXA) is often preferred due to lower radiation
exposure, seamless capture, and cost-effectiveness. Accurate Vertebral Landmark
Localization (VLL) on LSIs is important to detect spinal conditions like
kyphosis and lordosis, as well as assessing Abdominal Aortic Calcification
(AAC) using Inter-Vertebral Guides (IVGs). Nonetheless, few automated VLL
methodologies have concentrated on DXA LSIs. We present VerteNet, a hybrid
CNN-Transformer model featuring a novel dual-resolution attention mechanism in
self and cross-attention domains, referred to as Dual Resolution Self-Attention
(DRSA) and Dual Resolution Cross-Attention (DRCA). These mechanisms capture the
diverse frequencies in DXA images by operating at two different feature map
resolutions. Additionally, we design a Multi-Context Feature Fusion Block
(MCFB) that efficiently integrates the features using DRSA and DRCA. We train
VerteNet on 620 DXA LSIs from various machines and achieve superior results
compared to existing methods. We also design an algorithm that utilizes
VerteNet's predictions in estimating the Region of Interest (ROI) to detect
potential abdominal aorta cropping, where inadequate soft tissue hinders
calcification assessment. Additionally, we present a small proof-of-concept
study to show that IVGs generated from VLL information can improve inter-reader
correlation in AAC scoring, addressing two key areas of disagreement in expert
AAC-24 scoring: IVG placement and quality control for full abdominal aorta
assessment. The code for this work can be found at
https://github.com/zaidilyas89/VerteNet.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02071v1' target='_blank'>Sequential Multi-objective Multi-agent Reinforcement Learning Approach
  for Predictive Maintenance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yan Chen, Cheng Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 07:42:58</h6>
<p class='card-text'>Existing predictive maintenance (PdM) methods typically focus solely on
whether to replace system components without considering the costs incurred by
inspection. However, a well-considered approach should be able to minimize
Remaining Useful Life (RUL) at engine replacement while maximizing inspection
interval. To achieve this, multi-agent reinforcement learning (MARL) can be
introduced. However, due to the sequential and mutually constraining nature of
these 2 objectives, conventional MARL is not applicable. Therefore, this paper
introduces a novel framework and develops a Sequential Multi-objective
Multi-agent Proximal Policy Optimization (SMOMA-PPO) algorithm. Furthermore, to
provide comprehensive and effective degradation information to RL agents, we
also employed Gated Recurrent Unit, quantile regression, and probability
distribution fitting to develop a GRU-based RUL Prediction (GRP) model.
Experiments demonstrate that the GRP method significantly improves the accuracy
of RUL predictions in the later stages of system operation compared to existing
methods. When incorporating its output into SMOMA-PPO, we achieve at least a
15% reduction in average RUL without unscheduled replacements (UR), nearly a
10% increase in inspection interval, and an overall decrease in maintenance
costs. Importantly, our approach offers a new perspective for addressing
multi-objective maintenance planning with sequential constraints, effectively
enhancing system reliability and reducing maintenance expenses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02054v1' target='_blank'>RAPID: Robust and Agile Planner Using Inverse Reinforcement Learning for
  Vision-Based Drone Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minwoo Kim, Geunsik Bae, Jinwoo Lee, Woojae Shin, Changseung Kim, Myong-Yol Choi, Heejung Shin, Hyondong Oh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 06:42:08</h6>
<p class='card-text'>This paper introduces a learning-based visual planner for agile drone flight
in cluttered environments. The proposed planner generates collision-free
waypoints in milliseconds, enabling drones to perform agile maneuvers in
complex environments without building separate perception, mapping, and
planning modules. Learning-based methods, such as behavior cloning (BC) and
reinforcement learning (RL), demonstrate promising performance in visual
navigation but still face inherent limitations. BC is susceptible to
compounding errors due to limited expert imitation, while RL struggles with
reward function design and sample inefficiency. To address these limitations,
this paper proposes an inverse reinforcement learning (IRL)-based framework for
high-speed visual navigation. By leveraging IRL, it is possible to reduce the
number of interactions with simulation environments and improve capability to
deal with high-dimensional spaces while preserving the robustness of RL
policies. A motion primitive-based path planning algorithm collects an expert
dataset with privileged map data from diverse environments, ensuring
comprehensive scenario coverage. By leveraging both the acquired expert and
learner dataset gathered from the agent's interactions with the simulation
environments, a robust reward function and policy are learned across diverse
states. While the proposed method is trained in a simulation environment only,
it can be directly applied to real-world scenarios without additional training
or tuning. The performance of the proposed method is validated in both
simulation and real-world environments, including forests and various
structures. The trained policy achieves an average speed of 7 m/s and a maximum
speed of 8.8 m/s in real flight experiments. To the best of our knowledge, this
is the first work to successfully apply an IRL framework for high-speed visual
navigation of drones.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01956v1' target='_blank'>DHP: Discrete Hierarchical Planning for Hierarchical Reinforcement
  Learning Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shashank Sharma, Janina Hoffmann, Vinay Namboodiri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 03:05:55</h6>
<p class='card-text'>In this paper, we address the challenge of long-horizon visual planning tasks
using Hierarchical Reinforcement Learning (HRL). Our key contribution is a
Discrete Hierarchical Planning (DHP) method, an alternative to traditional
distance-based approaches. We provide theoretical foundations for the method
and demonstrate its effectiveness through extensive empirical evaluations.
  Our agent recursively predicts subgoals in the context of a long-term goal
and receives discrete rewards for constructing plans as compositions of
abstract actions. The method introduces a novel advantage estimation strategy
for tree trajectories, which inherently encourages shorter plans and enables
generalization beyond the maximum tree depth. The learned policy function
allows the agent to plan efficiently, requiring only $\log N$ computational
steps, making re-planning highly efficient. The agent, based on a soft-actor
critic (SAC) framework, is trained using on-policy imagination data.
Additionally, we propose a novel exploration strategy that enables the agent to
generate relevant training examples for the planning modules. We evaluate our
method on long-horizon visual planning tasks in a 25-room environment, where it
significantly outperforms previous benchmarks at success rate and average
episode length. Furthermore, an ablation study highlights the individual
contributions of key modules to the overall performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01937v1' target='_blank'>A Comprehensive Study of Bug-Fix Patterns in Autonomous Driving Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuntianyi Chen, Yuqi Huai, Yirui He, Shilong Li, Changnam Hong, Qi Alfred Chen, Joshua Garcia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 02:13:05</h6>
<p class='card-text'>As autonomous driving systems (ADSes) become increasingly complex and
integral to daily life, the importance of understanding the nature and
mitigation of software bugs in these systems has grown correspondingly.
Addressing the challenges of software maintenance in autonomous driving systems
(e.g., handling real-time system decisions and ensuring safety-critical
reliability) is crucial due to the unique combination of real-time
decision-making requirements and the high stakes of operational failures in
ADSes. The potential of automated tools in this domain is promising, yet there
remains a gap in our comprehension of the challenges faced and the strategies
employed during manual debugging and repair of such systems. In this paper, we
present an empirical study that investigates bug-fix patterns in ADSes, with
the aim of improving reliability and safety. We have analyzed the commit
histories and bug reports of two major autonomous driving projects, Apollo and
Autoware, from 1,331 bug fixes with the study of bug symptoms, root causes, and
bug-fix patterns. Our study reveals several dominant bug-fix patterns,
including those related to path planning, data flow, and configuration
management. Additionally, we find that the frequency distribution of bug-fix
patterns varies significantly depending on their nature and types and that
certain categories of bugs are recurrent and more challenging to exterminate.
Based on our findings, we propose a hierarchy of ADS bugs and two taxonomies of
15 syntactic bug-fix patterns and 27 semantic bug-fix patterns that offer
guidance for bug identification and resolution. We also contribute a benchmark
of 1,331 ADS bug-fix instances.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01918v1' target='_blank'>Wake-Informed 3D Path Planning for Autonomous Underwater Vehicles Using
  A* and Neural Network Approximations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zachary Cooper-Baldock, Stephen Turnock, Karl Sammut</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 01:23:23</h6>
<p class='card-text'>Autonomous Underwater Vehicles (AUVs) encounter significant energy, control
and navigation challenges in complex underwater environments, particularly
during close-proximity operations, such as launch and recovery (LAR), where
fluid interactions and wake effects present additional navigational and energy
challenges. Traditional path planning methods fail to incorporate these
detailed wake structures, resulting in increased energy consumption, reduced
control stability, and heightened safety risks. This paper presents a novel
wake-informed, 3D path planning approach that fully integrates localized wake
effects and global currents into the planning algorithm. Two variants of the A*
algorithm - a current-informed planner and a wake-informed planner - are
created to assess its validity and two neural network models are then trained
to approximate these planners for real-time applications. Both the A* planners
and NN models are evaluated using important metrics such as energy expenditure,
path length, and encounters with high-velocity and turbulent regions. The
results demonstrate a wake-informed A* planner consistently achieves the lowest
energy expenditure and minimizes encounters with high-velocity regions,
reducing energy consumption by up to 11.3%. The neural network models are
observed to offer computational speedup of 6 orders of magnitude, but exhibit
4.51 - 19.79% higher energy expenditures and 9.81 - 24.38% less optimal paths.
These findings underscore the importance of incorporating detailed wake
structures into traditional path planning algorithms and the benefits of neural
network approximations to enhance energy efficiency and operational safety for
AUVs in complex 3D domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01899v1' target='_blank'>Testing the wavelength dependence of oscillations and granulation in red
  giants using Kepler and TESS</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:K. R. Sreenivas, Timothy R. Bedding, Daniel Huber, Courtney L. Crawford, Dennis Stello, May G. Pedersen, Yaguang Li, Daniel Hey</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 00:08:45</h6>
<p class='card-text'>Stellar oscillations and granulation in red giants are both powered by
convection. Studying the wavelength dependence of their amplitudes can provide
useful insights on the driving mechanism. It is also important for plans to
carry out asteroseismology with the Nancy Grace Roman Space Telescope, which
will operate in the near infrared, to check the dependence of oscillations and
granulation on the observational wavelength. In this work, we aim to understand
how the oscillation and granulation power in red giants depend on the
wavelength and study how existing predictions compare with observations. We
measure the mean oscillation and granulation power of 279 Kepler red giants,
from the power density spectra derived using Kepler PDCSAP and TESS-SPOC light
curves. We find that selection of light curves is important for the study of
amplitudes, since different light curve products from TESS show different
values of amplitudes. We show that the oscillation and granulation power ratios
between TESS and Kepler match the theoretical prediction, confirming that both
decrease as we move to redder wavelengths. We also see that the mean ratios of
oscillations and granulation agree, suggesting that oscillation and granulation
have the same wavelength dependence. We also find that the mean
height-to-background ratio for Kepler agrees with previous results and shows
good agreement with TESS. These results suggest that the granulation signals
would not severely affect the detection of oscillations. We checked the
dependence of these ratio between Kepler and TESS on stellar parameters, and
see no trends.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01894v1' target='_blank'>SimBEV: A Synthetic Multi-Task Multi-Sensor Driving Data Generation Tool
  and Dataset</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Goodarz Mehr, Azim Eskandarian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 00:00:06</h6>
<p class='card-text'>Bird's-eye view (BEV) perception for autonomous driving has garnered
significant attention in recent years, in part because BEV representation
facilitates the fusion of multi-sensor data. This enables a variety of
perception tasks including BEV segmentation, a concise view of the environment
that can be used to plan a vehicle's trajectory. However, this representation
is not fully supported by existing datasets, and creation of new datasets can
be a time-consuming endeavor. To address this problem, in this paper we
introduce SimBEV, an extensively configurable and scalable randomized synthetic
data generation tool that incorporates information from multiple sources to
capture accurate BEV ground truth data, supports a comprehensive array of
sensors, and enables a variety of perception tasks including BEV segmentation
and 3D object detection. We use SimBEV to create the SimBEV dataset, a large
collection of annotated perception data from diverse driving scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01857v1' target='_blank'>Learning Human Perception Dynamics for Informative Robot Communication</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shenghui Chen, Ruihan Zhao, Sandeep Chinchali, Ufuk Topcu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 22:08:04</h6>
<p class='card-text'>Human-robot cooperative navigation is challenging in environments with
incomplete information. We introduce CoNav-Maze, a simulated robotics
environment where a robot navigates using local perception while a human
operator provides guidance based on an inaccurate map. The robot can share its
camera views to improve the operator's understanding of the environment. To
enable efficient human-robot cooperation, we propose Information Gain Monte
Carlo Tree Search (IG-MCTS), an online planning algorithm that balances
autonomous movement and informative communication. Central to IG-MCTS is a
neural human perception dynamics model that estimates how humans distill
information from robot communications. We collect a dataset through a
crowdsourced mapping task in CoNav-Maze and train this model using a fully
convolutional architecture with data augmentation. User studies show that
IG-MCTS outperforms teleoperation and instruction-following baselines,
achieving comparable task performance with significantly less communication and
lower human cognitive load, as evidenced by eye-tracking metrics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01828v2' target='_blank'>From Foresight to Forethought: VLM-In-the-Loop Policy Steering via
  Latent Alignment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yilin Wu, Ran Tian, Gokul Swamy, Andrea Bajcsy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 21:11:02</h6>
<p class='card-text'>While generative robot policies have demonstrated significant potential in
learning complex, multimodal behaviors from demonstrations, they still exhibit
diverse failures at deployment-time. Policy steering offers an elegant solution
to reducing the chance of failure by using an external verifier to select from
low-level actions proposed by an imperfect generative policy. Here, one might
hope to use a Vision Language Model (VLM) as a verifier, leveraging its
open-world reasoning capabilities. However, off-the-shelf VLMs struggle to
understand the consequences of low-level robot actions as they are represented
fundamentally differently than the text and images the VLM was trained on. In
response, we propose FOREWARN, a novel framework to unlock the potential of
VLMs as open-vocabulary verifiers for runtime policy steering. Our key idea is
to decouple the VLM's burden of predicting action outcomes (foresight) from
evaluation (forethought). For foresight, we leverage a latent world model to
imagine future latent states given diverse low-level action plans. For
forethought, we align the VLM with these predicted latent states to reason
about the consequences of actions in its native representation--natural
language--and effectively filter proposed plans. We validate our framework
across diverse robotic manipulation tasks, demonstrating its ability to bridge
representational gaps and provide robust, generalizable policy steering. Videos
can be found on the project website: https://yilin-wu98.github.io/forewarn/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01826v1' target='_blank'>Scalable 3D Gaussian Splatting-Based RF Signal Spatial Propagation
  Modeling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kang Yang, Gaofeng Dong, Sijie Ji, Wan Du, Mani Srivastava</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 21:08:03</h6>
<p class='card-text'>Effective network planning and sensing in wireless networks require
resource-intensive site surveys for data collection. An alternative is
Radio-Frequency (RF) signal spatial propagation modeling, which computes
received signals given transceiver positions in a scene (e.g.s a conference
room). We identify a fundamental trade-off between scalability and fidelity in
the state-of-the-art method. To address this issue, we explore leveraging 3D
Gaussian Splatting (3DGS), an advanced technique for the image synthesis of 3D
scenes in real-time from arbitrary camera poses. By integrating domain-specific
insights, we design three components for adapting 3DGS to the RF domain,
including Gaussian-based RF scene representation, gradient-guided RF attribute
learning, and RF-customized CUDA for ray tracing. Building on them, we develop
RFSPM, an end-to-end framework for scalable RF signal Spatial Propagation
Modeling. We evaluate RFSPM in four field studies and two applications across
RFID, BLE, LoRa, and 5G, covering diverse frequencies, antennas, signals, and
scenes. The results show that RFSPM matches the fidelity of the
state-of-the-art method while reducing data requirements, training GPU-hours,
and inference latency by up to 9.8\,$\times$, 18.6\,$\times$, and
84.4\,$\times$, respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01784v1' target='_blank'>VILP: Imitation Learning with Latent Video Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhengtong Xu, Qiang Qiu, Yu She</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 19:55:57</h6>
<p class='card-text'>In the era of generative AI, integrating video generation models into
robotics opens new possibilities for the general-purpose robot agent. This
paper introduces imitation learning with latent video planning (VILP). We
propose a latent video diffusion model to generate predictive robot videos that
adhere to temporal consistency to a good degree. Our method is able to generate
highly time-aligned videos from multiple views, which is crucial for robot
policy learning. Our video generation model is highly time-efficient. For
example, it can generate videos from two distinct perspectives, each consisting
of six frames with a resolution of 96x160 pixels, at a rate of 5 Hz. In the
experiments, we demonstrate that VILP outperforms the existing video generation
robot policy across several metrics: training costs, inference speed, temporal
consistency of generated videos, and the performance of the policy. We also
compared our method with other imitation learning methods. Our findings
indicate that VILP can rely less on extensive high-quality task-specific robot
action data while still maintaining robust performance. In addition, VILP
possesses robust capabilities in representing multi-modal action distributions.
Our paper provides a practical example of how to effectively integrate video
generation models into robot policies, potentially offering insights for
related fields and directions. For more details, please refer to our
open-source repository https://github.com/ZhengtongXu/VILP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01635v1' target='_blank'>The AI Agent Index</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stephen Casper, Luke Bailey, Rosco Hunter, Carson Ezell, Emma Cabalé, Michael Gerovitch, Stewart Slocum, Kevin Wei, Nikola Jurkovic, Ariba Khan, Phillip J. K. Christoffersen, A. Pinar Ozisik, Rakshit Trivedi, Dylan Hadfield-Menell, Noam Kolt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 18:59:13</h6>
<p class='card-text'>Leading AI developers and startups are increasingly deploying agentic AI
systems that can plan and execute complex tasks with limited human involvement.
However, there is currently no structured framework for documenting the
technical components, intended uses, and safety features of agentic systems. To
fill this gap, we introduce the AI Agent Index, the first public database to
document information about currently deployed agentic AI systems. For each
system that meets the criteria for inclusion in the index, we document the
system's components (e.g., base model, reasoning implementation, tool use),
application domains (e.g., computer use, software engineering), and risk
management practices (e.g., evaluation results, guardrails), based on publicly
available information and correspondence with developers. We find that while
developers generally provide ample information regarding the capabilities and
applications of agentic systems, they currently provide limited information
regarding safety and risk management practices. The AI Agent Index is available
online at https://aiagentindex.mit.edu/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01593v1' target='_blank'>Ultrafast Proton Delivery with Pin Ridge Filters (pRFs): A Novel
  Approach for Motion Management in Proton Therapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ahmal Jawad Zafar, Xiaofeng Yang, Yinan Wang, Zachary Diamond, Jun Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 18:26:04</h6>
<p class='card-text'>Active breath-hold techniques effectively mitigate respiratory motion but
pose challenges for patients who are ineligible for the procedure. Conventional
treatment planning relies on multiple energy layers, extending delivery time
due to slow layer switching. We propose to use pin ridge filters (pRFs),
initially developed for FLASH radiotherapy, to construct a single energy beam
plan and minimize dose delivery time. The conventional ITV--based
free--breathing treatment plan served as the reference. A GTV--based IMPT--DS
plan with a downstream energy modulation strategy was developed based on a new
beam model that was commissioned using the maximum energy of the IMPT plan.
Consequently, a nested iterative pencil beam direction (PBD) spot reduction
process removed low--weighted spots along each PBD, generating pRFs with
coarser resolution. Finally, the IMPT--DS plan was then converted into an
IMPT--pRF plan, using a monoenergetic beam with optimized spot positions and
weights. This approach was validated on lung and liver SBRT cases (10 Gy RBE x
5). For the lung case, the mean lung--GTV dose decreased from 10.3 Gy to 6.9
Gy, with delivery time reduced from 188.79 to 36.16 seconds. The largest time
reduction was at 150{\deg}, from 47.4 to 3.99 seconds. For the liver case, the
mean liver--GTV dose decreased from 5.7 Gy to 3.8 Gy, with delivery time
reduced from 111.13 to 30.54 seconds. The largest time reduction was at
180{\deg}, from 38.57 to 3.94 seconds. This method significantly reduces dose
delivery time and organ at risk dose. Further analysis is needed to validate
its clinical feasibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01517v1' target='_blank'>Regularized interpolation in 4D neural fields enables optimization of 3D
  printed geometries</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christos Margadji, Andi Kuswoyo, Sebastian W. Pattinson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 16:50:57</h6>
<p class='card-text'>The ability to accurately produce geometries with specified properties is
perhaps the most important characteristic of a manufacturing process. 3D
printing is marked by exceptional design freedom and complexity but is also
prone to geometric and other defects that must be resolved for it to reach its
full potential. Ultimately, this will require both astute design decisions and
timely parameter adjustments to maintain stability that is challenging even
with expert human operators. While machine learning is widely investigated in
3D printing, existing methods typically overlook spatial features that vary
across prints and thus find it difficult to produce desired geometries. Here,
we encode volumetric representations of printed parts into neural fields and
apply a new regularization strategy, based on minimizing the partial derivative
of the field's output with respect to a single, non-learnable parameter. By
thus encouraging small input changes to yield only small output variations, we
encourage smooth interpolation between observed volumes and hence realistic
geometry predictions. This framework therefore allows the extraction of
'imagined' 3D shapes, revealing how a part would look if manufactured under
previously unseen parameters. The resulting continuous field is used for
data-driven optimization to maximize geometric fidelity between expected and
produced geometries, reducing post-processing, material waste, and production
costs. By optimizing process parameters dynamically, our approach enables
advanced planning strategies, potentially allowing manufacturers to better
realize complex and feature-rich designs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01492v1' target='_blank'>Develop AI Agents for System Engineering in Factorio</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Neel Kant</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 16:26:17</h6>
<p class='card-text'>Continuing advances in frontier model research are paving the way for
widespread deployment of AI agents. Meanwhile, global interest in building
large, complex systems in software, manufacturing, energy and logistics has
never been greater. Although AI driven system engineering holds tremendous
promise, the static benchmarks dominating agent evaluations today fail to
capture the crucial skills required for implementing dynamic systems, such as
managing uncertain trade-offs and ensuring proactive adaptability. This
position paper advocates for training and evaluating AI agents' system
engineering abilities through automation-oriented sandbox games-particularly
Factorio. By directing research efforts in this direction, we can equip AI
agents with the specialized reasoning and long-horizon planning necessary to
design, maintain, and optimize tomorrow's most demanding engineering projects.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01484v1' target='_blank'>Robot Cell Modeling via Exploratory Robot Motions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gaetano Meli, Niels Dehio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 16:20:03</h6>
<p class='card-text'>Generating a collision-free robot motion is crucial for safe applications in
real-world settings. This requires an accurate model of all obstacle shapes
within the constrained robot cell, which is particularly challenging and
time-consuming. The difficulty is heightened in flexible production lines,
where the environment model must be updated each time the robot cell is
modified. Furthermore, sensor-based methods often necessitate costly hardware
and calibration procedures, and can be influenced by environmental factors
(e.g., light conditions or reflections). To address these challenges, we
present a novel data-driven approach to modeling a cluttered workspace,
leveraging solely the robot internal joint encoders to capture exploratory
motions. By computing the corresponding swept volume, we generate a
(conservative) mesh of the environment that is subsequently used for collision
checking within established path planning and control methods. Our method
significantly reduces the complexity and cost of classical environment modeling
by removing the need for CAD files and external sensors. We validate the
approach with the KUKA LBR iisy collaborative robot in a pick-and-place
scenario. In less than three minutes of exploratory robot motions and less than
four additional minutes of computation time, we obtain an accurate model that
enables collision-free motions. Our approach is intuitive, easy-to-use, making
it accessible to users without specialized technical knowledge. It is
applicable to all types of industrial robots or cobots.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01465v1' target='_blank'>Embrace Collisions: Humanoid Shadowing for Deployable Contact-Agnostics
  Motions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziwen Zhuang, Hang Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 15:57:54</h6>
<p class='card-text'>Previous humanoid robot research works treat the robot as a bipedal mobile
manipulation platform, where only the feet and hands contact the environment.
However, we humans use all body parts to interact with the world, e.g., we sit
in chairs, get up from the ground, or roll on the floor. Contacting the
environment using body parts other than feet and hands brings significant
challenges in both model-predictive control and reinforcement learning-based
methods. An unpredictable contact sequence makes it almost impossible for
model-predictive control to plan ahead in real time. The success of the
zero-shot sim-to-real reinforcement learning method for humanoids heavily
depends on the acceleration of GPU-based rigid-body physical simulator and
simplification of the collision detection. Lacking extreme torso movement of
the humanoid research makes all other components non-trivial to design, such as
termination conditions, motion commands and reward designs. To address these
potential challenges, we propose a general humanoid motion framework that takes
discrete motion commands and controls the robot's motor action in real time.
Using a GPU-accelerated rigid-body simulator, we train a humanoid whole-body
control policy that follows the high-level motion command in the real world in
real time, even with stochastic contacts and extremely large robot base
rotation and not-so-feasible motion command. More details at
https://project-instinct.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01461v1' target='_blank'>Docking-Aware Attention: Dynamic Protein Representations through
  Molecular Context Integration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Amitay Sicherman, Kira Radinsky</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 15:52:38</h6>
<p class='card-text'>Computational prediction of enzymatic reactions represents a crucial
challenge in sustainable chemical synthesis across various scientific domains,
ranging from drug discovery to materials science and green chemistry. These
syntheses rely on proteins that selectively catalyze complex molecular
transformations. These protein catalysts exhibit remarkable substrate
adaptability, with the same protein often catalyzing different chemical
transformations depending on its molecular partners. Current approaches to
protein representation in reaction prediction either ignore protein structure
entirely or rely on static embeddings, failing to capture how proteins
dynamically adapt their behavior to different substrates. We present
Docking-Aware Attention (DAA), a novel architecture that generates dynamic,
context-dependent protein representations by incorporating molecular docking
information into the attention mechanism. DAA combines physical interaction
scores from docking predictions with learned attention patterns to focus on
protein regions most relevant to specific molecular interactions. We evaluate
our method on enzymatic reaction prediction, where it outperforms previous
state-of-the-art methods, achieving 62.2\% accuracy versus 56.79\% on complex
molecules and 55.54\% versus 49.45\% on innovative reactions. Through detailed
ablation studies and visualizations, we demonstrate how DAA generates
interpretable attention patterns that adapt to different molecular contexts.
Our approach represents a general framework for context-aware protein
representation in biocatalysis prediction, with potential applications across
enzymatic synthesis planning. We open-source our implementation and pre-trained
models to facilitate further research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01389v2' target='_blank'>MauveSim: the instrument simulator software for the Mauve mission</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arianna Saba, Fabio Favata, Giorgio Savini, Giovanna Tinetti, Lawrence Bradley, Ian Stotesbury, Marcell Tessenyi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 14:22:44</h6>
<p class='card-text'>We present MauveSim, the instrument simulator software for Mauve, the latest
mission from Blue Skies Space dedicated to time-domain stellar astronomy. The
tool is designed to generate simulated stellar spectra, enabling the assessment
of various scientific objectives, as well as determining limiting magnitudes
and conducting signal-to-noise (S/N) analyses. MauveSim functions as an
end-to-end simulator that takes an input stellar spectrum-either observed or
synthetic-and produces a simulated observation based on the instrument's
performance and characteristics. The results of MauveSim have been validated
against instrument performance data from extensive ground testing campaigns,
ensuring that the software reflects the most up-to-date understanding of the
payload performance. Accessible to all scientists involved in the mission,
MauveSim serves as a crucial tool for target selection and observation
planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01331v1' target='_blank'>Modeling Technological Deployment and Renewal: Monotonic vs. Oscillating
  Industrial Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joseph Le Bihan, Thomas Lapi, José Halloy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 13:10:13</h6>
<p class='card-text'>This study proposes a new model based on a classic S-curve that describes
deployment and stabilization at maximum capacity. In addition, the model
extends to the post-growth plateau, where technological capacity is renewed
according to the distribution of equipment lifespans. We obtain two
qualitatively different results. In the case of "fast" deployment,
characterized by a short deployment time in relation to the average equipment
lifetime, production is subject to significant oscillations. In the case of
"slow" deployment, production increases monotonically until it reaches a
renewal plateau. These results are counterintuitively validated by two case
studies: nuclear power plants as a fast deployment and smartphones as a slow
deployment. These results are important for long-term industrial planning, as
they enable us to anticipate future business cycles. Our study demonstrates
that business cycles can originate endogenously from industrial dynamics of
installation and renewal, contrasting with traditional views attributing
fluctuations to exogenous macroeconomic factors. These endogenous cycles
interact with broader trends, potentially being modulated, amplified, or
attenuated by macroeconomic conditions. This dynamic of deployment and renewal
is relevant for long-life infrastructure technologies, such as those supporting
the renewable energy sector and has major policy implications for industry
players.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04343v1' target='_blank'>Synergistic Traffic Assignment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thomas Bläsius, Adrian Feilhauer, Markus Jung, Moritz Laupichler, Peter Sanders, Michael Zündorf</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 12:36:46</h6>
<p class='card-text'>Traffic assignment analyzes traffic flows in road networks that emerge due to
traveler interaction. Traditionally, travelers are assumed to use private cars,
so road costs grow with the number of users due to congestion. However, in
sustainable transit systems, travelers share vehicles s.t. more users on a road
lead to higher sharing potential and reduced cost per user. Thus, we invert the
usual avoidant traffic assignment (ATA) and instead consider synergistic
traffic assignment (STA) where road costs decrease with use.
  We find that STA is significantly different from ATA from a game-theoretical
point of view. We show that a simple iterative best-response method with
simultaneous updates converges to an equilibrium state. This enables efficient
computation of equilibria using optimized speedup techniques for shortest-path
queries. In contrast, ATA requires slower sequential updates or more
complicated iteration schemes that only approximate an equilibrium. Experiments
with a realistic scenario for the city of Stuttgart indicate that STA indeed
quickly converges to an equilibrium. We envision STA as a part of
software-defined transportation systems that dynamically adapt to current
travel demand. As a first demonstration, we show that an STA equilibrium can be
used to incorporate traveler synergism in a simple bus line planning algorithm
to potentially greatly reduce the required vehicle resources.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01300v2' target='_blank'>Magnetic field Amplification in a Rotating Astrophysical Plasma Sphere:
  $α$ and $β$ Effects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kiwan Park</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 12:20:48</h6>
<p class='card-text'>We investigated the generation of the $\alpha$ and $\beta$ effects in a
rotating spherical plasma system with oppositely polarized kinetic helicity in
the northern and southern hemispheres and examined their contributions to the
induction of magnetic fields. We found that the $\alpha$ effect is relatively
small, and its sign depends on the polarization of kinetic helicity. In
contrast, the $\beta$ effect remains negative regardless of the sign of kinetic
helicity. Despite its small magnitude, the $\alpha$ effect plays a crucial role
in determining the polarity of helical magnetic structures, while a negative
$\beta$ indicates energy diffusion from turbulent regions into the large-scale
magnetic field. We derived the $\alpha$ and $\beta$ effects with oppositely
polarized kinetic helicity using different approaches, incorporating
large-scale magnetic data and turbulent kinetic data. These were used to
reproduce the large-scale magnetic field and compare it with DNS results. In
the kinematic regime, where the magnetic field strength is weak, our results
align well; however, in regions with strong nonlinear magnetic effects, the
magnetic field reproduced using turbulent kinetic data diverges. This
divergence is attributed to insufficient quenching of the $\beta$ effect,
suggesting that including the second-moment terms of velocity in the magnetic
field effect would improve the accuracy of the $\beta$ coefficient. In this
study, we considered the case of a rotating plasma sphere with $Pr_M = 1$ and
low Reynolds numbers. However, in reality, Reynolds numbers are much higher,
and $Pr_M$ is much less than 1, which necessitates further studies on this
topic. We plan to address this in future research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01268v1' target='_blank'>Resilient UAV Trajectory Planning via Few-Shot Meta-Offline
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eslam Eldeeb, Hirley Alves</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 11:39:12</h6>
<p class='card-text'>Reinforcement learning (RL) has been a promising essence in future 5G-beyond
and 6G systems. Its main advantage lies in its robust model-free
decision-making in complex and large-dimension wireless environments. However,
most existing RL frameworks rely on online interaction with the environment,
which might not be feasible due to safety and cost concerns. Another problem
with online RL is the lack of scalability of the designed algorithm with
dynamic or new environments. This work proposes a novel, resilient, few-shot
meta-offline RL algorithm combining offline RL using conservative Q-learning
(CQL) and meta-learning using model-agnostic meta-learning (MAML). The proposed
algorithm can train RL models using static offline datasets without any online
interaction with the environments. In addition, with the aid of MAML, the
proposed model can be scaled up to new unseen environments. We showcase the
proposed algorithm for optimizing an unmanned aerial vehicle (UAV) 's
trajectory and scheduling policy to minimize the age-of-information (AoI) and
transmission power of limited-power devices. Numerical results show that the
proposed few-shot meta-offline RL algorithm converges faster than baseline
schemes, such as deep Q-networks and CQL. In addition, it is the only algorithm
that can achieve optimal joint AoI and transmission power using an offline
dataset with few shots of data points and is resilient to network failures due
to unprecedented environmental changes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01229v1' target='_blank'>How Good are Learned Cost Models, Really? Insights from Query
  Optimization Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Roman Heinrich, Manisha Luthra, Johannes Wehrstein, Harald Kornmayer, Carsten Binnig</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 10:37:05</h6>
<p class='card-text'>Traditionally, query optimizers rely on cost models to choose the best
execution plan from several candidates, making precise cost estimates critical
for efficient query execution. In recent years, cost models based on machine
learning have been proposed to overcome the weaknesses of traditional cost
models. While these models have been shown to provide better prediction
accuracy, only limited efforts have been made to investigate how well Learned
Cost Models (LCMs) actually perform in query optimization and how they affect
overall query performance. In this paper, we address this by a systematic study
evaluating LCMs on three of the core query optimization tasks: join ordering,
access path selection, and physical operator selection. In our study, we
compare seven state-of-the-art LCMs to a traditional cost model and,
surprisingly, find that the traditional model often still outperforms LCMs in
these tasks. We conclude by highlighting major takeaways and recommendations to
guide future research toward making LCMs more effective for query optimization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01210v1' target='_blank'>Modelling change in neural dynamics during phonetic accommodation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sam Kirkham, Patrycja Strycharczuk, Rob Davies, Danielle Welburn</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 10:00:29</h6>
<p class='card-text'>Short-term phonetic accommodation is a fundamental driver behind accent
change, but how does real-time input from another speaker's voice shape the
speech planning representations of an interlocutor? We advance a computational
model of change in phonetic representations during phonetic accommodation,
grounded in dynamic neural field equations for movement planning and memory
dynamics. We test the model's ability to capture empirical patterns from an
experimental study where speakers shadowed a model talker with a different
accent from their own. The experimental data shows vowel-specific degrees of
convergence during shadowing, followed by return to baseline (or minor
divergence) post-shadowing. The model can reproduce these phenomena by
modulating the magnitude of inhibitory memory dynamics, which may reflect
resistance to accommodation due to phonological and/or sociolinguistic
pressures. We discuss the implications of these results for the relation
between short-term phonetic accommodation and longer-term patterns of sound
change.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01108v1' target='_blank'>Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for
  Wearable Applications Across Lab and Field Settings</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mithun Saha, Maxwell A. Xu, Wanting Mao, Sameer Neupane, James M. Rehg, Santosh Kumar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 06:56:40</h6>
<p class='card-text'>Photoplethysmography (PPG)-based foundation models are gaining traction due
to the widespread use of PPG in biosignal monitoring and their potential to
generalize across diverse health applications. In this paper, we introduce
Pulse-PPG, the first open-source PPG foundation model trained exclusively on
raw PPG data collected over a 100-day field study with 120 participants.
Existing PPG foundation models are either open-source but trained on clinical
data or closed-source, limiting their applicability in real-world settings. We
evaluate Pulse-PPG across multiple datasets and downstream tasks, comparing its
performance against a state-of-the-art foundation model trained on clinical
data. Our results demonstrate that Pulse-PPG, trained on uncurated field data,
exhibits superior generalization across clinical and mobile health applications
in both lab and field settings. This suggests that exposure to real-world
variability enables the model to learn fine-grained representations, making it
more adaptable across tasks. Furthermore, pre-training on field data
surprisingly outperforms its pre-training on clinical data in many tasks,
reinforcing the importance of training on real-world, diverse datasets. To
encourage further advancements in robust foundation models leveraging field
data, we plan to release Pulse-PPG, providing researchers with a powerful
resource for developing more generalizable PPG-based models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01055v1' target='_blank'>On the Surprising Robustness of Sequential Convex Optimization for
  Contact-Implicit Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yulin Li, Haoyu Han, Shucheng Kang, Jun Ma, Heng Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 05:01:39</h6>
<p class='card-text'>Contact-implicit motion planning-embedding contact sequencing as implicit
complementarity constraints-holds the promise of leveraging continuous
optimization to discover new contact patterns online. Nevertheless, the
resulting optimization, being an instance of Mathematical Programming with
Complementary Constraints, fails the classical constraint qualifications that
are crucial for the convergence of popular numerical solvers. We present robust
contact-implicit motion planning with sequential convex programming (CRISP), a
solver that departs from the usual primal-dual algorithmic framework but
instead only focuses on the primal problem. CRISP solves a convex quadratic
program with an adaptive trust region radius at each iteration, and its
convergence is evaluated by a merit function using weighted penalty. We (i)
provide sufficient conditions on CRISP's convergence to first-order stationary
points of the merit function; (ii) release a high-performance C++
implementation of CRISP with a generic nonlinear programming interface; and
(iii) demonstrate CRISP's surprising robustness in solving contact-implicit
planning with naive initialization. In fact, CRISP solves several
contact-implicit problems with all-zero initialization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01011v1' target='_blank'>An Adaptive Proton FLASH Therapy Using Modularized Pin Ridge Filter</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ahmal Jawad Zafar, Xiaofeng Yang, Zachary Diamond, Tian Sibo, David Yu, Pretesh R. Patel, Jun Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 03:02:52</h6>
<p class='card-text'>In this paper, we proposed a method to optimize adaptive proton FLASH therapy
(ADP FLASH) using modularized pin ridge filters (pRFs) by recycling module pins
from the initial plan while reducing pRF adjustments in adaptive FLASH
planning. Initially, single energy (250 MeV) FLASH pRF plans were created using
pencil beam directions (PBDs) from initial IMPT plans on the planning CT (pCT).
PBDs are classified as new/changed ($\Delta$E > > 5 MeV) or unchanged by
comparing spot maps for targets between pCT and re-CT. We used an iterative
least square regression model to identify recyclable PBDs with minimal relative
changes to spot MU weighting. Two PBDs with the least square error were
retrieved per iteration and added to the background plan, and the remaining
PBDs were reoptimized for the adaptive plan in subsequent iterations. The
method was validated on three liver SBRT cases (50 Gy in 5 fractions) by
comparing various dosimetric parameters across initial pRF plans on pCT, reCT
and the ADP FLASH pRF plans on reCT. V100 for initial pRF plans on pCT, reCT,
and ADP FLASH pRF plans for the three cases were as follows: (93.7%, 89.2%,
91.4%), (93.5%, 60.2%, 91.7%), (97.3%, 69.9%, 98.8%). We observe a decline in
plan quality when applying the initial pRF to the reCT, whereas the ADP FLASH
pRF approach restores quality comparable to the initial pRF on the pCT. FLASH
effect of the initial pRF and ADP pRF plans were evaluated with a dose and dose
rate threshold of 1Gy and 40Gy/s, respectively, using the FLASH effectiveness
model. The proposed method recycled 91.2%, 71%, and 64.7% of PBDs from initial
pRF plans for the three cases while maintaining all clinical goals and
preserving FLASH effects across all cases.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01009v1' target='_blank'>Robust Trajectory Generation and Control for Quadrotor Motion Planning
  with Field-of-View Control Barrier Certification</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lishuo Pan, Mattia Catellani, Lorenzo Sabattini, Nora Ayanian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 03:01:52</h6>
<p class='card-text'>Many approaches to multi-robot coordination are susceptible to failure due to
communication loss and uncertainty in estimation. We present a real-time
communication-free distributed algorithm for navigating robots to their desired
goals certified by control barrier functions, that model and control the
onboard sensing behavior to keep neighbors in the limited field of view for
position estimation. The approach is robust to temporary tracking loss and
directly synthesizes control in real time to stabilize visual contact through
control Lyapunov-barrier functions. The main contributions of this paper are a
continuous-time robust trajectory generation and control method certified by
control barrier functions for distributed multi-robot systems and a discrete
optimization procedure, namely, MPC-CBF, to approximate the certified
controller. In addition, we propose a linear surrogate of high-order control
barrier function constraints and use sequential quadratic programming to solve
MPC-CBF efficiently. We demonstrate results in simulation with 10 robots and
physical experiments with 2 custom-built UAVs. To the best of our knowledge,
this work is the first of its kind to generate a robust continuous-time
trajectory and controller concurrently, certified by control barrier functions
utilizing piecewise splines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00858v1' target='_blank'>Learning to Plan with Personalized Preferences</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Manjie Xu, Xinyi Yang, Wei Liang, Chi Zhang, Yixin Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-02 17:16:25</h6>
<p class='card-text'>Effective integration of AI agents into daily life requires them to
understand and adapt to individual human preferences, particularly in
collaborative roles. Although recent studies on embodied intelligence have
advanced significantly, they typically adopt generalized approaches that
overlook personal preferences in planning. We address this limitation by
developing agents that not only learn preferences from few demonstrations but
also learn to adapt their planning strategies based on these preferences. Our
research leverages the observation that preferences, though implicitly
expressed through minimal demonstrations, can generalize across diverse
planning scenarios. To systematically evaluate this hypothesis, we introduce
Preference-based Planning (PbP) benchmark, an embodied benchmark featuring
hundreds of diverse preferences spanning from atomic actions to complex
sequences. Our evaluation of SOTA methods reveals that while symbol-based
approaches show promise in scalability, significant challenges remain in
learning to generate and execute plans that satisfy personalized preferences.
We further demonstrate that incorporating learned preferences as intermediate
representations in planning significantly improves the agent's ability to
construct personalized plans. These findings establish preferences as a
valuable abstraction layer for adaptive planning, opening new directions for
research in preference-guided plan generation and execution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00843v1' target='_blank'>VLM-Assisted Continual learning for Visual Question Answering in
  Self-Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxin Lin, Mengshi Qi, Liang Liu, Huadong Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-02 16:27:44</h6>
<p class='card-text'>In this paper, we propose a novel approach for solving the Visual Question
Answering (VQA) task in autonomous driving by integrating Vision-Language
Models (VLMs) with continual learning. In autonomous driving, VQA plays a vital
role in enabling the system to understand and reason about its surroundings.
However, traditional models often struggle with catastrophic forgetting when
sequentially exposed to new driving tasks, such as perception, prediction, and
planning, each requiring different forms of knowledge. To address this
challenge, we present a novel continual learning framework that combines VLMs
with selective memory replay and knowledge distillation, reinforced by
task-specific projection layer regularization. The knowledge distillation
allows a previously trained model to act as a "teacher" to guide the model
through subsequent tasks, minimizing forgetting. Meanwhile, task-specific
projection layers calculate the loss based on the divergence of feature
representations, ensuring continuity in learning and reducing the shift between
tasks. Evaluated on the DriveLM dataset, our framework shows substantial
performance improvements, with gains ranging from 21.40% to 32.28% across
various metrics. These results highlight the effectiveness of combining
continual learning with VLMs in enhancing the resilience and reliability of VQA
systems in autonomous driving. We will release our source code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00835v1' target='_blank'>CAIMAN: Causal Action Influence Detection for Sample Efficient
  Loco-manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuanchen Yuan, Jin Cheng, Núria Armengol Urpí, Stelian Coros</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-02 16:16:53</h6>
<p class='card-text'>Enabling legged robots to perform non-prehensile loco-manipulation with large
and heavy objects is crucial for enhancing their versatility. However, this is
a challenging task, often requiring sophisticated planning strategies or
extensive task-specific reward shaping, especially in unstructured scenarios
with obstacles. In this work, we present CAIMAN, a novel framework for learning
loco-manipulation that relies solely on sparse task rewards. We leverage causal
action influence to detect states where the robot is in control over other
entities in the environment, and use this measure as an intrinsically motivated
objective to enable sample-efficient learning. We employ a hierarchical control
strategy, combining a low-level locomotion policy with a high-level policy that
prioritizes task-relevant velocity commands. Through simulated and real-world
experiments, including object manipulation with obstacles, we demonstrate the
framework's superior sample efficiency, adaptability to diverse environments,
and successful transfer to hardware without fine-tuning. The proposed approach
paves the way for scalable, robust, and autonomous loco-manipulation in
real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00695v1' target='_blank'>TMI-CLNet: Triple-Modal Interaction Network for Chronic Liver Disease
  Prognosis From Imaging, Clinical, and Radiomic Data Fusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Linglong Wu, Xuhao Shan, Ruiquan Ge, Ruoyu Liang, Chi Zhang, Yonghong Li, Ahmed Elazab, Huoling Luo, Yunbi Liu, Changmiao Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-02 07:05:28</h6>
<p class='card-text'>Chronic liver disease represents a significant health challenge worldwide and
accurate prognostic evaluations are essential for personalized treatment plans.
Recent evidence suggests that integrating multimodal data, such as computed
tomography imaging, radiomic features, and clinical information, can provide
more comprehensive prognostic information. However, modalities have an inherent
heterogeneity, and incorporating additional modalities may exacerbate the
challenges of heterogeneous data fusion. Moreover, existing multimodal fusion
methods often struggle to adapt to richer medical modalities, making it
difficult to capture inter-modal relationships. To overcome these limitations,
We present the Triple-Modal Interaction Chronic Liver Network (TMI-CLNet).
Specifically, we develop an Intra-Modality Aggregation module and a
Triple-Modal Cross-Attention Fusion module, which are designed to eliminate
intra-modality redundancy and extract cross-modal information, respectively.
Furthermore, we design a Triple-Modal Feature Fusion loss function to align
feature representations across modalities. Extensive experiments on the liver
prognosis dataset demonstrate that our approach significantly outperforms
existing state-of-the-art unimodal models and other multi-modal techniques. Our
code is available at https://github.com/Mysterwll/liver.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01680v1' target='_blank'>Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree
  Rules into Neural Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kamal Acharya, Mehul Lad, Liang Sun, Houbing Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-02 05:10:31</h6>
<p class='card-text'>Travel demand prediction is crucial for optimizing transportation planning,
resource allocation, and infrastructure development, ensuring efficient
mobility and economic sustainability. This study introduces a Neurosymbolic
Artificial Intelligence (Neurosymbolic AI) framework that integrates decision
tree (DT)-based symbolic rules with neural networks (NNs) to predict travel
demand, leveraging the interpretability of symbolic reasoning and the
predictive power of neural learning. The framework utilizes data from diverse
sources, including geospatial, economic, and mobility datasets, to build a
comprehensive feature set. DTs are employed to extract interpretable if-then
rules that capture key patterns, which are then incorporated as additional
features into a NN to enhance its predictive capabilities. Experimental results
show that the combined dataset, enriched with symbolic rules, consistently
outperforms standalone datasets across multiple evaluation metrics, including
Mean Absolute Error (MAE), \(R^2\), and Common Part of Commuters (CPC). Rules
selected at finer variance thresholds (e.g., 0.0001) demonstrate superior
effectiveness in capturing nuanced relationships, reducing prediction errors,
and aligning with observed commuter patterns. By merging symbolic and neural
learning paradigms, this Neurosymbolic approach achieves both interpretability
and accuracy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00633v1' target='_blank'>Lipschitz Lifelong Monte Carlo Tree Search for Mastering Non-Stationary
  Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zuyuan Zhang, Tian Lan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-02 02:45:20</h6>
<p class='card-text'>Monte Carlo Tree Search (MCTS) has proven highly effective in solving complex
planning tasks by balancing exploration and exploitation using Upper Confidence
Bound for Trees (UCT). However, existing work have not considered MCTS-based
lifelong planning, where an agent faces a non-stationary series of tasks --
e.g., with varying transition probabilities and rewards -- that are drawn
sequentially throughout the operational lifetime. This paper presents LiZero
for Lipschitz lifelong planning using MCTS. We propose a novel concept of
adaptive UCT (aUCT) to transfer knowledge from a source task to the
exploration/exploitation of a new task, depending on both the Lipschitz
continuity between tasks and the confidence of knowledge in in Monte Carlo
action sampling. We analyze LiZero's acceleration factor in terms of improved
sampling efficiency and also develop efficient algorithms to compute aUCT in an
online fashion by both data-driven and model-based approaches, whose sampling
complexity and error bounds are also characterized. Experiment results show
that LiZero significantly outperforms existing MCTS and lifelong learning
baselines in terms of much faster convergence (3$\sim$4x) to optimal rewards.
Our results highlight the potential of LiZero to advance decision-making and
planning in dynamic real-world environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00581v1' target='_blank'>Trajectory Planning and Control for Differentially Flat Fixed-Wing
  Aerial Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luca Morando, Sanket A. Salunkhe, Nishanth Bobbili, Jeffrey Mao, Luca Masci, Hung Nguyen, Cristino de Souza, Giuseppe Loianno</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 22:30:42</h6>
<p class='card-text'>Efficient real-time trajectory planning and control for fixed-wing unmanned
aerial vehicles is challenging due to their non-holonomic nature, complex
dynamics, and the additional uncertainties introduced by unknown aerodynamic
effects. In this paper, we present a fast and efficient real-time trajectory
planning and control approach for fixed-wing unmanned aerial vehicles,
leveraging the differential flatness property of fixed-wing aircraft in
coordinated flight conditions to generate dynamically feasible trajectories.
The approach provides the ability to continuously replan trajectories, which we
show is useful to dynamically account for the curvature constraint as the
aircraft advances along its path. Extensive simulations and real-world
experiments validate our approach, showcasing its effectiveness in generating
trajectories even in challenging conditions for small FW such as wind
disturbances.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00466v1' target='_blank'>Enhancing Memory and Imagination Consistency in Diffusion-based World
  Models via Linear-Time Sequence Modeling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jia-Hua Lee, Bor-Jiun Lin, Wei-Fang Sun, Chun-Yi Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 15:49:59</h6>
<p class='card-text'>World models are crucial for enabling agents to simulate and plan within
environments, yet existing approaches struggle with long-term dependencies and
inconsistent predictions. We introduce EDELINE, a novel framework that
integrates diffusion models with linear-time state space modelsto enhance
memory retention and temporal consistency. EDELINE employs a recurrent
embedding module based on Mamba SSMs for processing unbounded sequences, a
unified architecture for joint reward and termination prediction, and dynamic
loss harmonization to balance multi-task learning. Our results across multiple
benchmarks demonstrate EDELINE's superiority and robustness over prior
baselines in long-horizon tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00395v1' target='_blank'>FlexCloud: Direct, Modular Georeferencing and Drift-Correction of Point
  Cloud Maps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maximilian Leitenstern, Marko Alten, Christian Bolea-Schaser, Dominik Kulmer, Marcel Weinmann, Markus Lienkamp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 10:56:05</h6>
<p class='card-text'>Current software stacks for real-world applications of autonomous driving
leverage map information to ensure reliable localization, path planning, and
motion prediction. An important field of research is the generation of point
cloud maps, referring to the topic of simultaneous localization and mapping
(SLAM). As most recent developments do not include global position data, the
resulting point cloud maps suffer from internal distortion and missing
georeferencing, preventing their use for map-based localization approaches.
Therefore, we propose FlexCloud for an automatic georeferencing of point cloud
maps created from SLAM. Our approach is designed to work modularly with
different SLAM methods, utilizing only the generated local point cloud map and
its odometry. Using the corresponding GNSS positions enables direct
georeferencing without additional control points. By leveraging a 3D
rubber-sheet transformation, we can correct distortions within the map caused
by long-term drift while maintaining its structure. Our approach enables the
creation of consistent, globally referenced point cloud maps from data
collected by a mobile mapping system (MMS). The source code of our work is
available at https://github.com/TUMFTM/FlexCloud.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00362v1' target='_blank'>Left-Deep Join Order Selection with Higher-Order Unconstrained Binary
  Optimization on Quantum Computers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Valter Uotila</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 08:00:36</h6>
<p class='card-text'>Join order optimization is among the most crucial query optimization
problems, and its central position is also evident in the new research field
where quantum computing is applied to database optimization and data
management. In the field, join order optimization is the most studied database
problem, usually tackled with a quadratic unconstrained binary optimization
model, which is solved with various meta-heuristics such as quantum annealing,
quantum approximate optimization algorithm, or variational quantum eigensolver.
In this work, we continue developing quantum computing techniques for join
order optimization by presenting three novel quantum optimization algorithms.
These algorithms are based on a higher-order unconstrained binary optimization
model, which is a generalization of the quadratic model and has not previously
been applied to database problems. Theoretically, these optimization problems
naturally map to universal quantum computers and quantum annealers. Compared to
previous research, two of our algorithms are the first quantum algorithms to
precisely model the join order cost function. We prove theoretical bounds by
showing that these two methods encode the same plans as the dynamic programming
algorithm without cross-products, which provides the optimal result up to
cross-products. The third algorithm reaches at least as good plans as the
greedy algorithm without cross-products. These results set an important
theoretical connection between the classical and quantum algorithms for join
order selection, which has not been studied in the previous research. To
demonstrate our algorithms' practical usability, we have conducted an
experimental evaluation on thousands of clique, cycle, star, tree, and chain
query graphs using quantum and classical solvers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00346v1' target='_blank'>Actor Critic with Experience Replay-based automatic treatment planning
  for prostate cancer intensity modulated radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md Mainul Abrar, Parvat Sapkota, Damon Sprouts, Xun Jia, Yujie Chi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 07:09:40</h6>
<p class='card-text'>Background: Real-time treatment planning in IMRT is challenging due to
complex beam interactions. AI has improved automation, but existing models
require large, high-quality datasets and lack universal applicability. Deep
reinforcement learning (DRL) offers a promising alternative by mimicking human
trial-and-error planning.
  Purpose: Develop a stochastic policy-based DRL agent for automatic treatment
planning with efficient training, broad applicability, and robustness against
adversarial attacks using Fast Gradient Sign Method (FGSM).
  Methods: Using the Actor-Critic with Experience Replay (ACER) architecture,
the agent tunes treatment planning parameters (TPPs) in inverse planning.
Training is based on prostate cancer IMRT cases, using dose-volume histograms
(DVHs) as input. The model is trained on a single patient case, validated on
two independent cases, and tested on 300+ plans across three datasets. Plan
quality is assessed using ProKnow scores, and robustness is tested against
adversarial attacks.
  Results: Despite training on a single case, the model generalizes well.
Before ACER-based planning, the mean plan score was 6.20$\pm$1.84; after,
93.09% of cases achieved a perfect score of 9, with a mean of 8.93$\pm$0.27.
The agent effectively prioritizes optimal TPP tuning and remains robust against
adversarial attacks.
  Conclusions: The ACER-based DRL agent enables efficient, high-quality
treatment planning in prostate cancer IMRT, demonstrating strong
generalizability and robustness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00338v1' target='_blank'>OneForecast: A Universal Framework for Global and Regional Weather
  Forecasting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuan Gao, Hao Wu, Ruiqi Shu, Huanshuo Dong, Fan Xu, Rui Chen, Yibo Yan, Qingsong Wen, Xuming Hu, Kun Wang, Jiahao Wu, Qing Li, Hui Xiong, Xiaomeng Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 06:49:16</h6>
<p class='card-text'>Accurate weather forecasts are important for disaster prevention,
agricultural planning, and water resource management. Traditional numerical
weather prediction (NWP) methods offer physically interpretable high-accuracy
predictions but are computationally expensive and fail to fully leverage
rapidly growing historical data. In recent years, deep learning methods have
made significant progress in weather forecasting, but challenges remain, such
as balancing global and regional high-resolution forecasts, excessive smoothing
in extreme event predictions, and insufficient dynamic system modeling. To
address these issues, this paper proposes a global-regional nested weather
forecasting framework based on graph neural networks (GNNs). By combining a
dynamic system perspective with multi-grid theory, we construct a multi-scale
graph structure and densify the target region to capture local high-frequency
features. We introduce an adaptive information propagation mechanism, using
dynamic gating units to deeply integrate node and edge features for more
accurate extreme event forecasting. For high-resolution regional forecasts, we
propose a neural nested grid method to mitigate boundary information loss.
Experimental results show that the proposed method performs excellently across
global to regional scales and short-term to long-term forecasts, especially in
extreme event predictions (e.g., typhoons), significantly improving forecast
accuracy. Our codes are available at https://github.com/YuanGao-YG/OneForecast.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00300v1' target='_blank'>Uncertainty Quantification of Wind Gust Predictions in the Northeast US:
  An Evidential Neural Network and Explainable Artificial Intelligence Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Israt Jahan, John S. Schreck, David John Gagne, Charlie Becker, Marina Astitha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 03:50:11</h6>
<p class='card-text'>Machine learning has shown promise in reducing bias in numerical weather
model predictions of wind gusts. Yet, they underperform to predict high gusts
even with additional observations due to the right-skewed distribution of
gusts. Uncertainty quantification (UQ) addresses this by identifying when
predictions are reliable or needs cautious interpretation. Using data from 61
extratropical storms in the Northeastern USA, we introduce evidential neural
network (ENN) as a novel approach for UQ in gust predictions, leveraging
atmospheric variables from the Weather Research and Forecasting (WRF) model as
features and gust observations as targets. Explainable artificial intelligence
(XAI) techniques demonstrated that key predictive features also contributed to
higher uncertainty. Estimated uncertainty correlated with storm intensity and
spatial gust gradients. ENN allowed constructing gust prediction intervals
without requiring an ensemble. From an operational perspective, providing gust
forecasts with quantified uncertainty enhances stakeholders' confidence in risk
assessment and response planning for extreme gust events.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00188v1' target='_blank'>Dynamics of Magnetic Evaporative Beamline Cooling for Preparation of
  Cold Atomic Beams</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:A. Ashtari Esfahani, S. Bhagvati, S. Böser, M. J. Brandsema, R. Cabral, V. A. Chirayath, C. Claessens, N. Coward, L. de Viveiros, P. J. Doe, M. G. Elliott, S. Enomoto, M. Fertl, J. A. Formaggio, B. T. Foust, J. K. Gaison, P. Harmston, K. M. Heeger, B. J. P. Jones, E. Karim, K. Kazkaz, P. T. Kolbeck, M. Li, A. Lindman, C. Y. Liu, C. Matthé, R. Mohiuddin, B. Monreal, B. Mucogllava, R. Mueller, A. Negi, J. A. Nikkel, E. Novitski, N. S. Oblath, M. Oueslati, J. I. Peña, W. Pettus, V. S. Ranatunga, R. Reimann, A. L. Reine, R. G. H. Robertson, L. Saldaña, P. L. Slocum, F. Spanier, J. Stachurska, K. Stogsdill, Y. H. Sun, P. T. Surukuchi, L. Taylor, A. B. Telles, F. Thomas, L. A. Thorne, T. Thuümmler, W. Van De Pontseele, B. A. VanDevender, T. E. Weiss, M. Wynne, A. Ziegler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 22:06:08</h6>
<p class='card-text'>The most sensitive direct neutrino mass searches today are based on
measurement of the endpoint of the beta spectrum of tritium to infer limits on
the mass of the unobserved recoiling neutrino. To avoid the smearing associated
with the distribution of molecular final states in the T-He molecule, the next
generation of these experiments will need to employ atomic (T) rather than
molecular (T$_{2}$) tritium sources. Following production, atomic T can be
trapped in gravitational and / or magnetic bottles for beta spectrum
experiments, if and only if it can first be cooled to millikelvin temperatures.
Accomplishing this cooling presents substantial technological challenges. The
Project 8 collaboration is developing a technique based on magnetic evaporative
cooling along a beamline (MECB) for the purpose of cooling T to feed a
magneto-gravitational trap that also serves as a cyclotron radiation emission
spectroscope. Initial tests of the approach are planned in a pathfinder
apparatus using atomic Li. This paper presents a method for analyzing the
dynamics of the MECB technique, and applies these calculations to the design of
systems for cooling and slowing of atomic Li and T. A scheme is outlined that
could provide a current of T at the millikelvin temperatures required for the
Project 8 neutrino mass search.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00185v1' target='_blank'>Optimal Coupled Sensor Placement and Path-Planning in Unknown
  Time-Varying Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Prakash Poudel, Raghvendra V. Cowlagi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 22:01:53</h6>
<p class='card-text'>We address path-planning for a mobile agent to navigate in an unknown
environment with minimum exposure to a spatially and temporally varying threat
field. The threat field is estimated using pointwise noisy measurements from a
mobile sensor network. For this problem, we present a new information gain
measure for optimal sensor placement that quantifies reduction in uncertainty
in the path cost rather than the environment state. This measure, which we call
the context-relevant mutual information (CRMI), couples the sensor placement
and path-planning problem. We propose an iterative coupled sensor configuration
and path-planning (CSCP) algorithm. At each iteration, this algorithm places
sensors to maximize CRMI, updates the threat estimate using new measurements,
and recalculates the path with minimum expected exposure to the threat. The
iterations converge when the path cost variance, which is an indicator of risk,
reduces below a desired threshold. We show that CRMI is submodular, and
therefore, greedy optimization provides near-optimal sensor placements while
maintaining computational efficiency of the CSCP algorithm. Distance-based
sensor reconfiguration costs are introduced in a modified CRMI measure, which
we also show to be submodular. Through numerical simulations, we demonstrate
that the principal advantage of this algorithm is that near-optimal
low-variance paths are achieved using far fewer sensor measurements as compared
to a standard sensor placement method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00146v1' target='_blank'>Multimodal MRI-Ultrasound AI for Prostate Cancer Detection Outperforms
  Radiologist MRI Interpretation: A Multi-Center Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hassan Jahanandish, Shengtian Sang, Cynthia Xinran Li, Sulaiman Vesal, Indrani Bhattacharya, Jeong Hoon Lee, Richard Fan, Geoffrey A. Sonna, Mirabela Rusu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 20:04:20</h6>
<p class='card-text'>Pre-biopsy magnetic resonance imaging (MRI) is increasingly used to target
suspicious prostate lesions. This has led to artificial intelligence (AI)
applications improving MRI-based detection of clinically significant prostate
cancer (CsPCa). However, MRI-detected lesions must still be mapped to
transrectal ultrasound (TRUS) images during biopsy, which results in missing
CsPCa. This study systematically evaluates a multimodal AI framework
integrating MRI and TRUS image sequences to enhance CsPCa identification. The
study included 3110 patients from three cohorts across two institutions who
underwent prostate biopsy. The proposed framework, based on the 3D UNet
architecture, was evaluated on 1700 test cases, comparing performance to
unimodal AI models that use either MRI or TRUS alone. Additionally, the
proposed model was compared to radiologists in a cohort of 110 patients. The
multimodal AI approach achieved superior sensitivity (80%) and Lesion Dice
(42%) compared to unimodal MRI (73%, 30%) and TRUS models (49%, 27%). Compared
to radiologists, the multimodal model showed higher specificity (88% vs. 78%)
and Lesion Dice (38% vs. 33%), with equivalent sensitivity (79%). Our findings
demonstrate the potential of multimodal AI to improve CsPCa lesion targeting
during biopsy and treatment planning, surpassing current unimodal models and
radiologists; ultimately improving outcomes for prostate cancer patients.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00145v1' target='_blank'>Counting and Reasoning with Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David Speck, Markus Hecher, Daniel Gnad, Johannes K. Fichte, Augusto B. Corrêa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 20:03:51</h6>
<p class='card-text'>Classical planning asks for a sequence of operators reaching a given goal.
While the most common case is to compute a plan, many scenarios require more
than that. However, quantitative reasoning on the plan space remains mostly
unexplored. A fundamental problem is to count plans, which relates to the
conditional probability on the plan space. Indeed, qualitative and quantitative
approaches are well-established in various other areas of automated reasoning.
We present the first study to quantitative and qualitative reasoning on the
plan space. In particular, we focus on polynomially bounded plans. On the
theoretical side, we study its complexity, which gives rise to rich reasoning
modes. Since counting is hard in general, we introduce the easier notion of
facets, which enables understanding the significance of operators. On the
practical side, we implement quantitative reasoning for planning. Thereby, we
transform a planning task into a propositional formula and use knowledge
compilation to count different plans. This framework scales well to large plan
spaces, while enabling rich reasoning capabilities such as learning pruning
functions and explainable planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00114v1' target='_blank'>Mobile Robot Navigation Using Hand-Drawn Maps: A Vision Language Model
  Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aaron Hao Tan, Angus Fung, Haitong Wang, Goldie Nejat</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 19:03:33</h6>
<p class='card-text'>Hand-drawn maps can be used to convey navigation instructions between humans
and robots in a natural and efficient manner. However, these maps can often
contain inaccuracies such as scale distortions and missing landmarks which
present challenges for mobile robot navigation. This paper introduces a novel
Hand-drawn Map Navigation (HAM-Nav) architecture that leverages pre-trained
vision language models (VLMs) for robot navigation across diverse environments,
hand-drawing styles, and robot embodiments, even in the presence of map
inaccuracies. HAM-Nav integrates a unique Selective Visual Association
Prompting approach for topological map-based position estimation and navigation
planning as well as a Predictive Navigation Plan Parser to infer missing
landmarks. Extensive experiments were conducted in photorealistic simulated
environments, using both wheeled and legged robots, demonstrating the
effectiveness of HAM-Nav in terms of navigation success rates and Success
weighted by Path Length. Furthermore, a user study in real-world environments
highlighted the practical utility of hand-drawn maps for robot navigation as
well as successful navigation outcomes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19391v1' target='_blank'>Perceptive Mixed-Integer Footstep Control for Underactuated Bipedal
  Walking on Rough Terrain</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Brian Acosta, Michael Posa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 18:47:21</h6>
<p class='card-text'>Traversing rough terrain requires dynamic bipeds to stabilize themselves
through foot placement without stepping in unsafe areas. Planning these
footsteps online is challenging given non-convexity of the safe terrain, and
imperfect perception and state estimation. This paper addresses these
challenges with a full-stack perception and control system for achieving
underactuated walking on discontinuous terrain. First, we develop
model-predictive footstep control (MPFC), a single mixed-integer quadratic
program which assumes a convex polygon terrain decomposition to optimize over
discrete foothold choice, footstep position, ankle torque, template dynamics,
and footstep timing at over 100 Hz. We then propose a novel approach for
generating convex polygon terrain decompositions online. Our perception stack
decouples safe-terrain classification from fitting planar polygons, generating
a temporally consistent terrain segmentation in real time using a single CPU
thread. We demonstrate the performance of our perception and control stack
through outdoor experiments with the underactuated biped Cassie, achieving
state of the art perceptive bipedal walking on discontinuous terrain.
Supplemental Video: https://youtu.be/eCOD1bMi638</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19246v1' target='_blank'>Computational Assessment of Hemodynamics in Asymmetric-type Lesion of
  Idealized Coronary Stenoses</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ayodele Oyejide, Oluwatosin Abodunrin, Ebenezer Ige, Adetokunbo Awonusi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 16:01:59</h6>
<p class='card-text'>Coronary artery stenosis, characterized by the narrowing of the lumen,
significantly affects blood flow and contributes to the progression of
cardiovascular diseases. This study investigates the hemodynamics of coronary
artery models with varying stenosis configurations, all maintaining an 80%
lumen reduction, to determine how differences in morphology influence flow
behavior and mechanical stresses. We employed computational fluid dynamics to
analyze five idealized geometries with (10% & 70%), (20% & 60%), (30% & 50%),
(40% & 40%), and (0% & 80%) stenosis configurations. Through physiological
pulsatile flow conditions, we evaluated key hemodynamic pattern including
velocity profiles, wall shear stress, and pressure distribution. Our results
reveal that despite the same degree of lumen reduction, each stenosis
configuration produced distinct flow patterns and hemodynamic profiles.
Asymmetric configurations, such as 10% & 70% and 20% & 60%, exhibited
pronounced flow disruptions and higher wall shear stress at the stenosis
throats, while symmetric configurations, such as 40% & 40%, demonstrated more
uniform flow and reduced vortex. Our findings challenge the practice of
generalizing results across stenosis configurations without accounting for
morphological variations, which is prevalent in many CFD studies using
idealized models. This study emphasizes the importance of considering
stenosis-specific morphology in CFD analyses and clinical interpretations to
enhance the accuracy of diagnostic tools, improve personalized treatment
planning, and guide the design of medical devices such as stents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19027v1' target='_blank'>True Online TD-Replan(lambda) Achieving Planning through Replaying</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abdulrahman Altahhan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 10:51:37</h6>
<p class='card-text'>In this paper, we develop a new planning method that extends the capabilities
of the true online TD to allow an agent to efficiently replay all or part of
its past experience, online in the sequence that they appear with, either in
each step or sparsely according to the usual {\lambda} parameter. In this new
method that we call True Online TD-Replan({\lambda}), the {\lambda} parameter
plays a new role in specifying the density of the replay process in addition to
the usual role of specifying the depth of the target's updates. We demonstrate
that, for problems that benefit from experience replay, our new method
outperforms true online TD({\lambda}), albeit quadratic in complexity due to
its replay capabilities. In addition, we demonstrate that our method
outperforms other methods with similar quadratic complexity such as Dyna
Planning and TD({\lambda})-Replan algorithms. We test our method on two
benchmarking environments, a random walk problem that uses simple binary
features and a myoelectric control domain that uses both simple sEMG features
and deeply extracted features to showcase its capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19007v1' target='_blank'>A heuristic for the deployment of collecting routes for urban recycle
  stations (eco-points)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guido Marseglia, Juan Antonio Mesa, Francisco A Ortega, Ramón Piedra-de-la-Cuadra</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 10:19:12</h6>
<p class='card-text'>The rapid and constant increase in urban population has led to a drastic rise
in urban solid waste production with worrying consequences for the environment
and society. In many cities, an efficient waste management combined with a
suitable design of vehicle routes (VR) can lead to benefits in the
environmental, economic, and social impacts. The general population is becoming
increasingly aware of the need for the separation of the various categories of
municipal solid waste. The numerous materials collected include glass, PET or
batteries, and electric components, which are sorted at the eco-points. The
management of eco-points gives rise to several problems that can be formulated
analytically. The location and number of eco-point containers, the
determination of the fleet size for picking up the collected waste, and the
design of itineraries are all intertwined, and present computationally
difficult problems, and therefore must be solved in a sequential way. In this
paper, a mathematical model has been formulated, based on the Bin Packing (BP)
and VR schemes, for the deployment of routes of mobile containers in the
selective collection of urban solid waste. A heuristic algorithm has also been
developed, which considers two different configurations of the containers to
solve the proposed mathematical programming model. The results obtained from
the numerical simulations show the validation of the proposed methodology
carried out for the benchmark of the Sioux Falls network and the specific real
case study.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19003v1' target='_blank'>Virtual airways heatmaps to optimize point of entry location in lung
  biopsy planning systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Debora Gil, Pere Lloret, Marta Diez-Ferrer, Carles Sanchez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 10:14:47</h6>
<p class='card-text'>Purpose: We present a virtual model to optimize point of entry (POE) in lung
biopsy planning systems. Our model allows to compute the quality of a biopsy
sample taken from potential POE, taking into account the margin of error that
arises from discrepancies between the orientation in the planning simulation
and the actual orientation during the operation. Additionally, the study
examines the impact of the characteristics of the lesion. Methods: The quality
of the biopsy is given by a heatmap projected onto the skeleton of a
patient-specific model of airways. The skeleton provides a 3D representation of
airways structure, while the heatmap intensity represents the potential amount
of tissue that it could be extracted from each POE. This amount of tissue is
determined by the intersection of the lesion with a cone that represents the
uncertainty area in the introduction of biopsy instruments. The cone, lesion,
and skeleton are modelled as graphical objects that define a 3D scene of the
intervention. Results: We have simulated different settings of the intervention
scene from a single anatomy extracted from a CT scan and two lesions with
regular and irregular shapes. The different scenarios are simulated by
systematic rotation of each lesion placed at different distances from airways.
Analysis of the heatmaps for the different settings show a strong impact of
lesion orientation for irregular shape and the distance for both shapes.
Conclusion: The proposed heatmaps help to visually assess the optimal POE and
identify whether multiple optimal POEs exist in different zones of the bronchi.
They also allow us to model the maximum allowable error in navigation systems
and study which variables have the greatest influence on the success of the
operation. Additionally, they help determine at what point this influence could
potentially jeopardize the operation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18942v1' target='_blank'>Open-Source Autonomous Driving Software Platforms: Comparison of
  Autoware and Apollo</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hee-Yang Jung, Dong-Hee Paek, Seung-Hyun Kong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 08:05:28</h6>
<p class='card-text'>Full-stack autonomous driving system spans diverse technological
domains-including perception, planning, and control-that each require in-depth
research. Moreover, validating such technologies of the system necessitates
extensive supporting infrastructure, from simulators and sensors to
high-definition maps. These complexities with barrier to entry pose substantial
limitations for individual developers and research groups. Recently,
open-source autonomous driving software platforms have emerged to address this
challenge by providing autonomous driving technologies and practical supporting
infrastructure for implementing and evaluating autonomous driving
functionalities. Among the prominent open-source platforms, Autoware and Apollo
are frequently adopted in both academia and industry. While previous studies
have assessed each platform independently, few have offered a quantitative and
detailed head-to-head comparison of their capabilities. In this paper, we
systematically examine the core modules of Autoware and Apollo and evaluate
their middleware performance to highlight key differences. These insights serve
as a practical reference for researchers and engineers, guiding them in
selecting the most suitable platform for their specific development
environments and advancing the field of full-stack autonomous driving system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01654v1' target='_blank'>Predicting concentration levels of air pollutants by transfer learning
  and recurrent neural network</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Iat Hang Fong, Tengyue Li, Simon Fong, Raymond K. Wong, Antonio J. Tallón-Ballesteros</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 23:39:19</h6>
<p class='card-text'>Air pollution (AP) poses a great threat to human health, and people are
paying more attention than ever to its prediction. Accurate prediction of AP
helps people to plan for their outdoor activities and aids protecting human
health. In this paper, long-short term memory (LSTM) recurrent neural networks
(RNNs) have been used to predict the future concentration of air pollutants
(APS) in Macau. Additionally, meteorological data and data on the concentration
of APS have been utilized. Moreover, in Macau, some air quality monitoring
stations (AQMSs) have less observed data in quantity, and, at the same time,
some AQMSs recorded less observed data of certain types of APS. Therefore, the
transfer learning and pre-trained neural networks have been employed to assist
AQMSs with less observed data to build a neural network with high prediction
accuracy. The experimental sample covers a period longer than 12-year and
includes daily measurements from several APS as well as other more classical
meteorological values. Records from five stations, four out of them are AQMSs
and the remaining one is an automatic weather station, have been prepared from
the aforesaid period and eventually underwent to computational intelligence
techniques to build and extract a prediction knowledge-based system. As shown
by experimentation, LSTM RNNs initialized with transfer learning methods have
higher prediction accuracy; it incurred shorter training time than randomly
initialized recurrent neural networks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18802v1' target='_blank'>Agile and Cooperative Aerial Manipulation of a Cable-Suspended Load</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sihao Sun, Xuerui Wang, Dario Sanalitro, Antonio Franchi, Marco Tognon, Javier Alonso-Mora</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 23:38:52</h6>
<p class='card-text'>Quadrotors can carry slung loads to hard-to-reach locations at high speed.
Since a single quadrotor has limited payload capacities, using a team of
quadrotors to collaboratively manipulate a heavy object is a scalable and
promising solution. However, existing control algorithms for multi-lifting
systems only enable low-speed and low-acceleration operations due to the
complex dynamic coupling between quadrotors and the load, limiting their use in
time-critical missions such as search and rescue. In this work, we present a
solution to significantly enhance the agility of cable-suspended multi-lifting
systems. Unlike traditional cascaded solutions, we introduce a trajectory-based
framework that solves the whole-body kinodynamic motion planning problem
online, accounting for the dynamic coupling effects and constraints between the
quadrotors and the load. The planned trajectory is provided to the quadrotors
as a reference in a receding-horizon fashion and is tracked by an onboard
controller that observes and compensates for the cable tension. Real-world
experiments demonstrate that our framework can achieve at least eight times
greater acceleration than state-of-the-art methods to follow agile
trajectories. Our method can even perform complex maneuvers such as flying
through narrow passages at high speed. Additionally, it exhibits high
robustness against load uncertainties and does not require adding any sensors
to the load, demonstrating strong practicality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18766v1' target='_blank'>Breaking the Fake News Barrier: Deep Learning Approaches in Bangla
  Language</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pronoy Kumar Mondal, Sadman Sadik Khan, Md. Masud Rana, Shahriar Sultan Ramit, Abdus Sattar, Md. Sadekur Rahman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 21:41:26</h6>
<p class='card-text'>The rapid development of digital stages has greatly compounded the dispersal
of untrue data, dissolving certainty and judgment in society, especially among
the Bengali-speaking community. Our ponder addresses this critical issue by
presenting an interesting strategy that utilizes a profound learning
innovation, particularly the Gated Repetitive Unit (GRU), to recognize fake
news within the Bangla dialect. The strategy of our proposed work incorporates
intensive information preprocessing, which includes lemmatization,
tokenization, and tending to course awkward nature by oversampling. This comes
about in a dataset containing 58,478 passages. We appreciate the creation of a
demonstration based on GRU (Gated Repetitive Unit) that illustrates remarkable
execution with a noteworthy precision rate of 94%. This ponder gives an
intensive clarification of the methods included in planning the information,
selecting the show, preparing it, and assessing its execution. The performance
of the model is investigated by reliable metrics like precision, recall, F1
score, and accuracy. The commitment of the work incorporates making a huge fake
news dataset in Bangla and a demonstration that has outperformed other Bangla
fake news location models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18505v1' target='_blank'>Path Planning and Optimization for Cuspidal 6R Manipulators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexander J. Elias, John T. Wen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 17:15:11</h6>
<p class='card-text'>A cuspidal robot can move from one inverse kinematics (IK) solution to
another without crossing a singularity. Multiple industrial robots are
cuspidal. They tend to have a beautiful mechanical design, but they pose path
planning challenges. A task-space path may have a valid IK solution for each
point along the path, but a continuous joint-space path may depend on the
choice of the IK solution or even be infeasible. This paper presents new
analysis, path planning, and optimization methods to enhance the utility of
cuspidal robots. We first demonstrate an efficient method to identify cuspidal
robots and show, for the first time, that the ABB GoFa and certain robots with
three parallel joint axes are cuspidal. We then propose a new path planning
method for cuspidal robots by finding all IK solutions for each point along a
task-space path and constructing a graph to connect each vertex corresponding
to an IK solution. Graph edges are weighted based on the optimization metric,
such as minimizing joint velocity. The optimal feasible path is the shortest
path in the graph. This method can find non-singular paths as well as smooth
paths which pass through singularities. Finally, this path planning method is
incorporated into a path optimization algorithm. Given a fixed workspace
toolpath, we optimize the offset of the toolpath in the robot base frame while
ensuring continuous joint motion. Code examples are available in a publicly
accessible repository.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18433v2' target='_blank'>A Comparative Dosimetric Study of Proton and Photon Therapy in
  Stereotactic Arrhythmia Radioablation for Ventricular Tachycardia</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Keyur D. Shah, Chih-Wei Chang, Pretesh Patel, Sibo Tian, Yuan Shao, Kristin A Higgins, Yinan Wang, Justin Roper, Jun Zhou, Zhen Tian, Xiaofeng Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 15:39:03</h6>
<p class='card-text'>Purpose: VT is a life-threatening arrhythmia commonly treated with catheter
ablation; however, some cases remain refractory to conventional treatment. STAR
has emerged as a non-invasive option for such patients. While photon-based STAR
has shown efficacy, proton therapy offers potential advantages due to its
superior dose conformity and sparing of critical OARs, including the heart
itself. This study aims to investigate and compare the dosimetry between proton
and photon therapy for VT, focusing on target coverage and OAR sparing.
Methods: We performed a retrospective study on a cohort of 34 VT patients who
received photon STAR. Proton STAR plans were generated using robust
optimization in RayStation to deliver the same prescription dose of 25 Gy in a
single fraction while minimizing dose to OARs. Dosimetric metrics, including
D99, D95, Dmean, and D0.03cc, were extracted for critical OARs and VAS.
Shapiro-Wilk tests were used to assess normality, followed by paired t-tests or
Wilcoxon signed-rank tests for statistical comparisons between modalities, with
Bonferroni correction applied for multiple comparisons. Results: Proton and
photon plans achieved comparable target coverage, with VAS D95 of 24.1 +/- 1.2
Gy vs. 24.7 +/- 1.0 Gy (p=0.294). Proton therapy significantly reduced OAR
doses, including heart Dmean (3.6 +/- 1.5 Gy vs. 5.5 +/- 2.0 Gy, p<0.001),
lungs Dmean (1.6 +/- 1.5 Gy vs. 2.1 +/- 1.4 Gy, p<0.001), and esophagus Dmean
(0.3 +/- 0.6 Gy vs. 1.6 +/- 1.3 Gy, p<0.001), while maintaining optimal target
coverage. Conclusion: Proton therapy for STAR demonstrates significant
dosimetric advantages in sparing the heart and other critical OARs compared to
photon therapy for VT, while maintaining equivalent target coverage. These
findings highlight the potential of proton therapy to reduce treatment-related
toxicity and improve outcomes for VT patients.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18432v2' target='_blank'>Solving Drone Routing Problems with Quantum Computing: A Hybrid Approach
  Combining Quantum Annealing and Gate-Based Paradigms</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eneko Osaba, Pablo Miranda-Rodriguez, Andreas Oikonomakis, Matic Petrič, Alejandra Ruiz, Sebastian Bock, Michail-Alexandros Kourtis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 15:38:40</h6>
<p class='card-text'>This paper presents a novel hybrid approach to solving real-world drone
routing problems by leveraging the capabilities of quantum computing. The
proposed method, coined Quantum for Drone Routing (Q4DR), integrates the two
most prominent paradigms in the field: quantum gate-based computing, through
the Eclipse Qrisp programming language; and quantum annealers, by means of
D-Wave System's devices. The algorithm is divided into two different phases: an
initial clustering phase executed using a Quantum Approximate Optimization
Algorithm (QAOA), and a routing phase employing quantum annealers. The efficacy
of Q4DR is demonstrated through three use cases of increasing complexity, each
incorporating real-world constraints such as asymmetric costs, forbidden paths,
and itinerant charging points. This research contributes to the growing body of
work in quantum optimization, showcasing the practical applications of quantum
computing in logistics and route planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18411v1' target='_blank'>Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nolan Koblischke, Hyunseok Jang, Kristen Menou, Mohamad Ali-Dib</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 15:06:34</h6>
<p class='card-text'>Modern science emerged from reasoning over repeatedly-observed planetary
motions. We present Gravity-Bench-v1, an environment-based benchmark that
challenges AI agents on tasks that parallel this historical development.
Gravity-Bench-v1 evaluates agents on the discovery of physics concealed within
a dynamic environment, using rigorous gravitational dynamics simulations.
Gravity-Bench includes out-of-distribution cases, i.e. with physics that
deviates from the real world, to evaluate true scientific generalization
capabilities. Agents must plan to collect data within an experimental budget
and must perform a dynamic form of data analysis and reasoning to solve tasks
efficiently. Our benchmark admits an open-ended space of solutions. PhD-level
solutions for each task are provided, to calibrate AI performance against human
expertise. Technically at an upper-undergraduate level, our benchmark proves
challenging to baseline AI agents. Gravity-Bench-v1 and planned extensions
should help map out AI progress towards scientific discovery capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18383v1' target='_blank'>A tutorial on conducting sample size and power calculations for
  detecting treatment effect heterogeneity in cluster randomized trials</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mary Ryan Baumann, Monica Taljaard, Patrick J. Heagerty, Michael O. Harhay, Guangyu Tong, Rui Wang, Fan Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 14:32:57</h6>
<p class='card-text'>Cluster-randomized trials (CRTs) are a well-established class of designs for
evaluating large-scale, community-based research questions. An essential task
in planning these trials is determining the required number of clusters and
cluster sizes to achieve sufficient statistical power for detecting a
clinically relevant effect size. Compared to methods for evaluating the average
treatment effect (ATE) for the entire study population, there is more recent
development of sample size methods for testing the heterogeneity of treatment
effects (HTEs), i.e., modification of treatment effects by subpopulation
characteristics, in CRTs. For confirmatory analyses of HTEs in CRTs, effect
modifiers must be pre-specified, and ideally, accompanied by sample size or
power calculations to ensure the trial has adequate power for the planned
analyses. Power analysis for HTE analyses is more complex than for ATEs due to
the additional design parameters that must be specified. Power and sample size
formulas for HTE analyses have been separately derived under several
cluster-randomized designs, including single and multi-period parallel designs,
crossover designs, and stepped-wedge designs, as well as under continuous and
binary outcomes. This tutorial provides a consolidated reference guide for
these methods and enhances their accessibility through the development of an
online R Shiny calculator. We further discuss key considerations for
researchers conducting sample size and power calculations for testing
pre-specified HTE hypotheses in CRTs, including the essential role of advance
estimates of intracluster correlation coefficients for both outcomes and
covariates on power. The sample size methodology and calculator functionality
are demonstrated through real CRT examples.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18351v1' target='_blank'>Dual-BEV Nav: Dual-layer BEV-based Heuristic Path Planning for Robotic
  Navigation in Unstructured Outdoor Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jianfeng Zhang, Hanlin Dong, Jian Yang, Jiahui Liu, Shibo Huang, Ke Li, Xuan Tang, Xian Wei, Xiong You</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 13:55:08</h6>
<p class='card-text'>Path planning with strong environmental adaptability plays a crucial role in
robotic navigation in unstructured outdoor environments, especially in the case
of low-quality location and map information. The path planning ability of a
robot depends on the identification of the traversability of global and local
ground areas. In real-world scenarios, the complexity of outdoor open
environments makes it difficult for robots to identify the traversability of
ground areas that lack a clearly defined structure. Moreover, most existing
methods have rarely analyzed the integration of local and global traversability
identifications in unstructured outdoor scenarios. To address this problem, we
propose a novel method, Dual-BEV Nav, first introducing Bird's Eye View (BEV)
representations into local planning to generate high-quality traversable paths.
Then, these paths are projected onto the global traversability map generated by
the global BEV planning model to obtain the optimal waypoints. By integrating
the traversability from both local and global BEV, we establish a dual-layer
BEV heuristic planning paradigm, enabling long-distance navigation in
unstructured outdoor environments. We test our approach through both public
dataset evaluations and real-world robot deployments, yielding promising
results. Compared to baselines, the Dual-BEV Nav improved temporal distance
prediction accuracy by up to $18.7\%$. In the real-world deployment, under
conditions significantly different from the training set and with notable
occlusions in the global BEV, the Dual-BEV Nav successfully achieved a
65-meter-long outdoor navigation. Further analysis demonstrates that the local
BEV representation significantly enhances the rationality of the planning,
while the global BEV probability map ensures the robustness of the overall
planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18299v1' target='_blank'>Model-Free RL Agents Demonstrate System 1-Like Intentionality</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hal Ashton, Matija Franklin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 12:21:50</h6>
<p class='card-text'>This paper argues that model-free reinforcement learning (RL) agents, while
lacking explicit planning mechanisms, exhibit behaviours that can be analogised
to System 1 ("thinking fast") processes in human cognition. Unlike model-based
RL agents, which operate akin to System 2 ("thinking slow") reasoning by
leveraging internal representations for planning, model-free agents react to
environmental stimuli without anticipatory modelling. We propose a novel
framework linking the dichotomy of System 1 and System 2 to the distinction
between model-free and model-based RL. This framing challenges the prevailing
assumption that intentionality and purposeful behaviour require planning,
suggesting instead that intentionality can manifest in the structured, reactive
behaviours of model-free agents. By drawing on interdisciplinary insights from
cognitive psychology, legal theory, and experimental jurisprudence, we explore
the implications of this perspective for attributing responsibility and
ensuring AI safety. These insights advocate for a broader, contextually
informed interpretation of intentionality in RL systems, with implications for
their ethical deployment and regulation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18257v2' target='_blank'>DATCloud: A Model-Driven Framework for Multi-Layered Data-Intensive
  Architectures</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Moamin Abughazala, Henry Muccini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 10:39:17</h6>
<p class='card-text'>The complexity of multi-layered, data-intensive systems demands frameworks
that ensure flexibility, scalability, and efficiency. DATCloud is a
model-driven framework designed to facilitate the modeling, validation, and
refinement of multi-layered architectures, addressing scalability, modularity,
and real-world requirements. By adhering to ISO/IEC/IEEE 42010 standards,
DATCloud leverages structural and behavioral meta-models and graphical
domain-specific languages (DSLs) to enhance reusability and stakeholder
communication. Initial validation through the VASARI system at the Uffizi
Gallery demonstrates a 40% reduction in modeling time and a 32% improvement in
flexibility compared to manual methods. While effective, DATCloud is a work in
progress, with plans to integrate advanced code generation, simulation tools,
and domain-specific extensions to further enhance its capabilities for
applications in healthcare, smart cities, and other data-intensive domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18232v1' target='_blank'>Free-T2M: Frequency Enhanced Text-to-Motion Diffusion Model With
  Consistency Loss</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenshuo Chen, Haozhe Jia, Songning Lai, Keming Wu, Hongru Xiao, Lijie Hu, Yutao Yue</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 09:45:23</h6>
<p class='card-text'>Rapid progress in text-to-motion generation has been largely driven by
diffusion models. However, existing methods focus solely on temporal modeling,
thereby overlooking frequency-domain analysis. We identify two key phases in
motion denoising: the **semantic planning stage** and the **fine-grained
improving stage**. To address these phases effectively, we propose
**Fre**quency **e**nhanced **t**ext-**to**-**m**otion diffusion model
(**Free-T2M**), incorporating stage-specific consistency losses that enhance
the robustness of static features and improve fine-grained accuracy. Extensive
experiments demonstrate the effectiveness of our method. Specifically, on
StableMoFusion, our method reduces the FID from **0.189** to **0.051**,
establishing a new SOTA performance within the diffusion architecture. These
findings highlight the importance of incorporating frequency-domain insights
into text-to-motion generation for more precise and robust results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18229v1' target='_blank'>GPD: Guided Polynomial Diffusion for Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ajit Srikanth, Parth Mahanjan, Kallol Saha, Vishal Mandadi, Pranjal Paul, Pawan Wadhwani, Brojeshwar Bhowmick, Arun Singh, Madhava Krishna</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 09:35:17</h6>
<p class='card-text'>Diffusion-based motion planners are becoming popular due to their
well-established performance improvements, stemming from sample diversity and
the ease of incorporating new constraints directly during inference. However, a
primary limitation of the diffusion process is the requirement for a
substantial number of denoising steps, especially when the denoising process is
coupled with gradient-based guidance. In this paper, we introduce, diffusion in
the parametric space of trajectories, where the parameters are represented as
Bernstein coefficients. We show that this representation greatly improves the
effectiveness of the cost function guidance and the inference speed. We also
introduce a novel stitching algorithm that leverages the diversity in
diffusion-generated trajectories to produce collision-free trajectories with
just a single cost function-guided model. We demonstrate that our approaches
outperform current SOTA diffusion-based motion planners for manipulators and
provide an ablation study on key components.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18220v1' target='_blank'>On-Line Learning for Planning and Control of Underactuated Robots with
  Uncertain Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Giulio Turrisi, Marco Capotondi, Claudio Gaz, Valerio Modugno, Giuseppe Oriolo, Alessandro De Luca</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 09:22:56</h6>
<p class='card-text'>We present an iterative approach for planning and controlling motions of
underactuated robots with uncertain dynamics. At its core, there is a learning
process which estimates the perturbations induced by the model uncertainty on
the active and passive degrees of freedom. The generic iteration of the
algorithm makes use of the learned data in both the planning phase, which is
based on optimization, and the control phase, where partial feedback
linearization of the active dofs is performed on the model updated on-line. The
performance of the proposed approach is shown by comparative simulations and
experiments on a Pendubot executing various types of swing-up maneuvers. Very
few iterations are typically needed to generate dynamically feasible
trajectories and the tracking control that guarantees their accurate execution,
even in the presence of large model uncertainties.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18153v1' target='_blank'>Volumetric modulated arc therapy or step-shoot IMRT? A 4D dosimetry
  study of motion effect in lung SBRT using a dynamic virtual patient model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianjun Ma, Bingqi Guo, Salim Balik, Peng Qi, Anthony Magnelli, Gregory M M. Videtic, Kevin L Stephans, Tingliang Zhuang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 05:38:35</h6>
<p class='card-text'>Purpose: To investigate the impact of delivery techniques and planning
parameters on interplay effect in lung SBRT.
  Methods: A dynamic virtual patient model containing normal structures and a
tumor with adjustable sizes, locations, and 3D breathing motion was utilized.
SBRT plans were developed using both step-and-shoot IMRT and VMAT with
different planning parameters (energy, isocenter location, PTV margin, and PTV
dose heterogeneity). 4D doses were calculated by simulating synchronized
delivery of SBRT to the virtual patient model with random initial positions of
tumor motion. The expected dose (average) and the standard deviation of the 4D
doses were obtained. The relative difference between the expected GTV
minimal/mean (GTVMin/GTVMean) dose and the planned ITVMin/ITVMean dose (denoted
by %E/P), and between the GTVMin and the prescription dose (DRx) were computed.
  Results: The %E/P for GTVMean was significantly lower for IMRT than VMAT
(0.5% +/- 7.7% v.s. 3.5% +/- 5.0%, p=0.04). The expected GTVMin was lower than
DRx in 9.4% of all IMRT plans versus 3.1% in VMAT. The worst-case scenario, 4D
GTVMin was 14.1% lower than the ITVMin. Choices of PTV margin or dose
heterogeneity to be achieved in PTV can result in significant difference
(p<0.05) in motion interplay depending on delivery techniques.
  Conclusion: Motion interplay may cause the expected GTVMin to be less than
the planned ITV minimal dose and DRx for both IMRT and VMAT plans. The
differences between the expected GTV dose and the ITV dose depended on the
delivery technique and planning parameters. Overall, VMAT is less prone to
motion interplay than IMRT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18653v1' target='_blank'>Cogito, ergo sum: A Neurobiologically-Inspired Cognition-Memory-Growth
  System for Code Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanlong Li, Jindong Li, Qi Wang, Menglin Yang, He Kong, Shengsheng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 01:41:44</h6>
<p class='card-text'>Large language models based Multi Agent Systems (MAS) have demonstrated
promising performance for enhancing the efficiency and accuracy of code
generation tasks. However,most existing methods follow a conventional sequence
of planning, coding, and debugging,which contradicts the growth-driven nature
of human learning process. Additionally,the frequent information interaction
between multiple agents inevitably involves high computational costs. In this
paper,we propose Cogito,a neurobiologically inspired multi-agent framework to
enhance the problem-solving capabilities in code generation tasks with lower
cost. Specifically,Cogito adopts a reverse sequence: it first undergoes
debugging, then coding,and finally planning. This approach mimics human
learning and development,where knowledge is acquired progressively.
Accordingly,a hippocampus-like memory module with different functions is
designed to work with the pipeline to provide quick retrieval in similar tasks.
Through this growth-based learning model,Cogito accumulates knowledge and
cognitive skills at each stage,ultimately forming a Super Role an all capable
agent to perform the code generation task. Extensive experiments against
representative baselines demonstrate the superior performance and efficiency of
Cogito. The code is publicly available at
https://anonymous.4open.science/r/Cogito-0083.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18075v1' target='_blank'>Synthesizing Grasps and Regrasps for Complex Manipulation Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aditya Patankar, Dasharadhan Mahalingam, Nilanjan Chakraborty</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 00:58:31</h6>
<p class='card-text'>In complex manipulation tasks, e.g., manipulation by pivoting, the motion of
the object being manipulated has to satisfy path constraints that can change
during the motion. Therefore, a single grasp may not be sufficient for the
entire path, and the object may need to be regrasped. Additionally, geometric
data for objects from a sensor are usually available in the form of point
clouds. The problem of computing grasps and regrasps from point-cloud
representation of objects for complex manipulation tasks is a key problem in
endowing robots with manipulation capabilities beyond pick-and-place. In this
paper, we formalize the problem of grasping/regrasping for complex manipulation
tasks with objects represented by (partial) point clouds and present an
algorithm to solve it. We represent a complex manipulation task as a sequence
of constant screw motions. Using a manipulation plan skeleton as a sequence of
constant screw motions, we use a grasp metric to find graspable regions on the
object for every constant screw segment. The overlap of the graspable regions
for contiguous screws are then used to determine when and how many times the
object needs to be regrasped. We present experimental results on point cloud
data collected from RGB-D sensors to illustrate our approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17982v1' target='_blank'>Belief Roadmaps with Uncertain Landmark Evanescence</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Erick Fuentes, Jared Strader, Ethan Fahnestock, Nicholas Roy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 20:37:01</h6>
<p class='card-text'>We would like a robot to navigate to a goal location while minimizing state
uncertainty. To aid the robot in this endeavor, maps provide a prior belief
over the location of objects and regions of interest. To localize itself within
the map, a robot identifies mapped landmarks using its sensors. However, as the
time between map creation and robot deployment increases, portions of the map
can become stale, and landmarks, once believed to be permanent, may disappear.
We refer to the propensity of a landmark to disappear as landmark evanescence.
Reasoning about landmark evanescence during path planning, and the associated
impact on localization accuracy, requires analyzing the presence or absence of
each landmark, leading to an exponential number of possible outcomes of a given
motion plan. To address this complexity, we develop BRULE, an extension of the
Belief Roadmap. During planning, we replace the belief over future robot poses
with a Gaussian mixture which is able to capture the effects of landmark
evanescence. Furthermore, we show that belief updates can be made efficient,
and that maintaining a random subset of mixture components is sufficient to
find high quality solutions. We demonstrate performance in simulated and
real-world experiments. Software is available at https://bit.ly/BRULE.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17968v1' target='_blank'>Online Trajectory Replanner for Dynamically Grasping Irregular Objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minh Nhat Vu, Florian Grander, Anh Nguyen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 20:06:15</h6>
<p class='card-text'>This paper presents a new trajectory replanner for grasping irregular
objects. Unlike conventional grasping tasks where the object's geometry is
assumed simple, we aim to achieve a "dynamic grasp" of the irregular objects,
which requires continuous adjustment during the grasping process. To
effectively handle irregular objects, we propose a trajectory optimization
framework that comprises two phases. Firstly, in a specified time limit of 10s,
initial offline trajectories are computed for a seamless motion from an initial
configuration of the robot to grasp the object and deliver it to a pre-defined
target location. Secondly, fast online trajectory optimization is implemented
to update robot trajectories in real-time within 100 ms. This helps to mitigate
pose estimation errors from the vision system. To account for model
inaccuracies, disturbances, and other non-modeled effects, trajectory tracking
controllers for both the robot and the gripper are implemented to execute the
optimal trajectories from the proposed framework. The intensive experimental
results effectively demonstrate the performance of our trajectory planning
framework in both simulation and real-world scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17963v1' target='_blank'>Physics-Grounded Differentiable Simulation for Soft Growing Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lucas Chen, Yitian Gao, Sicheng Wang, Francesco Fuentes, Laura H. Blumenschein, Zachary Kingston</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 19:53:14</h6>
<p class='card-text'>Soft-growing robots (i.e., vine robots) are a promising class of soft robots
that allow for navigation and growth in tightly confined environments. However,
these robots remain challenging to model and control due to the complex
interplay of the inflated structure and inextensible materials, which leads to
obstacles for autonomous operation and design optimization. Although there
exist simulators for these systems that have achieved qualitative and
quantitative success in matching high-level behavior, they still often fail to
capture realistic vine robot shapes using simplified parameter models and have
difficulties in high-throughput simulation necessary for planning and parameter
optimization. We propose a differentiable simulator for these systems, enabling
the use of the simulator "in-the-loop" of gradient-based optimization
approaches to address the issues listed above. With the more complex parameter
fitting made possible by this approach, we experimentally validate and
integrate a closed-form nonlinear stiffness model for thin-walled inflated
tubes based on a first-principles approach to local material wrinkling. Our
simulator also takes advantage of data-parallel operations by leveraging
existing differentiable computation frameworks, allowing multiple simultaneous
rollouts. We demonstrate the feasibility of using a physics-grounded nonlinear
stiffness model within our simulator, and how it can be an effective tool in
sim-to-real transfer. We provide our implementation open source.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17797v1' target='_blank'>The SPHEREx Target List of Ice Sources (SPLICES)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Matthew L. N. Ashby, Joseph L. Hora, Kiran Lakshmipathaiah, Sarita Vig, Rama Krishna Sai Subrahmanyam Gorthi, Miju Kang, Volker Tolls, Gary J. Melnick, Michael W. Werner, Brendan P. Crill, Daniel C. Masters, Carlos Contreras Pena, Jeong-Eun Lee, Jaeyeong Kim, Ho-Gyu Lee, Sung-Yong Yoon, Soung-Chul Yang, Nicholas Flagey, Bertrand Mennesson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 17:35:41</h6>
<p class='card-text'>One of the primary objectives of the SPHEREx mission is to understand the
origin of molecules such as H2O, CO2, and other volatile compounds at the early
stages of planetary system formation. Because the vast majority of these
compounds -- typically exceeding 95% -- exist in the solid phase rather than
the gaseous phase in the systems of concern here, the observing strategy
planned to characterize them is slightly unusual. Specifically, SPHEREx will
target highly obscured sources throughout the Milky Way, and observe the
species of concern in absorption against background illumination. SPHEREx
spectrophotometry will yield ice column density measurements for millions of
obscured Milky Way sources of all ages and types. By correlating those column
densities with source ages, the SPHEREx mission will shed light on whether
those molecules were formed in situ along with their nascent stellar systems,
or whether instead they formed elsewhere and were introduced into those systems
after their formation. To that end, this work describes version 7$.$1 of the
SPHEREx Target List of Ice Sources (SPLICES) for the community. It contains
about 8$.$6 million objects brighter than W2~12 Vega mag over much of the sky,
principally within a broad strip running the length of the Milky Way midplane,
but also within high-latitude molecular clouds and even the Magellanic Clouds.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00056v1' target='_blank'>Sustainable Multi-Modal Transportation and Routing focusing on Costs and
  Carbon Emissions Reduction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saba Javanpour, A. Radman, Sarow Saeedi, Sina Feizi Karimabadi, Daniel A. Larson, Eric C. Jones</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 16:53:28</h6>
<p class='card-text'>Transportation plays a critical role in supply chain networks, directly
impacting cost efficiency, delivery reliability, and environmental
sustainability. This study provides an enhanced optimization model for
transportation planning, emphasizing environmental sustainability and
cost-efficiency. An Integer Linear Programming (ILP) model was developed to
minimize the total transportation costs by considering organizational and
third-party vehicles' operational and rental costs while incorporating
constraints on carbon emissions. The model incorporates multi-modal
transportation routing and emission caps to select the optimized number of
organizational and rental vehicles of different modes in each route to ensure
adherence to sustainability goals. Key innovations include adding carbon
emission constraints and optimizing route selection to reduce overall
emissions. The model was implemented using the Gurobi solver, and numerical
analysis reveals a trade-off between cost minimization and carbon footprint
reduction. The results indicate that adopting tight environmental policies
increases the costs by around 8% on average while more than 95% of the vehicles
utilized will be rented. These insights provide actionable guidance for
industries aiming to enhance both economic performance and environmental
responsibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17661v1' target='_blank'>Multi-Agent Path Finding Using Conflict-Based Search and
  Structural-Semantic Topometric Maps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Scott Fredriksson, Yifan Bai, Akshit Saradagi, George Nikolakopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 14:01:41</h6>
<p class='card-text'>As industries increasingly adopt large robotic fleets, there is a pressing
need for computationally efficient, practical, and optimal conflict-free path
planning for multiple robots. Conflict-Based Search (CBS) is a popular method
for multi-agent path finding (MAPF) due to its completeness and optimality;
however, it is often impractical for real-world applications, as it is
computationally intensive to solve and relies on assumptions about agents and
operating environments that are difficult to realize. This article proposes a
solution to overcome computational challenges and practicality issues of CBS by
utilizing structural-semantic topometric maps. Instead of running CBS over
large grid-based maps, the proposed solution runs CBS over a sparse topometric
map containing structural-semantic cells representing intersections, pathways,
and dead ends. This approach significantly accelerates the MAPF process and
reduces the number of conflict resolutions handled by CBS while operating in
continuous time. In the proposed method, robots are assigned time ranges to
move between topometric regions, departing from the traditional CBS assumption
that a robot can move to any connected cell in a single time step. The approach
is validated through real-world multi-robot path-finding experiments and
benchmarking simulations. The results demonstrate that the proposed MAPF method
can be applied to real-world non-holonomic robots and yields significant
improvement in computational efficiency compared to traditional CBS methods
while improving conflict detection and resolution in cases of corridor
symmetries.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17645v1' target='_blank'>A modified Bellman-Ford Algorithm for Application in Symbolic Optimal
  Control and Plan and Goal Recognition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marcus Kreuzer, Alexander Weber, Alexander Knoll</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 13:27:32</h6>
<p class='card-text'>The contributions of this short technical note are two-fold. Firstly, we
introduce a modified version of a generalized Bellman-Ford algorithm
calculating the value function of optimal control problems defined on
hyper-graphs. Those Bellman-Ford algorithms can be used in particular for the
synthesis of near-optimal controllers by the principle of symbolic control. Our
modification causes less nodes of the hyper-graph being iterated during the
execution compared to our initial version of the algorithm published in 2020.
Our second contribution lies in the field of Plan recognition applied to drone
missions driven by symbolic controllers. We address and resolve the Plan and
Goal Recognition monitor's dependence on a pre-defined initial guess for a
drone's task allocation and mission execution. To validate the enhanced
implementation, we use a more challenging scenario for UAV-based aerial
firefighting, demonstrating the practical applicability and robustness of the
system architecture.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17529v1' target='_blank'>Accelerated DC loadflow solver for topology optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nico Westerbeck, Joost van Dijk, Jan Viebahn, Christian Merz, Dirk Witthaut</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 09:57:53</h6>
<p class='card-text'>We present a massively parallel solver that accelerates DC loadflow
computations for power grid topology optimization tasks. Our approach leverages
low-rank updates of the Power Transfer Distribution Factors (PTDFs) to
represent substation splits, line outages, and reconfigurations without ever
refactorizing the system. Furthermore, we implement the core routines on
Graphics Processing Units (GPUs), thereby exploiting their high-throughput
architecture for linear algebra. A two-level decomposition separates changes in
branch topology from changes in nodal injections, enabling additional speed-ups
by an in-the-loop brute force search over injection variations at minimal
additional cost. We demonstrate billion-loadflow-per-second performance on
power grids of varying sizes in workload settings which are typical for
gradient-free topology optimization such as Reinforcement Learning or Quality
Diversity methods. While adopting the DC approximation sacrifices some accuracy
and prohibits the computation of voltage magnitudes, we show that this
sacrifice unlocks new scales of computational feasibility, offering a powerful
tool for large-scale grid planning and operational topology optimization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17484v1' target='_blank'>Capacity Expansion Planning under Uncertainty subject to Expected Energy
  Not Served Constraints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marilena Zampara, Daniel Ávila, Anthony Papavasiliou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 08:52:04</h6>
<p class='card-text'>We present a method for solving a large-scale stochastic capacity expansion
problem which explicitly considers reliability constraints, in particular
constraints on expected energy not served. Our method tackles this problem by a
Lagrange relaxation of the expected energy not served constraints. We solve the
relaxed formulation in an iterative manner, using a subgradient-based method.
Each iteration requires the solution of a stochastic capacity expansion
problem, for which we implement a subgradient decomposition scheme in a
high-performance computing infrastructure. We apply the proposed methodology on
the Economic Viability Assessment model that is used by ENTSO-E in the annual
European Resource Adequacy Assessment, extended to include explicit reliability
constraints. The approach is able to solve this model achieving a 1.3%
optimality gap. We compare our approach against accounting for reliability
through penalizing load shedding at VOLL, and find that the former results in
1.6% savings in total cost. We are also able to quantify the cost savings from
allowing some load curtailment in the capacity planning process, which ranges
from 1.6 to 6% in the cases analyzed.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17437v1' target='_blank'>Bayesian BIM-Guided Construction Robot Navigation with NLP Safety
  Prompts in Dynamic Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mani Amani, Reza Akhavian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 06:32:55</h6>
<p class='card-text'>Construction robotics increasingly relies on natural language processing for
task execution, creating a need for robust methods to interpret commands in
complex, dynamic environments. While existing research primarily focuses on
what tasks robots should perform, less attention has been paid to how these
tasks should be executed safely and efficiently. This paper presents a novel
probabilistic framework that uses sentiment analysis from natural language
commands to dynamically adjust robot navigation policies in construction
environments. The framework leverages Building Information Modeling (BIM) data
and natural language prompts to create adaptive navigation strategies that
account for varying levels of environmental risk and uncertainty. We introduce
an object-aware path planning approach that combines exponential potential
fields with a grid-based representation of the environment, where the potential
fields are dynamically adjusted based on the semantic analysis of user prompts.
The framework employs Bayesian inference to consolidate multiple information
sources: the static data from BIM, the semantic content of natural language
commands, and the implied safety constraints from user prompts. We demonstrate
our approach through experiments comparing three scenarios: baseline
shortest-path planning, safety-oriented navigation, and risk-aware routing.
Results show that our method successfully adapts path planning based on natural
language sentiment, achieving a 50\% improvement in minimum distance to
obstacles when safety is prioritized, while maintaining reasonable path
lengths. Scenarios with contrasting prompts, such as "dangerous" and "safe",
demonstrate the framework's ability to modify paths. This approach provides a
flexible foundation for integrating human knowledge and safety considerations
into construction robot navigation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17414v1' target='_blank'>Reqo: A Robust and Explainable Query Optimization Cost Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Baoming Chang, Amin Kamali, Verena Kantere</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 04:48:51</h6>
<p class='card-text'>In recent years, there has been a growing interest in using machine learning
(ML) in query optimization to select more efficient plans. Existing
learning-based query optimizers use certain model architectures to convert
tree-structured query plans into representations suitable for downstream ML
tasks. As the design of these architectures significantly impacts cost
estimation, we propose a tree model architecture based on Bidirectional Graph
Neural Networks (Bi-GNN) aggregated by Gated Recurrent Units (GRUs) to achieve
more accurate cost estimates. The inherent uncertainty of data and model
parameters also leads to inaccurate cost estimates, resulting in suboptimal
plans and less robust query performance. To address this, we implement a novel
learning-to-rank cost model that effectively quantifies the uncertainty in cost
estimates using approximate probabilistic ML. This model adaptively integrates
quantified uncertainty with estimated costs and learns from comparing pairwise
plans, achieving more robust performance. In addition, we propose the first
explainability technique specifically designed for learning-based cost models.
This technique explains the contribution of any subgraphs in the query plan to
the final predicted cost, which can be integrated and trained with any
learning-based cost model to significantly boost the model's explainability. By
incorporating these innovations, we propose a cost model for a Robust and
Explainable Query Optimizer, Reqo, that improves the accuracy, robustness, and
explainability of cost estimation, outperforming state-of-the-art approaches in
all three dimensions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00051v1' target='_blank'>A two-stage dual-task learning strategy for early prediction of
  pathological complete response to neoadjuvant chemotherapy for breast cancer
  using dynamic contrast-enhanced magnetic resonance images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bowen Jing, Jing Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 21:13:14</h6>
<p class='card-text'>Rationale and Objectives: Early prediction of pathological complete response
(pCR) can facilitate personalized treatment for breast cancer patients. To
improve prediction accuracy at the early time point of neoadjuvant
chemotherapy, we proposed a two-stage dual-task learning strategy to train a
deep neural network for early prediction of pCR using early-treatment magnetic
resonance images. Methods: We developed and validated the two-stage dual-task
learning strategy using the dataset from the national-wide, multi-institutional
I-SPY2 clinical trial, which included dynamic contrast-enhanced magnetic
resonance images acquired at three time points: pretreatment (T0), after 3
weeks (T1), and after 12 weeks of treatment (T2). First, we trained a
convolutional long short-term memory network to predict pCR and extract the
latent space image features at T2. At the second stage, we trained a dual-task
network to simultaneously predict pCR and the image features at T2 using images
from T0 and T1. This allowed us to predict pCR earlier without using images
from T2. Results: The conventional single-stage single-task strategy gave an
area under the receiver operating characteristic curve (AUROC) of 0.799 for pCR
prediction using all the data at time points T0 and T1. By using the proposed
two-stage dual-task learning strategy, the AUROC was improved to 0.820.
Conclusions: The proposed two-stage dual-task learning strategy can improve
model performance significantly (p=0.0025) for predicting pCR at the early
stage (3rd week) of neoadjuvant chemotherapy. The early prediction model can
potentially help physicians to intervene early and develop personalized plans
at the early stage of chemotherapy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17131v1' target='_blank'>Scenario Understanding of Traffic Scenes Through Large Visual Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rivera Esteban, Lübberstedt Jannik, Nico Uhlemann, Markus Lienkamp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 18:23:12</h6>
<p class='card-text'>Deep learning models for autonomous driving, encompassing perception,
planning, and control, depend on vast datasets to achieve their high
performance. However, their generalization often suffers due to domain-specific
data distributions, making an effective scene-based categorization of samples
necessary to improve their reliability across diverse domains. Manual
captioning, though valuable, is both labor-intensive and time-consuming,
creating a bottleneck in the data annotation process. Large Visual Language
Models (LVLMs) present a compelling solution by automating image analysis and
categorization through contextual queries, often without requiring retraining
for new categories. In this study, we evaluate the capabilities of LVLMs,
including GPT-4 and LLaVA, to understand and classify urban traffic scenes on
both an in-house dataset and the BDD100K. We propose a scalable captioning
pipeline that integrates state-of-the-art models, enabling a flexible
deployment on new datasets. Our analysis, combining quantitative metrics with
qualitative insights, demonstrates the effectiveness of LVLMs to understand
urban traffic scenarios and highlights their potential as an efficient tool for
data-driven advancements in autonomous driving.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17068v1' target='_blank'>SWIPE: Stars WIth Pulsations and Eclipses</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:John Southworth</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 16:52:50</h6>
<p class='card-text'>Eclipses and pulsations are the two primary ways in which the physical
properties of stars can be deduced and used to improve our understanding of
stellar theory. An obvious idea is to combine these two analyses into the study
of pulsating stars in eclipsing binaries. This is the aim of the SWIPE project.
This paper summarises the scientific arguments, current status and future plans
of the project.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16922v1' target='_blank'>Agential AI for Integrated Continual Learning, Deliberative Behavior,
  and Comprehensible Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeki Doruk Erden, Boi Faltings</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 13:09:08</h6>
<p class='card-text'>Contemporary machine learning paradigm excels in statistical data analysis,
solving problems that classical AI couldn't. However, it faces key limitations,
such as a lack of integration with planning, incomprehensible internal
structure, and inability to learn continually. We present the initial design
for an AI system, Agential AI (AAI), in principle operating independently or on
top of statistical methods, designed to overcome these issues. AAI's core is a
learning method that models temporal dynamics with guarantees of completeness,
minimality, and continual learning, using component-level variation and
selection to learn the structure of the environment. It integrates this with a
behavior algorithm that plans on a learned model and encapsulates high-level
behavior patterns. Preliminary experiments on a simple environment show AAI's
effectiveness and potential.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16918v1' target='_blank'>On Rollouts in Model-Based Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bernd Frauenknecht, Devdutt Subhasish, Friedrich Solowjow, Sebastian Trimpe</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 13:02:52</h6>
<p class='card-text'>Model-based reinforcement learning (MBRL) seeks to enhance data efficiency by
learning a model of the environment and generating synthetic rollouts from it.
However, accumulated model errors during these rollouts can distort the data
distribution, negatively impacting policy learning and hindering long-term
planning. Thus, the accumulation of model errors is a key bottleneck in current
MBRL methods. We propose Infoprop, a model-based rollout mechanism that
separates aleatoric from epistemic model uncertainty and reduces the influence
of the latter on the data distribution. Further, Infoprop keeps track of
accumulated model errors along a model rollout and provides termination
criteria to limit data corruption. We demonstrate the capabilities of Infoprop
in the Infoprop-Dyna algorithm, reporting state-of-the-art performance in
Dyna-style MBRL on common MuJoCo benchmark tasks while substantially increasing
rollout length and data quality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16864v1' target='_blank'>A methodology and a platform for high-quality rich personal data
  collection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ivan Kayongo, Leonardo Malcotti, Haonan Zhao, Fausto Giunchiglia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 11:28:22</h6>
<p class='card-text'>In the last years the pervasive use of sensors, as they exist in smart
devices, e.g., phones, watches, medical devices, has increased dramatically the
availability of personal data. However, existing research on data collection
primarily focuses on the objective view of reality, as provided, for instance,
by sensors, often neglecting the integration of subjective human input, as
provided, for instance, by user answers to questionnaires. This limits
substantially the exploitability of the collected data. In this paper we
present a methodology and a platform specifically designed for the collection
of a combination of large-scale sensor data and qualitative human feedback. The
methodology has been designed to be deployed on top, and enriches the
functionalities of, an existing data collection APP, called iLog, which has
been used in large scale, worldwide data collection experiments. The main goal
is to put the key actors involved in an experiment, i.e., the researcher in
charge, the participant, and iLog in better control of the experiment itself,
thus enabling a much improved quality and richness of the data collected. The
novel functionalities of the resulting platform are: (i) a time-wise
representation of the situational context within which the data collection is
performed, (ii) an explicit representation of the temporal context within which
the data collection is performed, (iii) a calendar-based dashboard for the
real-time monitoring of the data collection context(s), and, finally, (iv) a
mechanism for the run-time revision of the data collection plan. The
practicality and utility of the proposed functionalities are demonstrated by
showing how they apply to a case study involving 350 University students.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16839v3' target='_blank'>Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christian Wald, Gabriele Steidl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 10:28:17</h6>
<p class='card-text'>Among generative neural models, flow matching techniques stand out for their
simple applicability and good scaling properties. Here, velocity fields of
curves connecting a simple latent and a target distribution are learned. Then
the corresponding ordinary differential equation can be used to sample from a
target distribution, starting in samples from the latent one. This paper
reviews from a mathematical point of view different techniques to learn the
velocity fields of absolutely continuous curves in the Wasserstein geometry. We
show how the velocity fields can be characterized and learned via i) transport
plans (couplings) between latent and target distributions, ii) Markov kernels
and iii) stochastic processes, where the latter two include the coupling
approach, but are in general broader. Besides this main goal, we show how flow
matching can be used for solving Bayesian inverse problems, where the
definition of conditional Wasserstein distances plays a central role. Finally,
we briefly address continuous normalizing flows and score matching techniques,
which approach the learning of velocity fields of curves from other directions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16818v1' target='_blank'>Evaluation of new radio occultation observations among small satellites
  at Venus by data assimilation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yukiko Fujisawa, Norihiko Sugimoto, Chi Ao, Asako Hosono, Hiroki Ando, Masahiro Takagi, Itziar Garate-Lopez, Sebastien Lebonnois</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 09:50:13</h6>
<p class='card-text'>We conducted observing system simulation experiments (OSSEs) for radio
occultation measurements (RO) among small satellites, which are expected to be
useful for future Venus missions. The effectiveness of the observations based
on realistic orbit calculations was evaluated by reproduction of the "cold
collar", a unique thermal structure in the polar atmosphere of Venus.
Pseudo-temperature observations for the OSSEs were provided from the Venus
atmospheric GCM in which the cold collar was reproduced by the thermal forcing.
The vertical temperature distributions between 40 and 90 km altitudes at
observation points were assimilated. The result showed that the cold collar was
most clearly reproduced in the case where the temperature field in
high-latitudes was observed twice a day, suggesting that the proposed
observation is quite effective to improve the polar atmospheric structure at
least. Although the cold collar was also reproduced in the OSSEs for Longwave
Infrared Camera (LIR) observations, the result seemed unrealistic and
inefficient compared to that obtained in the RO OSSEs. The present study shows
that the OSSEs can be used to evaluate observation plans and instruments in
terms of reproducibility of specific atmospheric phenomena, and applied to
future missions targeting planetary atmospheres.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16743v1' target='_blank'>Hierarchical Trajectory (Re)Planning for a Large Scale Swarm</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lishuo Pan, Yutong Wang, Nora Ayanian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 06:40:29</h6>
<p class='card-text'>We consider the trajectory replanning problem for a large-scale swarm in a
cluttered environment. Our path planner replans for robots by utilizing a
hierarchical approach, dividing the workspace, and computing collision-free
paths for robots within each cell in parallel. Distributed trajectory
optimization generates a deadlock-free trajectory for efficient execution and
maintains the control feasibility even when the optimization fails. Our
hierarchical approach combines the benefits of both centralized and
decentralized methods, achieving a high task success rate while providing
real-time replanning capability. Compared to decentralized approaches, our
approach effectively avoids deadlocks and collisions, significantly increasing
the task success rate. We demonstrate the real-time performance of our
algorithm with up to 142 robots in simulation, and a representative 24 physical
Crazyflie nano-quadrotor experiment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16725v1' target='_blank'>A strategic planning of a digital copy (an enterprise) as a task of
  control a dynamic system</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seregey Masaev, Valentina Vingert, Alexey Bogdanov, Yass Salal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 06:06:47</h6>
<p class='card-text'>The area of research includes: control theory, dynamic systems, parameters of
the external environment, mode, integral indicators, strategy. The general
problem of assessing the state of large economic objects (enterprises) is
revealed. There is no unified assessment a control of through strategic
planning. The article proposes an integral indicator method for a unified
assessment of the enterprise. The enterprise is formalized as a digital copy.
The digital copy includes all business processes at any given time. The digital
copy is presented as a multidimensional dynamic system. Dimension of
multidimensional dynamic system is 1.2 parameters This allows you to estimate
the modes operation of the enterprise in the normal mode and in the mode for
control of strategic planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16544v1' target='_blank'>PLANSIEVE: Real-time Suboptimal Query Plan Detection Through Incremental
  Refinements</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Asoke Datta, Yesdaulet Izenov, Brian Tsan, Abylay Amanbayev, Florin Rusu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 22:33:47</h6>
<p class='card-text'>Cardinality estimation remains a fundamental challenge in query optimization,
often resulting in sub-optimal execution plans and degraded performance. While
errors in cardinality estimation are inevitable, existing methods for
identifying sub-optimal plans -- such as metrics like Q-error, P-error, or
L1-error -- are limited to post-execution analysis, requiring complete
knowledge of true cardinalities and failing to prevent the execution of
sub-optimal plans in real-time. This paper introduces PLANSIEVE, a novel
framework that identifies sub-optimal plans during query optimization.
PLANSIEVE operates by analyzing the relative order of sub-plans generated by
the optimizer based on estimated and true cardinalities. It begins with
surrogate cardinalities from any third-party estimator and incrementally
refines these surrogates as the system processes more queries. Experimental
results on the augmented JOB-LIGHT-SCALE and STATS-CEB-SCALE workloads
demonstrate that PLANSIEVE achieves an accuracy of up to 88.7\% in predicting
sub-optimal plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16411v2' target='_blank'>PhysBench: Benchmarking and Enhancing Vision-Language Models for
  Physical World Understanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Chow, Jiageng Mao, Boyi Li, Daniel Seita, Vitor Guizilini, Yue Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 18:59:58</h6>
<p class='card-text'>Understanding the physical world is a fundamental challenge in embodied AI,
critical for enabling agents to perform complex tasks and operate safely in
real-world environments. While Vision-Language Models (VLMs) have shown great
promise in reasoning and task planning for embodied agents, their ability to
comprehend physical phenomena remains extremely limited. To close this gap, we
introduce PhysBench, a comprehensive benchmark designed to evaluate VLMs'
physical world understanding capability across a diverse set of tasks.
PhysBench contains 10,002 entries of interleaved video-image-text data,
categorized into four major domains: physical object properties, physical
object relationships, physical scene understanding, and physics-based dynamics,
further divided into 19 subclasses and 8 distinct capability dimensions. Our
extensive experiments, conducted on 75 representative VLMs, reveal that while
these models excel in common-sense reasoning, they struggle with understanding
the physical world -- likely due to the absence of physical knowledge in their
training data and the lack of embedded physical priors. To tackle the
shortfall, we introduce PhysAgent, a novel framework that combines the
generalization strengths of VLMs with the specialized expertise of vision
models, significantly enhancing VLMs' physical understanding across a variety
of tasks, including an 18.4\% improvement on GPT-4o. Furthermore, our results
demonstrate that enhancing VLMs' physical world understanding capabilities can
help embodied agents such as MOKA. We believe that PhysBench and PhysAgent
offer valuable insights and contribute to bridging the gap between VLMs and
physical world understanding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16197v1' target='_blank'>HERITRACE: A User-Friendly Semantic Data Editor with Change Tracking and
  Provenance Management for Cultural Heritage Institutions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arcangelo Massari, Silvio Peroni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 16:48:39</h6>
<p class='card-text'>HERITRACE is a data editor designed for galleries, libraries, archives and
museums, aimed at simplifying data curation while enabling non-technical domain
experts to manage data intuitively without losing its semantic integrity. While
the semantic nature of RDF can pose a barrier to data curation due to its
complexity, HERITRACE conceals this intricacy while preserving the advantages
of semantic representation. The system natively supports provenance management
and change tracking, ensuring transparency and accountability throughout the
curation process. Although HERITRACE functions effectively out of the box, it
offers a straightforward customization interface for technical staff, enabling
adaptation to the specific data model required by a given collection. Current
applications include the ParaText project, and its adoption is already planned
for OpenCitations. Future developments will focus on integrating the RDF
Mapping Language (RML) to enhance compatibility with non-RDF data formats,
further expanding its applicability in digital heritage management.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16142v1' target='_blank'>Towards General-Purpose Model-Free Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Scott Fujimoto, Pierluca D'Oro, Amy Zhang, Yuandong Tian, Michael Rabbat</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 15:36:37</h6>
<p class='card-text'>Reinforcement learning (RL) promises a framework for near-universal
problem-solving. In practice however, RL algorithms are often tailored to
specific benchmarks, relying on carefully tuned hyperparameters and algorithmic
choices. Recently, powerful model-based RL methods have shown impressive
general results across benchmarks but come at the cost of increased complexity
and slow run times, limiting their broader applicability. In this paper, we
attempt to find a unifying model-free deep RL algorithm that can address a
diverse class of domains and problem settings. To achieve this, we leverage
model-based representations that approximately linearize the value function,
taking advantage of the denser task objectives used by model-based RL while
avoiding the costs associated with planning or simulated trajectories. We
evaluate our algorithm, MR.Q, on a variety of common RL benchmarks with a
single set of hyperparameters and show a competitive performance against
domain-specific and general baselines, providing a concrete step towards
building general-purpose model-free deep RL algorithms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16135v1' target='_blank'>Evaluation of NMT-Assisted Grammar Transfer for a Multi-Language
  Configurable Data-to-Text System</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andreas Madsack, Johanna Heininger, Adela Schneider, Ching-Yi Chen, Christian Eckard, Robert Weißgraeber</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 15:25:26</h6>
<p class='card-text'>One approach for multilingual data-to-text generation is to translate
grammatical configurations upfront from the source language into each target
language. These configurations are then used by a surface realizer and in
document planning stages to generate output. In this paper, we describe a
rule-based NLG implementation of this approach where the configuration is
translated by Neural Machine Translation (NMT) combined with a one-time human
review, and introduce a cross-language grammar dependency model to create a
multilingual NLG system that generates text from the source data, scaling the
generation phase without a human in the loop. Additionally, we introduce a
method for human post-editing evaluation on the automatically translated text.
Our evaluation on the SportSett:Basketball dataset shows that our NLG system
performs well, underlining its grammatical correctness in translation tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16101v1' target='_blank'>3D Reconstruction of non-visible surfaces of objects from a Single Depth
  View -- Comparative Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rafał Staszak, Piotr Michałek, Jakub Chudziński, Marek Kopicki, Dominik Belter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 14:50:19</h6>
<p class='card-text'>Scene and object reconstruction is an important problem in robotics, in
particular in planning collision-free trajectories or in object manipulation.
This paper compares two strategies for the reconstruction of nonvisible parts
of the object surface from a single RGB-D camera view. The first method, named
DeepSDF predicts the Signed Distance Transform to the object surface for a
given point in 3D space. The second method, named MirrorNet reconstructs the
occluded objects' parts by generating images from the other side of the
observed object. Experiments performed with objects from the ShapeNet dataset,
show that the view-dependent MirrorNet is faster and has smaller reconstruction
errors in most categories.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16098v1' target='_blank'>Multi-Agent Meta-Offline Reinforcement Learning for Timely UAV Path
  Planning and Data Collection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eslam Eldeeb, Hirley Alves</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 14:47:19</h6>
<p class='card-text'>Multi-agent reinforcement learning (MARL) has been widely adopted in
high-performance computing and complex data-driven decision-making in the
wireless domain. However, conventional MARL schemes face many obstacles in
real-world scenarios. First, most MARL algorithms are online, which might be
unsafe and impractical. Second, MARL algorithms are environment-specific,
meaning network configuration changes require model retraining. This letter
proposes a novel meta-offline MARL algorithm that combines conservative
Q-learning (CQL) and model agnostic meta-learning (MAML). CQL enables offline
training by leveraging pre-collected datasets, while MAML ensures scalability
and adaptability to dynamic network configurations and objectives. We propose
two algorithm variants: independent training (M-I-MARL) and centralized
training decentralized execution (M-CTDE-MARL). Simulation results show that
the proposed algorithm outperforms conventional schemes, especially the CTDE
approach that achieves 50 % faster convergence in dynamic scenarios than the
benchmarks. The proposed framework enhances scalability, robustness, and
adaptability in wireless communication systems by optimizing UAV trajectories
and scheduling policies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16080v1' target='_blank'>Generating Spatial Synthetic Populations Using Wasserstein Generative
  Adversarial Network: A Case Study with EU-SILC Data for Helsinki and
  Thessaloniki</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vanja Falck</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 14:29:07</h6>
<p class='card-text'>Using agent-based social simulations can enhance our understanding of urban
planning, public health, and economic forecasting. Realistic synthetic
populations with numerous attributes strengthen these simulations. The
Wasserstein Generative Adversarial Network, trained on census data like
EU-SILC, can create robust synthetic populations. These methods, aided by
external statistics or EU-SILC weights, generate spatial synthetic populations
for agent-based models. The increased access to high-quality micro-data has
sparked interest in synthetic populations, which preserve demographic profiles
and analytical strength while ensuring privacy and preventing discrimination.
This study uses national data from Finland and Greece for Helsinki and
Thessaloniki to explore balanced spatial synthetic population generation.
Results show challenges related to balancing data with or without aggregated
statistics for the target population and the general under-representation of
fringe profiles by deep generative methods. The latter can lead to
discrimination in agent-based simulations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15847v2' target='_blank'>Can Location Embeddings Enhance Super-Resolution of Satellite Imagery?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Panangian, Ksenia Bittner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 08:16:54</h6>
<p class='card-text'>Publicly available satellite imagery, such as Sentinel- 2, often lacks the
spatial resolution required for accurate analysis of remote sensing tasks
including urban planning and disaster response. Current super-resolution
techniques are typically trained on limited datasets, leading to poor
generalization across diverse geographic regions. In this work, we propose a
novel super-resolution framework that enhances generalization by incorporating
geographic context through location embeddings. Our framework employs
Generative Adversarial Networks (GANs) and incorporates techniques from
diffusion models to enhance image quality. Furthermore, we address tiling
artifacts by integrating information from neighboring images, enabling the
generation of seamless, high-resolution outputs. We demonstrate the
effectiveness of our method on the building segmentation task, showing
significant improvements over state-of-the-art methods and highlighting its
potential for real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15819v1' target='_blank'>Navigation Framework for Blind and Visually Impaired Persons based on
  Sensor Fusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chathurika S. Silva, Prasad Wimalaratne</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 06:55:07</h6>
<p class='card-text'>Individuals who are differently-able in vision cannot proceed with their
day-to-day activities as smoothly as other people do. Especially independent
walking is a hard target to achieve with their visual impairment. Assistive
electronic travel aids equipped with different types of sensors are designed
for visually impaired persons to assist their safe navigation. The amount of
research on combining multiple sensors in assistive navigation aids for
visually impaired navigation is limited. Most work is targeted at sensor
integration but not at sensor fusion. This paper aims to address how sensor
fusion and integration will be used to improve the sub-processes of visually
impaired navigation and the way to evaluate the sensor fusion-based approach
for visually impaired navigation which consists of several contributions to
field sensor fusion in visually impaired navigation such as a novel homogeneous
sensor fusion algorithm based on extended Kalman filter, a novel heterogeneous
sensor integration approach, and a complementary sensor fusion algorithm based
on error state extended Kaman filter. Overall this research presents a novel
navigational framework to integrate obstacle detection, obstacle recognition,
localization, motion planning, and current context awareness with sensor
fusion.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15744v1' target='_blank'>Noise disturbance and lack of privacy: Modeling acoustic dissatisfaction
  in open-plan offices</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Manuj Yadav, Jungsoo Kim, Valtteri Hongisto, Densil Cabrera, Richard de Dear</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 03:10:07</h6>
<p class='card-text'>Open-plan offices are well-known to be adversely affected by acoustic issues.
This study aims to model acoustic dissatisfaction using measurements of room
acoustics, sound environment during occupancy, and occupant surveys (n = 349)
in 28 offices representing a diverse range of workplace parameters. As latent
factors, the contribution of $\textit{lack of privacy}$ (LackPriv) was 25%
higher than $\textit{noise disturbance}$ (NseDstrb) in predicting
$\textit{acoustic dissatisfaction}$ (AcDsat). Room acoustic metrics based on
sound pressure level (SPL) decay of speech ($L_{\text{p,A,s,4m}}$ and
$r_{\text{C}}$) were better in predicting these factors than distraction
distance ($r_{\text{D}}$) based on speech transmission index. This contradicts
previous findings, and the trends for SPL-based metrics in predicting AcDsat
and LackPriv go against expectations based on ISO 3382-3. For sound during
occupation, $L_{\text{A,90}}$ and psychoacoustic loudness ($N_{\text{90}}$)
predicted AcDsat, and a SPL fluctuation metric ($M_{\text{A,eq}}$) predicted
LackPriv. However, these metrics were weaker predictors than ISO 3382-3
metrics. Medium-sized offices exhibited higher dissatisfaction than larger
($\geq$50 occupants) offices. Dissatisfaction varied substantially across
parameters including ceiling heights, number of workstations, and years of
work, but not between offices with fixed seating compared to more flexible and
activity-based working configurations. Overall, these findings highlight the
complexities in characterizing occupants' perceptions using instrumental
acoustic measurements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15737v1' target='_blank'>Geometric Deep Learning for Automated Landmarking of Maxillary Arches on
  3D Oral Scans from Newborns with Cleft Lip and Palate</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Artur Agaronyan, HyeRan Choo, Marius Linguraru, Syed Muhammad Anwar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 02:50:14</h6>
<p class='card-text'>Rapid advances in 3D model scanning have enabled the mass digitization of
dental clay models. However, most clinicians and researchers continue to use
manual morphometric analysis methods on these models such as landmarking. This
is a significant step in treatment planning for craniomaxillofacial conditions.
We aimed to develop and test a geometric deep learning model that would
accurately and reliably label landmarks on a complicated and specialized
patient population -- infants, as accurately as a human specialist without a
large amount of training data. Our developed pipeline demonstrated an accuracy
of 94.44% with an absolute mean error of 1.676 +/- 0.959 mm on a set of 100
models acquired from newborn babies with cleft lip and palate. Our proposed
pipeline has the potential to serve as a fast, accurate, and reliable
quantifier of maxillary arch morphometric features, as well as an integral step
towards a future fully automated dental treatment pipeline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15684v1' target='_blank'>Compensator-based small animal IMRT enables conformal preclinical dose
  painting: application to tumor hypoxia</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jordan M. Slagowski, Erik Pearson, Rajit Tummala, Gage Redler, Daniela Olivera Velarde, Boris Epel, Howard J. Halpern, Bulent Aydogan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 21:57:42</h6>
<p class='card-text'>Techniques for preclinical intensity modulated radiation therapy are being
developed to improve translation by replicating the clinical paradigm. This
study presents the first treatment planning comparison between small animal
IMRT (SA-IMRT) and three-dimensional conformal radiotherapy (CRT) in a model
application, oxygen-guided dose painting of tumor hypoxia, using actual mouse
data. A novel compensator-based platform was employed to generate SA-IMRT and
CRT plans with 2-15 beam angles for seventeen mice with fibrosarcoma tumors.
The whole tumor received a dose of 22.5 Gy, with a simultaneous integrated
boost of 13 Gy to hypoxic voxels identified via electron paramagnetic resonance
imaging. Plan quality was assessed using the Paddick conformity index (CI),
uniformity, and dose volume histograms. For 3-angles, SA-IMRT yielded
significantly improved dose conformity (median hypoxic CI =0.45 versus 0.17),
tumor dose uniformity (11.0% versus 14.3%), and dosimetric spread between boost
and non-boost targets (D50% difference = 13.0 Gy [ideal], 13.1 Gy [SA-IMRT], 7.
3 Gy [CRT]). No significant improvement in CI was associated with >3 beam
angles (Wilcoxon signed-rank test, p < 0.05). This study demonstrates that
SA-IMRT provides significant improvements in radiation plan quality and yields
dose distributions that more closely mimic the clinical setting relative to
current CRT approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15664v1' target='_blank'>The Advanced Muon Facility: a proposed multi-purpose muon facility at
  Fermilab</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sophie Middleton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 19:54:54</h6>
<p class='card-text'>Charged lepton flavor violation (CLFV) is expected in a diverse set of new
physics scenarios. The current generation of experiments probe CLFV in the muon
sector in three complementary channels: $\mu^-N \rightarrow e^- N$ (Mu2e,
COMET), $\mu^+ \rightarrow e^+ \gamma$ (MEG-II), and $\mu^+ \rightarrow
e^+e^+e^-$s (Mu3e). These experiments aim to enhance existing limits by several
orders-of-magnitude in the coming decade and offer discovery potential to many
new physics models. The proposed Advanced Muon Facility (AMF) would be a
multi-purpose muon facility based at Fermilab and introduces an innovative
approach based on a muon storage ring to enable a full suite of muon CLFV
experiments. AMF would host CLFV experiments with sensitivities
orders-of-magnitude beyond the present era. In the event of a signal in these
currently planned experiments, AMF would enable additional measurements to
elucidate the nature of the new physics observed. The design and R$\&$D for AMF
is in its infancy. This article outlines the motivations for AMF, detailing
on-going R$\&$D efforts, and highlighting potential synergies with the proposed
muon collider.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15660v1' target='_blank'>Marker Track: Accurate Fiducial Marker Tracking for Evaluation of
  Residual Motions During Breath-Hold Radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aimee Guo, Weihua Mao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 19:46:49</h6>
<p class='card-text'>Fiducial marker positions in projection image of cone-beam computed
tomography (CBCT) scans have been studied to evaluate daily residual motion
during breath-hold radiation therapy. Fiducial marker migration posed
challenges in accurately locating markers, prompting the development of a novel
algorithm that reconstructs volumetric probability maps of marker locations
from filtered gradient maps of projections. This guides the development of a
Python-based algorithm to detect fiducial markers in projection images using
Meta AI's Segment Anything Model 2 (SAM 2). Retrospective data from a
pancreatic cancer patient with two fiducial markers were analyzed. The
three-dimensional (3D) marker positions from simulation computed tomography
(CT) were compared to those reconstructed from CBCT images, revealing a
decrease in relative distances between markers over time. Fiducial markers were
successfully detected in 2777 out of 2786 projection frames. The average
standard deviation of superior-inferior (SI) marker positions was 0.56 mm per
breath-hold, with differences in average SI positions between two breath-holds
in the same scan reaching up to 5.2 mm, and a gap of up to 7.3 mm between the
end of the first and beginning of the second breath-hold. 3D marker positions
were calculated using projection positions and confirmed marker migration. This
method effectively calculates marker probability volume and enables accurate
fiducial marker tracking during treatment without requiring any specialized
equipment, additional radiation doses, or manual initialization and labeling.
It has significant potential for automatically assessing daily residual motion
to adjust planning margins, functioning as an adaptive radiation therapy tool.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15578v1' target='_blank'>A Complexity-Informed Approach to Optimise Cyber Defences</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lampis Alevizos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 16:04:13</h6>
<p class='card-text'>This paper introduces a novel complexity-informed approach to cybersecurity
management, addressing the challenges found within complex cyber defences. We
adapt and extend the complexity theory to cybersecurity and develop a
quantitative framework that empowers decision-makers with strategies to
de-complexify defences, identify improvement opportunities, and resolve
bottlenecks. Our approach also provides a solid foundation for critical
cybersecurity decisions, such as tooling investment or divestment, workforce
capacity planning, and optimisation of processes and capabilities. Through a
case study, we detail and validate a systematic method for assessing and
managing the complexity within cybersecurity defences. The complexity-informed
approach based on MITRE ATT&CK, is designed to complement threat-informed
defences. Threat-informed methods focus on understanding and countering
adversary tactics, while the complexity-informed approach optimises the
underlying defence infrastructure, thereby optimising the overall efficiency
and effectiveness of cyber defences.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15564v2' target='_blank'>Diffusion-Based Planning for Autonomous Driving with Flexible Guidance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yinan Zheng, Ruiming Liang, Kexin Zheng, Jinliang Zheng, Liyuan Mao, Jianxiong Li, Weihao Gu, Rui Ai, Shengbo Eben Li, Xianyuan Zhan, Jingjing Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 15:49:50</h6>
<p class='card-text'>Achieving human-like driving behaviors in complex open-world environments is
a critical challenge in autonomous driving. Contemporary learning-based
planning approaches such as imitation learning methods often struggle to
balance competing objectives and lack of safety assurance,due to limited
adaptability and inadequacy in learning complex multi-modal behaviors commonly
exhibited in human planning, not to mention their strong reliance on the
fallback strategy with predefined rules. We propose a novel transformer-based
Diffusion Planner for closed-loop planning, which can effectively model
multi-modal driving behavior and ensure trajectory quality without any
rule-based refinement. Our model supports joint modeling of both prediction and
planning tasks under the same architecture, enabling cooperative behaviors
between vehicles. Moreover, by learning the gradient of the trajectory score
function and employing a flexible classifier guidance mechanism, Diffusion
Planner effectively achieves safe and adaptable planning behaviors. Evaluations
on the large-scale real-world autonomous planning benchmark nuPlan and our
newly collected 200-hour delivery-vehicle driving dataset demonstrate that
Diffusion Planner achieves state-of-the-art closed-loop performance with robust
transferability in diverse driving styles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15557v1' target='_blank'>Preventing Household Bankruptcy: The One-Third Rule in Financial
  Planning with Mathematical Validation and Game-Theoretic Insights</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aditi Godbole, Zubin Shah, Ranjeet S. Mudholkar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 15:17:48</h6>
<p class='card-text'>This paper analyzes the 1/3 Financial Rule, a method of allocating income
equally among debt repayment, savings, and living expenses. Through
mathematical modeling, game theory, behavioral finance, and technological
analysis, we examine the rule's potential for supporting household financial
stability and reducing bankruptcy risk. The research develops theoretical
foundations using utility maximization theory, demonstrating how equal
allocation emerges as a solution under standard economic assumptions. The
game-theoretic analysis explores the rule's effectiveness across different
household structures, revealing potential strategic advantages in financial
decision-making. We investigate psychological factors influencing financial
choices, including cognitive biases and neurobiological mechanisms that impact
economic behavior. Technological approaches, such as AI-driven personalization,
blockchain tracking, and smart contract applications, are examined for their
potential to support financial planning. Empirical validation using U.S. Census
data and longitudinal studies assesses the rule's performance across various
household types. Stress testing under different economic conditions provides
insights into its adaptability and resilience. The research integrates
mathematical analysis with behavioral insights and technological perspectives
to develop a comprehensive approach to household financial management.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15554v1' target='_blank'>BoTier: Multi-Objective Bayesian Optimization with Tiered Composite
  Objectives</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohammad Haddadnia, Leonie Grashoff, Felix Strieth-Kalthoff</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 15:05:37</h6>
<p class='card-text'>Scientific optimization problems are usually concerned with balancing
multiple competing objectives, which come as preferences over both the outcomes
of an experiment (e.g. maximize the reaction yield) and the corresponding input
parameters (e.g. minimize the use of an expensive reagent). Typically,
practical and economic considerations define a hierarchy over these objectives,
which must be reflected in algorithms for sample-efficient experiment planning.
Herein, we introduce BoTier, a composite objective that can flexibly represent
a hierarchy of preferences over both experiment outcomes and input parameters.
We provide systematic benchmarks on synthetic and real-life surfaces,
demonstrating the robust applicability of BoTier across a number of use cases.
Importantly, BoTier is implemented in an auto-differentiable fashion, enabling
seamless integration with the BoTorch library, thereby facilitating adoption by
the scientific community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15470v1' target='_blank'>Unveiling the Potential of Multimodal Retrieval Augmented Generation
  with Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaohan Yu, Zhihan Yang, Chong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 10:16:42</h6>
<p class='card-text'>Multimodal Retrieval Augmented Generation (MRAG) systems, while promising for
enhancing Multimodal Large Language Models (MLLMs), often rely on rigid,
single-step retrieval methods. This limitation hinders their ability to
effectively address real-world scenarios that demand adaptive information
acquisition and query refinement. To overcome this, we introduce the novel task
of Multimodal Retrieval Augmented Generation Planning (MRAG Planning), focusing
on optimizing MLLM performance while minimizing computational overhead. We
present CogPlanner, a versatile framework inspired by human cognitive
processes. CogPlanner iteratively refines queries and selects retrieval
strategies, enabling both parallel and sequential modeling approaches. To
rigorously evaluate MRAG Planning, we introduce CogBench, a new benchmark
specifically designed for this task. CogBench facilitates the integration of
lightweight CogPlanner with resource-efficient MLLMs. Our experimental findings
demonstrate that CogPlanner surpasses existing MRAG baselines, achieving
significant improvements in both accuracy and efficiency with minimal
computational overhead.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15464v2' target='_blank'>TractoGPT: A GPT architecture for White Matter Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anoushkrit Goel, Simroop Singh, Ankita Joshi, Ranjeet Ranjan Jha, Chirag Ahuja, Aditya Nigam, Arnav Bhavsar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 09:54:10</h6>
<p class='card-text'>White matter bundle segmentation is crucial for studying brain structural
connectivity, neurosurgical planning, and neurological disorders. White Matter
Segmentation remains challenging due to structural similarity in streamlines,
subject variability, symmetry in 2 hemispheres, etc. To address these
challenges, we propose TractoGPT, a GPT-based architecture trained on
streamline, cluster, and fusion data representations separately. TractoGPT is a
fully-automatic method that generalizes across datasets and retains shape
information of the white matter bundles. Experiments also show that TractoGPT
outperforms state-of-the-art methods on average DICE, Overlap and Overreach
scores. We use TractoInferno and 105HCP datasets and validate generalization
across dataset.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15440v2' target='_blank'>Dfilled: Repurposing Edge-Enhancing Diffusion for Guided DSM Void
  Filling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Panangian, Ksenia Bittner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 08:03:02</h6>
<p class='card-text'>Digital Surface Models (DSMs) are essential for accurately representing
Earth's topography in geospatial analyses. DSMs capture detailed elevations of
natural and manmade features, crucial for applications like urban planning,
vegetation studies, and 3D reconstruction. However, DSMs derived from stereo
satellite imagery often contain voids or missing data due to occlusions,
shadows, and lowsignal areas. Previous studies have primarily focused on void
filling for digital elevation models (DEMs) and Digital Terrain Models (DTMs),
employing methods such as inverse distance weighting (IDW), kriging, and spline
interpolation. While effective for simpler terrains, these approaches often
fail to handle the intricate structures present in DSMs. To overcome these
limitations, we introduce Dfilled, a guided DSM void filling method that
leverages optical remote sensing images through edge-enhancing diffusion.
Dfilled repurposes deep anisotropic diffusion models, which originally designed
for super-resolution tasks, to inpaint DSMs. Additionally, we utilize Perlin
noise to create inpainting masks that mimic natural void patterns in DSMs.
Experimental evaluations demonstrate that Dfilled surpasses traditional
interpolation methods and deep learning approaches in DSM void filling tasks.
Both quantitative and qualitative assessments highlight the method's ability to
manage complex features and deliver accurate, visually coherent results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05187v1' target='_blank'>An Adaptable Budget Planner for Enhancing Budget-Constrained
  Auto-Bidding in Online Advertising</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhijian Duan, Yusen Huo, Tianyu Wang, Zhilin Zhang, Yeshu Li, Chuan Yu, Jian Xu, Bo Zheng, Xiaotie Deng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 08:00:23</h6>
<p class='card-text'>In online advertising, advertisers commonly utilize auto-bidding services to
bid for impression opportunities. A typical objective of the auto-bidder is to
optimize the advertiser's cumulative value of winning impressions within
specified budget constraints. However, such a problem is challenging due to the
complex bidding environment faced by diverse advertisers. To address this
challenge, we introduce ABPlanner, a few-shot adaptable budget planner designed
to improve budget-constrained auto-bidding. ABPlanner is based on a
hierarchical bidding framework that decomposes the bidding process into
shorter, manageable stages. Within this framework, ABPlanner allocates the
budget across all stages, allowing a low-level auto-bidder to bids based on the
budget allocation plan. The adaptability of ABPlanner is achieved through a
sequential decision-making approach, inspired by in-context reinforcement
learning. For each advertiser, ABPlanner adjusts the budget allocation plan
episode by episode, using data from previous episodes as prompt for current
decisions. This enables ABPlanner to quickly adapt to different advertisers
with few-shot data, providing a sample-efficient solution. Extensive simulation
experiments and real-world A/B testing validate the effectiveness of ABPlanner,
demonstrating its capability to enhance the cumulative value achieved by
auto-bidders.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15413v1' target='_blank'>XR-penter: Material-Aware and In Situ Design of Scrap Wood Assemblies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ramya Iyer, Mustafa Doga Dogan, Maria Larsson, Takeo Igarashi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 05:59:23</h6>
<p class='card-text'>Woodworkers have to navigate multiple considerations when planning a project,
including available resources, skill-level, and intended effort. Do it yourself
(DIY) woodworkers face these challenges most acutely because of tight material
constraints and a desire for custom designs tailored to specific spaces. To
address these needs, we present XR-penter, an extended reality (XR) application
that supports in situ, material-aware woodworking for casual makers. Our system
enables users to design virtual scrap wood assemblies directly in their
workspace, encouraging sustainable practices through the use of discarded
materials. Users register physical material as virtual twins, manipulate these
twins into an assembly in XR, and preview cuts needed for fabrication. We
conducted a case study and feedback sessions to demonstrate how XR-penter
supports improvisational workflows in practice, the type of woodworker who
would benefit most from our system, and insights on integrating similar spatial
and material considerations into future work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15389v1' target='_blank'>CP2M: Clustered-Patch-Mixed Mosaic Augmentation for Aerial Image
  Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yijie Li, Hewei Wang, Jinfeng Xu, Zixiao Ma, Puzhen Wu, Shaofan Wang, Soumyabrata Dev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 04:03:08</h6>
<p class='card-text'>Remote sensing image segmentation is pivotal for earth observation,
underpinning applications such as environmental monitoring and urban planning.
Due to the limited annotation data available in remote sensing images, numerous
studies have focused on data augmentation as a means to alleviate overfitting
in deep learning networks. However, some existing data augmentation strategies
rely on simple transformations that may not sufficiently enhance data diversity
or model generalization capabilities. This paper proposes a novel augmentation
strategy, Clustered-Patch-Mixed Mosaic (CP2M), designed to address these
limitations. CP2M integrates a Mosaic augmentation phase with a clustered patch
mix phase. The former stage constructs a new sample from four random samples,
while the latter phase uses the connected component labeling algorithm to
ensure the augmented data maintains spatial coherence and avoids introducing
irrelevant semantics when pasting random patches. Our experiments on the ISPRS
Potsdam dataset demonstrate that CP2M substantially mitigates overfitting,
setting new benchmarks for segmentation accuracy and model robustness in remote
sensing tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15339v1' target='_blank'>DER Hosting capacity for distribution networks: definitions, attributes,
  use-cases and challenges</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md Umar Hashmi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-25 22:40:47</h6>
<p class='card-text'>The rapid adoption of distributed energy resources (DERs) has outpaced grid
modernization, leading to capacity limitations that challenge their further
integration. Hosting Capacity Assessment (HCA) is a critical tool for
evaluating how much DER capacity a grid can handle without breaching
operational limits. HCA serves multiple goals: enabling higher DER penetration,
accelerating grid connection times, guiding infrastructure upgrades or flexible
resource deployment, ensuring equitable policies, and improving grid
flexibility while minimizing curtailment. HCA lacks a universal definition,
varying by modelling approaches, uncertainty considerations, and objectives.
This paper addresses five key questions to standardize and enhance HCA
practices. First, it classifies HCA objectives associated with different
stakeholders such as system operators, consumers, market operators and
consumers. Second, it examines model attributes, including modelling
sophistication, data requirements, and uncertainty handling, thus balancing
complexity with computational efficiency. Third, it explores HCA applications,
such as planning grid investments or operational decisions, and summarizes use
cases associated with HCA. Fourth, it emphasizes the need for periodic updates
to reflect dynamic grid conditions, evolving technologies, and new DER
installations. Finally, it identifies challenges, such as ensuring data
quality, managing computational demands, and aligning short-term and long-term
goals. By addressing these aspects, this paper provides a structured approach
to perform and apply HCA, offering insights for engineers, planners, and
policymakers to manage DER integration effectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15272v1' target='_blank'>Safe and Agile Transportation of Cable-Suspended Payload via Multiple
  Aerial Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yongchao Wang, Junjie Wang, Xiaobin Zhou, Tiankai Yang, Chao Xu, Fei Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-25 16:49:54</h6>
<p class='card-text'>Transporting a heavy payload using multiple aerial robots (MARs) is an
efficient manner to extend the load capacity of a single aerial robot. However,
existing schemes for the multiple aerial robots transportation system (MARTS)
still lack the capability to generate a collision-free and dynamically feasible
trajectory in real-time and further track an agile trajectory especially when
there are no sensors available to measure the states of payload and cable.
Therefore, they are limited to low-agility transportation in simple
environments. To bridge the gap, we propose complete planning and control
schemes for the MARTS, achieving safe and agile aerial transportation (SAAT) of
a cable-suspended payload in complex environments. Flatness maps for the aerial
robot considering the complete kinematical constraint and the dynamical
coupling between each aerial robot and payload are derived. To improve the
responsiveness for the generation of the safe, dynamically feasible, and agile
trajectory in complex environments, a real-time spatio-temporal trajectory
planning scheme is proposed for the MARTS. Besides, we break away from the
reliance on the state measurement for both the payload and cable, as well as
the closed-loop control for the payload, and propose a fully distributed
control scheme to track the agile trajectory that is robust against imprecise
payload mass and non-point mass payload. The proposed schemes are extensively
validated through benchmark comparisons, ablation studies, and simulations.
Finally, extensive real-world experiments are conducted on a MARTS integrated
by three aerial robots with onboard computers and sensors. The result validates
the efficiency and robustness of our proposed schemes for SAAT in complex
environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15249v2' target='_blank'>An Automatic Sound and Complete Abstraction Method for Generalized
  Planning with Baggable Types</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hao Dong, Zheyuan Shi, Hemeng Zeng, Yongmei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-25 15:44:25</h6>
<p class='card-text'>Generalized planning is concerned with how to find a single plan to solve
multiple similar planning instances. Abstractions are widely used for solving
generalized planning, and QNP (qualitative numeric planning) is a popular
abstract model. Recently, Cui et al. showed that a plan solves a sound and
complete abstraction of a generalized planning problem if and only if the
refined plan solves the original problem. However, existing work on automatic
abstraction for generalized planning can hardly guarantee soundness let alone
completeness. In this paper, we propose an automatic sound and complete
abstraction method for generalized planning with baggable types. We use a
variant of QNP, called bounded QNP (BQNP), where integer variables are
increased or decreased by only one. Since BQNP is undecidable, we propose and
implement a sound but incomplete solver for BQNP. We present an automatic
method to abstract a BQNP problem from a classical planning instance with
baggable types. The basic idea for abstraction is to introduce a counter for
each bag of indistinguishable tuples of objects. We define a class of domains
called proper baggable domains, and show that for such domains, the BQNP
problem got by our automatic method is a sound and complete abstraction for a
generalized planning problem whose instances share the same bags with the given
instance but the sizes of the bags might be different. Thus, the refined plan
of a solution to the BQNP problem is a solution to the generalized planning
problem. Finally, we implement our abstraction method and experiments on a
number of domains demonstrate the promise of our approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15198v1' target='_blank'>Towards Conscious Service Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sven Behnke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-25 12:32:52</h6>
<p class='card-text'>Deep learning's success in perception, natural language processing, etc.
inspires hopes for advancements in autonomous robotics. However, real-world
robotics face challenges like variability, high-dimensional state spaces,
non-linear dependencies, and partial observability. A key issue is
non-stationarity of robots, environments, and tasks, leading to performance
drops with out-of-distribution data. Unlike current machine learning models,
humans adapt quickly to changes and new tasks due to a cognitive architecture
that enables systematic generalization and meta-cognition. Human brain's System
1 handles routine tasks unconsciously, while System 2 manages complex tasks
consciously, facilitating flexible problem-solving and self-monitoring. For
robots to achieve human-like learning and reasoning, they need to integrate
causal models, working memory, planning, and metacognitive processing. By
incorporating human cognition insights, the next generation of service robots
will handle novel situations and monitor themselves to avoid risks and mitigate
errors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15149v1' target='_blank'>Mapping Galaxy Images Across Ultraviolet, Visible and Infrared Bands
  Using Generative Deep Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Youssef Zaazou, Alex Bihlo, Terrence S. Tricco</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-25 09:13:21</h6>
<p class='card-text'>We demonstrate that generative deep learning can translate galaxy
observations across ultraviolet, visible, and infrared photometric bands.
Leveraging mock observations from the Illustris simulations, we develop and
validate a supervised image-to-image model capable of performing both band
interpolation and extrapolation. The resulting trained models exhibit high
fidelity in generating outputs, as verified by both general image comparison
metrics (MAE, SSIM, PSNR) and specialized astronomical metrics (GINI
coefficient, M20). Moreover, we show that our model can be used to predict
real-world observations, using data from the DECaLS survey as a case study.
These findings highlight the potential of generative learning to augment
astronomical datasets, enabling efficient exploration of multi-band information
in regions where observations are incomplete. This work opens new pathways for
optimizing mission planning, guiding high-resolution follow-ups, and enhancing
our understanding of galaxy morphology and evolution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15068v3' target='_blank'>An Atomic Skill Library Construction Method for Data-Efficient Embodied
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dongjiang Li, Bo Peng, Chang Li, Ning Qiao, Qi Zheng, Lei Sun, Yusen Qin, Bangguo Li, Yifeng Luan, Bo Wu, Yibing Zhan, Mingang Sun, Tong Xu, Lusong Li, Hui Shen, Xiaodong He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-25 04:19:33</h6>
<p class='card-text'>Embodied manipulation is a fundamental ability in the realm of embodied
artificial intelligence. Although current embodied manipulation models show
certain generalizations in specific settings, they struggle in new environments
and tasks due to the complexity and diversity of real-world scenarios. The
traditional end-to-end data collection and training manner leads to significant
data demands. Decomposing end-to-end tasks into atomic skills helps reduce data
requirements and improves the task success rate. However, existing methods are
limited by predefined skill sets that cannot be dynamically updated. To address
the issue, we introduce a three-wheeled data-driven method to build an atomic
skill library. We divide tasks into subtasks using the Vision-Language-Planning
(VLP). Then, atomic skill definitions are formed by abstracting the subtasks.
Finally, an atomic skill library is constructed via data collection and
Vision-Language-Action (VLA) fine-tuning. As the atomic skill library expands
dynamically with the three-wheel update strategy, the range of tasks it can
cover grows naturally. In this way, our method shifts focus from end-to-end
tasks to atomic skills, significantly reducing data costs while maintaining
high performance and enabling efficient adaptation to new tasks. Extensive
experiments in real-world settings demonstrate the effectiveness and efficiency
of our approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14979v1' target='_blank'>High-level environmental sustainability guidelines for large accelerator
  facilities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hannah Wakeling, Philip Burrows, Jim Clarke, Jo Colwell, Ben Shepherd, John Thomason</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 23:24:30</h6>
<p class='card-text'>The proposed construction of new particle accelerator-based facilities in the
coming decades -- and upgrades to existing facilities -- provides the unique
opportunity to embed innovative environmental impact reduction techniques into
their design. This living document provides high-level guidelines to improve
environmental sustainability in the planning, construction, operational and
decommissioning stages of large accelerator facilities. A collection of various
resources is provided, with examples of some existing and suggested practices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14952v1' target='_blank'>Exclusive $η$ production in proton-proton collisions at GSI-FAIR
  energies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Piotr Lebiedowicz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 22:39:14</h6>
<p class='card-text'>We evaluate the cross sections for the $p p \to p p \eta$ reaction at
energies relevant for the HADES, PANDA and SIS100 experiments at GSI-FAIR
within an effective Lagrangian approach. We consider the $\eta$-bremsstrahlung
mechanism with the intermediate proton exchange via the $\pi^{0}$, $\eta$,
$\rho^{0}$ and $\omega$ exchanges and the mechanism involving the nucleon
resonances $N(1535)$, $N(1650)$, $N(1710)$ and $N(1880)$ excited via the
pseudoscalar- or/and vector-meson exchanges, depending on the model. We also
discuss the role of the $\omega \omega$- and $\rho^{0} \rho^{0}$-fusion
processes with the reggeized vector-meson exchanges. To determine the
parameters of the model, the $\gamma p \to \eta p$ and $\pi^{-} p \to \eta n$
reactions are discussed and the results are compared with Crystal Ball and CLAS
data. For the $p p \to p p \eta$ reaction, the model results are compared with
the energy dependence of the cross section measured far from the threshold and
with the differential distributions $d\sigma/d\cos\theta_{\eta}$ and
$d\sigma/dp_{\eta}$ measured by the DISTO Collaboration. The comparison shows
that the $N(1535)$ resonance is the dominant contribution and that other
contributions are also important due to interference effects. Assuming that the
$\rho$ exchange is the dominant resonant excitation process, the model is able
to describe the available data, e.g. it reproduces the shape of the angular
distributions measured by the DISTO Collaboration. Predictions are given for
the HADES experiment at center-of-mass energy of $\sqrt{s} = 3.46$~GeV, which
can be verified in the near future, and for planned PANDA and SIS100
experiments at higher energies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00034v1' target='_blank'>Towards Efficient Multi-Objective Optimisation for Real-World Power Grid
  Topology Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yassine El Manyari, Anton R. Fuxjager, Stefan Zahlner, Joost Van Dijk, Alberto Castagna, Davide Barbieri, Jan Viebahn, Marcel Wasserer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 21:40:19</h6>
<p class='card-text'>Power grid operators face increasing difficulties in the control room as the
increase in energy demand and the shift to renewable energy introduce new
complexities in managing congestion and maintaining a stable supply. Effective
grid topology control requires advanced tools capable of handling
multi-objective trade-offs. While Reinforcement Learning (RL) offers a
promising framework for tackling such challenges, existing Multi-Objective
Reinforcement Learning (MORL) approaches fail to scale to the large state and
action spaces inherent in real-world grid operations. Here we present a
two-phase, efficient and scalable Multi-Objective Optimisation (MOO) method
designed for grid topology control, combining an efficient RL learning phase
with a rapid planning phase to generate day-ahead plans for unseen scenarios.
We validate our approach using historical data from TenneT, a European
Transmission System Operator (TSO), demonstrating minimal deployment time,
generating day-ahead plans within 4-7 minutes with strong performance. These
results underline the potential of our scalable method to support real-world
power grid management, offering a practical, computationally efficient, and
time-effective tool for operational planning. Based on current congestion costs
and inefficiencies in grid operations, adopting our approach by TSOs could
potentially save millions of euros annually, providing a compelling economic
incentive for its integration in the control room.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14692v1' target='_blank'>Scintillating Fibre Detector for the Mu3e Experiment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Robert Mihai Amarinei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 18:05:25</h6>
<p class='card-text'>We present a compact scintillating fibre timing detector developed for the
Mu3e experiment. Mu3e is one of the flagship experiments of the Swiss particle
physics scene, aiming to search for the charged lepton flavour violating
(neutrinoless) muon decay $\mu^+ \rightarrow e^+e^-e^+$. Mu3e is planned to
start taking data in 2025 at the Paul Scherrer Institute in Switzerland, using
the most intense continuous surface muon beam in the world (10$^8$ muons per
second).
  At the University of Geneva, together with partners from ETH Zurich, we are
developing a scintillating fibre detector formed by staggering three layers of
250 $\mu m$ diameter round scintillating fibres. The fibre ribbons are coupled
at both ends to multi-channel silicon photo-multiplier arrays, which are read
out with the MuTRiG ASIC, specifically developed for this experiment.
  This presentation is focused on the performances of the scintillating fibre
detector, notably on the time resolution around 250 ps, the efficiency greater
than 97\% and the spatial resolution of $\sim$ 100 $\mu m$. In this
presentation, we also include the challenges overcome to build this very thin
scintillating fibre detector, having a thickness smaller than 0.2\% of the
radiation length. Furthermore, we discuss the operation and performance of the
MuTRiG ASIC, used for reading out the 3072 channels of the fibre detector.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14667v1' target='_blank'>The Mu3e Experiment: Status and Short-Term Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Robert Mihai Amarinei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 17:43:18</h6>
<p class='card-text'>Mu3e is an experiment currently under construction at the Paul Scherrer
Institute in Switzerland, designed to search for the Lepton Flavor Violating
(LFV) decay $\mu^+ \rightarrow e^+e^-e^+$. In extensions of the Standard Model
(SM) that account for neutrino masses, this decay is theoretically allowed but
occurs only through extremely rare loop processes, with a predicted branching
ratio of approximately $\mathcal{O}(10^{-54})$. Such a small probability
implies that any observation of this decay would provide clear evidence for
physics beyond the SM.
  The Mu3e experiment aims to probe the $\mu^+ \rightarrow e^+e^-e^+$ decay
with a sensitivity of approximately $\mathcal{O}(10^{-15})$ in its Phase-1 and
plans to achieve a sensitivity of $\mathcal{O}(10^{-16})$ after future
upgrades. To reach its Phase-1 ambitious goals, Mu3e is going to use the most
intense continuous muon beam in the world, generating 10$^{8}$ muon stops per
second in the target placed at the center of the Mu3e.
  Mu3e will use three main technologies for particle detection. The tracking
will done through ultra-thin (50 - 70 $\mu m$) pixel detectors based on MuPix11
sensors. These are high-voltage monolithic active pixel sensors (HV-MAPS) with
a $\sim$ 23~$\mu$m spatial resolution. The timing will be done through
scintillating fibres ($\sim$ 250 ps) and tiles ($\sim$ 40 ps), coupled to
silicon photomultipliers and read out by MuTRiG3 ASICs. A triggerless DAQ
system based on FPGAs will collect data from the detectors, which will then
undergo reconstruction in a GPU filter farm. The assembly of the detectors has
started, with a detector commissioning beam time planned for 2025. This
document reports on the status of the construction, installation, and
data-taking plans for the near future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14634v1' target='_blank'>Recommending Actionable Strategies: A Semantic Approach to Integrating
  Analytical Frameworks with Decision Heuristics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Renato Ghisellini, Remo Pareschi, Marco Pedroni, Giovanni Battista Raggi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 16:53:37</h6>
<p class='card-text'>We present a novel approach for recommending actionable strategies by
integrating strategic frameworks with decision heuristics through semantic
analysis. While strategy frameworks provide systematic models for assessment
and planning, and decision heuristics encode experiential knowledge,these
traditions have historically remained separate. Our methodology bridges this
gap using advanced natural language processing (NLP), demonstrated through
integrating frameworks like the 6C model with the Thirty-Six Stratagems. The
approach employs vector space representations and semantic similarity
calculations to map framework parameters to heuristic patterns, supported by a
computational architecture that combines deep semantic processing with
constrained use of Large Language Models. By processing both primary content
and secondary elements (diagrams, matrices) as complementary linguistic
representations, we demonstrate effectiveness through corporate strategy case
studies. The methodology generalizes to various analytical frameworks and
heuristic sets, culminating in a plug-and-play architecture for generating
recommender systems that enable cohesive integration of strategic frameworks
and decision heuristics into actionable guidance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14616v2' target='_blank'>QuIP: Experimental design for expensive simulators with many Qualitative
  factors via Integer Programming</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yen-Chun Liu, Simon Mak</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 16:33:56</h6>
<p class='card-text'>The need to explore and/or optimize expensive simulators with many
qualitative factors arises in broad scientific and engineering problems. Our
motivating application lies in path planning - the exploration of feasible
paths for navigation, which plays an important role in robotics, surgical
planning and assembly planning. Here, the feasibility of a path is evaluated
via expensive virtual experiments, and its parameter space is typically
discrete and high-dimensional. A carefully selected experimental design is thus
essential for timely decision-making. We propose here a novel framework, called
QuIP, for experimental design of Qualitative factors via Integer Programming
under a Gaussian process surrogate model with an exchangeable covariance
function. For initial design, we show that its asymptotic D-optimal design can
be formulated as a variant of the well-known assignment problem in operations
research, which can be efficiently solved to global optimality using
state-of-the-art integer programming solvers. For sequential design
(specifically, for active learning or black-box optimization), we show that its
design criterion can similarly be formulated as an assignment problem, thus
enabling efficient and reliable optimization with existing solvers. We then
demonstrate the effectiveness of QuIP over existing methods in a suite of path
planning experiments and an application to rover trajectory optimization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14574v1' target='_blank'>Harmonization of Noise Measurement Methods: Measurements of radio
  impulsive noise from a specific source</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marta Fernandez, Iratxe Landa, Amaia Arrinda, Ruben Torre, Manuel Velez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 15:29:17</h6>
<p class='card-text'>This article describes a procedure for measuring and evaluating radio
impulsive noise (IN) from a specific source. A good knowledge of the noise
caused by different sources is essential to plan radio services and to ensure
good quality of service. Moreover, it is necessary to harmonize noise
measurement methods to achieve results that can be mutually compared. This
article not only provides steps that should be followed to make proper
measurements, but also specifies appropriate parameters to characterize the IN
when it is generated by a principal source. A detailed description of parameter
calculation is presented, based on the recommendations of the International
Telecommunication Union (ITU). This answers the request made in an ITU-R
214-4/3 question, which suggests determining the appropriate parameters to
describe the noise when it has an impulsive characteristic.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14526v1' target='_blank'>Robustified Time-optimal Point-to-point Motion Planning and Control
  under Uncertainty</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuhao Zhang, Jan Swevers</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 14:29:58</h6>
<p class='card-text'>This paper proposes a novel approach to formulate time-optimal point-to-point
motion planning and control under uncertainty. The approach defines a
robustified two-stage Optimal Control Problem (OCP), in which stage 1, with a
fixed time grid, is seamlessly stitched with stage 2, which features a variable
time grid. Stage 1 optimizes not only the nominal trajectory, but also feedback
gains and corresponding state covariances, which robustify constraints in both
stages. The outcome is a minimized uncertainty in stage 1 and a minimized total
motion time for stage 2, both contributing to the time optimality and safety of
the total motion. A timely replanning strategy is employed to handle changes in
constraints and maintain feasibility, while a tailored iterative algorithm is
proposed for efficient, real-time OCP execution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14503v1' target='_blank'>Benchmarking global optimization techniques for unmanned aerial vehicle
  path planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mhd Ali Shehadeh, Jakub Kudela</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 14:01:53</h6>
<p class='card-text'>The Unmanned Aerial Vehicle (UAV) path planning problem is a complex
optimization problem in the field of robotics. In this paper, we investigate
the possible utilization of this problem in benchmarking global optimization
methods. We devise a problem instance generator and pick 56 representative
instances, which we compare to established benchmarking suits through
Exploratory Landscape Analysis to show their uniqueness. For the computational
comparison, we select twelve well-performing global optimization techniques
from both subfields of stochastic algorithms (evolutionary computation methods)
and deterministic algorithms (Dividing RECTangles, or DIRECT-type methods). The
experiments were conducted in settings with varying dimensionality and
computational budgets. The results were analyzed through several criteria
(number of best-found solutions, mean relative error, Friedman ranks) and
utilized established statistical tests. The best-ranking methods for the UAV
problems were almost universally the top-performing evolutionary techniques
from recent competitions on numerical optimization at the Institute of
Electrical and Electronics Engineers Congress on Evolutionary Computation.
Lastly, we discussed the variable dimension characteristics of the studied UAV
problems that remain still largely under-investigated.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14488v1' target='_blank'>Breaking the Pre-Planning Barrier: Real-Time Adaptive Coordination of
  Mission and Charging UAVs Using Graph Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuhan Hu, Yirong Sun, Yanjun Chen, Xinghao Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 13:42:00</h6>
<p class='card-text'>Unmanned Aerial Vehicles (UAVs) are pivotal in applications such as search
and rescue and environmental monitoring, excelling in intelligent perception
tasks. However, their limited battery capacity hinders long-duration and
long-distance missions. Charging UAVs (CUAVs) offers a potential solution by
recharging mission UAVs (MUAVs), but existing methods rely on impractical
pre-planned routes, failing to enable organic cooperation and limiting mission
efficiency. We introduce a novel multi-agent deep reinforcement learning model
named \textbf{H}eterogeneous \textbf{G}raph \textbf{A}ttention
\textbf{M}ulti-agent Deep Deterministic Policy Gradient (HGAM), designed to
dynamically coordinate MUAVs and CUAVs. This approach maximizes data
collection, geographical fairness, and energy efficiency by allowing UAVs to
adapt their routes in real-time to current task demands and environmental
conditions without pre-planning. Our model uses heterogeneous graph attention
networks (GATs) to present heterogeneous agents and facilitate efficient
information exchange. It operates within an actor-critic framework. Simulation
results show that our model significantly improves cooperation among
heterogeneous UAVs, outperforming existing methods in several metrics,
including data collection rate and charging efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14451v1' target='_blank'>MARL-OT: Multi-Agent Reinforcement Learning Guided Online Fuzzing to
  Detect Safety Violation in Autonomous Driving Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Linfeng Liang, Xi Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 12:34:04</h6>
<p class='card-text'>Autonomous Driving Systems (ADSs) are safety-critical, as real-world safety
violations can result in significant losses. Rigorous testing is essential
before deployment, with simulation testing playing a key role. However, ADSs
are typically complex, consisting of multiple modules such as perception and
planning, or well-trained end-to-end autonomous driving systems. Offline
methods, such as the Genetic Algorithm (GA), can only generate predefined
trajectories for dynamics, which struggle to cause safety violations for ADSs
rapidly and efficiently in different scenarios due to their evolutionary
nature. Online methods, such as single-agent reinforcement learning (RL), can
quickly adjust the dynamics' trajectory online to adapt to different scenarios,
but they struggle to capture complex corner cases of ADS arising from the
intricate interplay among multiple vehicles. Multi-agent reinforcement learning
(MARL) has a strong ability in cooperative tasks. On the other hand, it faces
its own challenges, particularly with convergence. This paper introduces
MARL-OT, a scalable framework that leverages MARL to detect safety violations
of ADS resulting from surrounding vehicles' cooperation. MARL-OT employs MARL
for high-level guidance, triggering various dangerous scenarios for the
rule-based online fuzzer to explore potential safety violations of ADS, thereby
generating dynamic, realistic safety violation scenarios. Our approach improves
the detected safety violation rate by up to 136.2% compared to the
state-of-the-art (SOTA) testing technique.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14377v1' target='_blank'>Dream to Fly: Model-Based Reinforcement Learning for Vision-Based Drone
  Flight</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Angel Romero, Ashwin Shenai, Ismail Geles, Elie Aljalbout, Davide Scaramuzza</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 10:24:39</h6>
<p class='card-text'>Autonomous drone racing has risen as a challenging robotic benchmark for
testing the limits of learning, perception, planning, and control. Expert human
pilots are able to agilely fly a drone through a race track by mapping the
real-time feed from a single onboard camera directly to control commands.
Recent works in autonomous drone racing attempting direct pixel-to-commands
control policies (without explicit state estimation) have relied on either
intermediate representations that simplify the observation space or performed
extensive bootstrapping using Imitation Learning (IL). This paper introduces an
approach that learns policies from scratch, allowing a quadrotor to
autonomously navigate a race track by directly mapping raw onboard camera
pixels to control commands, just as human pilots do. By leveraging model-based
reinforcement learning~(RL) - specifically DreamerV3 - we train visuomotor
policies capable of agile flight through a race track using only raw pixel
observations. While model-free RL methods such as PPO struggle to learn under
these conditions, DreamerV3 efficiently acquires complex visuomotor behaviors.
Moreover, because our policies learn directly from pixel inputs, the
perception-aware reward term employed in previous RL approaches to guide the
training process is no longer needed. Our experiments demonstrate in both
simulation and real-world flight how the proposed approach can be deployed on
agile quadrotors. This approach advances the frontier of vision-based
autonomous flight and shows that model-based RL is a promising direction for
real-world robotics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14325v1' target='_blank'>Joint Infrastructure Planning and Order Assignment for On-Demand
  Food-Delivery Services with Coordinated Drones and Human Couriers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Liu, Yitong Shang, Sen Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 08:36:41</h6>
<p class='card-text'>This paper investigates the optimal infrastructure planning and order
assignment problem of an on-demand food-delivery platform with a mixed fleet of
drones and human couriers. The platform has two delivery modes: (a) ground
delivery and (b) drone-assisted delivery (i.e., air delivery). In ground
delivery, couriers directly collect and transport orders from restaurants to
destinations. For air delivery, the delivery process involves three legs:
initially, a human courier picks up the order from the restaurant and
transports it to a nearby launchpad, where personnel load the orders onto
drones and replace batteries as needed. The loaded drone then transports the
order from the launchpad to a kiosk, where another courier retrieves the order
from the kiosk for final delivery. The platform must determine the optimal
locations for launchpads and kiosks within a transportation network, and devise
an order assignment strategy that allocates food-delivery orders between ground
and air delivery considering the bundling probabilities of ground deliveries
and the waiting times at launchpads and kiosks. We formulate the platform's
problem as a mixed-integer nonlinear program and develop a novel neural
network-assisted optimization method to obtain high-quality solutions. A case
study in Hong Kong validates our model and algorithm, revealing that drone
delivery reduces operational costs, minimizes courier fleet size, and increases
order bundling opportunities. We also find that the expansion of air delivery
services may entail larger delivery times due to the trade-off between the
travel time savings induced by the faster air delivery and the associated
detours incurred by intermodal transfer and extra waiting times at launchpads
and kiosks, which crucially depends on the distance of the orders and the
sequence of activating long-distance air delivery routes versus short-distance
ones.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14841v1' target='_blank'>Insights from Publishing Open Data in Industry-Academia Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Per Erik Strandberg, Philipp Peterseil, Julian Karoliny, Johanna Kallio, Johannes Peltola</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 07:30:46</h6>
<p class='card-text'>Effective data management and sharing are critical success factors in
industry-academia collaboration. This paper explores the motivations and
lessons learned from publishing open data sets in such collaborations. Through
a survey of participants in a European research project that published 13 data
sets, and an analysis of metadata from almost 281 thousand datasets in Zenodo,
we collected qualitative and quantitative results on motivations, achievements,
research questions, licences and file types. Through inductive reasoning and
statistical analysis we found that planning the data collection is essential,
and that only few datasets (2.4%) had accompanying scripts for improved reuse.
We also found that authors are not well aware of the importance of licences or
which licence to choose. Finally, we found that data with a synthetic origin,
collected with simulations and potentially mixed with real measurements, can be
very meaningful, as predicted by Gartner and illustrated by many datasets
collected in our research project.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14266v1' target='_blank'>TrajFlow: A Generative Framework for Occupancy Density Estimation Using
  Normalizing Flows</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mitch Kosieradzki, Seongjin Choi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 06:09:09</h6>
<p class='card-text'>In transportation systems and autonomous vehicles, intelligent agents must
understand the future motion of traffic participants to effectively plan motion
trajectories. At the same time, the motion of traffic participants is
inherently uncertain. In this paper, we propose TrajFlow, a generative
framework for estimating the occupancy density of traffic participants. Our
framework utilizes a causal encoder to extract semantically meaningful
embeddings of the observed trajectory, as well as a normalizing flow to decode
these embeddings and determine the most likely future location of traffic
participants at some time point in the future. Our formulation differs from
existing approaches because we model the marginal distribution of spatial
locations instead of the joint distribution of unobserved trajectories. The
advantages of a marginal formulation are numerous. First, we demonstrate that
the marginal formulation produces higher accuracy on challenging trajectory
forecasting benchmarks. Second, the marginal formulation allows for a fully
continuous sampling of future locations. Finally, marginal densities are better
suited for downstream tasks as they allow for the computation of per-agent
motion trajectories and occupancy grids, the two most commonly used
representations for motion forecasting. We present a novel architecture based
entirely on neural differential equations as an implementation of this
framework and provide ablations to demonstrate the advantages of a continuous
implementation over a more traditional discrete neural network based approach.
The code is available at https://github.com/kosieram21/TrajFlow .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14196v1' target='_blank'>PASER: A Physics-Inspired Theory for Stimulated Growth and Real-Time
  Optimization in On-Demand Platforms</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ioannis Dritsas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 03:00:37</h6>
<p class='card-text'>This paper introduces an innovative framework for understanding on-demand
platforms by quantifying positive network effects, trust, revenue dynamics, and
the influence of demand on platform operations at per-minute or even per-second
granularity. Drawing inspiration from physics, the framework provides both a
theoretical and pragmatic perspective, offering a pictorial and quantitative
representation of how on-demand platforms create value. It seeks to demystify
their nuanced operations by providing practical, tangible, and highly
applicable metrics, platform design templates, and real-time optimization tools
for strategic what-if scenario planning. Its model demonstrates strong
predictive power and is deeply rooted in raw data. The framework offers a
deterministic insight into the workings of diverse platforms like Uber, Airbnb,
and food delivery services. Furthermore, it generalizes to model all on-demand
service platforms with cyclical operations. It works synergistically with
machine learning, game theory, and agent-based models by providing a solid
quantitative core rooted in raw data, based on physical truths, and is capable
of delivering tangible predictions for real-time operational adjustments. The
framework's mathematical model was rigorously validated using highly detailed
historical data retrieved with near 100% certainty. Applying data-driven
induction, distinct qualities were identified in big data sets via an iterative
process. Through analogical thinking, a clear and highly intuitive mapping
between the elements, operational principles, and dynamic behaviors of a
well-known physical system was established to create a physics-inspired lens
for Uber. This novel quantitative framework was named PASER (Profit
Amplification by Stimulated Emission of Revenue), drawing an analogy to its
physical counterpart, the LASER (Light Amplification by Stimulated Emission of
Radiation).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14194v1' target='_blank'>ENTER: Event Based Interpretable Reasoning for VideoQA</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hammad Ayyubi, Junzhang Liu, Ali Asgarov, Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Zhecan Wang, Chia-Wei Tang, Hani Alomari, Md. Atabuzzaman, Xudong Lin, Naveen Reddy Dyava, Shih-Fu Chang, Chris Thomas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 02:56:59</h6>
<p class='card-text'>In this paper, we present ENTER, an interpretable Video Question Answering
(VideoQA) system based on event graphs. Event graphs convert videos into
graphical representations, where video events form the nodes and event-event
relationships (temporal/causal/hierarchical) form the edges. This structured
representation offers many benefits: 1) Interpretable VideoQA via generated
code that parses event-graph; 2) Incorporation of contextual visual information
in the reasoning process (code generation) via event graphs; 3) Robust VideoQA
via Hierarchical Iterative Update of the event graphs. Existing interpretable
VideoQA systems are often top-down, disregarding low-level visual information
in the reasoning plan generation, and are brittle. While bottom-up approaches
produce responses from visual data, they lack interpretability. Experimental
results on NExT-QA, IntentQA, and EgoSchema demonstrate that not only does our
method outperform existing top-down approaches while obtaining competitive
performance against bottom-up approaches, but more importantly, offers superior
interpretability and explainability in the reasoning process.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14160v1' target='_blank'>Leveraging three-dimensionality for navigation in bluff-body wakes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vedasri Godavarthi, Kartik Krishna, Steven L. Brunton, Kunihiko Taira</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 01:12:25</h6>
<p class='card-text'>Biological flyers and swimmers navigate in unsteady wake flows using limited
sensory abilities and actuation energies. Understanding how vortical structures
can be leveraged for energy-efficient navigation in unsteady flows is
beneficial in developing autonomous navigation for small-scale aerial and
marine vehicles. Such vehicles are typically operated with constrained onboard
actuation and sensing capabilities, making energy-efficient trajectory planning
critically important. This study finds that trajectory planners can leverage
three-dimensionality appearing in a complex unsteady wake for efficient
navigation using limited flowfield information. This is revealed with
comprehensive investigations by finite-horizon model-predictive control for
trajectory planning of a swimmer behind a cylinder wake at Re=300. The
navigation performance of three-dimensional (3D) cases is compared to scenarios
in a two-dimensional (2D) wake. The underactuated swimmer is able to reach the
target by leveraging the background flow when the prediction horizon exceeds
one-tenth of the wake-shedding period, demonstrating that navigation is
feasible with limited information about the flowfield. Further, we identify
that the swimmer can leverage the secondary transverse vortical structures to
reach the target faster than is achievable navigating in a 2D wake.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14118v1' target='_blank'>Selecting Critical Scenarios of DER Adoption in Distribution Grids Using
  Bayesian Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Olivier Mulkin, Miguel Heleno, Mike Ludkovski</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 22:20:30</h6>
<p class='card-text'>We develop a new methodology to select scenarios of DER adoption most
critical for distribution grids. Anticipating risks of future voltage and line
flow violations due to additional PV adopters is central for utility investment
planning but continues to rely on deterministic or ad hoc scenario selection.
We propose a highly efficient search framework based on multi-objective
Bayesian Optimization. We treat underlying grid stress metrics as
computationally expensive black-box functions, approximated via Gaussian
Process surrogates and design an acquisition function based on probability of
scenarios being Pareto-critical across a collection of line- and bus-based
violation objectives. Our approach provides a statistical guarantee and offers
an order of magnitude speed-up relative to a conservative exhaustive search.
Case studies on realistic feeders with 200-400 buses demonstrate the
effectiveness and accuracy of our approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14112v1' target='_blank'>CoPERLex: Content Planning with Event-based Representations for Legal
  Case Summarization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:T. Y. S. S. Santosh, Youssef Farag, Matthias Grabmair</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 22:03:45</h6>
<p class='card-text'>Legal professionals often struggle with lengthy judgments and require
efficient summarization for quick comprehension. To address this challenge, we
investigate the need for structured planning in legal case summarization,
particularly through event-centric representations that reflect the narrative
nature of legal case documents. We propose our framework, CoPERLex, which
operates in three stages: first, it performs content selection to identify
crucial information from the judgment; second, the selected content is utilized
to generate intermediate plans through event-centric representations modeled as
Subject-Verb-Object tuples; and finally, it generates coherent summaries based
on both the content and the structured plan. Our experiments on four legal
summarization datasets demonstrate the effectiveness of integrating content
selection and planning components, highlighting the advantages of event-centric
plans over traditional entity-centric approaches in the context of legal
judgements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13819v1' target='_blank'>Line planning under crowding: A cut-and-column generation approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yahan Lu, Rolf N. van Lieshout, Layla Martin, Lixing Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 16:41:09</h6>
<p class='card-text'>Problem definition: To mitigate excessive crowding in public transit
networks, network expansion is often not feasible due to financial and time
constraints. Instead, operators are required to make use of existing
infrastructure more efficiently. In this regard, this paper considers the
problem of determining lines and frequencies in a public transit system,
factoring in the impact of crowding. Methodology: We introduce a novel
formulation to address the line planning problem under crowding and propose a
mixed-integer second-order cone programming (MI-SOCP) reformulation. Three
variants of the cut-and-column generation algorithm with tailored acceleration
techniques find near-system-optimal solutions by dynamically generating
passenger routes and adding linear cutting planes to deal with the
non-linearity introduced by the crowding terms. We find integral solutions
using a diving heuristic. In practice, passengers may deviate from
system-optimal routes. We, thus, evaluate line plans by computing a
user-equilibrium routing based on Wardrop's first principle. Results and
implications: We experimentally evaluate the performance of the proposed
approaches on both an artificial network and the Beijing metro network. The
results demonstrate that our algorithm effectively scales to large-scale
instances involving hundreds of stations and candidate lines, and nearly 57,000
origin-destination pairs. We find that considering crowding while developing
line plans can significantly reduce crowding, at only a minor expense to the
travel time passengers experience. This holds both for system-optimal passenger
routing and user-optimal passenger routing, which only differ slightly.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13817v1' target='_blank'>Temporal Logic Guided Safe Navigation for Autonomous Vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aditya Parameshwaran, Yue Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 16:39:08</h6>
<p class='card-text'>Safety verification for autonomous vehicles (AVs) and ground robots is
crucial for ensuring reliable operation given their uncertain environments.
Formal language tools provide a robust and sound method to verify safety rules
for such complex cyber-physical systems. In this paper, we propose a hybrid
approach that combines the strengths of formal verification languages like
Linear Temporal Logic (LTL) and Signal Temporal Logic (STL) to generate safe
trajectories and optimal control inputs for autonomous vehicle navigation. We
implement a symbolic path planning approach using LTL to generate a formally
safe reference trajectory. A mixed integer linear programming (MILP) solver is
then used on this reference trajectory to solve for the control inputs while
satisfying the state, control and safety constraints described by STL. We test
our proposed solution on two environments and compare the results with popular
path planning algorithms. In contrast to conventional path planning algorithms,
our formally safe solution excels in handling complex specification scenarios
while ensuring both safety and comparable computation times.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00031v2' target='_blank'>GNN-based Anchor Embedding for Exact Subgraph Matching</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bin Yang, Zhaonian Zou, Jianxiong Ye</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 15:11:30</h6>
<p class='card-text'>Subgraph matching query is a classic problem in graph data management and has
a variety of real-world applications, such as discovering structures in
biological or chemical networks, finding communities in social network
analysis, explaining neural networks, and so on. To further solve the subgraph
matching problem, several recent advanced works attempt to utilize
deep-learning-based techniques to handle the subgraph matching query. However,
most of these works only obtain approximate results for subgraph matching
without theoretical guarantees of accuracy. In this paper, we propose a novel
and effective graph neural network (GNN)-based anchor embedding framework
(GNN-AE), which allows exact subgraph matching. Unlike GNN-based approximate
subgraph matching approaches that only produce inexact results, in this paper,
we pioneer a series of concepts related to anchor (including anchor, anchor
graph/path, etc.) in subgraph matching and carefully devise the anchor (graph)
embedding technique based on GNN models. We transform the subgraph matching
problem into a search problem in the embedding space via the anchor (graph &
path) embedding techniques. With the proposed anchor matching mechanism, GNN-AE
can guarantee subgraph matching has no false dismissals. We design an efficient
matching growth algorithm, which can retrieve the locations of all exact
matches in parallel. We also propose a cost-model-based DFS query plan to
enhance the parallel matching growth algorithm. Through extensive experiments
on 6 real-world and 3 synthetic datasets, we confirm the effectiveness and
efficiency of our GNN-AE approach for exact subgraph matching.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13690v1' target='_blank'>Variational U-Net with Local Alignment for Joint Tumor Extraction and
  Registration (VALOR-Net) of Breast MRI Data Acquired at Two Different Field
  Strengths</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Shahkar Khan, Haider Ali, Laura Villazan Garcia, Noor Badshah, Siegfried Trattnig, Florian Schwarzhans, Ramona Woitek, Olgica Zaric</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 14:15:54</h6>
<p class='card-text'>Background: Multiparametric breast MRI data might improve tumor diagnostics,
characterization, and treatment planning. Accurate alignment and delineation of
images acquired at different field strengths such as 3T and 7T, remain
challenging research tasks. Purpose: To address alignment challenges and enable
consistent tumor segmentation across different MRI field strengths. Study type:
Retrospective. Subjects: Nine female subjects with breast tumors were involved:
six histologically proven invasive ductal carcinomas (IDC) and three
fibroadenomas. Field strength/sequence: Imaging was performed at 3T and 7T
scanners using post-contrast T1-weighted three-dimensional time-resolved
angiography with stochastic trajectories (TWIST) sequence. Assessments: The
method's performance for joint image registration and tumor segmentation was
evaluated using several quantitative metrics, including signal-to-noise ratio
(PSNR), structural similarity index (SSIM), normalized cross-correlation (NCC),
Dice coefficient, F1 score, and relative sum of squared differences (rel SSD).
Statistical tests: The Pearson correlation coefficient was used to test the
relationship between the registration and segmentation metrics. Results: When
calculated for each subject individually, the PSNR was in a range from 27.5 to
34.5 dB, and the SSIM was from 82.6 to 92.8%. The model achieved an NCC from
96.4 to 99.3% and a Dice coefficient of 62.9 to 95.3%. The F1 score was between
55.4 and 93.2% and the rel SSD was in the range of 2.0 and 7.5%. The
segmentation metrics Dice and F1 Score are highly correlated (0.995), while a
moderate correlation between NCC and SSIM (0.681) was found for registration.
Data conclusion: Initial results demonstrate that the proposed method may be
feasible in providing joint tumor segmentation and registration of MRI data
acquired at different field strengths.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14004v2' target='_blank'>ME-CPT: Multi-Task Enhanced Cross-Temporal Point Transformer for Urban
  3D Change Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luqi Zhang, Haiping Wang, Chong Liu, Zhen Dong, Bisheng Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 13:07:41</h6>
<p class='card-text'>The point clouds collected by the Airborne Laser Scanning (ALS) system
provide accurate 3D information of urban land covers. By utilizing
multi-temporal ALS point clouds, semantic changes in urban area can be
captured, demonstrating significant potential in urban planning, emergency
management, and infrastructure maintenance. Existing 3D change detection
methods struggle to efficiently extract multi-class semantic information and
change features, still facing the following challenges: (1) the difficulty of
accurately modeling cross-temporal point clouds spatial relationships for
effective change feature extraction; (2) class imbalance of change samples
which hinders distinguishability of semantic features; (3) the lack of
real-world datasets for 3D semantic change detection. To resolve these
challenges, we propose the Multi-task Enhanced Cross-temporal Point Transformer
(ME-CPT) network. ME-CPT establishes spatiotemporal correspondences between
point cloud across different epochs and employs attention mechanisms to jointly
extract semantic change features, facilitating information exchange and change
comparison. Additionally, we incorporate a semantic segmentation task and
through the multi-task training strategy, further enhance the
distinguishability of semantic features, reducing the impact of class imbalance
in change types. Moreover, we release a 22.5 $km^2$ 3D semantic change
detection dataset, offering diverse scenes for comprehensive evaluation.
Experiments on multiple datasets show that the proposed MT-CPT achieves
superior performance compared to existing state-of-the-art methods. The source
code and dataset will be released upon acceptance at
https://github.com/zhangluqi0209/ME-CPT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10410v1' target='_blank'>Auto-Evaluation: A Critical Measure in Driving Improvements in Quality
  and Safety of AI-Generated Lesson Resources</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hannah-Beth Clark, Margaux Dowland, Laura Benton, Reka Budai, Ibrahim Kaan Keskin, Emma Searle, Matthew Gregory, Mark Hodierne, William Gayne, John Roberts</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 11:35:23</h6>
<p class='card-text'>As a publicly funded body in the UK, Oak National Academy is in a unique
position to innovate within this field as we have a comprehensive curriculum of
approximately 13,000 open education resources (OER) for all National Curriculum
subjects, designed and quality-assured by expert, human teachers. This has
provided the corpus of content needed for building a high-quality AI-powered
lesson planning tool, Aila, that is free to use and, therefore, accessible to
all teachers across the country. Furthermore, using our evidence-informed
curriculum principles, we have codified and exemplified each component of
lesson design. To assess the quality of lessons produced by Aila at scale, we
have developed an AI-powered auto-evaluation agent,facilitating informed
improvements to enhance output quality. Through comparisons between human and
auto-evaluations, we have begun to refine this agent further to increase its
accuracy, measured by its alignment with an expert human evaluator. In this
paper we present this iterative evaluation process through an illustrative case
study focused on one quality benchmark - the level of challenge within
multiple-choice quizzes. We also explore the contribution that this may make to
similar projects and the wider sector.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13557v1' target='_blank'>Duality Theorems and Vector Measures in Optimal Transportation Theory</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shlomi Gover</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 11:01:07</h6>
<p class='card-text'>The optimal transportation problem, first suggested by Gaspard Monge in the
18th century and later revived in the 1940s by Leonid Kantorovich, deals with
the question of transporting a certain measure to another, using transport maps
or transport plans that minimize the total cost of transportation. This problem
is very popular since it has a variety of applications in economics, physics,
computer science and more.
  One of the main tools in this theory is the duality theorem, which states
that the optimal total cost equals the value of a different optimization
problem called the dual problem.
  In this work, I show how the problem and duality theorem can be generalized
to an abstract formulation, in which I omit the use of measures. I show how
this generalization implies a wide range of different optimal transport
problems, and even other problems from game theory, linear programming and
functional analysis.
  In particular, I show how the optimal transport problem can be generalized to
deal with vector measures as a result of the abstract theorem and discuss the
properties of this problem: I present its corresponding duality theorem and
formulate conditions for the existence of transport plans, transport maps and
solutions to the dual problem.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13507v1' target='_blank'>Iterative Shaping of Multi-Particle Aggregates based on Action Trees and
  VLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hoi-Yin Lee, Peng Zhou, Anqing Duan, Chenguang Yang, David Navarro-Alarcon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 09:43:16</h6>
<p class='card-text'>In this paper, we address the problem of manipulating multi-particle
aggregates using a bimanual robotic system. Our approach enables the autonomous
transport of dispersed particles through a series of shaping and pushing
actions using robotically-controlled tools. Achieving this advanced
manipulation capability presents two key challenges: high-level task planning
and trajectory execution. For task planning, we leverage Vision Language Models
(VLMs) to enable primitive actions such as tool affordance grasping and
non-prehensile particle pushing. For trajectory execution, we represent the
evolving particle aggregate's contour using truncated Fourier series, providing
efficient parametrization of its closed shape. We adaptively compute trajectory
waypoints based on group cohesion and the geometric centroid of the aggregate,
accounting for its spatial distribution and collective motion. Through
real-world experiments, we demonstrate the effectiveness of our methodology in
actively shaping and manipulating multi-particle aggregates while maintaining
high system cohesion.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13457v1' target='_blank'>Zero-Shot Trajectory Planning for Signal Temporal Logic Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruijia Liu, Ancheng Hou, Xiao Yu, Xiang Yin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 08:15:52</h6>
<p class='card-text'>Signal Temporal Logic (STL) is a powerful specification language for
describing complex temporal behaviors of continuous signals, making it
well-suited for high-level robotic task descriptions. However, generating
executable plans for STL tasks is challenging, as it requires consideration of
the coupling between the task specification and the system dynamics. Existing
approaches either follow a model-based setting that explicitly requires
knowledge of the system dynamics or adopt a task-oriented data-driven approach
to learn plans for specific tasks. In this work, we investigate the problem of
generating executable STL plans for systems whose dynamics are unknown a
priori. We propose a new planning framework that uses only task-agnostic data
during the offline training stage, enabling zero-shot generalization to new STL
tasks. Our framework is hierarchical, involving: (i) decomposing the STL task
into a set of progress and time constraints, (ii) searching for time-aware
waypoints guided by task-agnostic data, and (iii) generating trajectories using
a pre-trained safe diffusion model. Simulation results demonstrate the
effectiveness of our method indeed in achieving zero-shot generalization to
various STL tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13347v1' target='_blank'>One Fits All: General Mobility Trajectory Modeling via Masked
  Conditional Diffusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingyue Long, Can Rong, Huandong Wang, Yong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 03:13:45</h6>
<p class='card-text'>Trajectory data play a crucial role in many applications, ranging from
network optimization to urban planning. Existing studies on trajectory data are
task-specific, and their applicability is limited to the specific tasks on
which they have been trained, such as generation, recovery, or prediction.
However, the potential of a unified model has not yet been fully explored in
trajectory modeling. Although various trajectory tasks differ in inputs,
outputs, objectives, and conditions, they share common mobility patterns. Based
on these common patterns, we can construct a general framework that enables a
single model to address different tasks. However, building a trajectory
task-general framework faces two critical challenges: 1) the diversity in the
formats of different tasks and 2) the complexity of the conditions imposed on
different tasks. In this work, we propose a general trajectory modeling
framework via masked conditional diffusion (named GenMove). Specifically, we
utilize mask conditions to unify diverse formats. To adapt to complex
conditions associated with different tasks, we utilize historical trajectory
data to obtain contextual trajectory embeddings, which include rich contexts
such as spatiotemporal characteristics and user preferences. Integrating the
contextual trajectory embedding into diffusion models through a classifier-free
guidance approach allows the model to flexibly adjust its outputs based on
different conditions. Extensive experiments on mainstream tasks demonstrate
that our model significantly outperforms state-of-the-art baselines, with the
highest performance improvement exceeding 13% in generation tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13203v1' target='_blank'>Safe and Efficient Robot Action Planning in the Presence of Unconcerned
  Humans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohsen Amiri, Mehdi Hosseinzadeh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 20:20:51</h6>
<p class='card-text'>This paper proposes a robot action planning scheme that provides an efficient
and probabilistically safe plan for a robot interacting with an unconcerned
human -- someone who is either unaware of the robot's presence or unwilling to
engage in ensuring safety. The proposed scheme is predictive, meaning that the
robot is required to predict human actions over a finite future horizon; such
predictions are often inaccurate in real-world scenarios. One possible approach
to reduce the uncertainties is to provide the robot with the capability of
reasoning about the human's awareness of potential dangers. This paper
discusses that by using a binary variable, so-called danger awareness
coefficient, it is possible to differentiate between concerned and unconcerned
humans, and provides a learning algorithm to determine this coefficient by
observing human actions. Moreover, this paper argues how humans rely on
predictions of other agents' future actions (including those of robots in
human-robot interaction) in their decision-making. It also shows that ignoring
this aspect in predicting human's future actions can significantly degrade the
efficiency of the interaction, causing agents to deviate from their optimal
paths. The proposed robot action planning scheme is verified and validated via
extensive simulation and experimental studies on a LoCoBot WidowX-250.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13200v1' target='_blank'>SRMT: Shared Memory for Multi-agent Lifelong Pathfinding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alsu Sagirova, Yuri Kuratov, Mikhail Burtsev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 20:08:53</h6>
<p class='card-text'>Multi-agent reinforcement learning (MARL) demonstrates significant progress
in solving cooperative and competitive multi-agent problems in various
environments. One of the principal challenges in MARL is the need for explicit
prediction of the agents' behavior to achieve cooperation. To resolve this
issue, we propose the Shared Recurrent Memory Transformer (SRMT) which extends
memory transformers to multi-agent settings by pooling and globally
broadcasting individual working memories, enabling agents to exchange
information implicitly and coordinate their actions. We evaluate SRMT on the
Partially Observable Multi-Agent Pathfinding problem in a toy Bottleneck
navigation task that requires agents to pass through a narrow corridor and on a
POGEMA benchmark set of tasks. In the Bottleneck task, SRMT consistently
outperforms a variety of reinforcement learning baselines, especially under
sparse rewards, and generalizes effectively to longer corridors than those seen
during training. On POGEMA maps, including Mazes, Random, and MovingAI, SRMT is
competitive with recent MARL, hybrid, and planning-based algorithms. These
results suggest that incorporating shared recurrent memory into the
transformer-based architectures can enhance coordination in decentralized
multi-agent systems. The source code for training and evaluation is available
on GitHub: https://github.com/Aloriosa/srmt.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13183v1' target='_blank'>MONA: Moving Object Detection from Videos Shot by Dynamic Camera</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Boxun Hu, Mingze Xia, Ding Zhao, Guanlin Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 19:30:28</h6>
<p class='card-text'>Dynamic urban environments, characterized by moving cameras and objects, pose
significant challenges for camera trajectory estimation by complicating the
distinction between camera-induced and object motion. We introduce MONA, a
novel framework designed for robust moving object detection and segmentation
from videos shot by dynamic cameras. MONA comprises two key modules: Dynamic
Points Extraction, which leverages optical flow and tracking any point to
identify dynamic points, and Moving Object Segmentation, which employs adaptive
bounding box filtering, and the Segment Anything for precise moving object
segmentation. We validate MONA by integrating with the camera trajectory
estimation method LEAP-VO, and it achieves state-of-the-art results on the MPI
Sintel dataset comparing to existing methods. These results demonstrate MONA's
effectiveness for moving object detection and its potential in many other
applications in the urban planning field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13084v1' target='_blank'>Attention-Driven Hierarchical Reinforcement Learning with Particle
  Filtering for Source Localization in Dynamic Fields</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiwei Shi, Mengyue Yang, Qi Zhang, Weinan Zhang, Cunjia Liu, Weiru Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 18:45:29</h6>
<p class='card-text'>In many real-world scenarios, such as gas leak detection or environmental
pollutant tracking, solving the Inverse Source Localization and
Characterization problem involves navigating complex, dynamic fields with
sparse and noisy observations. Traditional methods face significant challenges,
including partial observability, temporal and spatial dynamics,
out-of-distribution generalization, and reward sparsity. To address these
issues, we propose a hierarchical framework that integrates Bayesian inference
and reinforcement learning. The framework leverages an attention-enhanced
particle filtering mechanism for efficient and accurate belief updates, and
incorporates two complementary execution strategies: Attention Particle
Filtering Planning and Attention Particle Filtering Reinforcement Learning.
These approaches optimize exploration and adaptation under uncertainty.
Theoretical analysis proves the convergence of the attention-enhanced particle
filter, while extensive experiments across diverse scenarios validate the
framework's superior accuracy, adaptability, and computational efficiency. Our
results highlight the framework's potential for broad applications in dynamic
field estimation tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13083v1' target='_blank'>Boosting MCTS with Free Energy Minimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mawaba Pascal Dao, Adrian M. Peter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 18:45:15</h6>
<p class='card-text'>Active Inference, grounded in the Free Energy Principle, provides a powerful
lens for understanding how agents balance exploration and goal-directed
behavior in uncertain environments. Here, we propose a new planning framework,
that integrates Monte Carlo Tree Search (MCTS) with active inference objectives
to systematically reduce epistemic uncertainty while pursuing extrinsic
rewards. Our key insight is that MCTS already renowned for its search
efficiency can be naturally extended to incorporate free energy minimization by
blending expected rewards with information gain. Concretely, the Cross-Entropy
Method (CEM) is used to optimize action proposals at the root node, while tree
expansions leverage reward modeling alongside intrinsic exploration bonuses.
This synergy allows our planner to maintain coherent estimates of value and
uncertainty throughout planning, without sacrificing computational
tractability. Empirically, we benchmark our planner on a diverse set of
continuous control tasks, where it demonstrates performance gains over both
standalone CEM and MCTS with random rollouts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13073v4' target='_blank'>CHaRNet: Conditioned Heatmap Regression for Robust Dental Landmark
  Localization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:José Rodríguez-Ortega, Francisco Pérez-Hernández, Siham Tabik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 18:35:57</h6>
<p class='card-text'>Identifying anatomical landmarks in 3D dental models is vital for orthodontic
treatment, yet manual placement is complex and time-consuming. Although some
machine learning approaches have been proposed for automatic tooth landmark
detection in 3D Intraoral Scans (IOS), none provide a fully end-to-end solution
that bypasses teeth segmentation, limiting practical applicability. We
introduce CHaRNet (Conditioned Heatmap Regression Network), the first fully
end-to-end deep learning framework for tooth landmark detection in 3D IOS.
Unlike traditional two-stage workflows that segment teeth before detecting
landmarks, CHaRNet directly operates on the input point cloud, thus reducing
complexity and computational overhead. Our method integrates four modules: (1)
a point cloud encoder, (2) a point cloud decoder with a heatmap regression
head, (3) a teeth presence classification head, and (4) the novel Conditioned
Heatmap Regression (CHaR) module. By leveraging teeth presence classification,
the CHaR module dynamically adapts to missing teeth and enhances detection
accuracy in complex dental models. We evaluate CHaRNet using five point cloud
learning algorithms on a clinical dataset of 1,214 annotated 3D models. Both
the dataset and code will be publicly released to address the lack of open
datasets in orthodontics and inspire further research. CHaRNet achieves a Mean
Euclidean Distance Error (MEDE) of 0.51 mm on typical dental models and 1.28 mm
across all dentition types, with corresponding Mean Success Rates (MSR) of
87.06% and 82.40%, respectively. Notably, it exhibits robust performance on
irregular geometries, including models with missing teeth. This end-to-end
approach streamlines orthodontic workflows, enhances 3D IOS analysis precision,
and supports efficient computer-assisted treatment planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13072v2' target='_blank'>AdaWM: Adaptive World Model based Planning for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hang Wang, Xin Ye, Feng Tao, Chenbin Pan, Abhirup Mallik, Burhaneddin Yaman, Liu Ren, Junshan Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 18:34:51</h6>
<p class='card-text'>World model based reinforcement learning (RL) has emerged as a promising
approach for autonomous driving, which learns a latent dynamics model and uses
it to train a planning policy. To speed up the learning process, the
pretrain-finetune paradigm is often used, where online RL is initialized by a
pretrained model and a policy learned offline. However, naively performing such
initialization in RL may result in dramatic performance degradation during the
online interactions in the new task. To tackle this challenge, we first analyze
the performance degradation and identify two primary root causes therein: the
mismatch of the planning policy and the mismatch of the dynamics model, due to
distribution shift. We further analyze the effects of these factors on
performance degradation during finetuning, and our findings reveal that the
choice of finetuning strategies plays a pivotal role in mitigating these
effects. We then introduce AdaWM, an Adaptive World Model based planning
method, featuring two key steps: (a) mismatch identification, which quantifies
the mismatches and informs the finetuning strategy, and (b) alignment-driven
finetuning, which selectively updates either the policy or the model as needed
using efficient low-rank updates. Extensive experiments on the challenging
CARLA driving tasks demonstrate that AdaWM significantly improves the
finetuning process, resulting in more robust and efficient performance in
autonomous driving systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13053v1' target='_blank'>Evaluation of patient activation and dosimetry after Boron Neutron
  Capture Therapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Giovanni Garini, Chiara Magni, Ian Postuma, Setareh Fatemi, Ricardo Ramos, Barbara Marcaccio, Cristina Pezzi, Laura Bagnale, Sandro Sandri, Gianfranco De Matteis, Giuseppe Paolisso, Valerio Vercesi, Silva Bortolussi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 18:01:36</h6>
<p class='card-text'>Boron Neutron Capture Therapy (BNCT) is a form of radiotherapy based on the
irradiation of the tumour with a low energy neutron beam, after the
administration of a selective drug enriched in boron-10. The therapy exploits
the high cross section of thermal neutron capture in boron, generating two
low-range charged particles. The availability of accelerators able to generate
high-intensity neutron beams via proton nuclear interaction is boosting the
construction of new clinical centres. One of these is under development in
Italy, using a 5 MeV, 30 mA proton radiofrequency accelerator coupled to a
beryllium target, funded by the Complementary Plan to the Recovery and
Resilience National Plan, under the project ANTHEM. The present study focuses
on radiation protection aspects of patients undergoing BNCT, specifically on
the activation of their organs and tissues. A criterion to establish the
relevance of such activation after BNCT has been proposed. Based on the current
Italian regulatory framework, the level of patient activation following BNCT
treatment does not pose a significant radiological concern, even shortly after
irradiation. Another aspect is the activation of patient's excretions, which
can impact on the design of the building and requires a process for the
discharge. The described study contributes to the radiation protection study
for the ANTHEM BNCT centre in Italy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12993v1' target='_blank'>European Energy Vision 2060: Charting Diverse Pathways for Europe's
  Energy Transition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mostafa Barani, Konstantin Löffler, Pedro Crespo del Granado, Nikita Moskalenko, Evangelos Panos, Franziska M. Hoffart, Christian von Hirschhausen, Maria Kannavou, Hans Auer, Karlo Hainsch, Tatiana González Grandón, Siri Mathisen, Asgeir Tomasgard</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 16:29:16</h6>
<p class='card-text'>Europe is warming at the fastest rate of all continents, experiencing a
temperature increase of about 1{\deg}C higher than the corresponding global
increase. Aiming to be the first climate-neutral continent by 2050 under the
European Green Deal, Europe requires an in-depth understanding of the potential
energy transition pathways. In this paper, we develop four qualitative
long-term scenarios covering the European energy landscape, considering key
uncertainty pillars -- categorized under social, technological, economic,
political, and geopolitical aspects. First, we place the scenarios in a
three-dimensional space defined by Social dynamics, Innovation, and
Geopolitical instabilities. These scenarios are brought to life by defining
their narratives and focus areas according to their location in this
three-dimensional space. The scenarios envision diverse futures and include
distinct features. The EU Trinity scenario pictures how internal divisions
among EU member states, in the context of global geopolitical instability,
affect the EU climate targets. The REPowerEU++ scenario outlines the steps
needed for a self-sufficient, independent European energy system by 2050. The
Go RES scenario examines the feasibility of achieving carbon neutrality earlier
than 2050 given favourable uncertain factors. The NECP Essentials scenario
extends current national energy and climate plans until 2060 to assess their
role in realizing climate neutrality. The scenarios are extended by
incorporating policies and economic factors and detailed in a Qualitative to
Quantitative (Q2Q) matrix, linking narratives to quantification. Finally, two
scenarios are quantified to illustrate the quantification process. All the
scenarios are in the process of being quantified and will be openly available
and reusable.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13972v1' target='_blank'>Synthetic CT image generation from CBCT: A Systematic Review</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alzahra Altalib, Scott McGregor, Chunhui Li, Alessandro Perelli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 13:54:07</h6>
<p class='card-text'>The generation of synthetic CT (sCT) images from cone-beam CT (CBCT) data
using deep learning methodologies represents a significant advancement in
radiation oncology. This systematic review, following PRISMA guidelines and
using the PICO model, comprehensively evaluates the literature from 2014 to
2024 on the generation of sCT images for radiation therapy planning in
oncology. A total of 35 relevant studies were identified and analyzed,
revealing the prevalence of deep learning approaches in the generation of sCT.
This review comprehensively covers synthetic CT generation based on CBCT and
proton-based studies. Some of the commonly employed architectures explored are
convolutional neural networks (CNNs), generative adversarial networks (GANs),
transformers, and diffusion models. Evaluation metrics including mean absolute
error (MAE), root mean square error (RMSE), peak signal-to-noise ratio (PSNR)
and structural similarity index (SSIM) consistently demonstrate the
comparability of sCT images with gold-standard planning CTs (pCT), indicating
their potential to improve treatment precision and patient outcomes. Challenges
such as field-of-view (FOV) disparities and integration into clinical workflows
are discussed, along with recommendations for future research and
standardization efforts. In general, the findings underscore the promising role
of sCT-based approaches in personalized treatment planning and adaptive
radiation therapy, with potential implications for improved oncology treatment
delivery and patient care.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12882v1' target='_blank'>Seasonal Changes -- Time for Paradigm Shift</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Branislava Lalic, Ana Firanj Sremac</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 13:42:41</h6>
<p class='card-text'>Season and their transitions play a critical role in sharpening ecosystems
and human activities, yet traditional classifications, meteorological and
astronomical, fail to capture the complexities of biosphere-atmosphere
interactions. Conventional definitions often overlook the interplay between
climate variables, biosphere processes, and seasonal anticipation, particularly
as global climate change disrupts traditional patterns. This study addresses
the limitations of current seasonal classification by proposing a framework
based on phenological markers such as NDVI, EVI, LAI, fPAR, and the Bowen
ratio, using plants as a nature-based sensor of seasonal transitions.
Indicators derived from satellite data and ground observations provide robust
foundations for defining seasonal boundaries. The normalized daily temperature
range (DTRT), validated in crop and orchard regions, is hypothesized as a
reliable seasonality index to capture transitions. We demonstrated the
alignment of this index with phenological markers across boreal, temperate, and
deciduous forests. Analyzing trends, extreme values and inflection points in
the seasonality index time series, we established a methodology to identify
seasonal onset, duration, and transitions. This universal, scalable
classification aligns with current knowledge and perception of seasonal shifts
and captures site-specific timing. Findings reveal shifts in the
Euro-Mediterranean region, with winters shortening, summers extending, and
transitions becoming more pronounced. Effects include the Gulf Stream s
influence on milder transitions, urban heat islands accelerating seasonal
shifts, and large inland lakes moderating durations. This underscores the
importance of understanding seasonal transitions to enable climate change
adaptive strategies in agriculture, forestry, urban planning, medicine, trade,
marketing, and tourism.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12815v1' target='_blank'>Certified Guidance for Planning with Deep Generative Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Francesco Giacomarra, Mehran Hosseini, Nicola Paoletti, Francesca Cairoli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 11:46:28</h6>
<p class='card-text'>Deep generative models, such as generative adversarial networks and diffusion
models, have recently emerged as powerful tools for planning tasks and behavior
synthesis in autonomous systems. Various guidance strategies have been
introduced to steer the generative process toward outputs that are more likely
to satisfy the planning objectives. These strategies avoid the need for model
retraining but do not provide any guarantee that the generated outputs will
satisfy the desired planning objectives. To address this limitation, we
introduce certified guidance, an approach that modifies a generative model,
without retraining it, into a new model guaranteed to satisfy a given
specification with probability one. We focus on Signal Temporal Logic
specifications, which are rich enough to describe nontrivial planning tasks.
Our approach leverages neural network verification techniques to systematically
explore the latent spaces of the generative models, identifying latent regions
that are certifiably correct with respect to the STL property of interest. We
evaluate the effectiveness of our method on four planning benchmarks using GANs
and diffusion models. Our results confirm that certified guidance produces
generative models that are always correct, unlike existing guidance methods
that are not certified.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12799v1' target='_blank'>Int2Planner: An Intention-based Multi-modal Motion Planner for
  Integrated Prediction and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaolei Chen, Junchi Yan, Wenlong Liao, Tao He, Pai Peng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 11:13:31</h6>
<p class='card-text'>Motion planning is a critical module in autonomous driving, with the primary
challenge of uncertainty caused by interactions with other participants. As
most previous methods treat prediction and planning as separate tasks, it is
difficult to model these interactions. Furthermore, since the route path
navigates ego vehicles to a predefined destination, it provides relatively
stable intentions for ego vehicles and helps constrain uncertainty. On this
basis, we construct Int2Planner, an \textbf{Int}ention-based
\textbf{Int}egrated motion \textbf{Planner} achieves multi-modal planning and
prediction. Instead of static intention points, Int2Planner utilizes route
intention points for ego vehicles and generates corresponding planning
trajectories for each intention point to facilitate multi-modal planning. The
experiments on the private dataset and the public nuPlan benchmark show the
effectiveness of route intention points, and Int2Planner achieves
state-of-the-art performance. We also deploy it in real-world vehicles and have
conducted autonomous driving for hundreds of kilometers in urban areas. It
further verifies that Int2Planner can continuously interact with the traffic
environment. Code will be avaliable at https://github.com/cxlz/Int2Planner.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14827v1' target='_blank'>Proposal of the KOTO II experiment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jung Keun Ahn, Antonella Antonelli, Giuseppina Anzivino, Emile Augustine, Laura Bandiera, Jianming Bian, Francesco Brizioli, Stefano De Capua, Gabriella Carini, Veronika Chobanova, Giancarlo D'Ambrosio, John Bourke Dainton, Babette Dőbrich, John Fry, Alberto Gianoli, Alexander Glazov, Mario Gonzalez, Martin Gorbahn, Evgueni Goudzovski, Mei Homma, Yee B. Hsiung, Tomáš Husek, David Hutchcroft, Abhishek Iyer, Roger William Lewis Jones, Mai Katayama, Yuto Kawata, Eun-Joo Kim, Chong Kim, Takeshi Komatsubara, Katsushige Kotera, Michal Kreps, Gianluca Lamanna, Cristina Lazzeroni, Samet Lezki, GeiYoub Lim, Sanghoon Lim, Chieh Lin, Farvah Mahmoudi, Victoria Martin, Karim Massri, Toru Matsumura, Luigi Montalto, Matthew Moulson, Hajime Nanjo, Matthew Needham, Siavash Neshatpour, Tadashi Nomura, Daiki Ogawa, Keita Ono, Monica Pepe, Letizia Peruzzo, Jacopo Pinzino, Dan Protopopescu, Claire Prouve, Thomas Reddel, Joseph Redeker, Daniele Rinaldi, Marco Romagnoni, Angela Romano, Armine Rostomyan, Jack Sanders, Diego Martínez Santos, Ivano Sarra, Artur Shaikhiev, Koji Shiomi, Ryota Shiraishi, Mattia Soldani, Marco Sozzi, Benjamin Stillwell, Yi-Ting Su, Joel Swallow, Yasuhisa Tajima, Adam Tomczak, Yu-Chen Tung, Yau Wah, Rainer Wanke, Hiroaki Watanabe, John Wendel, Tong Wu, Maresa Wynd, Guang Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 09:53:20</h6>
<p class='card-text'>The KOTO II experiment is proposed to measure the branching ratio of the
decay $K_L\to\pi^0\nu\bar{\nu}$ at J-PARC. With a beamline to extract
long-lived neutral kaons at 5 degrees from a production target, the single
event sensitivity of the decay is $8.5\times 10^{-13}$, which is much smaller
than the Standard Model prediction $3\times 10^{-11}$. This allows searches for
new physics beyond the Standard Model and the first discovery of the decay with
a significance exceeding $5\sigma$. As the only experiment proposed in the
world dedicated to rare kaon decays, KOTO II will be indispensable in the quest
for a complete understanding of flavor dynamics in the quark sector. Moreover,
by combining efforts from the kaon community worldwide, we plan to develop the
KOTO II detector further and expand the physics reach of the experiment to
include measurements of the branching ratio of the $K_L\to\pi^0\ell^+\ell^-$
decays, studies of other $K_L$ decays, and searches for dark photons, axions,
and axion-like particles. KOTO II will therefore obtain a comprehensive
understanding of $K_L$ decays, providing further constraints on new physics
scenarios with existing $K^+$ results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12757v1' target='_blank'>Large discrepancies in error estimates for reverberation times derived
  from light curves of active galactic nuclei</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:C. Martin Gaskell</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 09:50:39</h6>
<p class='card-text'>Light-travel-time delays provide one of the most powerful ways of learning
about the structure and kinematics of active galactic nuclei (AGNs). Estimating
delays from observations of AGN variability presents statistical challenges
because the time series are almost invariably irregularly sampled. Correct
assessment of errors in lag estimates is important for evaluating results. The
most widely used method of determining phase lags has been the interpolated
cross-correlation function method introduced by Gaskell and Sparke (1986, GS).
It is shown here that the widely used modified smooth bootstrap method of
Peterson et al. (1998) significantly overestimates the error in lags derived
using the GS, especially for poorly sampled light curves. The remarkably high
accuracy claimed for lags obtained by the JAVELIN method of Zu et al. (2011)
(more than an order of magnitude improvement for 25% of cases) is spurious and
the accuracy no better than the GS method. A related method proposed by Li et
al. (2013) suffers from similar but less serious problems. A slightly modified
version of the analytic formula of Gaskell and Peterson (1987) gives an easy
and accurate way of estimating lag errors for well-sampled, high-quality data.
The width of the continuum autocorrelation function is shown to be proportional
to the square root of the luminosity. This is useful in planning observing
campaigns. The discrete correlation function method is less powerful than the
GS method and for many typical situations gives errors in the lag twice as
large as those of the GS method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10405v1' target='_blank'>Crop Yield Time-Series Data Prediction Based on Multiple Hybrid Machine
  Learning Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yueru Yan, Yue Wang, Jialin Li, Jingwei Zhang, Xingye Mo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 23:41:33</h6>
<p class='card-text'>Agriculture plays a crucial role in the global economy and social stability,
and accurate crop yield prediction is essential for rational planting planning
and decision-making. This study focuses on crop yield Time-Series Data
prediction. Considering the crucial significance of agriculture in the global
economy and social stability and the importance of accurate crop yield
prediction for rational planting planning and decision-making, this research
uses a dataset containing multiple crops, multiple regions, and data over many
years to deeply explore the relationships between climatic factors (average
rainfall, average temperature) and agricultural inputs (pesticide usage) and
crop yield. Multiple hybrid machine learning models such as Linear Regression,
Random Forest, Gradient Boost, XGBoost, KNN, Decision Tree, and Bagging
Regressor are adopted for yield prediction. After evaluation, it is found that
the Random Forest and Bagging Regressor models perform excellently in
predicting crop yield with high accuracy and low error.As agricultural data
becomes increasingly rich and time-series prediction techniques continue to
evolve, the results of this study contribute to advancing the practical
application of crop yield prediction in agricultural production management. The
integration of time-series analysis allows for more dynamic, data-driven
decision-making, enhancing the accuracy and reliability of crop yield forecasts
over time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12542v1' target='_blank'>Reinforcement Learning Constrained Beam Search for Parameter
  Optimization of Paper Drying Under Flexible Constraints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyuan Chen, Hanshen Yu, Jamal Yagoobi, Chenhui Shao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 23:16:19</h6>
<p class='card-text'>Existing approaches to enforcing design constraints in Reinforcement Learning
(RL) applications often rely on training-time penalties in the reward function
or training/inference-time invalid action masking, but these methods either
cannot be modified after training, or are limited in the types of constraints
that can be implemented. To address this limitation, we propose Reinforcement
Learning Constrained Beam Search (RLCBS) for inference-time refinement in
combinatorial optimization problems. This method respects flexible,
inference-time constraints that support exclusion of invalid actions and forced
inclusion of desired actions, and employs beam search to maximize sequence
probability for more sensible constraint incorporation. RLCBS is extensible to
RL-based planning and optimization problems that do not require real-time
solution, and we apply the method to optimize process parameters for a novel
modular testbed for paper drying. An RL agent is trained to minimize energy
consumption across varying machine speed levels by generating optimal dryer
module and air supply temperature configurations. Our results demonstrate that
RLCBS outperforms NSGA-II under complex design constraints on drying module
configurations at inference-time, while providing a 2.58-fold or higher speed
improvement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12323v2' target='_blank'>Deep Learning Based Segmentation of Blood Vessels from H&E Stained
  Oesophageal Adenocarcinoma Whole-Slide Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaqi Lv, Stefan S Antonowicz, Shan E Ahmed Raza</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 17:42:06</h6>
<p class='card-text'>Blood vessels (BVs) play a critical role in the Tumor Micro-Environment
(TME), potentially influencing cancer progression and treatment response.
However, manually quantifying BVs in Hematoxylin and Eosin (H&E) stained images
is challenging and labor-intensive due to their heterogeneous appearances. We
propose a novel approach of constructing guiding maps to improve the
performance of state-of-the-art segmentation models for BV segmentation, the
guiding maps encourage the models to learn representative features of BVs. This
is particularly beneficial for computational pathology, where labeled training
data is often limited and large models are prone to overfitting. We have
quantitative and qualitative results to demonstrate the efficacy of our
approach in improving segmentation accuracy. In future, we plan to validate
this method to segment BVs across various tissue types and investigate the role
of cellular structures in relation to BVs in the TME.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12234v1' target='_blank'>Multi-Agent Feedback Motion Planning using Probably Approximately
  Correct Nonlinear Model Predictive Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mark Gonzales, Adam Polevoy, Marin Kobilarov, Joseph Moore</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 15:57:15</h6>
<p class='card-text'>For many tasks, multi-robot teams often provide greater efficiency,
robustness, and resiliency. However, multi-robot collaboration in real-world
scenarios poses a number of major challenges, especially when dynamic robots
must balance competing objectives like formation control and obstacle avoidance
in the presence of stochastic dynamics and sensor uncertainty. In this paper,
we propose a distributed, multi-agent receding-horizon feedback motion planning
approach using Probably Approximately Correct Nonlinear Model Predictive
Control (PAC-NMPC) that is able to reason about both model and measurement
uncertainty to achieve robust multi-agent formation control while navigating
cluttered obstacle fields and avoiding inter-robot collisions. Our approach
relies not only on the underlying PAC-NMPC algorithm but also on a terminal
cost-function derived from gyroscopic obstacle avoidance. Through numerical
simulation, we show that our distributed approach performs on par with a
centralized formulation, that it offers improved performance in the case of
significant measurement noise, and that it can scale to more complex dynamical
systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12231v1' target='_blank'>InsTALL: Context-aware Instructional Task Assistance with Multi-modal
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 15:55:06</h6>
<p class='card-text'>The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12229v1' target='_blank'>Empower Healthcare through a Self-Sovereign Identity Infrastructure for
  Secure Electronic Health Data Access</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Antonio López Martínez, Montassar Naghmouchi, Maryline Laurent, Joaquin Garcia-Alfaro, Manuel Gil Pérez, Antonio Ruiz Martínez, Pantaleone Nespoli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 15:52:26</h6>
<p class='card-text'>Health data is one of the most sensitive data for people, which attracts the
attention of malicious activities. We propose an open-source health data
management framework, that follows a patient-centric approach. The proposed
framework implements the Self-Sovereign Identity paradigm with innovative
technologies such as Decentralized Identifiers and Verifiable Credentials. The
framework uses Blockchain technology to provide immutability, verifiable data
registry, and auditability, as well as an agent-based model to provide
protection and privacy for the patient data. We also define different use cases
regarding the daily patient-practitioner-laboratory interactions and specific
functions to cover patient data loss, data access revocation, and emergency
cases where patients are unable to give consent and access to their data. To
address this design, a proof of concept is created with an interaction between
patient and doctor. The most feasible technologies are selected and the created
design is validated. We discuss the differences and novelties of this
framework, which includes the patient-centric approach also for data storage,
the designed recovery and emergency plan, the defined backup procedure, and the
selected blockchain platform.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10403v1' target='_blank'>Implementing agile healthcare frame works in the context of low income
  countries: Proposed Framework and Review</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:P K Dutta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 07:52:34</h6>
<p class='card-text'>Agile healthcare frameworks, derived from methodologies in IT and
manufacturing, offer transformative potential for low-income regions. This
study explores Agile integration in resource-constrained environments, focusing
on Ghana. Key benefits include adaptability, iterative planning, and
stakeholder collaboration to address infrastructure gaps, workforce shortages,
and the "know-do gap." Digital tools like mobile health (mHealth) applications
and the District Health Information Management System (DHIMS) demonstrate Agile
scalability and efficacy in improving outcomes and resource allocation. Policy
alignment, such as through Ghana's National Health Insurance Scheme (NHIS), is
crucial for sustaining these practices. Findings reveal Agile ability to enable
real-time decision-making, foster community engagement, and drive
interdisciplinary collaboration. This paper provides actionable strategies and
systemic innovations, positioning Agile as a scalable model for equitable,
high-quality care delivery in other low-income regions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11946v1' target='_blank'>Towards Solutions of Manipulation Tasks via Optimal Control of Projected
  Dynamical Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anton Pozharskiy, Armin Nurkanović, Moritz Diehl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 07:42:18</h6>
<p class='card-text'>We introduce a modeling framework for manipulation planning based on the
formulation of the dynamics as a projected dynamical system. This method uses
implicit signed distance functions and their gradients to formulate an
equivalent gradient complementarity system. The optimal control problem is then
solved via a direct method, discretized using finite-elements with switch
detection. An extension to this approach is provided in the form of a friction
formulation commonly used in quasi-static models. We show that this approach is
able to generate trajectories for problems including multiple pushers,
friction, and non-convex objects modeled as unions of convex ellipsoids with
reasonable computational effort.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11803v1' target='_blank'>Automating High Quality RT Planning at Scale</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Riqiang Gao, Mamadou Diallo, Han Liu, Anthony Magliari, Jonathan Sackett, Wilko Verbakel, Sandra Meyers, Masoud Zarepisheh, Rafe Mcbeth, Simon Arberet, Martin Kraus, Florin C. Ghesu, Ali Kamen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 00:44:18</h6>
<p class='card-text'>Radiotherapy (RT) planning is complex, subjective, and time-intensive.
Advances in artificial intelligence (AI) promise to improve its precision,
efficiency, and consistency, but progress is often limited by the scarcity of
large, standardized datasets. To address this, we introduce the Automated
Iterative RT Planning (AIRTP) system, a scalable solution for generating
high-quality treatment plans. This scalable solution is designed to generate
substantial volumes of consistently high-quality treatment plans, overcoming a
key obstacle in the advancement of AI-driven RT planning. Our AIRTP pipeline
adheres to clinical guidelines and automates essential steps, including
organ-at-risk (OAR) contouring, helper structure creation, beam setup,
optimization, and plan quality improvement, using AI integrated with RT
planning software like Eclipse of Varian. Furthermore, a novel approach for
determining optimization parameters to reproduce 3D dose distributions, i.e. a
method to convert dose predictions to deliverable treatment plans constrained
by machine limitations. A comparative analysis of plan quality reveals that our
automated pipeline produces treatment plans of quality comparable to those
generated manually, which traditionally require several hours of labor per
plan. Committed to public research, the first data release of our AIRTP
pipeline includes nine cohorts covering head-and-neck and lung cancer sites to
support an AAPM 2025 challenge. This data set features more than 10 times the
number of plans compared to the largest existing well-curated public data set
to our best knowledge.
Repo:{https://github.com/RiqiangGao/GDP-HMM_AAPMChallenge}</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11739v2' target='_blank'>Episodic memory in AI agents poses risks that should be studied and
  mitigated</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chad DeChant</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 20:54:06</h6>
<p class='card-text'>Most current AI models have little ability to store and later retrieve a
record or representation of what they do. In human cognition, episodic memories
play an important role in both recall of the past as well as planning for the
future. The ability to form and use episodic memories would similarly enable a
broad range of improved capabilities in an AI agent that interacts with and
takes actions in the world. Researchers have begun directing more attention to
developing memory abilities in AI models. It is therefore likely that models
with such capability will be become widespread in the near future. This could
in some ways contribute to making such AI agents safer by enabling users to
better monitor, understand, and control their actions. However, as a new
capability with wide applications, we argue that it will also introduce
significant new risks that researchers should begin to study and address. We
outline these risks and benefits and propose four principles to guide the
development of episodic memory capabilities so that these will enhance, rather
than undermine, the effort to keep AI safe and trustworthy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11733v2' target='_blank'>Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenhailong Wang, Haiyang Xu, Junyang Wang, Xi Zhang, Ming Yan, Ji Zhang, Fei Huang, Heng Ji</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 20:35:46</h6>
<p class='card-text'>Smartphones have become indispensable in modern life, yet navigating complex
tasks on mobile devices often remains frustrating. Recent advancements in large
multimodal model (LMM)-based mobile agents have demonstrated the ability to
perceive and act in mobile environments. However, current approaches face
significant limitations: they fall short in addressing real-world human needs,
struggle with reasoning-intensive and long-horizon tasks, and lack mechanisms
to learn and improve from prior experiences. To overcome these challenges, we
introduce Mobile-Agent-E, a hierarchical multi-agent framework capable of
self-evolution through past experience. By hierarchical, we mean an explicit
separation of high-level planning and low-level action execution. The framework
comprises a Manager, responsible for devising overall plans by breaking down
complex tasks into subgoals, and four subordinate agents--Perceptor, Operator,
Action Reflector, and Notetaker--which handle fine-grained visual perception,
immediate action execution, error verification, and information aggregation,
respectively. Mobile-Agent-E also features a novel self-evolution module which
maintains a persistent long-term memory comprising Tips and Shortcuts. Tips are
general guidance and lessons learned from prior tasks on how to effectively
interact with the environment. Shortcuts are reusable, executable sequences of
atomic operations tailored for specific subroutines. The inclusion of Tips and
Shortcuts facilitates continuous refinement in performance and efficiency.
Alongside this framework, we introduce Mobile-Eval-E, a new benchmark featuring
complex mobile tasks requiring long-horizon, multi-app interactions. Empirical
results show that Mobile-Agent-E achieves a 22% absolute improvement over
previous state-of-the-art approaches across three foundation model backbones.
Project page: https://x-plug.github.io/MobileAgent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14819v1' target='_blank'>A Comprehensive Mathematical and System-Level Analysis of Autonomous
  Vehicle Timelines</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Paul Perrone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 19:46:46</h6>
<p class='card-text'>Fully autonomous vehicles (AVs) continue to spark immense global interest,
yet predictions on when they will operate safely and broadly remain heavily
debated. This paper synthesizes two distinct research traditions: computational
complexity and algorithmic constraints versus reliability growth modeling and
real-world testing to form an integrated, quantitative timeline for future AV
deployment. We propose a mathematical framework that unifies NP-hard
multi-agent path planning analyses, high-performance computing (HPC)
projections, and extensive Crow-AMSAA reliability growth calculations,
factoring in operational design domain (ODD) variations, severity, and partial
vs. full domain restrictions. Through category-specific case studies (e.g.,
consumer automotive, robo-taxis, highway trucking, industrial and defense
applications), we show how combining HPC limitations, safety demonstration
requirements, production/regulatory hurdles, and parallel/serial test
strategies can push out the horizon for universal Level 5 deployment by up to
several decades. Conversely, more constrained ODDs; like fenced industrial
sites or specialized defense operations; may see autonomy reach commercial
viability in the near-to-medium term. Our findings illustrate that while
targeted domains can achieve automated service sooner, widespread driverless
vehicles handling every environment remain far from realized. This paper thus
offers a unique and rigorous perspective on why AV timelines extend well beyond
short-term optimism, underscoring how each dimension of complexity and
reliability imposes its own multi-year delays. By quantifying these constraints
and exploring potential accelerators (e.g., advanced AI hardware,
infrastructure up-grades), we provide a structured baseline for researchers,
policymakers, and industry stakeholders to more accurately map their
expectations and investments in AV technology.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11560v1' target='_blank'>Explainable Lane Change Prediction for Near-Crash Scenarios Using
  Knowledge Graph Embeddings and Retrieval Augmented Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:M. Manzour, A. Ballardini, R. Izquierdo, M. Á. Sotelo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 16:02:26</h6>
<p class='card-text'>Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11546v2' target='_blank'>An Exploratory Study on the Engineering of Security Features</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kevin Hermann, Sven Peldszus, Jan-Philipp Steghöfer, Thorsten Berger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 15:37:53</h6>
<p class='card-text'>Software security is of utmost importance for most software systems.
Developers must systematically select, plan, design, implement, and especially,
maintain and evolve security features -- functionalities to mitigate attacks or
protect personal data such as cryptography or access control -- to ensure the
security of their software. Although security features are usually available in
libraries, integrating security features requires writing and maintaining
additional security-critical code. While there have been studies on the use of
such libraries, surprisingly little is known about how developers engineer
security features, how they select what security features to implement and
which ones may require custom implementation, and the implications for
maintenance. As a result, we currently rely on assumptions that are largely
based on common sense or individual examples. However, to provide them with
effective solutions, researchers need hard empirical data to understand what
practitioners need and how they view security -- data that we currently lack.
To fill this gap, we contribute an exploratory study with 26 knowledgeable
industrial participants. We study how security features of software systems are
selected and engineered in practice, what their code-level characteristics are,
and what challenges practitioners face. Based on the empirical data gathered,
we provide insights into engineering practices and validate four common
assumptions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17880v1' target='_blank'>Assessment of the January 2025 Los Angeles County wildfires: A
  multi-modal analysis of impact, response, and population exposure</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seyd Teymoor Seydi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 13:50:16</h6>
<p class='card-text'>This study presents a comprehensive analysis of four significant California
wildfires: Palisades, Eaton, Kenneth, and Hurst, examining their impacts
through multiple dimensions, including land cover change, jurisdictional
management, structural damage, and demographic vulnerability. Using the
Chebyshev-Kolmogorov-Arnold network model applied to Sentinel-2 imagery, the
extent of burned areas was mapped, ranging from 315.36 to 10,960.98 hectares.
Our analysis revealed that shrubland ecosystems were consistently the most
affected, comprising 57.4-75.8% of burned areas across all events. The
jurisdictional assessment demonstrated varying management complexities, from
singular authority (98.7% in the Palisades Fire) to distributed management
across multiple agencies. A structural impact analysis revealed significant
disparities between urban interface fires (Eaton: 9,869 structures; Palisades:
8,436 structures) and rural events (Kenneth: 24 structures; Hurst: 17
structures). The demographic analysis showed consistent gender distributions,
with 50.9% of the population identified as female and 49.1% as male.
Working-age populations made up the majority of the affected populations,
ranging from 53.7% to 54.1%, with notable temporal shifts in post-fire periods.
The study identified strong correlations between urban interface proximity,
structural damage, and population exposure. The Palisades and Eaton fires
affected over 20,000 people each, compared to fewer than 500 in rural events.
These findings offer valuable insights for the development of targeted wildfire
management strategies, particularly in wildland urban interface zones, and
emphasize the need for age- and gender-conscious approaches in emergency
response planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11434v1' target='_blank'>An Incremental Sampling and Segmentation-Based Approach for Motion
  Planning Infeasibility</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Antony Thomas, Fulvio Mastrogiovanni, Marco Baglietto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 12:13:03</h6>
<p class='card-text'>We present a simple and easy-to-implement algorithm to detect plan
infeasibility in kinematic motion planning. Our method involves approximating
the robot's configuration space to a discrete space, where each degree of
freedom has a finite set of values. The obstacle region separates the free
configuration space into different connected regions. For a path to exist
between the start and goal configurations, they must lie in the same connected
region of the free space. Thus, to ascertain plan infeasibility, we merely need
to sample adequate points from the obstacle region that isolate start and goal.
Accordingly, we progressively construct the configuration space by sampling
from the discretized space and updating the bitmap cells representing obstacle
regions. Subsequently, we partition this partially built configuration space to
identify different connected components within it and assess the connectivity
of the start and goal cells. We illustrate this methodology on five different
scenarios with configuration spaces having up to 5 degree-of-freedom (DOF).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11424v1' target='_blank'>A Grad-Shafranov model for compact quasisymmetric stellarators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nikita Nikulsin, Wrick Sengupta, Stefan Buller, Amitava Bhattacharjee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 11:46:01</h6>
<p class='card-text'>A Grad-Shafranov equation (GSE) valid for compact quasisymmetric stellarators
is derived by an asymptotic expansion around a vacuum field carried to first
order. We obtain an equation for the existence of flux surfaces leading up to
the GSE. The flux surface label must simultaneously satisfy the existence
equation and the GSE, which generally leads to an overdetermined problem. We
show how the overdetermined problem can be resolved within our model for a
class of hybrid devices similar to that studied by Henneberg and Plunk (S.
Henneberg and G. Plunk, PRR 2024). We are also able to solve the existence
equation for flux surfaces analytically in the most general case by introducing
a special coordinate system. In future work, we plan to carry out an
optimization seeking to minimize the error in our GSE while obeying the flux
surface existence equation. This should be faster than a conventional
stellarator optimization and will allow us to find solutions outside the class
of hybrid devices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11419v1' target='_blank'>An Analysis of the Correctness and Computational Complexity of Path
  Planning in Payment Channel Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Padraig Corcoran, Rhyd Lewis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 11:36:45</h6>
<p class='card-text'>Payment Channel Networks (PCNs) are a method for improving the scaling and
latency of cryptocurrency transactions. For a payment to be made between two
peers in a PCN, a feasible low-fee path in the network must be planned. Many
PCN path planning algorithms use a search algorithm that is a variant of
Dijkstra's algorithm. In this article, we prove the correctness and
computational complexity of this algorithm. Specifically, we show that, if the
PCN satisfies a consistency property relating to the fees charged by payment
channels, the algorithm is correct and has polynomial computational complexity.
However, in the general case, the algorithm is not correct and the path
planning problem is NP-hard. These newly developed results can be used to
inform the development of new or existing PCNs amenable to path planning. For
example, we show that the Lightning Network, which is the most widely used PCN
and is built on the Bitcoin cryptocurrency, currently satisfies the above
consistency property. As a second contribution, we demonstrate that a small
modification to the above path planning algorithm which, although having the
same asymptotic computational complexity, empirically shows better performance.
This modification involves the use of a bidirectional search and is empirically
evaluated by simulating transactions on the Lightning Network.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11260v2' target='_blank'>A Survey of World Models for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tuo Feng, Wenguan Wang, Yi Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 04:00:02</h6>
<p class='card-text'>Recent breakthroughs in autonomous driving have been propelled by advances in
robust world modeling, fundamentally transforming how vehicles interpret
dynamic scenes and execute safe decision-making. In particular, world models
have emerged as a linchpin technology, offering high-fidelity representations
of the driving environment that integrate multi-sensor data, semantic cues, and
temporal dynamics. This paper systematically reviews recent advances in world
models for autonomous driving, proposing a three-tiered taxonomy: 1) Generation
of Future Physical World, covering image-, BEV-, OG-, and PC-based generation
methods that enhance scene evolution modeling through diffusion models and 4D
occupancy forecasting; 2) Behavior Planning for Intelligent Agents, combining
rule-driven and learning-based paradigms with cost map optimization and
reinforcement learning for trajectory generation in complex traffic conditions;
3) Interaction Between Prediction and Planning, achieving multi-agent
collaborative decision-making through latent space diffusion and
memory-augmented architectures. The study further analyzes training paradigms
including self-supervised learning, multimodal pretraining, and generative data
augmentation, while evaluating world models' performance in scene understanding
and motion prediction tasks. Future research must address key challenges in
self-supervised representation learning, long-tail scenario generation, and
multimodal fusion to advance the practical deployment of world models in
complex urban environments. Overall, our comprehensive analysis provides a
theoretical framework and technical roadmap for harnessing the transformative
potential of world models in advancing safe and reliable autonomous driving
solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11214v1' target='_blank'>Mitigating Spatial Disparity in Urban Prediction Using Residual-Aware
  Spatiotemporal Graph Neural Networks: A Chicago Case Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dingyi Zhuang, Hanyong Xu, Xiaotong Guo, Yunhan Zheng, Shenhao Wang, Jinhua Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 01:28:49</h6>
<p class='card-text'>Urban prediction tasks, such as forecasting traffic flow, temperature, and
crime rates, are crucial for efficient urban planning and management. However,
existing Spatiotemporal Graph Neural Networks (ST-GNNs) often rely solely on
accuracy, overlooking spatial and demographic disparities in their predictions.
This oversight can lead to imbalanced resource allocation and exacerbate
existing inequities in urban areas. This study introduces a Residual-Aware
Attention (RAA) Block and an equality-enhancing loss function to address these
disparities. By adapting the adjacency matrix during training and incorporating
spatial disparity metrics, our approach aims to reduce local segregation of
residuals and errors. We applied our methodology to urban prediction tasks in
Chicago, utilizing a travel demand dataset as an example. Our model achieved a
48% significant improvement in fairness metrics with only a 9% increase in
error metrics. Spatial analysis of residual distributions revealed that models
with RAA Blocks produced more equitable prediction results, particularly by
reducing errors clustered in central regions. Attention maps demonstrated the
model's ability to dynamically adjust focus, leading to more balanced
predictions. Case studies of various community areas in Chicago further
illustrated the effectiveness of our approach in addressing spatial and
demographic disparities, supporting more balanced and equitable urban planning
and policy-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11202v2' target='_blank'>Online Hybrid-Belief POMDP with Coupled Semantic-Geometric Models and
  Semantic Safety Awareness</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tuvy Lemberg, Vadim Indelman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 00:22:44</h6>
<p class='card-text'>Robots operating in complex and unknown environments frequently require
geometric-semantic representations of the environment to safely perform their
tasks. While inferring the environment, they must account for many possible
scenarios when planning future actions. Since objects' class types are discrete
and the robot's self-pose and the objects' poses are continuous, the
environment can be represented by a hybrid discrete-continuous belief which is
updated according to models and incoming data. Prior probabilities and
observation models representing the environment can be learned from data using
deep learning algorithms. Such models often couple environmental semantic and
geometric properties. As a result, semantic variables are interconnected,
causing semantic state space dimensionality to increase exponentially. In this
paper, we consider planning under uncertainty using partially observable Markov
decision processes (POMDPs) with hybrid semantic-geometric beliefs. The models
and priors consider the coupling between semantic and geometric variables.
Within POMDP, we introduce the concept of semantically aware safety. Obtaining
representative samples of the theoretical hybrid belief, required for
estimating the value function, is very challenging. As a key contribution, we
develop a novel form of the hybrid belief and leverage it to sample
representative samples. We show that under certain conditions, the value
function and probability of safety can be calculated efficiently with an
explicit expectation over all possible semantic mappings. Our simulations show
that our estimates of the objective function and probability of safety achieve
similar levels of accuracy compared to estimators that run exhaustively on the
entire semantic state-space using samples from the theoretical hybrid belief.
Nevertheless, the complexity of our estimators is polynomial rather than
exponential.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07787v2' target='_blank'>A Simulation-Based Framework for Leveraging Shared Autonomous Vehicles
  to Enhance Disaster Evacuations in Rural Regions with a Focus on Vulnerable
  Populations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alican Sevim, Qian-wen Guo, Eren Erman Ozguven</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 00:12:31</h6>
<p class='card-text'>Rapid advancements in autonomous vehicles (AVs) are poised to revolutionize
transportation and communities, including disaster evacuations, particularly
through the deployment of Shared Autonomous Vehicles (SAVs). Despite the
potential, the use of SAVs in rural disaster evacuations remains an
underexplored area. To address this gap, this study proposes a simulation-based
framework that integrates both mathematical programming and SUMO traffic
simulation to deploy SAVs in pre- and post-disaster evacuations in rural areas.
The framework prioritizes the needs of vulnerable groups, including individuals
with disabilities, limited English proficiency, and elderly residents. Sumter
County, Florida, serves as the case study due to its unique characteristics: a
high concentration of vulnerable individuals and limited access to public
transportation, making it one of the most transportation-insecure counties in
the state. These conditions present significant challenges for evacuation
planning in the region. To explore potential solutions, we conducted mass
evacuation simulations by incorporating SAVs across seven scenarios. These
scenarios represented varying SAV penetration levels, ranging from 20% to 100%
of the vulnerable population, and were compared to a baseline scenario using
only passenger cars. Additionally, we examined both pre-disaster and
post-disaster conditions, accounting for infrastructure failures and road
closures. According to the simulation results, higher SAV integration
significantly improves traffic distribution and reduces congestion. Scenarios
featuring more SAVs exhibited lower congestion peaks and more stable traffic
flow. Conversely, mixed traffic environments demonstrate reduced average speeds
attributable to interactions between SAVs and passenger cars, while exclusive
use of SAVs results in higher speeds and more stable travel patterns.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11197v1' target='_blank'>Q-RESTORE: Quantum-Driven Framework for Resilient and Equitable
  Transportation Network Restoration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Udekwe, Ruimin Ke, Jiaqing Lu, Qian-wen Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 00:08:09</h6>
<p class='card-text'>Efficient and socially equitable restoration of transportation networks post
disasters is crucial for community resilience and access to essential services.
The ability to rapidly recover critical infrastructure can significantly
mitigate the impacts of disasters, particularly in underserved communities
where prolonged isolation exacerbates vulnerabilities. Traditional restoration
methods prioritize functionality over computational efficiency and equity,
leaving low-income communities at a disadvantage during recovery. To address
this gap, this research introduces a novel framework that combines quantum
computing technology with an equity-focused approach to network restoration.
Optimization of road link recovery within budget constraints is achieved by
leveraging D Wave's hybrid quantum solver, which targets the connectivity needs
of low, average, and high income communities. This framework combines
computational speed with equity, ensuring priority support for underserved
populations. Findings demonstrate that this hybrid quantum solver achieves near
instantaneous computation times of approximately 8.7 seconds across various
budget scenarios, significantly outperforming the widely used genetic
algorithm. It offers targeted restoration by first aiding low-income
communities and expanding aid as budgets increase, aligning with equity goals.
This work showcases quantum computing's potential in disaster recovery
planning, providing a rapid and equitable solution that elevates urban
resilience and social sustainability by aiding vulnerable populations in
disasters.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11196v1' target='_blank'>Enhancing Brain Tumor Segmentation Using Channel Attention and Transfer
  learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Majid Behzadpour, Ebrahim Azizi, Kai Wu, Bengie L. Ortiz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 23:58:16</h6>
<p class='card-text'>Accurate and efficient segmentation of brain tumors is critical for
diagnosis, treatment planning, and monitoring in clinical practice. In this
study, we present an enhanced ResUNet architecture for automatic brain tumor
segmentation, integrating an EfficientNetB0 encoder, a channel attention
mechanism, and an Atrous Spatial Pyramid Pooling (ASPP) module. The
EfficientNetB0 encoder leverages pre-trained features to improve feature
extraction efficiency, while the channel attention mechanism enhances the
model's focus on tumor-relevant features. ASPP enables multiscale contextual
learning, crucial for handling tumors of varying sizes and shapes. The proposed
model was evaluated on two benchmark datasets: TCGA LGG and BraTS 2020.
Experimental results demonstrate that our method consistently outperforms the
baseline ResUNet and its EfficientNet variant, achieving Dice coefficients of
0.903 and 0.851 and HD95 scores of 9.43 and 3.54 for whole tumor and tumor core
regions on the BraTS 2020 dataset, respectively. compared with state-of-the-art
methods, our approach shows competitive performance, particularly in whole
tumor and tumor core segmentation. These results indicate that combining a
powerful encoder with attention mechanisms and ASPP can significantly enhance
brain tumor segmentation performance. The proposed approach holds promise for
further optimization and application in other medical image segmentation tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11149v1' target='_blank'>CART-MPC: Coordinating Assistive Devices for Robot-Assisted Transferring
  with Multi-Agent Model Predictive Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruolin Ye, Shuaixing Chen, Yunting Yan, Joyce Yang, Christina Ge, Jose Barreiros, Kate Tsui, Tom Silver, Tapomayukh Bhattacharjee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 19:14:05</h6>
<p class='card-text'>Bed-to-wheelchair transferring is a ubiquitous activity of daily living
(ADL), but especially challenging for caregiving robots with limited payloads.
We develop a novel algorithm that leverages the presence of other assistive
devices: a Hoyer sling and a wheelchair for coarse manipulation of heavy loads,
alongside a robot arm for fine-grained manipulation of deformable objects
(Hoyer sling straps). We instrument the Hoyer sling and wheelchair with
actuators and sensors so that they can become intelligent agents in the
algorithm. We then focus on one subtask of the transferring ADL -- tying Hoyer
sling straps to the sling bar -- that exemplifies the challenges of transfer:
multi-agent planning, deformable object manipulation, and generalization to
varying hook shapes, sling materials, and care recipient bodies. To address
these challenges, we propose CART-MPC, a novel algorithm based on turn-taking
multi-agent model predictive control that uses a learned neural dynamics model
for a keypoint-based representation of the deformable Hoyer sling strap, and a
novel cost function that leverages linking numbers from knot theory and neural
amortization to accelerate inference. We validate it in both RCareWorld
simulation and real-world environments. In simulation, CART-MPC successfully
generalizes across diverse hook designs, sling materials, and care recipient
body shapes. In the real world, we show zero-shot sim-to-real generalization
capabilities to tie deformable Hoyer sling straps on a sling bar towards
transferring a manikin from a hospital bed to a wheelchair. See our website for
supplementary materials: https://emprise.cs.cornell.edu/cart-mpc/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11117v1' target='_blank'>Meteorological assessment of vertical axis wind turbine energy
  generation potentials across two Swiss cities in complex terrain</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aldo Brandi, Gabriele Manoli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 17:24:33</h6>
<p class='card-text'>Wind energy is the most mature renewable energy technology, however, its
exploitation in cities is often met with skepticism. Thanks to their ability to
operate effectively at low wind from any direction, vertical axis wind turbines
(VAWTs) offer an attractive opportunity for wind energy harvesting in cities,
but limited evidence exists on their potential in complex urban environments,
and the role of different geographical settings, local meteorological
conditions, and urban characteristics remains unclear. Here we use realistic
Weather Research and Forecast model high-resolution wind speed simulations
alongside representative VAWT power curves to quantify the range of
micro-generation potentials at the annual, seasonal, and diurnal scale across
two Swiss cities (Lausanne and Geneva) residing in complex terrain. Our results
show that Lausanne generally experiences higher (+24%) wind speed than Geneva.
Both cities present the greatest micro-generation potential during the summer
months, although Lausanne shows non-negligible potential also during the
wintertime. Wind speed is higher during the nighttime in Lausanne and during
the daytime in Geneva, due to the different interaction between the local
lake-breeze circulation and the synoptic flow. Simulated performance of
case-study VAWTs is dominated by cut-in wind speed and power curve inflection
point. On average, in 2022, an individual VAWT would have produced 2665 kWh of
total annual electricity, equivalent to 16.5 square meters of photovoltaic
panels. These results highlight the need for research on urban wind energy
featuring detailed city-scale assessments that account for urban
heterogeneities and regional circulation patters, to inform future planning
investment and engineering development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11097v1' target='_blank'>Unit Region Encoding: A Unified and Compact Geometry-aware
  Representation for Floorplan Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huichao Zhang, Pengyu Wang, Manyi Li, Zuojun Li, Yaguang Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 16:17:20</h6>
<p class='card-text'>We present the Unit Region Encoding of floorplans, which is a unified and
compact geometry-aware encoding representation for various applications,
ranging from interior space planning, floorplan metric learning to floorplan
generation tasks. The floorplans are represented as the latent encodings on a
set of boundary-adaptive unit region partition based on the clustering of the
proposed geometry-aware density map. The latent encodings are extracted by a
trained network (URE-Net) from the input dense density map and other available
semantic maps. Compared to the over-segmented rasterized images and the
room-level graph structures, our representation can be flexibly adapted to
different applications with the sliced unit regions while achieving higher
accuracy performance and better visual quality. We conduct a variety of
experiments and compare to the state-of-the-art methods on the aforementioned
applications to validate the superiority of our representation, as well as
extensive ablation studies to demonstrate the effect of our slicing choices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10991v2' target='_blank'>Front Hair Styling Robot System Using Path Planning for Root-Centric
  Strand Adjustment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Soonhyo Kim, Naoaki Kanazawa, Shun Hasegawa, Kento Kawaharazuka, Kei Okada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 09:23:57</h6>
<p class='card-text'>Hair styling is a crucial aspect of personal grooming, significantly
influenced by the appearance of front hair. While brushing is commonly used
both to detangle hair and for styling purposes, existing research primarily
focuses on robotic systems for detangling hair, with limited exploration into
robotic hair styling. This research presents a novel robotic system designed to
automatically adjust front hairstyles, with an emphasis on path planning for
root-centric strand adjustment. The system utilizes images to compare the
current hair state with the desired target state through an orientation map of
hair strands. By concentrating on the differences in hair orientation and
specifically targeting adjustments at the root of each strand, the system
performs detailed styling tasks. The path planning approach ensures effective
alignment of the hairstyle with the target, and a closed-loop mechanism refines
these adjustments to accurately evolve the hairstyle towards the desired
outcome. Experimental results demonstrate that the proposed system achieves a
high degree of similarity and consistency in front hair styling, showing
promising results for automated, precise hairstyle adjustments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10984v1' target='_blank'>Self-CephaloNet: A Two-stage Novel Framework using Operational Neural
  Network for Cephalometric Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md. Shaheenur Islam Sumon, Khandaker Reajul Islam, Tanzila Rafique, Gazi Shamim Hassan, Md. Sakib Abrar Hossain, Kanchon Kanti Podder, Noha Barhom, Faleh Tamimi, Abdulrahman Alqahtani, Muhammad E. H. Chowdhury</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 08:37:27</h6>
<p class='card-text'>Cephalometric analysis is essential for the diagnosis and treatment planning
of orthodontics. In lateral cephalograms, however, the manual detection of
anatomical landmarks is a time-consuming procedure. Deep learning solutions
hold the potential to address the time constraints associated with certain
tasks; however, concerns regarding their performance have been observed. To
address this critical issue, we proposed an end-to-end cascaded deep learning
framework (Self-CepahloNet) for the task, which demonstrated benchmark
performance over the ISBI 2015 dataset in predicting 19 dental landmarks. Due
to their adaptive nodal capabilities, Self-ONN (self-operational neural
networks) demonstrate superior learning performance for complex feature spaces
over conventional convolutional neural networks. To leverage this attribute, we
introduced a novel self-bottleneck in the HRNetV2 (High Resolution Network)
backbone, which has exhibited benchmark performance on the ISBI 2015 dataset
for the dental landmark detection task. Our first-stage results surpassed
previous studies, showcasing the efficacy of our singular end-to-end deep
learning model, which achieved a remarkable 70.95% success rate in detecting
cephalometric landmarks within a 2mm range for the Test1 and Test2 datasets.
Moreover, the second stage significantly improved overall performance, yielding
an impressive 82.25% average success rate for the datasets above within the
same 2mm distance. Furthermore, external validation was conducted using the PKU
cephalogram dataset. Our model demonstrated a commendable success rate of
75.95% within the 2mm range.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10950v1' target='_blank'>Factor Graph-Based Active SLAM for Spacecraft Proximity Operations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lorenzo Ticozzi, Panagiotis Tsiotras</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 05:13:39</h6>
<p class='card-text'>We investigate a scenario where a chaser spacecraft or satellite equipped
with a monocular camera navigates in close proximity to a target spacecraft.
The satellite's primary objective is to construct a representation of the
operational environment and localize itself within it, utilizing the available
image data. We frame the joint task of state trajectory and map estimation as
an instance of smoothing-based simultaneous localization and mapping (SLAM),
where the underlying structure of the problem is represented as a factor graph.
Rather than considering estimation and planning as separate tasks, we propose
to control the camera observations to actively reduce the uncertainty of the
estimation variables, the spacecraft state, and the map landmarks. This is
accomplished by adopting an information-theoretic metric to reason about the
impact of candidate actions on the evolution of the belief state. Numerical
simulations indicate that the proposed method successfully captures the
interplay between planning and estimation, hence yielding reduced uncertainty
and higher accuracy when compared to commonly adopted passive sensing
strategies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10934v1' target='_blank'>Automatic Calibration of Mesoscopic Traffic Simulation Using Vehicle
  Trajectory Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ran Sun, Zihao Wang, Xingmin Wang, Henry X. Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 04:02:00</h6>
<p class='card-text'>Traffic simulation models have long been popular in modern traffic planning
and operation applications. Efficient calibration of simulation models is
usually a crucial step in a simulation study. However, traditional calibration
procedures are often resource-intensive and time-consuming, limiting the
broader adoption of simulation models. In this study, a vehicle
trajectory-based automatic calibration framework for mesoscopic traffic
simulation is proposed. The framework incorporates behavior models from both
the demand and the supply sides of a traffic network. An optimization-based
network flow estimation model is designed for demand and route choice
calibration. Dimensionality reduction techniques are incorporated to define the
zoning system and the path choice set. A stochastic approximation model is
established for capacity and driving behavior parameter calibration. The
applicability and performance of the calibration framework are demonstrated
through a case study for the City of Birmingham network in Michigan.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10891v2' target='_blank'>OpenEarthMap-SAR: A Benchmark Synthetic Aperture Radar Dataset for
  Global High-Resolution Land Cover Mapping</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junshi Xia, Hongruixuan Chen, Clifford Broni-Bediako, Yimin Wei, Jian Song, Naoto Yokoya</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 22:30:27</h6>
<p class='card-text'>High-resolution land cover mapping plays a crucial role in addressing a wide
range of global challenges, including urban planning, environmental monitoring,
disaster response, and sustainable development. However, creating accurate,
large-scale land cover datasets remains a significant challenge due to the
inherent complexities of geospatial data, such as diverse terrain, varying
sensor modalities, and atmospheric conditions. Synthetic Aperture Radar (SAR)
imagery, with its ability to penetrate clouds and capture data in all-weather,
day-and-night conditions, offers unique advantages for land cover mapping.
Despite these strengths, the lack of benchmark datasets tailored for SAR
imagery has limited the development of robust models specifically designed for
this data modality. To bridge this gap and facilitate advancements in SAR-based
geospatial analysis, we introduce OpenEarthMap-SAR, a benchmark SAR dataset,
for global high-resolution land cover mapping. OpenEarthMap-SAR consists of 1.5
million segments of 5033 aerial and satellite images with the size of
1024$\times$1024 pixels, covering 35 regions from Japan, France, and the USA,
with partially manually annotated and fully pseudo 8-class land cover labels at
a ground sampling distance of 0.15--0.5 m. We evaluated the performance of
state-of-the-art methods for semantic segmentation and present challenging
problem settings suitable for further technical development. The dataset also
serves the official dataset for IEEE GRSS Data Fusion Contest Track I. The
dataset has been made publicly available at
https://zenodo.org/records/14622048.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05182v1' target='_blank'>Transportation Network Analysis, Volume I: Static and Dynamic Traffic
  Assignment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stephen D. Boyles, Nicholas E. Lownes, Avinash Unnikrishnan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 21:07:30</h6>
<p class='card-text'>This book covers static and dynamic traffic assignment models used in
transportation planning and network analysis. Traffic assignment is the final
step in the traditional planning process, and recent decades have seen many
advances in formulating and solving such models. The book discusses classical
solution methods alongside recent ones used in contemporary planning software.
  The primary audience for the book is graduate students new to transportation
network analysis, and to this end there are appendices providing general
mathematical background, and more specific background in formulating
optimization problems. We have also included appendices discussing more general
optimization applications outside of traffic assignment. We believe the book is
also of interest to practitioners seeking to understand recent advances in
network analysis, and to researchers wanting a unified reference for traffic
assignment content.
  A second volume is currently under preparation, and will cover transit,
freight, and logistics models in transportation networks. A free PDF version of
the text will always be available online at
https://sboyles.github.io/blubook.html. We will periodically post updated
versions of the text at this link, along with slides and other instructor
resources.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10812v1' target='_blank'>Graph Coloring to Reduce Computation Time in Prioritized Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Patrick Scheffe, Julius Kahle, Bassam Alrifaee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 16:22:07</h6>
<p class='card-text'>Distributing computations among agents in large networks reduces
computational effort in multi-agent path finding (MAPF). One distribution
strategy is prioritized planning (PP). In PP, we couple and prioritize
interacting agents to achieve a desired behavior across all agents in the
network. We characterize the interaction with a directed acyclic graph (DAG).
The computation time for solving MAPF problem using PP is mainly determined
through the longest path in this DAG. The longest path depends on the fixed
undirected coupling graph and the variable prioritization. The approaches from
literature to prioritize agents are numerous and pursue various goals. This
article presents an approach for prioritization in PP to reduce the longest
path length in the coupling DAG and thus the computation time for MAPF using
PP. We prove that this problem can be mapped to a graph-coloring problem, in
which the number of colors required corresponds to the longest path length in
the coupling DAG. We propose a decentralized graph-coloring algorithm to
determine priorities for the agents. We evaluate the approach by applying it to
multi-agent motion planning (MAMP) for connected and automated vehicles (CAVs)
on roads using, a variant of MAPF.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10781v1' target='_blank'>Simultaneous Computation with Multiple Prioritizations in Multi-Agent
  Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Patrick Scheffe, Julius Kahle, Bassam Alrifaee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 14:35:32</h6>
<p class='card-text'>Multi-agent path finding (MAPF) in large networks is computationally
challenging. An approach for MAPF is prioritized planning (PP), in which agents
plan sequentially according to their priority. Albeit a computationally
efficient approach for MAPF, the solution quality strongly depends on the
prioritization. Most prioritizations rely either on heuristics, which do not
generalize well, or iterate to find adequate priorities, which costs
computational effort. In this work, we show how agents can compute with
multiple prioritizations simultaneously. Our approach is general as it does not
rely on domain-specific knowledge. The context of this work is multi-agent
motion planning (MAMP) with a receding horizon subject to computation time
constraints. MAMP considers the system dynamics in more detail compared to
MAPF. In numerical experiments on MAMP, we demonstrate that our approach to
prioritization comes close to optimal prioritization and outperforms
state-of-the-art methods with only a minor increase in computation time. We
show real-time capability in an experiment on a road network with ten vehicles
in our Cyber-Physical Mobility Lab.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10769v1' target='_blank'>Risk-Averse Antibiotics Time Machine Problem</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Deniz Tuncer, Burak Kocuk</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 13:54:29</h6>
<p class='card-text'>Antibiotic resistance, which is a serious healthcare issue, emerges due to
uncontrolled and repeated antibiotic use that causes bacteria to mutate and
develop resistance to antibiotics. The Antibiotics Time Machine Problem aims to
come up with treatment plans that maximize the probability of reversing these
mutations. Motivated by the severity of the problem, we develop a risk-averse
approach and formulate a scenario-based mixed-integer linear program with a
conditional value-at-risk objective function. We propose a risk-averse scenario
batch decomposition algorithm that partitions the scenarios into manageable
risk-averse subproblems, enabling the construction of lower and upper bounds.
We develop several algorithmic enhancements in the form of stronger no-good
cuts and symmetry breaking constraints in addition to scenario regrouping and
warm starting. We conduct extensive computational experiments for static and
dynamic versions of the problem on a real dataset and demonstrate the
effectiveness of our approach. Our results suggest that risk-averse solutions
can achieve significantly better worst-case performance compared to
risk-neutral solutions with a slight decrease in terms of the average
performance, especially for the dynamic version. Although our methodology is
presented in the context of the Antibiotics Time Machine Problem, it can be
adapted to other risk-averse problem settings in which the decision variables
come from special ordered sets of type one.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10733v2' target='_blank'>A CNN-Transformer for Classification of Longitudinal 3D MRI Images -- A
  Case Study on Hepatocellular Carcinoma Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jakob Nolte, Maureen M. J. Guichelaar, Donald E. Bouman, Stephanie M. van den Berg, Maryam Amir Haeri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 11:39:46</h6>
<p class='card-text'>Longitudinal MRI analysis is crucial for predicting disease outcomes,
particularly in chronic conditions like hepatocellular carcinoma (HCC), where
early detection can significantly influence treatment strategies and patient
prognosis. Yet, due to challenges like limited data availability, subtle
parenchymal changes, and the irregular timing of medical screenings, current
approaches have so far focused on cross-sectional imaging data. To address
this, we propose HCCNet, a novel model architecture that integrates a 3D
adaptation of the ConvNeXt CNN architecture with a Transformer encoder,
capturing both the intricate spatial features of 3D MRIs and the complex
temporal dependencies across different time points. HCCNet utilizes a two-stage
pre-training process tailored for longitudinal MRI data. The CNN backbone is
pre-trained using a self-supervised learning framework adapted for 3D MRIs,
while the Transformer encoder is pre-trained with a sequence-order-prediction
task to enhance its understanding of disease progression over time. We
demonstrate the effectiveness of HCCNet by applying it to a cohort of liver
cirrhosis patients undergoing regular MRI screenings for HCC surveillance. Our
results show that HCCNet significantly improves predictive accuracy and
reliability over baseline models, providing a robust tool for personalized HCC
surveillance. The methodological approach presented in this paper is versatile
and can be adapted to various longitudinal MRI screening applications. Its
ability to handle varying patient record lengths and irregular screening
intervals establishes it as an invaluable framework for monitoring chronic
diseases, where timely and accurate disease prognosis is critical for effective
treatment planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10663v1' target='_blank'>PB-NBV: Efficient Projection-Based Next-Best-View Planning Framework for
  Reconstruction of Unknown Objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhizhou Jia, Yuetao Li, Qun Hao, Shaohui Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 06:00:29</h6>
<p class='card-text'>Completely capturing the three-dimensional (3D) data of an object is
essential in industrial and robotic applications. The task of next-best-view
(NBV) planning is to calculate the next optimal viewpoint based on the current
data, gradually achieving a complete 3D reconstruction of the object. However,
many existing NBV planning algorithms incur heavy computational costs due to
the extensive use of ray-casting. Specifically, this framework refits different
types of voxel clusters into ellipsoids based on the voxel structure. Then, the
next optimal viewpoint is selected from the candidate views using a
projection-based viewpoint quality evaluation function in conjunction with a
global partitioning strategy. This process replaces extensive ray-casting,
significantly improving the computational efficiency. Comparison experiments in
the simulation environment show that our framework achieves the highest point
cloud coverage with low computational time compared to other frameworks. The
real-world experiments also confirm the efficiency and feasibility of the
framework. Our method will be made open source to benefit the community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10636v1' target='_blank'>Efficient and Safe Trajectory Planning for Autonomous Agricultural
  Vehicle Headland Turning in Cluttered Orchard Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peng Wei, Chen Peng, Wenwu Lu, Yuankai Zhu, Stavros Vougioukas, Zhenghao Fei, Zhikang Ge</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 02:43:14</h6>
<p class='card-text'>Autonomous agricultural vehicles (AAVs), including field robots and
autonomous tractors, are becoming essential in modern farming by improving
efficiency and reducing labor costs. A critical task in AAV operations is
headland turning between crop rows. This task is challenging in orchards with
limited headland space, irregular boundaries, operational constraints, and
static obstacles. While traditional trajectory planning methods work well in
arable farming, they often fail in cluttered orchard environments. This letter
presents a novel trajectory planner that enhances the safety and efficiency of
AAV headland maneuvers, leveraging advancements in autonomous driving. Our
approach includes an efficient front-end algorithm and a high-performance
back-end optimization. Applied to vehicles with various implements, it
outperforms state-of-the-art methods in both standard and challenging orchard
fields. This work bridges agricultural and autonomous driving technologies,
facilitating a broader adoption of AAVs in complex orchards.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10621v1' target='_blank'>RoMu4o: A Robotic Manipulation Unit For Orchard Operations Automating
  Proximal Hyperspectral Leaf Sensing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mehrad Mortazavi, David J. Cappelleri, Reza Ehsani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 01:04:02</h6>
<p class='card-text'>Driven by the need to address labor shortages and meet the demands of a
rapidly growing population, robotic automation has become a critical component
in precision agriculture. Leaf-level hyperspectral spectroscopy is shown to be
a powerful tool for phenotyping, monitoring crop health, identifying essential
nutrients within plants as well as detecting diseases and water stress. This
work introduces RoMu4o, a robotic manipulation unit for orchard operations
offering an automated solution for proximal hyperspectral leaf sensing. This
ground robot is equipped with a 6DOF robotic arm and vision system for
real-time deep learning-based image processing and motion planning. We
developed robust perception and manipulation pipelines that enable the robot to
successfully grasp target leaves and perform spectroscopy. These frameworks
operate synergistically to identify and extract the 3D structure of leaves from
an observed batch of foliage, propose 6D poses, and generate collision-free
constraint-aware paths for precise leaf manipulation. The end-effector of the
arm features a compact design that integrates an independent lighting source
with a hyperspectral sensor, enabling high-fidelity data acquisition while
streamlining the calibration process for accurate measurements. Our ground
robot is engineered to operate in unstructured orchard environments. However,
the performance of the system is evaluated in both indoor and outdoor plant
models. The system demonstrated reliable performance for 1-LPB hyperspectral
sampling, achieving 95% success rate in lab trials and 79% in field trials.
Field experiments revealed an overall success rate of 70% for autonomous leaf
grasping and hyperspectral measurement in a pistachio orchard. The open-source
repository is available at: https://github.com/mehradmrt/UCM-AgBot-ROS2</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10592v1' target='_blank'>Analytical Models of Frequency and Voltage in Large-Scale All-Inverter
  Power Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marena Trujillo, Amir Sajadi, Bri-Mathias Hodge</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 22:53:21</h6>
<p class='card-text'>Low-order frequency response models for power systems have a decades-long
history in optimization and control problems such as unit commitment, economic
dispatch, and wide-area control. With a few exceptions, these models are built
upon the Newtonian mechanics of synchronous generators, assuming that the
frequency dynamics across a system are approximately homogeneous, and assume
the dynamics of nodal voltages for most operating conditions are negligible,
and thus are not directly computed at all buses. As a result, the use of system
frequency models results in the systematic underestimation of frequency minimum
nadir and maximum RoCoF, and provides no insight into the reactive
power-voltage dynamics. This paper proposes a low-order model of both frequency
and voltage response in grid-forming inverter-dominated power systems. The
proposed model accounts for spatial-temporal variations in frequency and
voltage behavior across a system and as a result, demonstrates the
heterogeneity of frequency response in future renewable power systems.
Electromagnetic transient (EMT) simulations are used to validate the utility,
accuracy, and computational efficiency of these models, setting the basis for
them to serve as fast, scalable alternatives to EMT simulation, especially when
dealing with very large-scale systems, for both planning and operational
studies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10569v1' target='_blank'>Tailwind turbulence: a bound on the energy available from turbulence for
  transit, tested in Kraichnan's model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Scott A. Bollt, Gregory P. Bewley</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 21:54:50</h6>
<p class='card-text'>We investigate the unconstrained minimum energy required for vehicles to move
through turbulence. We restrict our study to vehicles that interact with their
environment through thrust, weight and drag forces, such as rotorcraft or
submersibles. For such vehicles, theory predicts an optimum ratio between
vehicle velocity and a characteristic velocity of the turbulence. The energy
required for transit can be substantially smaller than what is required to move
through quiescent fluid. We describe a simple picture for how a flight
trajectory could preferentially put vehicles in tailwinds rather than
headwinds, predicated on the organization of turbulence around vortices. This
leads to an analytical parameter-free lower bound on the energy required to
traverse a turbulent flow. We test this bound by computationally optimizing
trajectories in Kraichnan's model of turbulence, and find that the energy
required by point-models of vehicles is slightly larger than but close to our
bound. Finally, we predict the existence of an optimum level of turbulence for
which power is minimized, so that turbulence can be both too strong or too weak
to be useful. This work strengthens previous findings that environmental
turbulence can always reduce energy use. Thus, favorable trajectories are
available to maneuverable vehicles if they have sufficient knowledge of the
flow and computational resources for path planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10560v1' target='_blank'>Picachv: Formally Verified Data Use Policy Enforcement for Secure Data
  Analytics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haobin Hiroki Chen, Hongbo Chen, Mingshen Sun, Chenghong Wang, XiaoFeng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 21:30:55</h6>
<p class='card-text'>Ensuring the proper use of sensitive data in analytics under complex privacy
policies is an increasingly critical challenge. Many existing approaches lack
portability, verifiability, and scalability across diverse data processing
frameworks. We introduce Picachv, a novel security monitor that automatically
enforces data use policies. It works on relational algebra as an abstraction
for program semantics, enabling policy enforcement on query plans generated by
programs during execution. This approach simplifies analysis across diverse
analytical operations and supports various front-end query languages. By
formalizing both data use policies and relational algebra semantics in Coq, we
prove that Picachv correctly enforces policies. Picachv also leverages Trusted
Execution Environments (TEEs) to enhance trust in runtime, providing provable
policy compliance to stakeholders that the analytical tasks comply with their
data use policies. We integrated Picachv into Polars, a state-of-the-art data
analytics framework, and evaluate its performance using the TPC-H benchmark. We
also apply our approach to real-world use cases. Our work demonstrates the
practical application of formal methods in securing data analytics, addressing
key challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10535v1' target='_blank'>Lead Times in Flux: Analyzing Airbnb Booking Dynamics During Global
  Upheavals (2018-2022)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Harrison Katz, Erica Savage, Peter Coles</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 20:16:32</h6>
<p class='card-text'>Short-term shifts in booking behaviors can disrupt forecasting in the travel
and hospitality industry, especially during global crises. Traditional metrics
like average or median lead times often overlook important distribution
changes. This study introduces a normalized L1 (Manhattan) distance to assess
Airbnb booking lead time divergences from 2018 to 2022, focusing on the
COVID-19 pandemic across four major U.S. cities. We identify a two-phase
disruption: an abrupt change at the pandemic's onset followed by partial
recovery with persistent deviations from pre-2018 patterns. Our method reveals
changes in travelers' planning horizons that standard statistics miss,
highlighting the need to analyze the entire lead-time distribution for more
accurate demand forecasting and pricing strategies. The normalized L1 metric
provides valuable insights for tourism stakeholders navigating ongoing market
volatility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10236v1' target='_blank'>Actively Coupled Sensor Configuration and Planning in Unknown Dynamic
  Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Prakash Poudel, Jeffrey DesRoches, Raghvendra V. Cowlagi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 15:00:41</h6>
<p class='card-text'>We address the problem of path-planning for an autonomous mobile vehicle,
called the ego vehicle, in an unknown andtime-varying environment. The
objective is for the ego vehicle to minimize exposure to a
spatiotemporally-varying unknown scalar field called the threat field. Noisy
measurements of the threat field are provided by a network of mobile sensors.
Weaddress the problem of optimally configuring (placing) these sensors in the
environment. To this end, we propose sensor reconfiguration by maximizing a
reward function composed of three different elements. First, the reward
includes an informa tion measure that we call context-relevant mutual
information (CRMI). Unlike typical sensor placement techniques that maxi mize
mutual information of the measurements and environment state, CRMI directly
quantifies uncertainty reduction in the ego path cost while it moves in the
environment. Therefore, the CRMI introduces active coupling between the ego
vehicle and the sensor network. Second, the reward includes a penalty on the
distances traveled by the sensors. Third, the reward includes a measure of
proximity of the sensors to the ego vehicle. Although we do not consider
communication issues in this paper, such proximity is of relevance for future
work that addresses communications between the sensors and the ego vehicle. We
illustrate and analyze the proposed technique via numerical simulations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10160v1' target='_blank'>CSSDM Ontology to Enable Continuity of Care Data Interoperability</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez, Pamela Hussey</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 12:48:48</h6>
<p class='card-text'>The rapid advancement of digital technologies and recent global pandemic
scenarios have led to a growing focus on how these technologies can enhance
healthcare service delivery and workflow to address crises. Action plans that
consolidate existing digital transformation programs are being reviewed to
establish core infrastructure and foundations for sustainable healthcare
solutions. Reforming health and social care to personalize home care, for
example, can help avoid treatment in overcrowded acute hospital settings and
improve the experiences and outcomes for both healthcare professionals and
service users. In this information-intensive domain, addressing the
interoperability challenge through standards-based roadmaps is crucial for
enabling effective connections between health and social care services. This
approach facilitates safe and trustworthy data workflows between different
healthcare system providers. In this paper, we present a methodology for
extracting, transforming, and loading data through a semi-automated process
using a Common Semantic Standardized Data Model (CSSDM) to create personalized
healthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology
of ISO 13940 ContSys and incorporates FHIR-based specifications to support
structural attributes for generating KGs. We propose that the CSSDM facilitates
data harmonization and linking, offering an alternative approach to
interoperability. This approach promotes a novel form of collaboration between
companies developing health information systems and cloud-enabled health
services. Consequently, it provides multiple stakeholders with access to
high-quality data and information sharing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10141v1' target='_blank'>Enhancing UAV Path Planning Efficiency Through Accelerated Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joseanne Viana, Boris Galkin, Lester Ho, Holger Claussen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 12:05:24</h6>
<p class='card-text'>Unmanned Aerial Vehicles (UAVs) are increasingly essential in various fields
such as surveillance, reconnaissance, and telecommunications. This study aims
to develop a learning algorithm for the path planning of UAV wireless
communication relays, which can reduce storage requirements and accelerate Deep
Reinforcement Learning (DRL) convergence. Assuming the system possesses terrain
maps of the area and can estimate user locations using localization algorithms
or direct GPS reporting, it can input these parameters into the learning
algorithms to achieve optimized path planning performance. However, higher
resolution terrain maps are necessary to extract topological information such
as terrain height, object distances, and signal blockages. This requirement
increases memory and storage demands on UAVs while also lengthening convergence
times in DRL algorithms. Similarly, defining the telecommunication coverage map
in UAV wireless communication relays using these terrain maps and user position
estimations demands higher memory and storage utilization for the learning path
planning algorithms. Our approach reduces path planning training time by
applying a dimensionality reduction technique based on Principal Component
Analysis (PCA), sample combination, Prioritized Experience Replay (PER), and
the combination of Mean Squared Error (MSE) and Mean Absolute Error (MAE) loss
calculations in the coverage map estimates, thereby enhancing a Twin Delayed
Deep Deterministic Policy Gradient (TD3) algorithm. The proposed solution
reduces the convergence episodes needed for basic training by approximately
four times compared to the traditional TD3.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10114v1' target='_blank'>Infrastructure for AI Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alan Chan, Kevin Wei, Sihao Huang, Nitarshan Rajkumar, Elija Perrier, Seth Lazar, Gillian K. Hadfield, Markus Anderljung</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 10:58:12</h6>
<p class='card-text'>Increasingly many AI systems can plan and execute interactions in open-ended
environments, such as making phone calls or buying online goods. As developers
grow the space of tasks that such AI agents can accomplish, we will need tools
both to unlock their benefits and manage their risks. Current tools are largely
insufficient because they are not designed to shape how agents interact with
existing institutions (e.g., legal and economic systems) or actors (e.g.,
digital service providers, humans, other AI agents). For example, alignment
techniques by nature do not assure counterparties that some human will be held
accountable when a user instructs an agent to perform an illegal action. To
fill this gap, we propose the concept of agent infrastructure: technical
systems and shared protocols external to agents that are designed to mediate
and influence their interactions with and impacts on their environments. Agent
infrastructure comprises both new tools and reconfigurations or extensions of
existing tools. For example, to facilitate accountability, protocols that tie
users to agents could build upon existing systems for user authentication, such
as OpenID. Just as the Internet relies on infrastructure like HTTPS, we argue
that agent infrastructure will be similarly indispensable to ecosystems of
agents. We identify three functions for agent infrastructure: 1) attributing
actions, properties, and other information to specific agents, their users, or
other actors; 2) shaping agents' interactions; and 3) detecting and remedying
harmful actions from agents. We propose infrastructure that could help achieve
each function, explaining use cases, adoption, limitations, and open questions.
Making progress on agent infrastructure can prepare society for the adoption of
more advanced agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10084v1' target='_blank'>Two-level Solar Irradiance Clustering with Season Identification: A
  Comparative Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Roshni Agrawal, Sivakumar Subramanian, Venkataramana Runkana</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 10:05:11</h6>
<p class='card-text'>Solar irradiance clustering can enhance solar power capacity planning and
help improve forecasting models by identifying similar irradiance patterns
influenced by seasonal and weather changes. In this study, we adopt an
efficient two-level clustering approach to automatically identify seasons using
the clear sky irradiance in first level and subsequently to identify daily
cloud level as clear, cloudy and partly cloudy within each season in second
level. In the second level of clustering, three methods are compared, namely,
Daily Irradiance Index (DII or $\beta$), Euclidean Distance (ED), and Dynamic
Time Warping (DTW) distance. The DII is computed as the ratio of time integral
of measured irradiance to time integral of the clear sky irradiance. The
identified clusters were compared quantitatively using established clustering
metrics and qualitatively by comparing the mean irradiance profiles. The
results clearly establish the superiority of the $\beta$-based clustering
approach as the leader, setting a new benchmark for solar irradiance clustering
studies. Moreover, $\beta$-based clustering remains effective even for annual
data unlike the time-series methods which suffer significant performance
degradation. Interestingly, contrary to expectations, ED-based clustering
outperforms the more compute-intensive DTW distance-based clustering. The
method has been rigorously validated using data from two distinct US locations,
demonstrating robust scalability for larger datasets and potential
applicability for other locations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10078v1' target='_blank'>Neutrino Experiments at the Large Hadron Collider</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Akitaka Ariga, Jamie Boyd, Felix Kling, Albert De Roeck</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 09:50:13</h6>
<p class='card-text'>The proton-proton collisions at the Large Hadron Collider (LHC) produce an
intense, high-energy beam of neutrinos of all flavors, collimated in the
forward direction. Recently two dedicated neutrino experiments, FASER and
SND@LHC, have started operating to take advantage of the TeV energy LHC
neutrino beam, with first results released in 2023 and further results released
in 2024. The first detection of neutrinos produced at a particle collider opens
up a new avenue of research, allowing to study the highest energy neutrinos
produced in a controlled laboratory environment, with an associated broad and
rich physics program. Neutrino measurements at the LHC will provide important
contributions to QCD, neutrino and BSM physics, with impactful implications for
astro-particle physics. This review article summarizes the physics motivation,
status and plans of, present and future neutrino experiments at the LHC.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10074v3' target='_blank'>SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and
  Chain-of-Thought for Embodied Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuecheng Liu, Dafeng Chi, Shiguang Wu, Zhanguang Zhang, Yaochen Hu, Lingfeng Zhang, Yingxue Zhang, Shuang Wu, Tongtong Cao, Guowei Huang, Helong Huang, Guangjian Tian, Weichao Qiu, Xingyue Quan, Jianye Hao, Yuzheng Zhuang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 09:46:27</h6>
<p class='card-text'>Spatial reasoning is an essential problem in embodied AI research. Efforts to
enhance spatial reasoning abilities through supplementary spatial data and
fine-tuning have proven limited and ineffective when addressing complex
embodied tasks, largely due to their dependence on language-based outputs.
While some approaches have introduced a point-based action space to mitigate
this issue, they fall short in managing more intricate tasks within complex
environments. This deficiency arises from their failure to fully exploit the
inherent thinking and reasoning capabilities that are fundamental strengths of
Vision-Language Models (VLMs). To address these limitations, we propose a novel
approach named SpatialCoT, specifically designed to bolster the spatial
reasoning capabilities of VLMs. Our approach comprises two stages: spatial
coordinate bi-directional alignment, which aligns vision-language inputs with
spatial coordinates, and chain-of-thought spatial grounding, which harnesses
the reasoning capabilities of language models for advanced spatial reasoning.
We evaluate SpatialCoT on challenging navigation and manipulation tasks, both
in simulation and real-world settings. Experimental results demonstrate that
our method significantly outperforms previous state-of-the-art approaches in
both tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09944v1' target='_blank'>Minimum-Time Sequential Traversal by a Team of Small Unmanned Aerial
  Vehicles in an Unknown Environment with Winds</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jeffrey A. DesRoches, Raghvendra V. Cowlagi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 03:52:54</h6>
<p class='card-text'>We consider the problem of transporting multiple packages from an initial
location to a destination location in a windy urban environment using a team of
SUAVs. Each SUAV carries one package. We assume that the wind field is unknown,
but wind speed can be measured by SUAVs during flight. The SUAVs fly
sequentially one after the other, measure wind speeds along their trajectories,
and report the measurements to a central computer. The overall objective is to
minimize the total travel time of all SUAVs, which is in turn related to the
number of SUAV traversals through the environment. For a discretized
environment modeled by a graph, we describe a method to estimate wind speeds
and the time of traversal for each SUAV path. Each SUAV traverses a
minimum-time path planned based on the current wind field estimate. We study
cases of static and time-varying wind fields with and without measurement
noise. For each case, we demonstrate via numerical simulation that the proposed
method finds the optimal path after a minimal number of traversals.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09832v1' target='_blank'>Crossover-BPSO Driven Multi-Agent Technology for Managing Local Energy
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hafiz Majid Hussain, Ashfaq Ahmad. Pedro H. J. Nardelli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 20:41:00</h6>
<p class='card-text'>This article presents a new hybrid algorithm, crossover binary particle swarm
optimization (crBPSO), for allocating resources in local energy systems via
multi-agent (MA) technology. Initially, a hierarchical MA-based architecture in
a grid-connected local energy setup is presented. In this architecture, task
specific agents operate in a master-slave manner. Where, the master runs a
well-formulated optimization routine aiming at minimizing costs of energy
procurement, battery degradation, and load scheduling delay. The slaves update
the master on their current status and receive optimal action plans
accordingly. Simulation results demonstrate that the proposed algorithm
outperforms selected existing ones by 21\% in terms average energy system costs
while satisfying customers' energy demand and maintaining the required quality
of service.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09803v1' target='_blank'>Graph Neural Networks for Travel Distance Estimation and Route
  Recommendation Under Probabilistic Hazards</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tong Liu, Hadi Meidani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 19:22:50</h6>
<p class='card-text'>Estimating the shortest travel time and providing route recommendation
between different locations in a city or region can quantitatively measure the
conditions of the transportation network during or after extreme events. One
common approach is to use Dijkstra's Algorithm, which produces the shortest
path as well as the shortest distance. However, this option is computationally
expensive when applied to large-scale networks. This paper proposes a novel
fast framework based on graph neural networks (GNNs) which approximate the
single-source shortest distance between pairs of locations, and predict the
single-source shortest path subsequently. We conduct multiple experiments on
synthetic graphs of different size to demonstrate the feasibility and
computational efficiency of the proposed model. In real-world case studies, we
also applied the proposed method of flood risk analysis of coastal urban areas
to calculate delays in evacuation to public shelters during hurricanes. The
results indicate the accuracy and computational efficiency of the GNN model,
and its potential for effective implementation in emergency planning and
management.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09783v1' target='_blank'>GeoManip: Geometric Constraints as General Interfaces for Robot
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiliang Tang, Jia-Hui Pan, Yun-Hui Liu, Masayoshi Tomizuka, Li Erran Li, Chi-Wing Fu, Mingyu Ding</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 18:59:51</h6>
<p class='card-text'>We present GeoManip, a framework to enable generalist robots to leverage
essential conditions derived from object and part relationships, as geometric
constraints, for robot manipulation. For example, cutting the carrot requires
adhering to a geometric constraint: the blade of the knife should be
perpendicular to the carrot's direction. By interpreting these constraints
through symbolic language representations and translating them into low-level
actions, GeoManip bridges the gap between natural language and robotic
execution, enabling greater generalizability across diverse even unseen tasks,
objects, and scenarios. Unlike vision-language-action models that require
extensive training, operates training-free by utilizing large foundational
models: a constraint generation module that predicts stage-specific geometric
constraints and a geometry parser that identifies object parts involved in
these constraints. A solver then optimizes trajectories to satisfy inferred
constraints from task descriptions and the scene. Furthermore, GeoManip learns
in-context and provides five appealing human-robot interaction features:
on-the-fly policy adaptation, learning from human demonstrations, learning from
failure cases, long-horizon action planning, and efficient data collection for
imitation learning. Extensive evaluations on both simulations and real-world
scenarios demonstrate GeoManip's state-of-the-art performance, with superior
out-of-distribution generalization while avoiding costly model training.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09685v2' target='_blank'>Inference-Time Alignment in Diffusion Models with Reward-Guided
  Generation: Tutorial and Review</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Masatoshi Uehara, Yulai Zhao, Chenyu Wang, Xiner Li, Aviv Regev, Sergey Levine, Tommaso Biancalani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 17:37:35</h6>
<p class='card-text'>This tutorial provides an in-depth guide on inference-time guidance and
alignment methods for optimizing downstream reward functions in diffusion
models. While diffusion models are renowned for their generative modeling
capabilities, practical applications in fields such as biology often require
sample generation that maximizes specific metrics (e.g., stability, affinity in
proteins, closeness to target structures). In these scenarios, diffusion models
can be adapted not only to generate realistic samples but also to explicitly
maximize desired measures at inference time without fine-tuning. This tutorial
explores the foundational aspects of such inference-time algorithms. We review
these methods from a unified perspective, demonstrating that current techniques
-- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling,
and classifier guidance -- aim to approximate soft optimal denoising processes
(a.k.a. policies in RL) that combine pre-trained denoising processes with value
functions serving as look-ahead functions that predict from intermediate states
to terminal rewards. Within this framework, we present several novel algorithms
not yet covered in the literature. Furthermore, we discuss (1) fine-tuning
methods combined with inference-time techniques, (2) inference-time algorithms
based on search algorithms such as Monte Carlo tree search, which have received
limited attention in current research, and (3) connections between
inference-time algorithms in language models and diffusion models. The code of
this tutorial on protein design is available at
https://github.com/masa-ue/AlignInversePro</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09649v1' target='_blank'>Monte Carlo Tree Search with Velocity Obstacles for safe and efficient
  motion planning in dynamic environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lorenzo Bonanni, Daniele Meli, Alberto Castellini, Alessandro Farinelli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 16:45:08</h6>
<p class='card-text'>Online motion planning is a challenging problem for intelligent robots moving
in dense environments with dynamic obstacles, e.g., crowds. In this work, we
propose a novel approach for optimal and safe online motion planning with
minimal information about dynamic obstacles. Specifically, our approach
requires only the current position of the obstacles and their maximum speed,
but it does not need any information about their exact trajectories or dynamic
model. The proposed methodology combines Monte Carlo Tree Search (MCTS), for
online optimal planning via model simulations, with Velocity Obstacles (VO),
for obstacle avoidance. We perform experiments in a cluttered simulated
environment with walls, and up to 40 dynamic obstacles moving with random
velocities and directions. With an ablation study, we show the key contribution
of VO in scaling up the efficiency of MCTS, selecting the safest and most
rewarding actions in the tree of simulations. Moreover, we show the superiority
of our methodology with respect to state-of-the-art planners, including
Non-linear Model Predictive Control (NMPC), in terms of improved collision
rate, computational and task performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09632v1' target='_blank'>Platform-Aware Mission Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stefan Panjkovic, Alessandro Cimatti, Andrea Micheli, Stefano Tonetta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 16:20:37</h6>
<p class='card-text'>Planning for autonomous systems typically requires reasoning with models at
different levels of abstraction, and the harmonization of two competing sets of
objectives: high-level mission goals that refer to an interaction of the system
with the external environment, and low-level platform constraints that aim to
preserve the integrity and the correct interaction of the subsystems. The
complicated interplay between these two models makes it very hard to reason on
the system as a whole, especially when the objective is to find plans with
robustness guarantees, considering the non-deterministic behavior of the lower
layers of the system.
  In this paper, we introduce the problem of Platform-Aware Mission Planning
(PAMP), addressing it in the setting of temporal durative actions. The PAMP
problem differs from standard temporal planning for its exists-forall nature:
the high-level plan dealing with mission goals is required to satisfy safety
and executability constraints, for all the possible non-deterministic
executions of the low-level model of the platform and the environment. We
propose two approaches for solving PAMP. The first baseline approach
amalgamates the mission and platform levels, while the second is based on an
abstraction-refinement loop that leverages the combination of a planner and a
verification engine. We prove the soundness and completeness of the proposed
approaches and validate them experimentally, demonstrating the importance of
heterogeneous modeling and the superiority of the technique based on
abstraction-refinement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09484v1' target='_blank'>Exploring the Inquiry-Diagnosis Relationship with Advanced Patient
  Simulators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaocheng Liu, Quan Tu, Wen Ye, Yu Xiao, Zhishou Zhang, Hengfu Cui, Yalun Zhu, Qiang Ju, Shizheng Li, Jian Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 11:41:14</h6>
<p class='card-text'>Online medical consultation (OMC) restricts doctors to gathering patient
information solely through inquiries, making the already complex sequential
decision-making process of diagnosis even more challenging. Recently, the rapid
advancement of large language models has demonstrated a significant potential
to transform OMC. However, most studies have primarily focused on improving
diagnostic accuracy under conditions of relatively sufficient information,
while paying limited attention to the "inquiry" phase of the consultation
process. This lack of focus has left the relationship between "inquiry" and
"diagnosis" insufficiently explored. In this paper, we first extract real
patient interaction strategies from authentic doctor-patient conversations and
use these strategies to guide the training of a patient simulator that closely
mirrors real-world behavior. By inputting medical records into our patient
simulator to simulate patient responses, we conduct extensive experiments to
explore the relationship between "inquiry" and "diagnosis" in the consultation
process. Experimental results demonstrate that inquiry and diagnosis adhere to
the Liebig's law: poor inquiry quality limits the effectiveness of diagnosis,
regardless of diagnostic capability, and vice versa. Furthermore, the
experiments reveal significant differences in the inquiry performance of
various models. To investigate this phenomenon, we categorize the inquiry
process into four types: (1) chief complaint inquiry; (2) specification of
known symptoms; (3) inquiry about accompanying symptoms; and (4) gathering
family or medical history. We analyze the distribution of inquiries across the
four types for different models to explore the reasons behind their significant
performance differences. We plan to open-source the weights and related code of
our patient simulator at https://github.com/LIO-H-ZEN/PatientSimulator.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09479v1' target='_blank'>Connectivity for AI enabled cities -- A field survey based study of
  emerging economies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dibakar Das, Jyotsna Bapat, Angeliki Katsenou, Sushmita Shrestha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 11:31:39</h6>
<p class='card-text'>The impact of Artificial Intelligence (AI) is transforming various aspects of
urban life, including, governance, policy and planning, healthcare,
sustainability, economics, entrepreneurship, etc. Although AI immense potential
for positively impacting urban living, its success depends on overcoming
significant challenges, particularly in telecommunications infrastructure.
Smart city applications, such as, federated learning, Internet of Things (IoT),
and online financial services, require reliable Quality of Service (QoS) from
telecommunications networks to ensure effective information transfer. However,
with over three billion people underserved or lacking access to internet, many
of these AI-driven applications are at risk of either remaining underutilized
or failing altogether. Furthermore, many IoT and video-based applications in
densely populated urban areas require high-quality connectivity. This paper
explores these issues, focusing on the challenges that need to be mitigated to
make AI succeed in emerging countries, where more than 80% of the world
population resides and urban migration grows. In this context, an overview of a
case study conducted in Kathmandu, Nepal, highlights citizens' aspirations for
affordable, high-quality internet-based services. The findings underscore the
pressing need for advanced telecommunication networks to meet diverse user
requirements while addressing investment and infrastructure gaps. This
discussion provides insights into bridging the digital divide and enabling AI's
transformative potential in urban areas.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09469v1' target='_blank'>Predicting Air Temperature from Volumetric Urban Morphology with Machine
  Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Berk Kıvılcım, Patrick Erik Bradley</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 11:10:38</h6>
<p class='card-text'>In this study, we firstly introduce a method that converts CityGML data into
voxels which works efficiently and fast in high resolution for large scale
datasets such as cities but by sacrificing some building details to overcome
the limitations of previous voxelization methodologies that have been
computationally intensive and inefficient at transforming large-scale urban
areas into voxel representations for high resolution. Those voxelized 3D city
data from multiple cities and corresponding air temperature data are used to
develop a machine learning model. Before the model training, Gaussian blurring
is implemented on input data to consider spatial relationships, as a result the
correlation rate between air temperature and volumetric building morphology is
also increased after the Gaussian blurring. After the model training, the
prediction results are not just evaluated with Mean Square Error (MSE) but some
image similarity metrics such as Structural Similarity Index Measure (SSIM) and
Learned Perceptual Image Patch Similarity (LPIPS) that are able to detect and
consider spatial relations during the evaluation process. This trained model is
capable of predicting the spatial distribution of air temperature by using
building volume information of corresponding pixel as input. By doing so, this
research aims to assist urban planners in incorporating environmental
parameters into their planning strategies, thereby facilitating more
sustainable and inhabitable urban environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09468v2' target='_blank'>Sensorimotor Control Strategies for Tactile Robotics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Enrico Donato, Matteo Lo Preti, Lucia Beccai, Egidio Falotico</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 11:10:10</h6>
<p class='card-text'>How are robots becoming smarter at interacting with their surroundings?
Recent advances have reshaped how robots use tactile sensing to perceive and
engage with the world. Tactile sensing is a game-changer, allowing robots to
embed sensorimotor control strategies to interact with complex environments and
skillfully handle heterogeneous objects. Such control frameworks plan
contact-driven motions while staying responsive to sudden changes. We review
the latest methods for building perception and control systems in tactile
robotics while offering practical guidelines for their design and
implementation. We also address key challenges to shape the future of
intelligent robots.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09450v1' target='_blank'>Real-Time Generation of Near-Minimum-Energy Trajectories via
  Constraint-Informed Residual Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Domenico Dona', Giovanni Franzese, Cosimo Della Santina, Paolo Boscariol, Basilio Lenzo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 10:25:24</h6>
<p class='card-text'>Industrial robotics demands significant energy to operate, making
energy-reduction methodologies increasingly important. Strategies for planning
minimum-energy trajectories typically involve solving nonlinear optimal control
problems (OCPs), which rarely cope with real-time requirements. In this paper,
we propose a paradigm for generating near minimum-energy trajectories for
manipulators by learning from optimal solutions. Our paradigm leverages a
residual learning approach, which embeds boundary conditions while focusing on
learning only the adjustments needed to steer a standard solution to an optimal
one. Compared to a computationally expensive OCP-based planner, our paradigm
achieves 87.3% of the performance near the training dataset and 50.8% far from
the dataset, while being two to three orders of magnitude faster.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09407v1' target='_blank'>NEBULA: A National Scale Dataset for Neighbourhood-Level Urban Building
  Energy Modelling for England and Wales</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Grace Colverd, Ronita Bardhan, Jonathan Cullen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 09:26:17</h6>
<p class='card-text'>Buildings are significant contributors to global greenhouse gas emissions,
accounting for 26% of global energy sector emissions in 2022. Meeting net zero
goals requires a rapid reduction in building emissions, both directly from the
buildings and indirectly from the production of electricity and heat used in
buildings. National energy planning for net zero demands both detailed and
comprehensive building energy consumption data. However, geo-located
building-level energy data is rarely available in Europe, with analysis
typically relying on anonymised, simulated or low-resolution data. To address
this problem, we introduce a dataset of Neighbourhood Energy, Buildings, and
Urban Landscapes (NEBULA) for modelling domestic energy consumption for small
neighbourhoods (5-150 households). NEBULA integrates data on building
characteristics, climate, urbanisation, environment, and socio-demographics and
contains 609,964 samples across England and Wales.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09357v1' target='_blank'>Path Planning for a UAV Swarm Using Formation Teaching-Learning-Based
  Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Van Truong Hoang, Manh Duong Phung</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 08:08:42</h6>
<p class='card-text'>This work addresses the path planning problem for a group of unmanned aerial
vehicles (UAVs) to maintain a desired formation during operation. Our approach
formulates the problem as an optimization task by defining a set of fitness
functions that not only ensure the formation but also include constraints for
optimal and safe UAV operation. To optimize the fitness function and obtain a
suboptimal path, we employ the teaching-learning-based optimization algorithm
and then further enhance it with mechanisms such as mutation, elite strategy,
and multi-subject combination. A number of simulations and experiments have
been conducted to evaluate the proposed method. The results demonstrate that
the algorithm successfully generates valid paths for the UAVs to fly in a
triangular formation for an inspection task.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09338v1' target='_blank'>Robust UAV Path Planning with Obstacle Avoidance for Emergency Rescue</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junteng Mao, Ziye Jia, Hanzhi Gu, Chenyu Shi, Haomin Shi, Lijun He, Qihui Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 07:38:56</h6>
<p class='card-text'>The unmanned aerial vehicles (UAVs) are efficient tools for diverse tasks
such as electronic reconnaissance, agricultural operations and disaster relief.
In the complex three-dimensional (3D) environments, the path planning with
obstacle avoidance for UAVs is a significant issue for security assurance. In
this paper, we construct a comprehensive 3D scenario with obstacles and no-fly
zones for dynamic UAV trajectory. Moreover, a novel artificial potential field
algorithm coupled with simulated annealing (APF-SA) is proposed to tackle the
robust path planning problem. APF-SA modifies the attractive and repulsive
potential functions and leverages simulated annealing to escape local minimum
and converge to globally optimal solutions. Simulation results demonstrate that
the effectiveness of APF-SA, enabling efficient autonomous path planning for
UAVs with obstacle avoidance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09290v1' target='_blank'>Interoceptive Robots for Convergent Shared Control in Collaborative
  Construction Work</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaoshan Zhou, Carol C. Menassa, Vineet R. Kamat</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 04:50:15</h6>
<p class='card-text'>Building autonomous mobile robots (AMRs) with optimized efficiency and
adaptive capabilities-able to respond to changing task demands and dynamic
environments-is a strongly desired goal for advancing construction robotics.
Such robots can play a critical role in enabling automation, reducing
operational carbon footprints, and supporting modular construction processes.
Inspired by the adaptive autonomy of living organisms, we introduce
interoception, which centers on the robot's internal state representation, as a
foundation for developing self-reflection and conscious learning to enable
continual learning and adaptability in robotic agents. In this paper, we
factorize internal state variables and mathematical properties as "cognitive
dissonance" in shared control paradigms, where human interventions occasionally
occur. We offer a new perspective on how interoception can help build adaptive
motion planning in AMRs by integrating the legacy of heuristic costs from
grid/graph-based algorithms with recent advances in neuroscience and
reinforcement learning. Declarative and procedural knowledge extracted from
human semantic inputs is encoded into a hypergraph model that overlaps with the
spatial configuration of onsite layout for path planning. In addition, we
design a velocity-replay module using an encoder-decoder architecture with
few-shot learning to enable robots to replicate velocity profiles in
contextualized scenarios for multi-robot synchronization and handover
collaboration. These "cached" knowledge representations are demonstrated in
simulated environments for multi-robot motion planning and stacking tasks. The
insights from this study pave the way toward artificial general intelligence in
AMRs, fostering their progression from complexity to competence in construction
automation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09249v1' target='_blank'>A Dynamic Unmanned Aerial Vehicle Routing Framework for Urban Traffic
  Monitoring</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yumeng Bai, Yiheng Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 02:20:25</h6>
<p class='card-text'>Unmanned Aerial Vehicles (UAVs) have great potential in urban traffic
monitoring due to their rapid speed, cost-effectiveness, and extensive
field-of-view, while being unconstrained by traffic congestion. However, their
limited flight duration presents critical challenges in sustainable recharging
strategies and efficient route planning in long-term monitoring tasks.
Additionally, existing approaches for long-term monitoring often neglect the
evolving nature of urban traffic networks. In this study, we introduce a novel
dynamic UAV routing framework for long-term, network-wide urban traffic
monitoring, leveraging existing ground vehicles as mobile charging stations
without disrupting their operations. To address the complexity of long-term
monitoring scenarios involving multiple flights, we decompose the problem into
manageable single-flight tasks, in which each flight is modeled as a Team Arc
Orienteering Problem with Decreasing Profits with the objective to collectively
maximize the spatiotemporal network coverage. Between flights, we adaptively
update the edge weights to incorporate real-time traffic changes and revisit
intervals. We validate our framework through extensive microscopic simulations
in a modified Sioux Falls network under various scenarios. Comparative results
demonstrate that our model outperforms three baseline approaches, especially
when historical information is incomplete or absent. Moreover, we show that our
monitoring framework can capture network-wide traffic trends and construct
accurate Macroscopic Fundamental Diagrams (MFDs). These findings demonstrate
the effectiveness of the proposed dynamic UAV routing framework, underscoring
its suitability for efficient and reliable long-term traffic monitoring. Our
approach's adaptability and high accuracy in capturing the MFD highlight its
potential in network-wide traffic control and management applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00020v2' target='_blank'>Temporal Reasoning in AI systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhishek Sharma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 23:47:50</h6>
<p class='card-text'>Commonsense temporal reasoning at scale is a core problem for cognitive
systems. The correct inference of the duration for which fluents hold is
required by many tasks, including natural language understanding and planning.
Many AI systems have limited deductive closure because they cannot extrapolate
information correctly regarding existing fluents and events. In this study, we
discuss the knowledge representation and reasoning schemes required for robust
temporal projection in the Cyc Knowledge Base. We discuss how events can start
and end risk periods for fluents. We then use discrete survival functions,
which represent knowledge of the persistence of facts, to extrapolate a given
fluent. The extrapolated intervals can be truncated by temporal constraints and
other types of commonsense knowledge. Finally, we present the results of
experiments to demonstrate that these methods obtain significant improvements
in terms of Q/A performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09198v1' target='_blank'>Combining Movement Primitives with Contraction Theory</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Moses C. Nah, Johannes Lachner, Neville Hogan, Jean-Jacques Slotine</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 23:12:38</h6>
<p class='card-text'>This paper presents a modular framework for motion planning using movement
primitives. Central to the approach is Contraction Theory, a modular stability
tool for nonlinear dynamical systems. The approach extends prior methods by
achieving parallel and sequential combinations of both discrete and rhythmic
movements, while enabling independent modulation of each movement. This modular
framework enables a divide-and-conquer strategy to simplify the programming of
complex robot motion planning. Simulation examples illustrate the flexibility
and versatility of the framework, highlighting its potential to address diverse
challenges in robot motion planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09192v1' target='_blank'>Estimation-Aware Trajectory Optimization with Set-Valued Measurement
  Uncertainties</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aditya Deole, Mehran Mesbahi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 22:50:02</h6>
<p class='card-text'>In this paper, we present an optimization-based framework for generating
estimation-aware trajectories in scenarios where measurement (output)
uncertainties are state-dependent and set-valued. The framework leverages the
concept of regularity for set-valued output maps. Specifically, we demonstrate
that, for output-regular maps, one can utilize a set-valued observability
measure that is concave with respect to finite-horizon state trajectories. By
maximizing this measure, optimized estimation-aware trajectories can be
designed for a broad class of systems, including those with locally linearized
dynamics. To illustrate the effectiveness of the proposed approach, we provide
a representative example in the context of trajectory planning for vision-based
estimation. We present an estimation-aware trajectory for an uncooperative
target-tracking problem that uses a machine learning (ML)-based estimation
module on an ego-satellite.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09168v1' target='_blank'>JERALD: high-fidelity dark matter, stellar mass and neutral hydrogen
  maps from fast N-body simulations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mauro Rigo, Roberto Trotta, Matteo Viel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 21:38:17</h6>
<p class='card-text'>We present a new code and approach, JERALD -- JAX Enhanced Resolution
Approximate Lagrangian Dynamics -- , that improves on and extends the
Lagrangian Deep Learning method of Dai & Seljak (2021), producing
high-resolution dark matter, stellar mass and neutral hydrogen maps from
lower-resolution approximate $N$-body simulations. The model is trained using
the Sherwood-Relics simulation suite (for a fixed cosmology), specifically
designed for the intergalactic medium and the neutral hydrogen distribution in
the cosmic web. The output is tested in the redshift range from $z=5$ to $z=0$
and the generalization properties of the learned mapping is demonstrated.
JERALD produces maps with dark matter, stellar and neutral hydrogen power
spectra in excellent agreement with full-hydrodynamic simulations with
$8\times$ higher resolution, at large and intermediate scales; in particular,
JERALD's neutral hydrogen power spectra agree with their higher-resolution
full-hydrodynamic counterparts within 90% up to $k\simeq1\,h$Mpc$^{-1}$ and
within 70% up to $k\simeq10\,h$Mpc$^{-1}$. JERALD provides a fast, accurate and
physically motivated approach that we plan to embed in a statistical inference
pipeline, such as Simulation-Based Inference, to constrain dark matter
properties from large- to intermediate-scale structure observables.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09081v1' target='_blank'>Inferring Transition Dynamics from Value Functions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jacob Adamczyk</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 19:00:47</h6>
<p class='card-text'>In reinforcement learning, the value function is typically trained to solve
the Bellman equation, which connects the current value to future values. This
temporal dependency hints that the value function may contain implicit
information about the environment's transition dynamics. By rearranging the
Bellman equation, we show that a converged value function encodes a model of
the underlying dynamics of the environment. We build on this insight to propose
a simple method for inferring dynamics models directly from the value function,
potentially mitigating the need for explicit model learning. Furthermore, we
explore the challenges of next-state identifiability, discussing conditions
under which the inferred dynamics model is well-defined. Our work provides a
theoretical foundation for leveraging value functions in dynamics modeling and
opens a new avenue for bridging model-free and model-based reinforcement
learning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09080v1' target='_blank'>Average-Reward Reinforcement Learning with Entropy Regularization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jacob Adamczyk, Volodymyr Makarenko, Stas Tiomkin, Rahul V. Kulkarni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 19:00:46</h6>
<p class='card-text'>The average-reward formulation of reinforcement learning (RL) has drawn
increased interest in recent years due to its ability to solve
temporally-extended problems without discounting. Independently, RL algorithms
have benefited from entropy-regularization: an approach used to make the
optimal policy stochastic, thereby more robust to noise. Despite the distinct
benefits of the two approaches, the combination of entropy regularization with
an average-reward objective is not well-studied in the literature and there has
been limited development of algorithms for this setting. To address this gap in
the field, we develop algorithms for solving entropy-regularized average-reward
RL problems with function approximation. We experimentally validate our method,
comparing it with existing algorithms on standard benchmarks for RL.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09770v1' target='_blank'>EVAL: EigenVector-based Average-reward Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jacob Adamczyk, Volodymyr Makarenko, Stas Tiomkin, Rahul V. Kulkarni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 19:00:45</h6>
<p class='card-text'>In reinforcement learning, two objective functions have been developed
extensively in the literature: discounted and averaged rewards. The
generalization to an entropy-regularized setting has led to improved robustness
and exploration for both of these objectives. Recently, the entropy-regularized
average-reward problem was addressed using tools from large deviation theory in
the tabular setting. This method has the advantage of linearity, providing
access to both the optimal policy and average reward-rate through properties of
a single matrix. In this paper, we extend that framework to more general
settings by developing approaches based on function approximation by neural
networks. This formulation reveals new theoretical insights into the
relationship between different objectives used in RL. Additionally, we combine
our algorithm with a posterior policy iteration scheme, showing how our
approach can also solve the average-reward RL problem without
entropy-regularization. Using classic control benchmarks, we experimentally
find that our method compares favorably with other algorithms in terms of
stability and rate of convergence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08963v1' target='_blank'>Training-Aware Risk Control for Intensity Modulated Radiation Therapies
  Quality Assurance with Conformal Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kevin He, David Adam, Sarah Han-Oh, Anqi Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 17:19:51</h6>
<p class='card-text'>Measurement quality assurance (QA) practices play a key role in the safe use
of Intensity Modulated Radiation Therapies (IMRT) for cancer treatment. These
practices have reduced measurement-based IMRT QA failure below 1%. However,
these practices are time and labor intensive which can lead to delays in
patient care. In this study, we examine how conformal prediction methodologies
can be used to robustly triage plans. We propose a new training-aware conformal
risk control method by combining the benefit of conformal risk control and
conformal training. We incorporate the decision making thresholds based on the
gamma passing rate, along with the risk functions used in clinical evaluation,
into the design of the risk control framework. Our method achieves high
sensitivity and specificity and significantly reduces the number of plans
needing measurement without generating a huge confidence interval. Our results
demonstrate the validity and applicability of conformal prediction methods for
improving efficiency and reducing the workload of the IMRT QA process.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08918v1' target='_blank'>Efficient Planning in Large-scale Systems Using Hierarchical Finite
  State Machines</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Elis Stefansson, Karl H. Johansson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 16:23:04</h6>
<p class='card-text'>We consider optimal planning in a large-scale system formalised as a
hierarchical finite state machine (HFSM). A planning algorithm is proposed
computing an optimal plan between any two states in the HFSM, consisting of two
steps: A pre-processing step that computes optimal exit costs of the machines
in the HFSM, with time complexity scaling with the number of machines; and a
query step that efficiently computes an optimal plan by removing irrelevant
subtrees of the HFSM using the optimal exit costs. The algorithm is
reconfigurable in the sense that changes in the HFSM are handled with ease,
where the pre-processing step recomputes only the optimal exit costs affected
by the change. The algorithm can also exploit compact representations that
groups together identical machines in the HFSM, where the algorithm only needs
to compute the optimal exit costs for one of the identical machines within each
group, thereby avoid unnecessary recomputations. We validate the algorithm on
large systems with millions of states and a robotic application. It is shown
that our approach outperforms Dijkstra's algorithm, Bidirectional Dijkstra and
Contraction Hierarchies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08861v1' target='_blank'>Generative Planning with 3D-vision Language Pre-training for End-to-End
  Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tengpeng Li, Hanli Wang, Xianfei Li, Wenlong Liao, Tao He, Pai Peng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 15:20:46</h6>
<p class='card-text'>Autonomous driving is a challenging task that requires perceiving and
understanding the surrounding environment for safe trajectory planning. While
existing vision-based end-to-end models have achieved promising results, these
methods are still facing the challenges of vision understanding, decision
reasoning and scene generalization. To solve these issues, a generative
planning with 3D-vision language pre-training model named GPVL is proposed for
end-to-end autonomous driving. The proposed paradigm has two significant
aspects. On one hand, a 3D-vision language pre-training module is designed to
bridge the gap between visual perception and linguistic understanding in the
bird's eye view. On the other hand, a cross-modal language model is introduced
to generate holistic driving decisions and fine-grained trajectories with
perception and navigation information in an auto-regressive manner. Experiments
on the challenging nuScenes dataset demonstrate that the proposed scheme
achieves excellent performances compared with state-of-the-art methods.
Besides, the proposed GPVL presents strong generalization ability and real-time
potential when handling high-level commands in various scenarios. It is
believed that the effective, robust and efficient performance of GPVL is
crucial for the practical application of future autonomous driving systems.
Code is available at https://github.com/ltp1995/GPVL</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08848v1' target='_blank'>RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Carlos Güemes-Palau, Miquel Ferriol-Galmés, Jordi Paillisse-Vilanova, Albert López-Brescó, Pere Barlet-Ros, Albert Cabellos-Aparicio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 15:00:11</h6>
<p class='card-text'>Network simulation is pivotal in network modeling, assisting with tasks
ranging from capacity planning to performance estimation. Traditional
approaches such as Discrete Event Simulation (DES) face limitations in terms of
computational cost and accuracy. This paper introduces RouteNet-Gauss, a novel
integration of a testbed network with a Machine Learning (ML) model to address
these challenges. By using the testbed as a hardware accelerator,
RouteNet-Gauss generates training datasets rapidly and simulates network
scenarios with high fidelity to real-world conditions. Experimental results
show that RouteNet-Gauss significantly reduces prediction errors by up to 95%
and achieves a 488x speedup in inference time compared to state-of-the-art
DES-based methods. RouteNet-Gauss's modular architecture is dynamically
constructed based on the specific characteristics of the network scenario, such
as topology and routing. This enables it to understand and generalize to
different network configurations beyond those seen during training, including
networks up to 10x larger. Additionally, it supports Temporal Aggregated
Performance Estimation (TAPE), providing configurable temporal granularity and
maintaining high accuracy in flow performance metrics. This approach shows
promise in improving both simulation efficiency and accuracy, offering a
valuable tool for network operators.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08808v1' target='_blank'>A Bayesian Hierarchical Model for Generating Synthetic Unbalanced Power
  Distribution Grids</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Henrique O. Caetano, Rahul K. Gupta, Marco Aiello, Carlos Dias Maciel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 14:03:42</h6>
<p class='card-text'>The real-world data of power networks is often inaccessible due to privacy
and security concerns, highlighting the need for tools to generate realistic
synthetic network data. Existing methods leverage geographic tools like
OpenStreetMap with heuristic rules to model system topology and typically focus
on single-phase, balanced systems, limiting their applicability to real-world
distribution systems, which are usually unbalanced. This work proposes a
Bayesian Hierarchical Model (BHM) to generate unbalanced three-phase
distribution systems learning from existing networks. The scheme takes as input
the base topology and aggregated demand per node and outputs a three-phase
unbalanced system. The proposed scheme achieves a Mean Absolute Percentage
Error (MAPE) of less than $8\%$ across all phases, with computation times of
20.4 seconds for model training and 3.1 seconds per sample generation. The tool
is applied to learn from publicly available SMART-DS dataset and applied to
generate European 906 and IEEE-123 systems. We demonstrate the transfer
learning capability of the proposed tool by leveraging a model trained on an
observed system to generate a synthetic network for an unobserved system.
Specifically, the tool is trained using the publicly available SMART-DS dataset
and subsequently applied to generate synthetic networks for the European
906-bus system and the IEEE 123-bus system. This tool allows researchers to
simulate realistic unbalanced three-phase power data with high accuracy and
speed, enhancing planning and operational analysis for modern power grids.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08765v1' target='_blank'>Designing and evaluating advanced adaptive randomised clinical trials: a
  practical guide</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anders Granholm, Aksel Karl Georg Jensen, Theis Lange, Anders Perner, Morten Hylander Møller, Benjamin Skov Kaas-Hansen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 12:39:24</h6>
<p class='card-text'>Background
  Advanced adaptive randomised clinical trials are increasingly used. Compared
to their conventional counterparts, their flexibility may make them more
efficient, increase the probability of obtaining conclusive results without
larger samples than necessary, and increase the probability that individual
participants are allocated to more promising interventions. However, limited
guidance is available on designing and evaluating the performance of advanced
adaptive trials.
  Methods
  We summarise the methodological considerations and provide practical guidance
on the entire workflow of planning and evaluating advanced adaptive trials
using adaptive stopping, adaptive arm dropping, and response-adaptive
randomisation within a Bayesian statistical framework.
  Results
  This comprehensive practical guide covers the key methodological decisions
for advanced adaptive trials and their specification and evaluation using
statistical simulation. These considerations include interventions and common
control use; outcome type and generation; analysis timing and outcome-data lag;
allocation rules; analysis model; adaptation rules for stopping and arm
dropping; clinical scenarios assessed; performance metrics; calibration;
sensitivity analyses; and reporting. The considerations are covered in the
context of realistic examples, along with simulation code using the adaptr R
package.
  Conclusions
  This practical guide will help clinical trialists, methodologists, and
biostatisticians design and evaluate advanced adaptive trials.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08591v1' target='_blank'>OpenMLDB: A Real-Time Relational Data Feature Computation System for
  Online ML</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuanhe Zhou, Wei Zhou, Liguo Qi, Hao Zhang, Dihao Chen, Bingsheng He, Mian Lu, Guoliang Li, Fan Wu, Yuqiang Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 05:20:01</h6>
<p class='card-text'>Efficient and consistent feature computation is crucial for a wide range of
online ML applications. Typically, feature computation is divided into two
distinct phases, i.e., offline stage for model training and online stage for
model serving. These phases often rely on execution engines with different
interface languages and function implementations, causing significant
inconsistencies. Moreover, many online ML features involve complex time-series
computations (e.g., functions over varied-length table windows) that differ
from standard streaming and analytical queries. Existing data processing
systems (e.g., Spark, Flink, DuckDB) often incur multi-second latencies for
these computations, making them unsuitable for real-time online ML applications
that demand timely feature updates.
  This paper presents OpenMLDB, a feature computation system deployed in
4Paradigm's SageOne platform and over 100 real scenarios. Technically, OpenMLDB
first employs a unified query plan generator for consistent computation results
across the offline and online stages, significantly reducing feature deployment
overhead. Second, OpenMLDB provides an online execution engine that resolves
performance bottlenecks caused by long window computations (via
pre-aggregation) and multi-table window unions (via data self-adjusting). It
also provides a high-performance offline execution engine with window parallel
optimization and time-aware data skew resolving. Third, OpenMLDB features a
compact data format and stream-focused indexing to maximize memory usage and
accelerate data access. Evaluations in testing and real workloads reveal
significant performance improvements and resource savings compared to the
baseline systems. The open community of OpenMLDB now has over 150 contributors
and gained 1.6k stars on GitHub.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08573v1' target='_blank'>Effects of taxes, redistribution actions and fiscal evasion on wealth
  inequality: an agent-based model approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Iago Nascimento Barros, Marcelo Lobato Martins</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 04:46:38</h6>
<p class='card-text'>In capitalist societies, only a single right can be fully exerted without
constraints of any kind: the limitless accumulation of wealth. Such imperative
or prime axiom is the ultimate cause of the raising waves of inequalities
observed today. In this work we extended the agent-based model proposed by
Castro de Oliveira arXiv:1711.06164 to study the effects of non-uniform income
redistribution policies and tax evasion on the final steady-state wealth
distribution of economic agents. Our simulational results strongly support that
well designed policies of income redistribution and rigid control of tax
planning possibilities are unavoidable instruments to promote the raise of more
economically egalitarian and sustainable societies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08548v1' target='_blank'>LAMOST medium-resolution spectroscopic survey of Galactic Open Clusters
  (LAMOST-MRS-O): An overview of survey plan and preliminary results</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xi Zhang, Chengzhi Liu, Jing Zhong, Li Chen, Ali Luo, Jian-Rong Shi, Chao Liu, JianJun Chen, Haotong Zhang, Jinliang Hou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 03:17:20</h6>
<p class='card-text'>As part of the LAMOST medium-resolution spectroscopic survey, the
LAMOST-MRS-O is a non-time domain survey that aims to perform medium-resolution
spectral observations for member stars in the open cluster area. This survey
plans to obtain the spectroscopic parameters such as radial velocity and metal
abundances of member stars and provide data support for further study on the
chemical and dynamical characteristics and evolution of open clusters in
combination with Gaia data. We have completed the observations on ten open
cluster fields and obtained 235184 medium-resolution spectra of 133792 stars.
Based on the data analyzed of LAMOST DR11V1.1, for some clusters of particular
concern, it is found that the sampling ratio of members stars with Gmag < 15
mag can reach 70%, which indicates that the LAMOST-MRS-O has reached our
initial design goal.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17867v1' target='_blank'>Low-Thrust Many-Revolution Trajectory Design Under Operational
  Uncertainties for DESTINY+ Mission</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Naoya Ozaki, Yuki Akiyama, Akira Hatakeyama, Shota Ito, Takuya Chikazawa, Takayuki Yamamoto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 01:26:37</h6>
<p class='card-text'>DESTINY+ is a planned JAXA medium-class Epsilon mission from Earth to deep
space using a low-thrust, many-revolution orbit. Such a trajectory design is a
challenging problem not only for trajectory design but also for flight
operations, and in particular, it is essential to evaluate the impact of
operational uncertainties to ensure mission success. In this study, we design
the low-thrust trajectory from Earth orbit to a lunar transfer orbit by
differential dynamic programming using the Sundman transformation. The results
of Monte Carlo simulations with operational uncertainties confirm that the
spacecraft can be successfully guided to the lunar transfer orbit by using the
feedback control law of differential dynamic programming in the angular domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08507v1' target='_blank'>A Framework for Dynamic Situational Awareness in Human Robot Teams: An
  Interview Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hashini Senaratne, Leimin Tian, Pavan Sikka, Jason Williams, David Howard, Dana Kulić, Cécile Paris</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 01:09:11</h6>
<p class='card-text'>In human-robot teams, human situational awareness is the operator's conscious
knowledge of the team's states, actions, plans and their environment.
Appropriate human situational awareness is critical to successful human-robot
collaboration. In human-robot teaming, it is often assumed that the best and
required level of situational awareness is knowing everything at all times.
This view is problematic, because what a human needs to know for optimal team
performance varies given the dynamic environmental conditions, task context and
roles and capabilities of team members. We explore this topic by interviewing
16 participants with active and repeated experience in diverse human-robot
teaming applications. Based on analysis of these interviews, we derive a
framework explaining the dynamic nature of required situational awareness in
human-robot teaming. In addition, we identify a range of factors affecting the
dynamic nature of required and actual levels of situational awareness (i.e.,
dynamic situational awareness), types of situational awareness inefficiencies
resulting from gaps between actual and required situational awareness, and
their main consequences. We also reveal various strategies, initiated by humans
and robots, that assist in maintaining the required situational awareness. Our
findings inform the implementation of accurate estimates of dynamic situational
awareness and the design of user-adaptive human-robot interfaces. Therefore,
this work contributes to the future design of more collaborative and effective
human-robot teams.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10456v1' target='_blank'>Planning sustainable carbon neutrality pathways: accounting challenges
  experienced by organizations and solutions from industrial ecology</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anne de Bortoli, Anders Bjorn, Francois Saunier, Manuele Margni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 22:00:23</h6>
<p class='card-text'>Purpose : Planning a transition towards sustainable carbon neutrality at the
organization level raises several accounting challenges. This paper aims to
shed light on key challenges, highlight answers from current accounting
standards and guidance, point out potential inconsistencies or limits, and
outline potential solutions from the industrial ecology community through
systemic environmental assessment tools, such as life cycle assessment (LCA)
and environmentally-extended input-output (EEIO) analysis.
  Results and discussion: We propose a Measure-Reduce-Neutralize-Control
sequence allowing organizations to plan their sustainable net-zero strategy,
and discuss 24 accounting challenges occurring within this sequence. We then
outline ways forward for organizations planning their carbon neutrality
trajectory, pointing to existing resources, and for guidelines providers and
the industrial ecology communities to address current limitations in the
development of future accounting methods and guidelines. Overarching solutions
to many accounting issues are to develop comprehensive, open-source, and
high-quality life cycle inventory databases, to enable improved dynamic
assessments and prospective LCA through integrated assessment models, to refine
methods for assessing mineral scarcity and environmental impacts, the supply in
some metals being expected to be a bottleneck to the energy transition, and to
identify the appropriate climate metrics for planning sustainable carbon
neutrality pathways at the organizational level.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08226v1' target='_blank'>Efficient Deep Learning-based Forward Solvers for Brain Tumor Growth
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeineb Haouari, Jonas Weidner, Ivan Ezhov, Aswathi Varma, Daniel Rueckert, Bjoern Menze, Benedikt Wiestler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 16:10:25</h6>
<p class='card-text'>Glioblastoma, a highly aggressive brain tumor, poses major challenges due to
its poor prognosis and high morbidity rates. Partial differential
equation-based models offer promising potential to enhance therapeutic outcomes
by simulating patient-specific tumor behavior for improved radiotherapy
planning. However, model calibration remains a bottleneck due to the high
computational demands of optimization methods like Monte Carlo sampling and
evolutionary algorithms. To address this, we recently introduced an approach
leveraging a neural forward solver with gradient-based optimization to
significantly reduce calibration time. This approach requires a highly accurate
and fully differentiable forward model. We investigate multiple architectures,
including (i) an enhanced TumorSurrogate, (ii) a modified nnU-Net, and (iii) a
3D Vision Transformer (ViT). The optimized TumorSurrogate achieved the best
overall results, excelling in both tumor outline matching and voxel-level
prediction of tumor cell concentration. It halved the MSE relative to the
baseline model and achieved the highest Dice score across all tumor cell
concentration thresholds. Our study demonstrates significant enhancement in
forward solver performance and outlines important future research directions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08222v1' target='_blank'>Data-driven Spatial Classification using Multi-Arm Bandits for
  Monitoring with Energy-Constrained Mobile Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaoshan Lin, Siddharth Nayak, Stefano Di Cairano, Abraham P. Vinod</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 16:05:32</h6>
<p class='card-text'>We consider the spatial classification problem for monitoring using data
collected by a coordinated team of mobile robots. Such classification problems
arise in several applications including search-and-rescue and precision
agriculture. Specifically, we want to classify the regions of a search
environment into interesting and uninteresting as quickly as possible using a
team of mobile sensors and mobile charging stations. We develop a data-driven
strategy that accommodates the noise in sensed data and the limited energy
capacity of the sensors, and generates collision-free motion plans for the
team. We propose a bi-level approach, where a high-level planner leverages a
multi-armed bandit framework to determine the potential regions of interest for
the drones to visit next based on the data collected online. Then, a low-level
path planner based on integer programming coordinates the paths for the team to
visit the target regions subject to the physical constraints. We characterize
several theoretical properties of the proposed approach, including anytime
guarantees and task completion time. We show the efficacy of our approach in
simulation, and further validate these observations in physical experiments
using mobile robots.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08220v1' target='_blank'>Optimization of Link Configuration for Satellite Communication Using
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tobias Rohe, Michael Kölle, Jan Matheis, Rüdiger Höpfl, Leo Sünkel, Claudia Linnhoff-Popien</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 16:04:46</h6>
<p class='card-text'>Satellite communication is a key technology in our modern connected world.
With increasingly complex hardware, one challenge is to efficiently configure
links (connections) on a satellite transponder. Planning an optimal link
configuration is extremely complex and depends on many parameters and metrics.
The optimal use of the limited resources, bandwidth and power of the
transponder is crucial. Such an optimization problem can be approximated using
metaheuristic methods such as simulated annealing, but recent research results
also show that reinforcement learning can achieve comparable or even better
performance in optimization methods. However, there have not yet been any
studies on link configuration on satellite transponders. In order to close this
research gap, a transponder environment was developed as part of this work. For
this environment, the performance of the reinforcement learning algorithm PPO
was compared with the metaheuristic simulated annealing in two experiments. The
results show that Simulated Annealing delivers better results for this static
problem than the PPO algorithm, however, the research in turn also underlines
the potential of reinforcement learning for optimization problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08076v1' target='_blank'>Reflection-dominated Compton-thick AGN Candidates in the SRG/eROSITA
  Lockman Hole Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:M. I. Belvedersky, S. D. Bykov, M. R. Gilfanov, P. S. Medvedev, R. A. Sunyaev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 12:42:56</h6>
<p class='card-text'>We search for reflection-dominated Compton-thick active galactic nuclei (CT
AGN) candidates in the Lockman Hole region using the data of SRG/eROSITA
Lockman Hole survey. We selected sources with anomalously hard photon indices
in the $0.3 - 8.0$ keV band, untypical for type I AGN. In particular, we
required that the upper end of the $90\%$ error interval did not exceed a
fiducial boundary of $\Gamma=1.3$. We found 291 sources which constitute a rare
subpopulation among extragalactic X-ray sources detected by eROSITA in the
Lockman Hole field, $\approx 5\%$. These sources constitute the eROSITA sample
of CT AGN candidates in the Lockman Hole field. We further divide the sources
into three categories depending on the availability of reliable redshift and
statistically significant detection of intrinsic absorption. We present two
catalogues: the bright sample (37 sources) and the faint one (254). We estimate
the fraction and sky density of reflection-dominated CT AGN candidates. We show
examples of individual spectra and use stacking analysis to search for possible
redshift evolution of their properties with redshift. We analyse combined
eROSITA spectra of bright sources of different categories with a physically
motivated spectral model UXCLUMPY and find them fully consistent with the fits
to the about $\sim 1$ Msec XMM-Newton data for one of our reflection-dominated
CT candidates, Type 2 galaxy $\text{SRGe J105348.6+573032}$. The catalogues of
CT AGN candidates could be a good starting point for planning future studies
and follow-ups at all wavelengths.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08020v1' target='_blank'>Cooperative Patrol Routing: Optimizing Urban Crime Surveillance through
  Multi-Agent Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Juan Palma-Borda, Eduardo Guzmán, María-Victoria Belmonte</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 11:20:19</h6>
<p class='card-text'>The effective design of patrol strategies is a difficult and complex problem,
especially in medium and large areas. The objective is to plan, in a
coordinated manner, the optimal routes for a set of patrols in a given area, in
order to achieve maximum coverage of the area, while also trying to minimize
the number of patrols. In this paper, we propose a multi-agent reinforcement
learning (MARL) model, based on a decentralized partially observable Markov
decision process, to plan unpredictable patrol routes within an urban
environment represented as an undirected graph. The model attempts to maximize
a target function that characterizes the environment within a given time frame.
Our model has been tested to optimize police patrol routes in three
medium-sized districts of the city of Malaga. The aim was to maximize
surveillance coverage of the most crime-prone areas, based on actual crime data
in the city. To address this problem, several MARL algorithms have been
studied, and among these the Value Decomposition Proximal Policy Optimization
(VDPPO) algorithm exhibited the best performance. We also introduce a novel
metric, the coverage index, for the evaluation of the coverage performance of
the routes generated by our model. This metric is inspired by the predictive
accuracy index (PAI), which is commonly used in criminology to detect hotspots.
Using this metric, we have evaluated the model under various scenarios in which
the number of agents (or patrols), their starting positions, and the level of
information they can observe in the environment have been modified. Results
show that the coordinated routes generated by our model achieve a coverage of
more than $90\%$ of the $3\%$ of graph nodes with the highest crime incidence,
and $65\%$ for $20\%$ of these nodes; $3\%$ and $20\%$ represent the coverage
standards for police resource allocation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07984v1' target='_blank'>Threshold Attention Network for Semantic Segmentation of Remote Sensing
  Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Long, Yongjun Zhang, Zhongwei Cui, Yujie Xu, Xuexue Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 10:09:55</h6>
<p class='card-text'>Semantic segmentation of remote sensing images is essential for various
applications, including vegetation monitoring, disaster management, and urban
planning. Previous studies have demonstrated that the self-attention mechanism
(SA) is an effective approach for designing segmentation networks that can
capture long-range pixel dependencies. SA enables the network to model the
global dependencies between the input features, resulting in improved
segmentation outcomes. However, the high density of attentional feature maps
used in this mechanism causes exponential increases in computational
complexity. Additionally, it introduces redundant information that negatively
impacts the feature representation. Inspired by traditional threshold
segmentation algorithms, we propose a novel threshold attention mechanism
(TAM). This mechanism significantly reduces computational effort while also
better modeling the correlation between different regions of the feature map.
Based on TAM, we present a threshold attention network (TANet) for semantic
segmentation. TANet consists of an attentional feature enhancement module
(AFEM) for global feature enhancement of shallow features and a threshold
attention pyramid pooling module (TAPP) for acquiring feature information at
different scales for deep features. We have conducted extensive experiments on
the ISPRS Vaihingen and Potsdam datasets. The results demonstrate the validity
and superiority of our proposed TANet compared to the most state-of-the-art
models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07913v2' target='_blank'>Governing AI Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Noam Kolt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 07:55:18</h6>
<p class='card-text'>The field of AI is undergoing a fundamental transition from generative models
that can produce synthetic content to artificial agents that can plan and
execute complex tasks with only limited human involvement. Companies that
pioneered the development of language models have now built AI agents that can
independently navigate the internet, perform a wide range of online tasks, and
increasingly serve as AI personal assistants and virtual coworkers. The
opportunities presented by this new technology are tremendous, as are the
associated risks. Fortunately, there exist robust analytic frameworks for
confronting many of these challenges, namely, the economic theory of
principal-agent problems and the common law doctrine of agency relationships.
Drawing on these frameworks, this Article makes three contributions. First, it
uses agency law and theory to identify and characterize problems arising from
AI agents, including issues of information asymmetry, discretionary authority,
and loyalty. Second, it illustrates the limitations of conventional solutions
to agency problems: incentive design, monitoring, and enforcement might not be
effective for governing AI agents that make uninterpretable decisions and
operate at unprecedented speed and scale. Third, the Article explores the
implications of agency law and theory for designing and regulating AI agents,
arguing that new technical and legal infrastructure is needed to support
governance principles of inclusivity, visibility, and liability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07881v1' target='_blank'>An Approach on the Modelling of Long Economic Cycles in the Context of
  Sustainable Development</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cristina Tanasescu, Amelia Bucur, Camelia Oprean-Stan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 06:43:08</h6>
<p class='card-text'>One of the themes that have been approached more and more within the
specialised literature is being represented by economic cycles. The analysis of
these is very useful in the long term predictions, in finding solutions for the
economic raise and for detecting the economic crisis. At the same time, it is
underlined in a lot of scientific and research papers, the importance of the
sustainable development in the present and future society. In this paper we
intend to bring contributions to the study of the cycles of a sustainable
economy and we will analyse it having in mind the purpose of creating the
sustainable economy. We will demonstrate the fact that curves that represent
graphically all these, are not simple logistics anymore, bi-logistics or
multilogistics curves, but curves in plan that are obtained by composing
logistics functions with the function of the sustainable development or with
the function that shapes the economic component of it mathematically. We will
present an interpretation of mathematic models within the frame of the
sustainable development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07789v1' target='_blank'>Using Statistical Precision Medicine to Identify Optimal Treatments in a
  Heart Failure Setting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arti Virkud, Jessie K. Edwards, Michele Jonsson Funk, Patricia Chang, Abhijit V. Kshirsagar, Emily W. Gower, Michael R. Kosorok</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 02:14:14</h6>
<p class='card-text'>Identifying optimal medical treatments to improve survival has long been a
critical goal of pharmacoepidemiology. Traditionally, we use an average
treatment effect measure to compare outcomes between treatment plans. However,
new methods leveraging advantages of machine learning combined with the
foundational tenets of causal inference are offering an alternative to the
average treatment effect. Here, we use three unique, precision medicine
algorithms (random forests, residual weighted learning, efficient augmentation
relaxed learning) to identify optimal treatment rules where patients receive
the optimal treatment as indicated by their clinical history. First, we present
a simple hypothetical example and a real-world application among heart failure
patients using Medicare claims data. We next demonstrate how the optimal
treatment rule improves the absolute risk in a hypothetical, three-modifier
setting. Finally, we identify an optimal treatment rule that optimizes the time
to outcome in a real-world heart failure setting. In both examples, we compare
the average time to death under the optimized, tailored treatment rule with the
average time to death under a universal treatment rule to show the benefit of
precision medicine methods. The improvement under the optimal treatment rule in
the real-world setting is greatest (additional ~9 days under the tailored rule)
for survival time free of heart failure readmission.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07468v2' target='_blank'>From Screens to Scenes: A Survey of Embodied AI in Healthcare</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 16:35:52</h6>
<p class='card-text'>Healthcare systems worldwide face persistent challenges in efficiency,
accessibility, and personalization. Powered by modern AI technologies such as
multimodal large language models and world models, Embodied AI (EmAI)
represents a transformative frontier, offering enhanced autonomy and the
ability to interact with the physical world to address these challenges. As an
interdisciplinary and rapidly evolving research domain, "EmAI in healthcare"
spans diverse fields such as algorithms, robotics, and biomedicine. This
complexity underscores the importance of timely reviews and analyses to track
advancements, address challenges, and foster cross-disciplinary collaboration.
In this paper, we provide a comprehensive overview of the "brain" of EmAI for
healthcare, wherein we introduce foundational AI algorithms for perception,
actuation, planning, and memory, and focus on presenting the healthcare
applications spanning clinical interventions, daily care & companionship,
infrastructure support, and biomedical research. Despite its promise, the
development of EmAI for healthcare is hindered by critical challenges such as
safety concerns, gaps between simulation platforms and real-world applications,
the absence of standardized benchmarks, and uneven progress across
interdisciplinary domains. We discuss the technical barriers and explore
ethical considerations, offering a forward-looking perspective on the future of
EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI
systems is also introduced to guide further development. By providing
systematic insights, this work aims to inspire innovation and practical
applications, paving the way for a new era of intelligent, patient-centered
healthcare.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07392v1' target='_blank'>The Essentials of AI for Life and Society: An AI Literacy Course for the
  University Community</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joydeep Biswas, Don Fussell, Peter Stone, Kristin Patterson, Kristen Procko, Lea Sabatini, Zifan Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 15:08:32</h6>
<p class='card-text'>We describe the development of a one-credit course to promote AI literacy at
The University of Texas at Austin. In response to a call for the rapid
deployment of class to serve a broad audience in Fall of 2023, we designed a
14-week seminar-style course that incorporated an interdisciplinary group of
speakers who lectured on topics ranging from the fundamentals of AI to societal
concerns including disinformation and employment. University students, faculty,
and staff, and even community members outside of the University, were invited
to enroll in this online offering: The Essentials of AI for Life and Society.
We collected feedback from course participants through weekly reflections and a
final survey. Satisfyingly, we found that attendees reported gains in their AI
literacy. We sought critical feedback through quantitative and qualitative
analysis, which uncovered challenges in designing a course for this general
audience. We utilized the course feedback to design a three-credit version of
the course that is being offered in Fall of 2024. The lessons we learned and
our plans for this new iteration may serve as a guide to instructors designing
AI courses for a broad audience.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07343v1' target='_blank'>Fast-Revisit Coverage Path Planning for Autonomous Mobile Patrol Robots
  Using Long-Range Sensor Information</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Srinivas Kachavarapu, Tobias Doernbach, Reinhard Gerndt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 13:57:37</h6>
<p class='card-text'>The utilization of Unmanned Ground Vehicles (UGVs) for patrolling industrial
sites has expanded significantly. These UGVs typically are equipped with
perception systems, e.g., computer vision, with limited range due to sensor
limitations or site topology. High-level control of the UGVs requires Coverage
Path Planning (CPP) algorithms that navigate all relevant waypoints and
promptly start the next cycle. In this paper, we propose the novel Fast-Revisit
Coverage Path Planning (FaRe-CPP) algorithm using a greedy heuristic approach
to propose waypoints for maximum coverage area and a random search-based path
optimization technique to obtain a path along the proposed waypoints with
minimum revisit time. We evaluated the algorithm in a simulated environment
using Gazebo and a camera-equipped TurtleBot3 against a number of existing
algorithms. Compared to their average revisit times and path lengths, our
FaRe-CPP algorithm approximately showed a 45% and 40% reduction, respectively,
in these highly relevant performance indicators.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07203v1' target='_blank'>Integrated Wind Farm Design: Optimizing Turbine Placement and Cable
  Routing with Wake Effects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jaap Pedersen, Niels Lindner, Daniel Rehfeldt, Thorsten Koch</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 10:56:23</h6>
<p class='card-text'>An accelerated deployment of renewable energy sources is crucial for a
successful transformation of the current energy system, with wind energy
playing a key role in this transition. This study addresses the integrated wind
farm layout and cable routing problem, a challenging nonlinear optimization
problem. We model this problem as an extended version of the Quota Steiner Tree
Problem (QSTP), optimizing turbine placement and network connectivity
simultaneously to meet specified expansion targets. Our proposed approach
accounts for the wake effect - a region of reduced wind speed induced by each
installed turbine - and enforces minimum spacing between turbines. We introduce
an exact solution framework in terms of the novel Quota Steiner Tree Problem
with interference (QSTPI). By leveraging an interference-based splitting
strategy, we develop an advanced solver capable of tackling large-scale problem
instances. The presented approach outperforms generic state-of-the-art mixed
integer programming solvers on our dataset by up to two orders of magnitude.
Moreover, we demonstrate that our integrated method significantly reduces the
costs in contrast to a sequential approach. Thus, we provide a planning tool
that enhances existing planning methodologies for supporting a faster and
cost-efficient expansion of wind energy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07196v1' target='_blank'>Crowdsourced human-based computational approach for tagging peripheral
  blood smear sample images from Sickle Cell Disease patients using non-expert
  users</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:José María Buades Rubio, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Nataša Petrović</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 10:42:55</h6>
<p class='card-text'>In this paper, we present a human-based computation approach for the analysis
of peripheral blood smear (PBS) images images in patients with Sickle Cell
Disease (SCD). We used the Mechanical Turk microtask market to crowdsource the
labeling of PBS images. We then use the expert-tagged erythrocytesIDB dataset
to assess the accuracy and reliability of our proposal. Our results showed that
when a robust consensus is achieved among the Mechanical Turk workers,
probability of error is very low, based on comparison with expert analysis.
This suggests that our proposed approach can be used to annotate datasets of
PBS images, which can then be used to train automated methods for the diagnosis
of SCD. In future work, we plan to explore the potential integration of our
findings with outcomes obtained through automated methodologies. This could
lead to the development of more accurate and reliable methods for the diagnosis
of SCD</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07157v1' target='_blank'>CureGraph: Contrastive Multi-Modal Graph Representation Learning for
  Urban Living Circle Health Profiling and Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinlin Li, Xiao Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 09:30:38</h6>
<p class='card-text'>The early detection and prediction of health status decline among the elderly
at the neighborhood level are of great significance for urban planning and
public health policymaking. While existing studies affirm the connection
between living environments and health outcomes, most rely on single data
modalities or simplistic feature concatenation of multi-modal information,
limiting their ability to comprehensively profile the health-oriented urban
environments. To fill this gap, we propose CureGraph, a contrastive multi-modal
representation learning framework for urban health prediction that employs
graph-based techniques to infer the prevalence of common chronic diseases among
the elderly within the urban living circles of each neighborhood. CureGraph
leverages rich multi-modal information, including photos and textual reviews of
residential areas and their surrounding points of interest, to generate urban
neighborhood embeddings. By integrating pre-trained visual and textual encoders
with graph modeling techniques, CureGraph captures cross-modal spatial
dependencies, offering a comprehensive understanding of urban environments
tailored to elderly health considerations. Extensive experiments on real-world
datasets demonstrate that CureGraph improves the best baseline by $28\%$ on
average in terms of $R^2$ across elderly disease risk prediction tasks.
Moreover, the model enables the identification of stage-wise chronic disease
progression and supports comparative public health analysis across
neighborhoods, offering actionable insights for sustainable urban development
and enhanced quality of life. The code is publicly available at
https://github.com/jinlin2021/CureGraph.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07016v1' target='_blank'>A Multi-Modal Deep Learning Framework for Pan-Cancer Prognosis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Binyu Zhang, Shichao Li, Junpeng Jian, Zhu Meng, Limei Guo, Zhicheng Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 02:29:42</h6>
<p class='card-text'>Prognostic task is of great importance as it closely related to the survival
analysis of patients, the optimization of treatment plans and the allocation of
resources. The existing prognostic models have shown promising results on
specific datasets, but there are limitations in two aspects. On the one hand,
they merely explore certain types of modal data, such as patient histopathology
WSI and gene expression analysis. On the other hand, they adopt the
per-cancer-per-model paradigm, which means the trained models can only predict
the prognostic effect of a single type of cancer, resulting in weak
generalization ability. In this paper, a deep-learning based model, named
UMPSNet, is proposed. Specifically, to comprehensively understand the condition
of patients, in addition to constructing encoders for histopathology images and
genomic expression profiles respectively, UMPSNet further integrates four types
of important meta data (demographic information, cancer type information,
treatment protocols, and diagnosis results) into text templates, and then
introduces a text encoder to extract textual features. In addition, the optimal
transport OT-based attention mechanism is utilized to align and fuse features
of different modalities. Furthermore, a guided soft mixture of experts (GMoE)
mechanism is introduced to effectively address the issue of distribution
differences among multiple cancer datasets. By incorporating the multi-modality
of patient data and joint training, UMPSNet outperforms all SOTA approaches,
and moreover, it demonstrates the effectiveness and generalization ability of
the proposed learning paradigm of a single model for multiple cancer types. The
code of UMPSNet is available at https://github.com/binging512/UMPSNet.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06938v1' target='_blank'>Evaluating unsupervised contrastive learning framework for MRI sequences
  classification</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuli Wang, Kritika Iyer, Sep Farhand, Yoshihisa Shinagawa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-12 21:30:44</h6>
<p class='card-text'>The automatic identification of Magnetic Resonance Imaging (MRI) sequences
can streamline clinical workflows by reducing the time radiologists spend
manually sorting and identifying sequences, thereby enabling faster diagnosis
and treatment planning for patients. However, the lack of standardization in
the parameters of MRI scans poses challenges for automated systems and
complicates the generation and utilization of datasets for machine learning
research. To address this issue, we propose a system for MRI sequence
identification using an unsupervised contrastive deep learning framework. By
training a convolutional neural network based on the ResNet-18 architecture,
our system classifies nine common MRI sequence types as a 9-class
classification problem. The network was trained using an in-house internal
dataset and validated on several public datasets, including BraTS, ADNI, Fused
Radiology-Pathology Prostate Dataset, the Breast Cancer Dataset (ACRIN), among
others, encompassing diverse acquisition protocols and requiring only 2D slices
for training. Our system achieves a classification accuracy of over 0.95 across
the nine most common MRI sequence types.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06904v1' target='_blank'>From Simulation to Field: Learning Terrain Traversability for Real-World
  Deployment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fetullah Atas, Grzegorz Cielniak, Lars Grimstad</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-12 19:05:44</h6>
<p class='card-text'>The challenge of traversability estimation is a crucial aspect of autonomous
navigation in unstructured outdoor environments such as forests. It involves
determining whether certain areas are passable or risky for robots, taking into
account factors like terrain irregularities, slopes, and potential obstacles.
The majority of current methods for traversability estimation operate on the
assumption of an offline computation, overlooking the significant influence of
the robot's heading direction on accurate traversability estimates. In this
work, we introduce a deep neural network that uses detailed geometric
environmental data together with the robot's recent movement characteristics.
This fusion enables the generation of robot direction awareness and continuous
traversability estimates, essential for enhancing robot autonomy in challenging
terrains like dense forests. The efficacy and significance of our approach are
underscored by experiments conducted on both simulated and real robotic
platforms in various environments, yielding quantitatively superior performance
results compared to existing methods. Moreover, we demonstrate that our method,
trained exclusively in a high-fidelity simulated setting, can accurately
predict traversability in real-world applications without any real data
collection. Our experiments showcase the advantages of our method for
optimizing path-planning and exploration tasks within difficult outdoor
environments, underscoring its practicality for effective, real-world robotic
navigation. In the spirit of collaborative advancement, we have made the code
implementation available to the public.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06897v1' target='_blank'>ActiveGAMER: Active GAussian Mapping through Efficient Rendering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liyan Chen, Huangying Zhan, Kevin Chen, Xiangyu Xu, Qingan Yan, Changjiang Cai, Yi Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-12 18:38:51</h6>
<p class='card-text'>We introduce ActiveGAMER, an active mapping system that utilizes 3D Gaussian
Splatting (3DGS) to achieve high-quality, real-time scene mapping and
exploration. Unlike traditional NeRF-based methods, which are computationally
demanding and restrict active mapping performance, our approach leverages the
efficient rendering capabilities of 3DGS, allowing effective and efficient
exploration in complex environments. The core of our system is a
rendering-based information gain module that dynamically identifies the most
informative viewpoints for next-best-view planning, enhancing both geometric
and photometric reconstruction accuracy. ActiveGAMER also integrates a
carefully balanced framework, combining coarse-to-fine exploration,
post-refinement, and a global-local keyframe selection strategy to maximize
reconstruction completeness and fidelity. Our system autonomously explores and
reconstructs environments with state-of-the-art geometric and photometric
accuracy and completeness, significantly surpassing existing approaches in both
aspects. Extensive evaluations on benchmark datasets such as Replica and MP3D
highlight ActiveGAMER's effectiveness in active mapping tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06757v2' target='_blank'>OptiCarVis: Improving Automated Vehicle Functionality Visualizations
  Using Bayesian Optimization to Enhance User Experience</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pascal Jansen, Mark Colley, Svenja Krauß, Daniel Hirschle, Enrico Rukzio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-12 09:25:10</h6>
<p class='card-text'>Automated vehicle (AV) acceptance relies on their understanding via feedback.
While visualizations aim to enhance user understanding of AV's detection,
prediction, and planning functionalities, establishing an optimal design is
challenging. Traditional "one-size-fits-all" designs might be unsuitable,
stemming from resource-intensive empirical evaluations. This paper introduces
OptiCarVis, a set of Human-in-the-Loop (HITL) approaches using Multi-Objective
Bayesian Optimization (MOBO) to optimize AV feedback visualizations. We compare
conditions using eight expert and user-customized designs for a Warm-Start HITL
MOBO. An online study (N=117) demonstrates OptiCarVis's efficacy in
significantly improving trust, acceptance, perceived safety, and predictability
without increasing cognitive load. OptiCarVis facilitates a comprehensive
design space exploration, enhancing in-vehicle interfaces for optimal passenger
experiences and broader applicability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06719v1' target='_blank'>Hierarchical Sampling-based Planner with LTL Constraints and Text
  Prompting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jingzhan Ge, Zi-Hao Zhang, Sheng-En Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-12 05:09:20</h6>
<p class='card-text'>This project introduces a hierarchical planner integrating Linear Temporal
Logic (LTL) constraints with natural language prompting for robot motion
planning. The framework decomposes maps into regions, generates directed
graphs, and converts them into transition systems for high-level planning. Text
instructions are translated into LTL formulas and converted to Deterministic
Finite Automata (DFA) for sequential goal-reaching tasks while adhering to
safety constraints. High-level plans, derived via Breadth-First Search (BFS),
guide low-level planners like Exploring Random Trees (RRT) and Probabilistic
Roadmaps (PRM) for obstacle-avoidant navigation along with LTL tasks. The
approach demonstrates adaptability to various task complexities, though
challenges such as graph construction overhead and suboptimal path generation
remain. Future directions include extending to considering terrain conditions
and incorporating higher-order dynamics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06702v1' target='_blank'>Tagging ultra-boosted jets at FCC-hh using machine learning techniques</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sanchari Bhattacharyya, Biplob Bhattacherjee, Camellia Bose, Debtosh Chowdhury, Swagata Mukherjee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-12 03:50:06</h6>
<p class='card-text'>The Future Circular Hadron Collider (FCC-hh) will probe unprecedented energy
regimes, enabling direct searches for new elementary particles at a scale of
tens of TeV. FCC-hh is currently in the planning stage, and one of its primary
physics goals is to search for physics beyond the Standard Model by exploring a
previously inaccessible kinematic domain. While venturing into uncharted
high-energy territories promises excitement, reconstructing objects with
enormous transverse momenta will require overcoming major experimental
challenges. This work investigates the identification of boosted $W$ bosons and
boosted top quarks in the context of three beyond the Standard Model scenarios:
heavy vector-like quark ($B'$), heavy neutral gauge boson ($Z'$), and heavy
neutral Higgs boson ($H$). We employ machine learning techniques, including
eXtreme Gradient Boosting (XGBoost) and convolutional neural networks (CNN), to
identify these ultra-boosted objects in the collider from their SM background
counterpart. We evaluate the performance of these techniques in distinguishing
$W$ jets and top jets from QCD jets at extremely high transverse momenta
($p_{T}$) values, demonstrating their potential for future FCC-hh analyses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06651v1' target='_blank'>Parking Space Detection in the City of Granada</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Crespo-Orti Luis, Moreno-Cuadrado Isabel, Olivares-Martínez Pablo, Sanz-Tornero Ximo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-11 22:29:12</h6>
<p class='card-text'>This paper addresses the challenge of parking space detection in urban areas,
focusing on the city of Granada. Utilizing aerial imagery, we develop and apply
semantic segmentation techniques to accurately identify parked cars, moving
cars and roads. A significant aspect of our research is the creation of a
proprietary dataset specific to Granada, which is instrumental in training our
neural network model. We employ Fully Convolutional Networks, Pyramid Networks
and Dilated Convolutions, demonstrating their effectiveness in urban semantic
segmentation. Our approach involves comparative analysis and optimization of
various models, including Dynamic U-Net, PSPNet and DeepLabV3+, tailored for
the segmentation of aerial images. The study includes a thorough
experimentation phase, using datasets such as UDD5 and UAVid, alongside our
custom Granada dataset. We evaluate our models using metrics like Foreground
Accuracy, Dice Coefficient and Jaccard Index. Our results indicate that
DeepLabV3+ offers the most promising performance. We conclude with future
directions, emphasizing the need for a dedicated neural network for parked car
detection and the potential for application in other urban environments. This
work contributes to the fields of urban planning and traffic management,
providing insights into efficient utilization of parking spaces through
advanced image processing techniques.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06639v1' target='_blank'>Enhancing Path Planning Performance through Image Representation
  Learning of High-Dimensional Configuration Spaces</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jorge Ocampo Jimenez, Wael Suleiman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-11 21:14:52</h6>
<p class='card-text'>This paper presents a novel method for accelerating path-planning tasks in
unknown scenes with obstacles by utilizing Wasserstein Generative Adversarial
Networks (WGANs) with Gradient Penalty (GP) to approximate the distribution of
waypoints for a collision-free path using the Rapidly-exploring Random Tree
algorithm. Our approach involves conditioning the WGAN-GP with a forward
diffusion process in a continuous latent space to handle multimodal datasets
effectively. We also propose encoding the waypoints of a collision-free path as
a matrix, where the multidimensional ordering of the waypoints is naturally
preserved. This method not only improves model learning but also enhances
training convergence. Furthermore, we propose a method to assess whether the
trained model fails to accurately capture the true waypoints. In such cases, we
revert to uniform sampling to ensure the algorithm's probabilistic
completeness; a process that traditionally involves manually determining an
optimal ratio for each scenario in other machine learning-based methods. Our
experiments demonstrate promising results in accelerating path-planning tasks
under critical time constraints. The source code is openly available at
https://bitbucket.org/joro3001/imagewgangpplanning/src/master/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06604v1' target='_blank'>Denoising Diffusion Probabilistic Model for Radio Map Estimation in
  Generative Wireless Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuanhao Luo, Zhizhen Li, Zhiyuan Peng, Mingzhe Chen, Yuchen Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-11 18:06:20</h6>
<p class='card-text'>The increasing demand for high-speed and reliable wireless networks has
driven advancements in technologies such as millimeter-wave and 5G radios,
which requires efficient planning and timely deployment of wireless access
points. A critical tool in this process is the radio map, a graphical
representation of radio-frequency signal strengths that plays a vital role in
optimizing overall network performance. However, existing methods for
estimating radio maps face challenges due to the need for extensive real-world
data collection or computationally intensive ray-tracing analyses, which is
costly and time-consuming. Inspired by the success of generative AI techniques
in large language models and image generation, we explore their potential
applications in the realm of wireless networks. In this work, we propose
RM-Gen, a novel generative framework leveraging conditional denoising diffusion
probabilistic models to synthesize radio maps using minimal and readily
collected data. We then introduce an environment-aware method for selecting
critical data pieces, enhancing the generative model's applicability and
usability. Comprehensive evaluations demonstrate that RM-Gen achieves over 95%
accuracy in generating radio maps for networks that operate at 60 GHz and
sub-6GHz frequency bands, outperforming the baseline GAN and pix2pix models.
This approach offers a cost-effective, adaptable solution for various
downstream network optimization tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06573v1' target='_blank'>Modeling the residual queue and queue-dependent capacity in a static
  traffic assignment problem</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hao Fu, William H. K. Lam, Wei Ma, Yuxin Shi, Rui Jiang, Huijun Sun, Ziyou Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-11 15:49:20</h6>
<p class='card-text'>The residual queue during a given study period (e.g., peak hour) is an
important feature that should be considered when solving a traffic assignment
problem under equilibrium for strategic traffic planning. Although studies have
focused extensively on static or quasi-dynamic traffic assignment models
considering the residual queue, they have failed to capture the situation
wherein the equilibrium link flow passing through the link is less than the
link physical capacity under congested conditions. To address this critical
issue, we introduce a novel static traffic assignment model that explicitly
incorporates the residual queue and queue-dependent link capacity. The proposed
model ensures that equilibrium link flows remain within the physical capacity
bounds, yielding estimations more aligned with data observed by traffic
detectors, especially in oversaturated scenarios. A generalized link cost
function considering queue-dependent capacity, with an additional queuing delay
term is proposed. The queuing delay term represents the added travel cost under
congestion, offering a framework wherein conventional static models, both with
and without physical capacity constraints, become special cases of our model.
Our study rigorously analyzes the mathematical properties of the new model,
establishing the theoretical uniqueness of solutions for link flow and residual
queue under certain conditions. We also introduce a gradient projection-based
alternating minimization algorithm tailored for the proposed model. Numerical
examples are conducted to demonstrate the superiority and merit of the proposed
model and solution algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06566v2' target='_blank'>Cooperative Aerial Robot Inspection Challenge: A Benchmark for
  Heterogeneous Multi-UAV Planning and Lessons Learned</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muqing Cao, Thien-Minh Nguyen, Shenghai Yuan, Andreas Anastasiou, Angelos Zacharia, Savvas Papaioannou, Panayiotis Kolios, Christos G. Panayiotou, Marios M. Polycarpou, Xinhang Xu, Mingjie Zhang, Fei Gao, Boyu Zhou, Ben M. Chen, Lihua Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-11 15:06:34</h6>
<p class='card-text'>We propose the Cooperative Aerial Robot Inspection Challenge (CARIC), a
simulation-based benchmark for motion planning algorithms in heterogeneous
multi-UAV systems. CARIC features UAV teams with complementary sensors,
realistic constraints, and evaluation metrics prioritizing inspection quality
and efficiency. It offers a ready-to-use perception-control software stack and
diverse scenarios to support the development and evaluation of task allocation
and motion planning algorithms. Competitions using CARIC were held at IEEE CDC
2023 and the IROS 2024 Workshop on Multi-Robot Perception and Navigation,
attracting innovative solutions from research teams worldwide. This paper
examines the top three teams from CDC 2023, analyzing their exploration,
inspection, and task allocation strategies while drawing insights into their
performance across scenarios. The results highlight the task's complexity and
suggest promising directions for future research in cooperative multi-UAV
systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06493v1' target='_blank'>Whole-Body Integrated Motion Planning for Aerial Manipulators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiliang Deng, Hongming Chen, Biyu Ye, Haoran Chen, Ximin Lyu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-11 09:45:38</h6>
<p class='card-text'>Efficient motion planning for Aerial Manipulators (AMs) is essential for
tackling complex manipulation tasks, yet achieving coupled trajectory planning
remains challenging. In this work, we propose, to the best of our knowledge,
the first whole-body integrated motion planning framework for aerial
manipulators, which is facilitated by an improved Safe Flight Corridor (SFC)
generation strategy and high-dimensional collision-free trajectory planning. In
particular, we formulate an optimization problem to generate feasible
trajectories for both the quadrotor and manipulator while ensuring collision
avoidance, dynamic feasibility, kinematic feasibility, and waypoint
constraints. To achieve collision avoidance, we introduce a variable geometry
approximation method, which dynamically models the changing collision volume
induced by different manipulator configurations. Moreover, waypoint constraints
in our framework are defined in $\mathrm{SE(3)\times\mathbb{R}^3}$, allowing
the aerial manipulator to traverse specified positions while maintaining
desired attitudes and end-effector states. The effectiveness of our framework
is validated through comprehensive simulations and real-world experiments
across various environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06333v1' target='_blank'>VLA+VLBA to ngVLA Transition Option Concepts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alessandra Corsi, Joseph W. Lazio, Stefi Baum, Simona Giacintucci, George Heald, Patricia Henning, Ian Heywood, Daisuke Iono, Megan Johnson, Michael T. Lam, Adam Leroy, Laurent Loinard, Leslie Looney, Lynn Matthews, Ned Molter, Eric Murphy, Eva Schinnerer, Alex Tetarenko, Grazia Umana, Alexander van der Horst</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 20:26:14</h6>
<p class='card-text'>The next-generation Very Large Array (ngVLA) is intended to be the premier
centimeter-wavelength facility for astronomy and astrophysics, building on the
substantial scientific legacies of the Karl G. Jansky Very Large Array (VLA)
and the Very Long Baseline Array (VLBA). The ngVLA would open a new window on
the Universe through ultra-sensitive imaging of thermal line and continuum
emission to milliarcsecond resolution, while delivering unprecedented
broad-band continuum imaging and polarimetry of non-thermal emission. The ngVLA
would provide a critical electromagnetic complement to a suite of particle
detectors and gravitational-wave observatories, as well as space- and
ground-based telescopes operating from infrared to gamma-ray wavelengths, hence
enabling multi-messenger and multi-band astronomy and astrophysics. Current
construction plans call for the ngVLA to leverage some of the physical
infrastructure of both the VLA and the VLBA, potentially drawing on overlapping
personnel and information infrastructure. Multiple options can be envisioned
for a VLA+VLBA to ngVLA transition. In order to assess risks and benefits of
possible transition plans, the ngVLA project established the VLA+VLBA to ngVLA
Transition Advisory Group (TAG). The primary deliverable from the TAG is a
``VLA+VLBA to ngVLA Transition Option Concepts'' report (this report) that
includes a prioritized list of transition options.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06316v1' target='_blank'>Trends in urban flows: A transfer entropy approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Roberto Murcio, Balamurugan Soundararaj</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 19:38:22</h6>
<p class='card-text'>The accurate estimation of human activity in cities is one of the first steps
towards understanding the structure of the urban environment. Human activities
are highly granular and dynamic in spatial and temporal dimensions. Estimating
confidence is crucial for decision-making in numerous applications such as
urban management, retail, transport planning and emergency management.
Detecting general trends in the flow of people between spatial locations is
neither obvious nor easy due to the high cost of capturing these movements
without compromising the privacy of those involved. This research intends to
address this problem by examining the movement of people in a
SmartStreetSensors network at a fine spatial and temporal resolution using a
Transfer Entropy approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06308v1' target='_blank'>Uncertainty Estimation for Path Loss and Radio Metric Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexis Bose, Jonathan Ethier, Ryan G. Dempsey, Yifeng Qiu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 19:11:29</h6>
<p class='card-text'>This research leverages Conformal Prediction (CP) in the form of Conformal
Predictive Systems (CPS) to accurately estimate uncertainty in a suite of
machine learning (ML)-based radio metric models [1] as well as in a 2-D
map-based ML path loss model [2]. Utilizing diverse difficulty estimators, we
construct 95% confidence prediction intervals (PIs) that are statistically
robust. Our experiments demonstrate that CPS models, trained on Toronto
datasets, generalize effectively to other cities such as Vancouver and
Montreal, maintaining high coverage and reliability. Furthermore, the employed
difficulty estimators identify challenging samples, leading to measurable
reductions in RMSE as dataset difficulty decreases. These findings highlight
the effectiveness of scalable and reliable uncertainty estimation through CPS
in wireless network modeling, offering important potential insights for network
planning, operations, and spectrum management.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06306v1' target='_blank'>On How Traffic Signals Impact the Fundamental Diagrams of Urban Roads</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chao Zhang, Yechen Li, Neha Arora, Carolina Osorio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 19:06:50</h6>
<p class='card-text'>Being widely adopted by the transportation and planning practitioners, the
fundamental diagram (FD) is the primary tool used to relate the key macroscopic
traffic variables of speed, flow, and density. We empirically analyze the
relation between vehicular space-mean speeds and flows given different signal
settings and postulate a parsimonious parametric function form of the
traditional FD where its function parameters are explicitly modeled as a
function of the signal plan factors. We validate the proposed formulation using
data from signalized urban road segments in Salt Lake City, Utah, USA. The
proposed formulation builds our understanding of how changes to signal settings
impact the FDs, and more generally the congestion patterns, of signalized urban
segments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06177v1' target='_blank'>ScooterLab: A Programmable and Participatory Sensing Research Testbed
  using Micromobility Vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ubaidullah Khan, Raveen Wijewickrama, Buddhi Ashan M. K., A. H. M. Nazmus Sakib, Khoi Trinh, Christina Duthie, Nima Najafian, Ahmer Patel, R. N. Molina, Anindya Maiti, Sushil K. Prasad, Greg P. Griffin, Murtuza Jadliwala</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 18:58:14</h6>
<p class='card-text'>Micromobility vehicles, such as e-scooters, are increasingly popular in urban
communities but present significant challenges in terms of road safety, user
privacy, infrastructure planning, and civil engineering. Addressing these
critical issues requires a large-scale and easily accessible research
infrastructure to collect diverse mobility and contextual data from
micromobility users in realistic settings. To this end, we present ScooterLab,
a community research testbed comprising a fleet of customizable battery-powered
micromobility vehicles retrofitted with advanced sensing, communication, and
control capabilities. ScooterLab enables interdisciplinary research at the
intersection of computing, mobility, and urban planning by providing
researchers with tools to design and deploy customized sensing experiments and
access curated datasets. The testbed will enable advances in machine learning,
privacy, and urban transportation research while promoting sustainable
mobility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06132v1' target='_blank'>CoDriveVLM: VLM-Enhanced Urban Cooperative Dispatching and Motion
  Planning for Future Autonomous Mobility on Demand Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haichao Liu, Ruoyu Yao, Wenru Liu, Zhenmin Huang, Shaojie Shen, Jun Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 17:44:57</h6>
<p class='card-text'>The increasing demand for flexible and efficient urban transportation
solutions has spotlighted the limitations of traditional Demand Responsive
Transport (DRT) systems, particularly in accommodating diverse passenger needs
and dynamic urban environments. Autonomous Mobility-on-Demand (AMoD) systems
have emerged as a promising alternative, leveraging connected and autonomous
vehicles (CAVs) to provide responsive and adaptable services. However, existing
methods primarily focus on either vehicle scheduling or path planning, which
often simplify complex urban layouts and neglect the necessity for simultaneous
coordination and mutual avoidance among CAVs. This oversimplification poses
significant challenges to the deployment of AMoD systems in real-world
scenarios. To address these gaps, we propose CoDriveVLM, a novel framework that
integrates high-fidelity simultaneous dispatching and cooperative motion
planning for future AMoD systems. Our method harnesses Vision-Language Models
(VLMs) to enhance multi-modality information processing, and this enables
comprehensive dispatching and collision risk evaluation. The VLM-enhanced CAV
dispatching coordinator is introduced to effectively manage complex and
unforeseen AMoD conditions, thus supporting efficient scheduling
decision-making. Furthermore, we propose a scalable decentralized cooperative
motion planning method via consensus alternating direction method of
multipliers (ADMM) focusing on collision risk evaluation and decentralized
trajectory optimization. Simulation results demonstrate the feasibility and
robustness of CoDriveVLM in various traffic conditions, showcasing its
potential to significantly improve the fidelity and effectiveness of AMoD
systems in future urban transportation networks. The code is available at
https://github.com/henryhcliu/CoDriveVLM.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06007v2' target='_blank'>CoNOAir: A Neural Operator for Forecasting Carbon Monoxide Evolution in
  Cities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sanchit Bedi, Karn Tiwari, Prathosh A. P., Sri Harsha Kota, N. M. Anoop Krishnan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 14:42:08</h6>
<p class='card-text'>Carbon Monoxide (CO) is a dominant pollutant in urban areas due to the energy
generation from fossil fuels for industry, automobile, and domestic
requirements. Forecasting the evolution of CO in real-time can enable the
deployment of effective early warning systems and intervention strategies.
However, the computational cost associated with the physics and chemistry-based
simulation makes it prohibitive to implement such a model at the city and
country scale. To address this challenge, here, we present a machine learning
model based on neural operator, namely, Complex Neural Operator for Air Quality
(CoNOAir), that can effectively forecast CO concentrations. We demonstrate this
by developing a country-level model for short-term (hourly) and long-term
(72-hour) forecasts of CO concentrations. Our model outperforms
state-of-the-art models such as Fourier neural operators (FNO) and provides
reliable predictions for both short and long-term forecasts. We further analyse
the capability of the model to capture extreme events and generate forecasts in
urban cities in India. Interestingly, we observe that the model predicts the
next hour CO concentrations with R2 values greater than 0.95 for all the cities
considered. The deployment of such a model can greatly assist the governing
bodies to provide early warning, plan intervention strategies, and develop
effective strategies by considering several what-if scenarios. Altogether, the
present approach could provide a fillip to real-time predictions of CO
pollution in urban cities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05858v1' target='_blank'>The Geostrategy of Youth Player Recruitment in Portuguese Clubs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tiago Mendes-Neves, Luís Meireles, João Mendes-Moreira, Nuno de Almeida</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 10:56:35</h6>
<p class='card-text'>Portugal's prominent role as a global exporter of football talent is
primarily driven by youth academies. Notably, Portugal leads the global ranking
in terms of net transfer balance. This study aims to uncover and understand the
recruitment strategies of Portuguese clubs for sourcing young talent and
evaluate the relative success of different strategies. A comprehensive dataset
spanning recent decades of Portuguese youth and professional football provides
granular insights, including information such as players' birthplaces and the
initial grassroots clubs where they developed. The initial findings suggest a
correlation between a club's prominence and the geographic reach of its youth
scouting operations, with larger clubs able to cast their net wider. Analysis
of the correlation between players' birthplace and high-tier football club
location suggests that the performance of senior teams acts as a catalyst for
investment in youth teams. Regions without professional clubs are often left
underserved. That said, certain clubs have made significant gains by focusing
on player recruitment outside their district, such as the Algarve region,
demonstrating how geographically targeted strategies can deliver substantial
returns on investment. This study underscores data's role in sharpening youth
player recruitment operations at football clubs. Clubs have access to in-depth
and comprehensive datasets that can be used for resource allocation,
territorial coverage planning, and identifying strategic partnerships with
other clubs, potentially influencing their future success both on the field and
financially. This offers opportunities for growth for individual clubs and
holds implications for the continued strength of Portuguese football.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05818v1' target='_blank'>Scenario-free robust optimization algorithm for IMRT and IMPT treatment
  planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Remo Cristoforetti, Jennifer Josephine Hardt, Niklas Wahl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 09:46:28</h6>
<p class='card-text'>Robust treatment planning algorithms for Intensity Modulated Proton Therapy
(IMPT) and Intensity Modulated Radiation Therapy (IMRT) allow for uncertainty
reduction in the delivered dose distributions through explicit inclusion of
error scenarios. Due to the curse of dimensionality, application of such
algorithms can easily become computationally prohibitive. This work proposes a
scenario-free probabilistic robust optimization algorithm that overcomes both
the runtime and memory limitations typical of traditional robustness
algorithms. The scenario-free approach minimizes cost-functions evaluated on
expected-dose distributions and total variance. Calculation of these quantities
relies on precomputed expected-dose-influence and total-variance-influence
matrices, such that no scenarios need to be stored for optimization. The
algorithm was developed within matRad and tested in several optimization
configurations for photon and proton irradiation plans. A traditional robust
optimization algorithm and a margin-based approach are used as a reference to
benchmark the performances of the scenario-free algorithm in terms of plan
quality, robustness and computational workload. The scenario-free approach
achieves plan quality compatible with traditional robust optimization
algorithms and it reduces the standard deviation within selected structures
when variance reduction objectives are defined. Avoiding the storage of
individual scenario information allows for the inclusion of an arbitrary number
of error scenarios. The observed optimization time is independent on the number
of included scenarios, compatible with a nominal, non-robust algorithm and
significantly lower than the traditional robust approach. These properties make
the scenario-free approach suitable for the optimization of robust plans
involving a high number of error scenarios and CT phases as 4D robust
optimization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05795v3' target='_blank'>Robust Counterfactual Explanations under Model Multiplicity Using
  Multi-Objective Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Keita Kinjo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 08:57:50</h6>
<p class='card-text'>In recent years, explainability in machine learning has gained importance. In
this context, counterfactual explanation (CE), which is an explanation method
that uses examples, has attracted attention. However, it has been pointed out
that CE is not robust when there are multiple machine-learning models with
similar accuracy. These problems are important when using machine learning to
make safe decisions. In this paper, we propose robust CEs that introduce a new
viewpoint -- Pareto improvement -- and a method that uses multi-objective
optimization to generate it. To evaluate the proposed method, we conducted
experiments using both simulated and real data. The results demonstrate that
the proposed method is both robust and practical. This study highlights the
potential of ensuring robustness in decision-making by applying the concept of
social welfare. We believe that this research can serve as a valuable
foundation for various fields, including explainability in machine learning,
decision-making, and action planning based on machine learning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05789v1' target='_blank'>Automating Care by Self-maintainability for Full Laboratory Automation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Koji Ochiai, Yuya Tahara-Arai, Akari Kato, Kazunari Kaizu, Hirokazu Kariyazaki, Makoto Umeno, Koichi Takahashi, Genki N. Kanda, Haruka Ozaki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 08:49:37</h6>
<p class='card-text'>The automation of experiments in life sciences and chemistry has
significantly advanced with the development of various instruments and AI
technologies. However, achieving full laboratory automation, where experiments
conceived by scientists are seamlessly executed in automated laboratories,
remains a challenge. We identify the lack of automation in planning and
operational tasks--critical human-managed processes collectively termed
"care"--as a major barrier. Automating care is the key enabler for full
laboratory automation. To address this, we propose the concept of
self-maintainability (SeM): the ability of a laboratory system to autonomously
adapt to internal and external disturbances, maintaining operational readiness
akin to living cells. A SeM-enabled laboratory features autonomous recognition
of its state, dynamic resource and information management, and adaptive
responses to unexpected conditions. This shifts the planning and execution of
experimental workflows, including scheduling and reagent allocation, from
humans to the system. We present a conceptual framework for implementing
SeM-enabled laboratories, comprising three modules--Requirement manager,
Labware manager, and Device manager--and a Central manager. SeM not only
enables scientists to execute envisioned experiments seamlessly but also
provides developers with a design concept that drives the technological
innovations needed for full automation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05770v1' target='_blank'>Path Planning for Multi-Copter UAV Formation Employing a Generalized
  Particle Swarm Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Van Truong Hoang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 07:58:52</h6>
<p class='card-text'>The paper investigates the problem of path planning techniques for
multi-copter uncrewed aerial vehicles (UAV) cooperation in a formation shape to
examine surrounding surfaces. We first describe the problem as a joint
objective cost for planning a path of the formation centroid working in a
complicated space. The path planning algorithm, named the generalized particle
swarm optimization algorithm, is then presented to construct an optimal,
flyable path while avoiding obstacles and ensuring the flying mission
requirements. A path-development scheme is then incorporated to generate a
relevant path for each drone to maintain its position in the formation
configuration. Simulation, comparison, and experiments have been conducted to
verify the proposed approach. Results show the feasibility of the proposed
path-planning algorithm with GEPSO.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14792v1' target='_blank'>A Wearable Strain-Sensor-Based Shoulder Patch for Fatigue Detection in
  Bicep Curls</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ming Xuan Chua, Shuhua Peng, Thanh Nho Do, Chun Hui Wang, Liao Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 06:21:17</h6>
<p class='card-text'>A common challenge in home-based rehabilitation is muscle compensation
induced by pain or fatigue, where patients with weakened primary muscles
recruit secondary muscle groups to assist their movement, causing issues such
as delayed rehabilitation progress or risk of further injury. In a home-based
setting, the subtle compensatory actions may not be perceived since
physiotherapists cannot directly observe patients. To address this problem,
this study develops a novel wearable strain-sensor-based shoulder patch to
detect fatigue-induced muscle compensation during bicep curl exercises. Built
on an observation that the amplitude of a strain sensor's resistance is
correlated to the motion of a joint that the sensor is attached to, we develop
an algorithm that can robustly detect the state when significant changes appear
in the shoulder joint motion, which indicates fatigue-induced muscle
compensation in bicep curls. The developed shoulder patch is tested on 13
subjects who perform bicep curl exercises with a 5 kg dumbell until reaching
fatigue. During the experiment, the performance of the shoulder patch is also
benchmarked with optical tracking sensors and surface electromyography (sEMG)
sensors. Results reveal that the proposed wearable sensor and detection methods
effectively monitor fatigue-induced muscle compensation during bicep curl
exercises in both Real-Time and Post Hoc modes. This development marks a
significant step toward enhancing the effectiveness of home-based
rehabilitation by providing physiotherapists with a tool to monitor and adjust
treatment plans remotely.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05733v1' target='_blank'>TB-Bench: Training and Testing Multi-Modal AI for Understanding
  Spatio-Temporal Traffic Behaviors from Dashcam Images/Videos</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Korawat Charoenpitaks, Van-Quang Nguyen, Masanori Suganuma, Kentaro Arai, Seiji Totsuka, Hiroshi Ino, Takayuki Okatani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 06:02:06</h6>
<p class='card-text'>The application of Multi-modal Large Language Models (MLLMs) in Autonomous
Driving (AD) faces significant challenges due to their limited training on
traffic-specific data and the absence of dedicated benchmarks for
spatiotemporal understanding. This study addresses these issues by proposing
TB-Bench, a comprehensive benchmark designed to evaluate MLLMs on understanding
traffic behaviors across eight perception tasks from ego-centric views. We also
introduce vision-language instruction tuning datasets, TB-100k and TB-250k,
along with simple yet effective baselines for the tasks. Through extensive
experiments, we show that existing MLLMs underperform in these tasks, with even
a powerful model like GPT-4o achieving less than 35% accuracy on average. In
contrast, when fine-tuned with TB-100k or TB-250k, our baseline models achieve
average accuracy up to 85%, significantly enhancing performance on the tasks.
Additionally, we demonstrate performance transfer by co-training TB-100k with
another traffic dataset, leading to improved performance on the latter.
Overall, this study represents a step forward by introducing a comprehensive
benchmark, high-quality datasets, and baselines, thus supporting the gradual
integration of MLLMs into the perception, prediction, and planning stages of
AD.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05684v1' target='_blank'>Data driven discovery of human mobility models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hao Guo, Weiyu Zhang, Junjie Yang, Yuanqiao Hou, Lei Dong, Yu Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 03:21:40</h6>
<p class='card-text'>Human mobility is a fundamental aspect of social behavior, with broad
applications in transportation, urban planning, and epidemic modeling. However,
for decades new mathematical formulas to model mobility phenomena have been
scarce and usually discovered by analogy to physical processes, such as the
gravity model and the radiation model. These sporadic discoveries are often
thought to rely on intuition and luck in fitting empirical data. Here, we
propose a systematic approach that leverages symbolic regression to
automatically discover interpretable models from human mobility data. Our
approach finds several well-known formulas, such as the distance decay effect
and classical gravity models, as well as previously unknown ones, such as an
exponential-power-law decay that can be explained by the maximum entropy
principle. By relaxing the constraints on the complexity of model expressions,
we further show how key variables of human mobility are progressively
incorporated into the model, making this framework a powerful tool for
revealing the underlying mathematical structures of complex social phenomena
directly from observational data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05673v1' target='_blank'>Network Diffuser for Placing-Scheduling Service Function Chains with
  Inverse Demonstration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zuyuan Zhang, Vaneet Aggarwal, Tian Lan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 02:51:58</h6>
<p class='card-text'>Network services are increasingly managed by considering chained-up virtual
network functions and relevant traffic flows, known as the Service Function
Chains (SFCs). To deal with sequential arrivals of SFCs in an online fashion,
we must consider two closely-coupled problems - an SFC placement problem that
maps SFCs to servers/links in the network and an SFC scheduling problem that
determines when each SFC is executed. Solving the whole SFC problem targeting
these two optimizations jointly is extremely challenging. In this paper, we
propose a novel network diffuser using conditional generative modeling for this
SFC placing-scheduling optimization. Recent advances in generative AI and
diffusion models have made it possible to generate high-quality images/videos
and decision trajectories from language description. We formulate the SFC
optimization as a problem of generating a state sequence for planning and
perform graph diffusion on the state trajectories to enable extraction of SFC
decisions, with SFC optimization constraints and objectives as conditions. To
address the lack of demonstration data due to NP-hardness and exponential
problem space of the SFC optimization, we also propose a novel and somewhat
maverick approach -- Rather than solving instances of this difficult
optimization, we start with randomly-generated solutions as input, and then
determine appropriate SFC optimization problems that render these solutions
feasible. This inverse demonstration enables us to obtain sufficient expert
demonstrations, i.e., problem-solution pairs, through further optimization. In
our numerical evaluations, the proposed network diffuser outperforms learning
and heuristic baselines, by $\sim$20\% improvement in SFC reward and $\sim$50\%
reduction in SFC waiting time and blocking rate.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05639v1' target='_blank'>Scaling Safe Multi-Agent Control for Signal Temporal Logic
  Specifications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joe Eappen, Zikang Xiong, Dipam Patel, Aniket Bera, Suresh Jagannathan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 00:56:39</h6>
<p class='card-text'>Existing methods for safe multi-agent control using logic specifications like
Signal Temporal Logic (STL) often face scalability issues. This is because they
rely either on single-agent perspectives or on Mixed Integer Linear Programming
(MILP)-based planners, which are complex to optimize. These methods have proven
to be computationally expensive and inefficient when dealing with a large
number of agents. To address these limitations, we present a new scalable
approach to multi-agent control in this setting. Our method treats the
relationships between agents using a graph structure rather than in terms of a
single-agent perspective. Moreover, it combines a multi-agent collision
avoidance controller with a Graph Neural Network (GNN) based planner, models
the system in a decentralized fashion, and trains on STL-based objectives to
generate safe and efficient plans for multiple agents, thereby optimizing the
satisfaction of complex temporal specifications while also facilitating
multi-agent collision avoidance. Our experiments show that our approach
significantly outperforms existing methods that use a state-of-the-art
MILP-based planner in terms of scalability and performance. The project website
is https://jeappen.com/mastl-gcbf-website/ and the code is at
https://github.com/jeappen/mastl-gcbf .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05632v1' target='_blank'>OpenUniverse2024: A shared, simulated view of the sky for the next
  generation of cosmological surveys</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:OpenUniverse, The LSST Dark Energy Science Collaboration, The Roman HLIS Project Infrastructure Team, The Roman RAPID Project Infrastructure Team, The Roman Supernova Cosmology Project Infrastructure Team, A. Alarcon, L. Aldoroty, G. Beltz-Mohrmann, A. Bera, J. Blazek, J. Bogart, G. Braeunlich, A. Broughton, K. Cao, J. Chiang, N. E. Chisari, V. Desai, Y. Fang, L. Galbany, A. Hearin, K. Heitmann, C. Hirata, R. Hounsell, B. Jain, M. Jarvis, J. Jencson, A. Kannawadi, M. K. Kasliwal, R. Kessler, A. Kiessling, R. Knop, E. Kovacs, R. Laher, K. Laliotis, C. Lin, I. Lopes, A. Mahabal, R. Mandelbaum, J. Masiero, S. Mau, C. Meehan, J. Meyers, B. Moraes, R. Paladini, A. Pearl, A. Plazas Malagon, B. Rose, D. Rubin, B. Rusholme, A. Santos, N. Šarčević, D. Scolnic, M. A. Troxel, N. Van Alfen, S. Van Dyke, C. W. Walter, T. Wu, M. Yamamoto, Y. Yan, T. Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-10 00:20:38</h6>
<p class='card-text'>The OpenUniverse2024 simulation suite is a cross-collaboration effort to
produce matched simulated imaging for multiple surveys as they would observe a
common simulated sky. Both the simulated data and associated tools used to
produce it are intended to uniquely enable a wide range of studies to maximize
the science potential of the next generation of cosmological surveys. We have
produced simulated imaging for approximately 70 deg$^2$ of the Vera C. Rubin
Observatory Legacy Survey of Space and Time (LSST) Wide-Fast-Deep survey and
the Nancy Grace Roman Space Telescope High-Latitude Wide-Area Survey, as well
as overlapping versions of the ELAIS-S1 Deep-Drilling Field for LSST and the
High-Latitude Time-Domain Survey for Roman. OpenUniverse2024 includes i) an
early version of the updated extragalactic model called Diffsky, which
substantially improves the realism of optical and infrared photometry of
objects, compared to previous versions of these models; ii) updated transient
models that extend through the wavelength range probed by Roman and Rubin; and
iii) improved survey, telescope, and instrument realism based on up-to-date
survey plans and known properties of the instruments. It is built on a new and
updated suite of simulation tools that improves the ease of consistently
simulating multiple observatories viewing the same sky. The approximately 400
TB of synthetic survey imaging and simulated universe catalogs are publicly
available, and we preview some scientific uses of the simulations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05604v1' target='_blank'>The LSPE-Strip Pointing Reconstruction and Star Tracker</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Michele Maris, Maurizio Tomasi, Matteo Baratto, Fabio Paonessa, Cristian Franceschet, Daniele Tavagnacco, Oscar Antonio Peverini, Fabrizio Villa, Mario Zannoni, Marco Bersanelli, Barbara Caccianiga, Stefano Mandelli, Aniello Mennella, Federico Nati, Stefano Sartor, Ricardo T. Génova-Santos, Jose A. Rubino-Martin, Francesco Cuttaia, Francesco Cavaliere, Luciano Mandelli, Massimo Gervasi, Andrea Zacchei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 22:36:00</h6>
<p class='card-text'>This paper aims to describe the Pointing Reconstruction Model (PRM) and the
prototype Star Tracker, which will be mounted on LSPE-Strip, a microwave Q- and
W-band CMB telescope planned for installation at the "Observatorio del Teide"
in Tenerife. The PRM integrates information on the instantaneous attitude
provided by the telescope control system to determine the actual pointing
direction and focal plane orientation of the telescope. It accounts for various
non-idealities in the telescope setup, represented by eight configuration
angles, which will be calibrated using the Star Tracker. Following the
derivation of the PRM formalism and its implementation, we investigate the
pointing errors caused by incorrect calibration of these configuration angles
to validate the required 1 arcminute maximum systematic pointing error for the
LSPE-Strip survey. This paper also describes the main structure and operations
of the Star Tracker and presents the results of a campaign of actual sky
observations conducted with a prototype. The results demonstrate a Star Tracker
RMS accuracy of approximately 3 arcseconds, while systematic errors remain
below 10 arcseconds. Based on these results, we analyzed the problem of
reconstructing the PRM configuration angles. Two methods for intercalibrating
the Star Tracker's pointing direction with respect to the focal plane's
pointing direction were examined: (1) observations of planets and (2)
observations of a drone carrying both an optical beacon and a radio beacon. In
the first case, an intercalibration accuracy between 1/3 arcminute and 1
arcminute is achievable. In the second case, the expected intercalibration
accuracy ranges from 0.25 arcminute to 1 arcminute.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05524v2' target='_blank'>A Starter Kit for Diversity-Oriented Communities for Undergraduates:
  Near-Peer Mentorship Programs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Emily J. Griffith, Gloria Lee, Joel C. Corbo, Gabriela Huckabee, Hannah Inés Shamloo, Gina Quan, Noah Charles, Brianne Gutmann, Gabrielle Jones-Hall, Mayisha Zeb Nakib, Benjamin Pollard, Marisa Romanelli, Devyn Shafer, Megan Marshall Smith, Chandra Turpen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 19:03:48</h6>
<p class='card-text'>This mentoring resource is a guide to establishing and running near-peer
mentorship programs. It is based on the working knowledge and best practices
developed by the Access Network, a collection of nine student-led communities
at universities across the country working towards a vision of a more diverse,
equitable, inclusive, and accessible STEM environment. Many of these
communities, also referred to as sites, include a near-peer mentoring program
that is developed to best support their local context. The format of these
programs vary, ranging from structured classes with peer mentoring groups to
student clubs supporting 1-on-1 relationships. To further support program
participants as both students and as whole people, sites often run additional
events such as lecture series, workshops, and social activities guided tailored
to each student community's needs. Through this process, student leaders have
generated and honed best practices for all aspects of running their sites. This
guide is an attempt to synthesize those efforts, offering practical advice for
student leaders setting up near-peer mentorship programs in their own
departments. It has been written through the lens of undergraduate near-peer
mentorship programs, although our framework could easily be extended to other
demographics (e.g. high schoolers, graduate students, etc.). Our experience is
with STEM mentorship specifically, though these practices can extend to any
discipline. In this document, we outline best practices for designing, running,
and sustaining near-peer mentorship programs. We provide template resources to
assist with this work, and lesson plans to run mentor and mentee training
sessions. We hope you find this guide useful in designing, implementing, and
re-evaluating community oriented near-peer mentoring programs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05414v1' target='_blank'>LongProc: Benchmarking Long-Context Language Models on Long Procedural
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 18:16:55</h6>
<p class='card-text'>Existing benchmarks for evaluating long-context language models (LCLMs)
primarily focus on long-context recall, requiring models to produce short
responses based on a few critical snippets while processing thousands of
irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new
benchmark that requires both the integration of highly dispersed information
and long-form generation. LongProc consists of six diverse procedural
generation tasks, such as extracting structured information from HTML pages
into a TSV format and executing complex search procedures to create travel
plans. These tasks challenge LCLMs by testing their ability to follow detailed
procedural instructions, synthesize and reason over dispersed information, and
generate structured, long-form outputs (up to 8K tokens). Furthermore, as these
tasks adhere to deterministic procedures and yield structured outputs, they
enable reliable rule-based evaluation. We evaluate 17 LCLMs on LongProc across
three difficulty levels, with maximum numbers of output tokens set at 500, 2K,
and 8K. Notably, while all tested models claim a context window size above 32K
tokens, open-weight models typically falter on 2K-token tasks, and
closed-source models like GPT-4o show significant degradation on 8K-token
tasks. Further analysis reveals that LCLMs struggle to maintain long-range
coherence in long-form generations. These findings highlight critical
limitations in current LCLMs and suggest substantial room for improvement. Data
and code available at: https://princeton-pli.github.io/LongProc</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05411v1' target='_blank'>Adaptive Path-Planning for Autonomous Robots: A UCH-Enhanced Q-Learning
  Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Liu, Ruiyang Wang, Haonan Wang, Guangwei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 18:10:16</h6>
<p class='card-text'>Q-learning methods are widely used in robot path planning but often face
challenges of inefficient search and slow convergence. We propose an Improved
Q-learning (IQL) framework that enhances standard Q-learning in two significant
ways. First, we introduce the Path Adaptive Collaborative Optimization (PACO)
algorithm to optimize Q-table initialization, providing better initial
estimates and accelerating learning. Second, we incorporate a
Utility-Controlled Heuristic (UCH) mechanism with dynamically tuned parameters
to optimize the reward function, enhancing the algorithm's accuracy and
effectiveness in path-planning tasks. Extensive experiments in three different
raster grid environments validate the superior performance of our IQL
framework. The results demonstrate that our IQL algorithm outperforms existing
methods, including FIQL, PP-QL-based CPP, DFQL, and QMABC algorithms, in terms
of path-planning capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05499v1' target='_blank'>Generalization of Urban Wind Environment Using Fourier Neural Operator
  Across Different Wind Directions and Cities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cheng Chen, Geng Tian, Shaoxiang Qin, Senwen Yang, Dingyang Geng, Dongxue Zhan, Jinqiu Yang, David Vidal, Liangzhu Leon Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 18:02:12</h6>
<p class='card-text'>Simulation of urban wind environments is crucial for urban planning,
pollution control, and renewable energy utilization. However, the computational
requirements of high-fidelity computational fluid dynamics (CFD) methods make
them impractical for real cities. To address these limitations, this study
investigates the effectiveness of the Fourier Neural Operator (FNO) model in
predicting flow fields under different wind directions and urban layouts. In
this study, we investigate the effectiveness of the Fourier Neural Operator
(FNO) model in predicting urban wind conditions under different wind directions
and urban layouts. By training the model on velocity data from large eddy
simulation data, we evaluate the performance of the model under different urban
configurations and wind conditions. The results show that the FNO model can
provide accurate predictions while significantly reducing the computational
time by 99%. Our innovative approach of dividing the wind field into smaller
spatial blocks for training improves the ability of the FNO model to capture
wind frequency features effectively. The SDF data also provides important
spatial building information, enhancing the model's ability to recognize
physical boundaries and generate more realistic predictions. The proposed FNO
approach enhances the AI model's generalizability for different wind directions
and urban layouts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05280v1' target='_blank'>Exploring near-optimal energy systems with stakeholders: a novel
  approach for participatory modelling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oskar Vågerö, Koen van Greevenbroek, Aleksander Grochowicz, Maximilian Roithner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 14:43:29</h6>
<p class='card-text'>Involving people in energy systems planning can increase the legitimacy and
socio-political feasibility of energy transitions. Participatory research in
energy modelling offers the opportunity to engage with stakeholders in a
comprehensive way, but is limited by how results can be generated and presented
without imposing assumptions and discrete scenarios on the participants. To
this end, we present a methodology and a framework, based on near-optimal
modelling results, that can incorporate stakeholders in a holistic and engaging
way. We confront stakeholders with a continuum of modelling-based energy system
designs via an interactive interface allowing them to choose essentially any
combination of components that meet the system requirements. Together with
information on the implications of different technologies, it is possible to
assess how participants prioritise different aspects in energy systems planning
while also facilitating learning in an engaging and stimulating way. We
showcase the methodology for the remote Arctic settlement of Longyearbyen and
illustrate how participants deviate consistently from the cost optimum. At the
same time, they manage to balance different priorities such as emissions,
costs, and system vulnerability leading to a better understanding of the
complexity and intertwined nature of decisions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06262v1' target='_blank'>Towards smart and adaptive agents for active sensing on edge devices</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Devendra Vyas, Miguel de Prado, Tim Verbelen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 13:27:02</h6>
<p class='card-text'>TinyML has made deploying deep learning models on low-power edge devices
feasible, creating new opportunities for real-time perception in constrained
environments. However, the adaptability of such deep learning methods remains
limited to data drift adaptation, lacking broader capabilities that account for
the environment's underlying dynamics and inherent uncertainty. Deep learning's
scaling laws, which counterbalance this limitation by massively up-scaling data
and model size, cannot be applied when deploying on the Edge, where deep
learning limitations are further amplified as models are scaled down for
deployment on resource-constrained devices.
  This paper presents a smart agentic system capable of performing on-device
perception and planning, enabling active sensing on the edge. By incorporating
active inference into our solution, our approach extends beyond deep learning
capabilities, allowing the system to plan in dynamic environments while
operating in real time with a modest total model size of 2.3 MB. We showcase
our proposed system by creating and deploying a saccade agent connected to an
IoT camera with pan and tilt capabilities on an NVIDIA Jetson embedded device.
The saccade agent controls the camera's field of view following optimal
policies derived from the active inference principles, simulating human-like
saccadic motion for surveillance and robotics applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05200v1' target='_blank'>On Coordinated Drone-Courier Logistics for Intra-city Express Services</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuiwang Chen, Kai Wang, Lingxiao Wu, Wei Qi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 12:51:39</h6>
<p class='card-text'>Problem definition: Drones, despite being acknowledged as a transformative
force in the city logistics sector, are unable to execute the
\textit{last-meter delivery} (unloading goods directly to customers' doorsteps)
due to airspace restrictions and safety concerns. To leverage advancements and
overcome the limitations of drones in providing intra-city express services, we
introduce a coordinated drone-courier logistics system where drones operate
within a closed network among vertiports, while couriers connect customers to
the drone delivery system. This paper aims to shed light on this coordinated
system in terms of system feasibility, network interactivity, and long-term
sustainability. Methodology/Results: We develop an integrated optimization
model to optimize the network planning of the coordinated logistics system. The
interplay between network planning and tactical operations is mirrored by a
queueing network model, resulting in the nonlinear and nonconvex (partially
convex and partially concave) feasible region of the optimization model. An
iterative exact algorithm that tightens lower and upper bounds by adaptively
refining the linear approximations of nonlinear constraints is developed to
provide optimality-guaranteed solutions with finite convergence. The
computational experiments demonstrate the scalability and robustness of our
algorithm across various network configurations and scenarios.Managerial
implications: The case study, based on a real-world dataset from SF Express, a
logistics giant in China, validates that the coordinated logistics system
efficiently attains cost and time savings by leveraging the effective turnover
of drones and the coordination between drones and couriers. The optimal network
design features a concentrated structure, streamlining demand consolidation and
reducing deadhead repositioning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05156v2' target='_blank'>State-Based Disassembly Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chao Lei, Nir Lipovetzky, Krista A. Ehinger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 11:23:31</h6>
<p class='card-text'>It has been shown recently that physics-based simulation significantly
enhances the disassembly capabilities of real-world assemblies with diverse 3D
shapes and stringent motion constraints. However, the efficiency suffers when
tackling intricate disassembly tasks that require numerous simulations and
increased simulation time. In this work, we propose a State-Based Disassembly
Planning (SBDP) approach, prioritizing physics-based simulation with
translational motion over rotational motion to facilitate autonomy, reducing
dependency on human input, while storing intermediate motion states to improve
search scalability. We introduce two novel evaluation functions derived from
new Directional Blocking Graphs (DBGs) enriched with state information to scale
up the search. Our experiments show that SBDP with new evaluation functions and
DBGs constraints outperforms the state-of-the-art in disassembly planning in
terms of success rate and computational efficiency over benchmark datasets
consisting of thousands of physically valid industrial assemblies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05132v1' target='_blank'>CorrDiff: Adaptive Delay-aware Detector with Temporal Cue Inputs for
  Real-time Object Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiang Zhang, Chenchen Fu, Yufei Cui, Lan Yi, Yuyang Sun, Weiwei Wu, Xue Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 10:34:25</h6>
<p class='card-text'>Real-time object detection takes an essential part in the decision-making
process of numerous real-world applications, including collision avoidance and
path planning in autonomous driving systems. This paper presents a novel
real-time streaming perception method named CorrDiff, designed to tackle the
challenge of delays in real-time detection systems. The main contribution of
CorrDiff lies in its adaptive delay-aware detector, which is able to utilize
runtime-estimated temporal cues to predict objects' locations for multiple
future frames, and selectively produce predictions that matches real-world
time, effectively compensating for any communication and computational delays.
The proposed model outperforms current state-of-the-art methods by leveraging
motion estimation and feature enhancement, both for 1) single-frame detection
for the current frame or the next frame, in terms of the metric mAP, and 2) the
prediction for (multiple) future frame(s), in terms of the metric sAP (The sAP
metric is to evaluate object detection algorithms in streaming scenarios,
factoring in both latency and accuracy). It demonstrates robust performance
across a range of devices, from powerful Tesla V100 to modest RTX 2080Ti,
achieving the highest level of perceptual accuracy on all platforms. Unlike
most state-of-the-art methods that struggle to complete computation within a
single frame on less powerful devices, CorrDiff meets the stringent real-time
processing requirements on all kinds of devices. The experimental results
emphasize the system's adaptability and its potential to significantly improve
the safety and reliability for many real-world systems, such as autonomous
driving. Our code is completely open-sourced and is available at
https://anonymous.4open.science/r/CorrDiff.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05128v3' target='_blank'>Development of a high-rate capable DLC-RPC based on a current evacuation
  pattern</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Masato Takahashi, Sei Ban, Weiyuan Li, Atsuhiko Ochi, Wataru Ootani, Atsushi Oya, Hiromu Suzuki, Kensuke Yamamoto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 10:31:23</h6>
<p class='card-text'>A Resistive Plate Chamber using Diamond-Like Carbon electrodes (DLC-RPC) has
been developed as a background tagging detector in the MEG$~$II experiment. The
DLC-RPC is planned to be installed in a high-intensity and low-momentum muon
beam. This detector is required to have a detection efficiency above 90 % with
four active gaps in the muon beam due to the limitation of the material budget.
In such an environment, the high current flowing through the resistive
electrodes causes a voltage drop, which reduces the performance of the DLC-RPC.
This voltage drop can be suppressed by implementing a current evacuation
pattern, though discharges are more likely to occur near the pattern. Therefore
the pattern must be covered by a protection cover made of an insulator. In this
study, electrode samples with a current evacuation pattern and different widths
of protection cover (0.2 mm and 0.8 mm) have been produced, and their
performance and stability were measured. The detection efficiency of a
single-gap chamber for $\beta$-rays from a $^{90}$Sr source was measured to be
up to approximately 60 % in both electrode samples. The target efficiency can
be achieved even with a drop of 100 $-$ 150 V. On the other hand, after more
than a dozen hours of operation, discharges suddenly occurred and the detector
was prevented from further operation. These discharges created current paths on
the spacing pillars. This serious problem must be investigated and solved in
the future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05095v1' target='_blank'>Advancing ALS Applications with Large-Scale Pre-training: Dataset
  Development and Downstream Assessment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoyi Xiu, Xin Liu, Taehoon Kim, Kyoung-Sook Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 09:21:09</h6>
<p class='card-text'>The pre-training and fine-tuning paradigm has revolutionized satellite remote
sensing applications. However, this approach remains largely underexplored for
airborne laser scanning (ALS), an important technology for applications such as
forest management and urban planning. In this study, we address this gap by
constructing a large-scale ALS point cloud dataset and evaluating its impact on
downstream applications. Our dataset comprises ALS point clouds collected
across the contiguous United States, provided by the United States Geological
Survey's 3D Elevation Program. To ensure efficient data collection while
capturing diverse land cover and terrain types, we introduce a geospatial
sampling method that selects point cloud tiles based on land cover maps and
digital elevation models. As a baseline self-supervised learning model, we
adopt BEV-MAE, a state-of-the-art masked autoencoder for 3D outdoor point
clouds, and pre-train it on the constructed dataset. The pre-trained models are
subsequently fine-tuned for downstream tasks, including tree species
classification, terrain scene recognition, and point cloud semantic
segmentation. Our results show that the pre-trained models significantly
outperform their scratch counterparts across all downstream tasks,
demonstrating the transferability of the representations learned from the
proposed dataset. Furthermore, we observe that scaling the dataset using our
geospatial sampling method consistently enhances performance, whereas
pre-training on datasets constructed with random sampling fails to achieve
similar improvements. These findings highlight the utility of the constructed
dataset and the effectiveness of our sampling strategy in the pre-training and
fine-tuning paradigm. The source code and pre-trained models will be made
publicly available at \url{https://github.com/martianxiu/ALS_pretraining}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05046v1' target='_blank'>Quantum-Assisted Space Logistics Mission Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Amiratabak Bahengam, Mohammad-Ali Miri, R. Joseph Rupert, Wesley Dyk, Hao Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 08:12:34</h6>
<p class='card-text'>Quantum computing provides a novel approach to addressing conventionally
intractable issues in large-scale optimization. Space logistics missions
require the efficient routing of payloads, spacecraft, and resources across
complex networks, often resulting in an exponential growth of the solution
space that classical methods cannot efficiently solve. This paper leverages
entropy quantum computing to model and solve the space logistics problem as a
time-dependent multicommodity network flow, enabling the exploration of large
solution spaces. The findings highlight quantum computing's potential to
address complex aerospace logistics, demonstrating its suitability for complex
interplanetary mission planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05037v1' target='_blank'>LongViTU: Instruction Tuning for Long-Form Video Understanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rujie Wu, Xiaojian Ma, Hai Ci, Yue Fan, Yuxuan Wang, Haozhe Zhao, Qing Li, Yizhou Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 07:51:14</h6>
<p class='card-text'>This paper introduce LongViTU, a large-scale (~121k QA pairs, ~900h videos),
automatically generated dataset for long-form video understanding. We developed
a systematic approach that organizes videos into a hierarchical tree structure
and incorporates self-revision mechanisms to ensure high-quality QA pairs. Each
QA pair in LongViTU features: 1) long-term context (average certificate length
of 4.6 minutes); 2) rich knowledge and condensed reasoning (commonsense,
causality, planning, etc.); and 3) explicit timestamp labels for relevant
events. LongViTU also serves as a benchmark for instruction following in
long-form and streaming video understanding. We evaluate the open-source
state-of-the-art long video understanding model, LongVU, and the commercial
model, Gemini-1.5-Pro, on our benchmark. They achieve GPT-4 scores of 49.9 and
52.3, respectively, underscoring the substantial challenge posed by our
benchmark. Further supervised fine-tuning (SFT) on LongVU led to performance
improvements of 12.0% on our benchmark, 2.2% on the in-distribution (ID)
benchmark EgoSchema, 1.0%, 2.2% and 1.2% on the out-of-distribution (OOD)
benchmarks VideoMME (Long), WorldQA and OpenEQA, respectively. These outcomes
demonstrate LongViTU's high data quality and robust OOD generalizability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05014v1' target='_blank'>UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oleg Sautenkov, Yasheerah Yaqoot, Artem Lykov, Muhammad Ahsan Mustafa, Grik Tadevosyan, Aibek Akhmetkazy, Miguel Altamirano Cabrera, Mikhail Martynov, Sausar Karaf, Dzmitry Tsetserukou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 07:15:59</h6>
<p class='card-text'>The UAV-VLA (Visual-Language-Action) system is a tool designed to facilitate
communication with aerial robots. By integrating satellite imagery processing
with the Visual Language Model (VLM) and the powerful capabilities of GPT,
UAV-VLA enables users to generate general flight paths-and-action plans through
simple text requests. This system leverages the rich contextual information
provided by satellite images, allowing for enhanced decision-making and mission
planning. The combination of visual analysis by VLM and natural language
processing by GPT can provide the user with the path-and-action set, making
aerial operations more efficient and accessible. The newly developed method
showed the difference in the length of the created trajectory in 22% and the
mean error in finding the objects of interest on a map in 34.22 m by Euclidean
distance in the K-Nearest Neighbors (KNN) approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05006v1' target='_blank'>CHASE: A Native Relational Database for Hybrid Queries on Structured and
  Unstructured Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rui Ma, Kai Zhang, Zhenying He, Yinan Jing, X. Sean Wang, Zhenqiang Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 06:59:08</h6>
<p class='card-text'>Querying both structured and unstructured data has become a new paradigm in
data analytics and recommendation. With unstructured data, such as text and
videos, are converted to high-dimensional vectors and queried with approximate
nearest neighbor search (ANNS). State-of-the-art database systems implement
vector search as a plugin in the relational query engine, which tries to
utilize the ANN index to enhance performance. After investigating a broad range
of hybrid queries, we find that such designs may miss potential optimization
opportunities and achieve suboptimal performance for certain queries. In this
paper, we propose CHASE, a query engine that is natively designed to support
efficient hybrid queries on structured and unstructured data. CHASE performs
specific designs and optimizations on multiple stages in query processing.
First, semantic analysis is performed to categorize queries and optimize query
plans dynamically. Second, new physical operators are implemented to avoid
redundant computations, which is the case with existing operators. Third,
compilation-based techniques are adopted for efficient machine code generation.
Extensive evaluations using real-world datasets demonstrate that CHASE achieves
substantial performance improvements, with speedups ranging from 13% to an
extraordinary 7500 times compared to existing systems. These results highlight
CHASE's potential as a robust solution for executing hybrid queries.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05004v1' target='_blank'>A Fast Path-Planning Method for Continuous Harvesting of Table-Top Grown
  Strawberries</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhonghua Miao, Yang Chen, Lichao Yang, Shimin Hu, Ya Xiong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 06:56:44</h6>
<p class='card-text'>Continuous harvesting and storage of multiple fruits in a single operation
allow robots to significantly reduce the travel distance required for
repetitive back-and-forth movements. Traditional collision-free path planning
algorithms, such as Rapidly-Exploring Random Tree (RRT) and A-star (A), often
fail to meet the demands of efficient continuous fruit harvesting due to their
low search efficiency and the generation of excessive redundant points. This
paper presents the Interactive Local Minima Search Algorithm (ILMSA), a fast
path-planning method designed for the continuous harvesting of table-top grown
strawberries. The algorithm featured an interactive node expansion strategy
that iteratively extended and refined collision-free path segments based on
local minima points. To enable the algorithm to function in 3D, the 3D
environment was projected onto multiple 2D planes, generating optimal paths on
each plane. The best path was then selected, followed by integrating and
smoothing the 3D path segments. Simulations demonstrated that ILMSA
outperformed existing methods, reducing path length by 21.5% and planning time
by 97.1% compared to 3D-RRT, while achieving 11.6% shorter paths and 25.4%
fewer nodes than the Lowest Point of the Strawberry (LPS) algorithm in 3D
environments. In 2D, ILMSA achieved path lengths 16.2% shorter than A, 23.4%
shorter than RRT, and 20.9% shorter than RRT-Connect, while being over 96%
faster and generating significantly fewer nodes. Field tests confirmed ILMSA's
suitability for complex agricultural tasks, having a combined planning and
execution time and an average path length that were approximately 58% and 69%,
respectively, of those achieved by the LPS algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04988v1' target='_blank'>Intelligent Sailing Model for Open Sea Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanna Krasowski, Stefan Schärdinger, Murat Arcak, Matthias Althoff</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 06:01:34</h6>
<p class='card-text'>Autonomous vessels potentially enhance safety and reliability of seaborne
trade. To facilitate the development of autonomous vessels, high-fidelity
simulations are required to model realistic interactions with other vessels.
However, modeling realistic interactive maritime traffic is challenging due to
the unstructured environment, coarsely specified traffic rules, and largely
varying vessel types. Currently, there is no standard for simulating
interactive maritime environments in order to rigorously benchmark autonomous
vessel algorithms. In this paper, we introduce the first intelligent sailing
model (ISM), which simulates rule-compliant vessels for navigation on the open
sea. An ISM vessel reacts to other traffic participants according to maritime
traffic rules while at the same time solving a motion planning task
characterized by waypoints. In particular, the ISM monitors the applicable
rules, generates rule-compliant waypoints accordingly, and utilizes a model
predictive control for tracking the waypoints. We evaluate the ISM in two
environments: interactive traffic with only ISM vessels and mixed traffic where
some vessel trajectories are from recorded real-world maritime traffic data or
handcrafted for criticality. Our results show that simulations with many ISM
vessels of different vessel types are rule-compliant and scalable. We tested
4,049 critical traffic scenarios. For interactive traffic with ISM vessels, no
collisions occurred while goal-reaching rates of about 97 percent were
achieved. We believe that our ISM can serve as a standard for challenging and
realistic maritime traffic simulation to accelerate autonomous vessel
development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06255v1' target='_blank'>Progressive Supervision via Label Decomposition: An Long-Term and
  Large-Scale Wireless Traffic Forecasting Method</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daojun Liang, Haixia Zhang, Dongfeng Yuan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 03:35:00</h6>
<p class='card-text'>Long-term and Large-scale Wireless Traffic Forecasting (LL-WTF) is pivotal
for strategic network management and comprehensive planning on a macro scale.
However, LL-WTF poses greater challenges than short-term ones due to the
pronounced non-stationarity of extended wireless traffic and the vast number of
nodes distributed at the city scale. To cope with this, we propose a
Progressive Supervision method based on Label Decomposition (PSLD).
Specifically, we first introduce a Random Subgraph Sampling (RSS) algorithm
designed to sample a tractable subset from large-scale traffic data, thereby
enabling efficient network training. Then, PSLD employs label decomposition to
obtain multiple easy-to-learn components, which are learned progressively at
shallow layers and combined at deep layers to effectively cope with the
non-stationary problem raised by LL-WTF tasks. Finally, we compare the proposed
method with various state-of-the-art (SOTA) methods on three large-scale WT
datasets. Extensive experimental results demonstrate that the proposed PSLD
significantly outperforms existing methods, with an average 2%, 4%, and 11%
performance improvement on three WT datasets, respectively. In addition, we
built an open source library for WT forecasting (WTFlib) to facilitate related
research, which contains numerous SOTA methods and provides a strong
benchmark.Experiments can be reproduced through
https://github.com/Anoise/WTFlib.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04932v1' target='_blank'>The Catalogue of Virtual Early-Type Galaxies from IllustrisTNG:
  Validation and Real Observation Consistency</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pedro de Araujo Ferreira, Nicola R. Napolitano, Luciano Casarini, Crescenzo Tortora, Rodrigo von Marttens, Sirui Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-09 02:47:50</h6>
<p class='card-text'>Early-type galaxies (ETGs) are reference systems to understand galaxy
formation and evolution processes. The physics of their collapse and internal
dynamics are codified in well-known scaling relations. Cosmological
hydrodynamical simulations play an important role, providing insights into the
3D distribution of matter and galaxy formation mechanisms, as well as
validating methods to infer the properties of real objects. In this work, we
present the closest-to-reality sample of ETGs from the IllustrisTNG100-1
simulation, dubbed "virtual-ETGs," based on an observational-like algorithm
that combines standard projected and three-dimensional galaxy structural
parameters. We extract 2D photometric information by projecting the galaxies'
light into three planes and modeling them via S\'ersic profiles. Aperture
velocity dispersions, corrected for softened central dynamics, are calculated
along the line-of-sight orthogonal to the photometric projection plane. Central
mass density profiles assume a power-law model, while 3D masses remain
unmodified from the IllustrisTNG catalogue. The final catalogue includes
$10121$ galaxies at redshifts $z \leq 0.1$. By comparing the virtual properties
with observations, we find that the virtual-ETG scaling relations (e.g.,
size-mass, size-central surface brightness, and Faber-Jackson), central density
slopes, and scaling relations among total density slopes and galaxy structural
parameters are generally consistent with observations. We make the virtual-ETG
publicly available for galaxy formation studies and plan to use this sample as
a training set for machine learning tools to infer galaxy properties in future
imaging and spectroscopic surveys.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04839v1' target='_blank'>DRL-Based Medium-Term Planning of Renewable-Integrated Self-Scheduling
  Cascaded Hydropower to Guide Wholesale Market Participation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xianbang Chen, Yikui Liu, Neng Fan, Lei Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 20:57:14</h6>
<p class='card-text'>For self-scheduling cascaded hydropower (S-CHP) facilities, medium-term
planning is a critical step that coordinates water availability over the
medium-term horizon, providing water usage guidance for their short-term
operations in wholesale market participation. Typically, medium-term planning
strategies (e.g., reservoir storage targets at the end of each short-term
period) are determined by either optimization methods or rules of thumb.
However, with the integration of variable renewable energy sources (VRESs),
optimization-based methods suffer from deviations between the anticipated and
actual reservoir storage, while rules of thumb could be financially
conservative, thereby compromising short-term operating profitability in
wholesale market participation. This paper presents a deep reinforcement
learning (DRL)-based framework to derive medium-term planning policies for
VRES-integrated S-CHPs (VS-CHPs), which can leverage contextual information
underneath individual short-term periods and train planning policies by their
induced short-term operating profits in wholesale market participation. The
proposed DRL-based framework offers two practical merits. First, its planning
strategies consider both seasonal requirements of reservoir storage and needs
for short-term operating profits. Second, it adopts a multi-parametric
programming-based strategy to accelerate the expensive training process
associated with multi-step short-term operations. Finally, the DRL-based
framework is evaluated on a real-world VS-CHP, demonstrating its advantages
over current practice.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04830v1' target='_blank'>A Deep Learning-Based Method for Power System Resilience Evaluation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuesong Wang, Caisheng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 20:36:10</h6>
<p class='card-text'>Power systems are critical infrastructure in modern society, and power
outages can cause significant disruptions to communities and individuals' daily
lives. The resilience of a power system measures its ability to maintain power
supply during highly disruptive events such as hurricanes, earthquakes, and
thunderstorms. Traditional methods for quantifying power system resilience
include statistics-based and simulation-based approaches. Statistics-based
methods offer a retrospective analysis of system performance without requiring
a physical model, while simulation-based methods necessitate detailed physical
system information and often simplify real-world scenarios. This paper
introduces a deep learning-based method for evaluating power system resilience
using historical power outage data. The method leverages the generalization
capabilities of deep learning models and incorporates socio-economic and
demographic factors as weighting terms to highlight the impacts on vulnerable
demographic groups. The effectiveness of the proposed method is demonstrated
through two case studies: one with real historical outage data and the other
with simulated outage records. This approach provides valuable insights into
measuring power system resilience against hazardous weather events without
requiring a physical model of the target systems. The evaluation results can
further guide the planning of distributed energy resources for resilience
enhancement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04685v1' target='_blank'>Integrating IPbus ALFRED into the ALICE-FIT setup</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Krystian Roslon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 18:48:42</h6>
<p class='card-text'>The official data collection for the Run 3 of the Large Hadron Collider (LHC)
at CERN in Geneva commenced on July 5, 2022, following approximately three and
a half years of maintenance, upgrades, and commissioning. Among the many
upgrades to ALICE (A Large Ion Collider Experiment) is the new Fast Interaction
Trigger (FIT) detector. Constant improvements to FIT's hardware, firmware, and
software will enable progressively better performance. Between November 2024
and March 2025, during the year-end technical stop, an update to the
communication path between the Front-End Electronics (FEE) and the Detector
Control System (DCS) is planned. This update will introduce a new approach
based on the ALFRED (ALICE Low-Level Front-End Device) software, supported by
the central DCS ALICE system. To address the challenge of integrating custom
electronics with distributed control systems, this paper describes a novel
extension of the Front-End Device (FRED) framework, which can interface bespoke
electronics with standard SCADA (Supervisory Control and Data Acquisition)
systems using IPbus. This framework can be applied to all detectors utilizing
IPbus communication.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04578v1' target='_blank'>Analysis of Climatic Trends and Variability in Indian Topography</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ayush Prusty, Akshita Gupta, Vivek Ashok Bohara</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 15:47:30</h6>
<p class='card-text'>The climatic change is one of the serious concerns nowadays. The impacts of
climate change are global in scope and unprecedented in scale. Moreover, a
small perturbation in climatic changes affects not only the pristine ecosystem
but also the socioeconomic sectors. Specifically, the affect of climatic
changes is related to frequent casualties. This makes it essential to dwelve
deeper into analyzing the socio-climatic trends and variability. This work
provides a comprehensive analysis of India's climatic trends, emphasizing on
regional variations and specifically delving into the unique climate of Delhi.
Specifically, this research unveils the temporal and spatial variations in
temperature patterns by amalgamating extensive datasets encompassing India's
diverse landscapes. The study uses advanced statistical tools and methodologies
to scrutinize temperature's annual and seasonal variability. The insights drawn
from this rigorous analysis may offer invaluable contributions to regional
planning strategies, adaptive measures, and informed decision-making amidst the
complex impacts of climate change. By bridging the gap between broader climatic
trends and localized impacts, this research aims to facilitate more effective
measures to mitigate and adapt to the multifaceted challenges of climate
change, ensuring a more nuanced and tailored approaches. We utilized the
Mann-Kendall test and Theil-Sen's slope estimator to analyze the trends and
variability of the climatic conditions over the decades. The results
demonstrate that temperature variations have increased over 0.58oC on average
over the last decade. Moreover, over last decade the variability of Indian
states shows that Lakshadweep faced the highest change (0.87oC), highlighting
coastal vulnerability, while Tripura observed the least change of 0.07oC.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04459v1' target='_blank'>Rapid Automated Mapping of Clouds on Titan With Instance Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zachary Yahn, Douglas M Trent, Ethan Duncan, Benoît Seignovert, John Santerre, Conor Nixon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 12:30:06</h6>
<p class='card-text'>Despite widespread adoption of deep learning models to address a variety of
computer vision tasks, planetary science has yet to see extensive utilization
of such tools to address its unique problems. On Titan, the largest moon of
Saturn, tracking seasonal trends and weather patterns of clouds provides
crucial insights into one of the most complex climates in the Solar System, yet
much of the available image data are still analyzed in a conventional way. In
this work, we apply a Mask R-CNN trained via transfer learning to perform
instance segmentation of clouds in Titan images acquired by the Cassini
spacecraft - a previously unexplored approach to a big data problem in
planetary science. We demonstrate that an automated technique can provide
quantitative measures for clouds, such as areas and centroids, that may
otherwise be prohibitively time-intensive to produce by human mapping.
Furthermore, despite Titan specific challenges, our approach yields accuracy
comparable to contemporary cloud identification studies on Earth and other
worlds. We compare the efficiencies of human-driven versus algorithmic
approaches, showing that transfer learning provides speed-ups that may open new
horizons for data investigation for Titan. Moreover, we suggest that such
approaches have broad potential for application to similar problems in
planetary science where they are currently under-utilized. Future planned
missions to the planets and remote sensing initiatives for the Earth promise to
provide a deluge of image data in the coming years that will benefit strongly
from leveraging machine learning approaches to perform the analysis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04442v1' target='_blank'>A Survey on Path Planning Problem of Rolling Contacts: Approaches,
  Applications and Future Challenges</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seyed Amir Tafrishi, Mikhail Svinin, Kenji Tahara</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 11:46:43</h6>
<p class='card-text'>This paper explores an eclectic range of path-planning methodologies
engineered for rolling surfaces. Our focus is on the kinematic intricacies of
rolling contact systems, which are investigated through a motion planning lens.
Beyond summarizing the approaches to single-contact rotational surfaces, we
explore the challenging domain of spin-rolling multi-contact systems. Our work
proposes solutions for the higher-dimensional problem of multiple rotating
objects in contact. Venturing beyond kinematics, these methodologies find
application across a spectrum of domains, including rolling robots,
reconfigurable swarm robotics, micro/nano manipulation, and nonprehensile
manipulations. Through meticulously examining established planning strategies,
we unveil their practical implementations in various real-world scenarios, from
intricate dexterous manipulation tasks to the nimble manoeuvring of rolling
robots and even shape planning of multi-contact swarms of particles. This study
introduces the persistent challenges and unexplored frontiers of robotics,
intricately linked to both path planning and mechanism design. As we illuminate
existing solutions, we also set the stage for future breakthroughs in this
dynamic and rapidly evolving field by highlighting the critical importance of
addressing rolling contact problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04347v1' target='_blank'>Keyword Search in the Deep Web</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrea Calì, Davide Martinenghi, Riccardo Torlone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 08:42:51</h6>
<p class='card-text'>The Deep Web is constituted by data that are accessible through Web pages,
but not readily indexable by search engines as they are returned in dynamic
pages. In this paper we propose a conceptual framework for answering keyword
queries on Deep Web sources represented as relational tables with so-called
access limitations. We formalize the notion of optimal answer, characterize
queries for which an answer can be found, and present a method for query
processing based on the construction of a query plan that minimizes the
accesses to the data sources.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04290v1' target='_blank'>Research on the Interstellar Medium and Star Formation in the Galaxy: An
  Indian Perspective</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bhaswati Mookerjea, Maheswar G., Kinsuk Acharyya, Tapas Baug, Prasun Datta, Jessy Jose, D. K. Ojha, Jagadheep D. Pandian, Nirupam Roy, Manash Samal, Saurabh Sharma, Archana Soam, Sarita Vig, Ankan Das, Lokesh Dewangan, Somnath Dutta, C. Eswariah, Liton Majumdar, Kshitiz Kumar Mallick, Soumen Mondal, Joe P. Ninan, Neelam Panwar, Amit Pathak, Shantanu Rastogi, Dipen Sahu, Anandmayee Tej, Veena V. S</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 05:30:46</h6>
<p class='card-text'>Although the star formation process has been studied for decades, many
important aspects of the physics involved remain unsolved. Recent advancement
of instrumentation in the infrared, far-infrared and sub-millimetre wavelength
regimes have contributed to a significantly improved understanding of processes
in the interstellar medium (ISM) leading to star formation. The future of
research on the ISM and star formation looks exciting with instruments like the
JWST, ALMA, etc., already contributing to the topic by gathering
high-resolution high-sensitivity data and with several larger ground- and
space-bound facilities either being planned or constructed. India has a sizable
number of astronomers engaged in research on topics related to the ISM and star
formation. In this white paper invited by the Astronomical Society of India to
prepare a vision document for Indian astronomy, we review the Indian
contributions to the global understanding of the star formation process and
suggest areas that require focused efforts both in creating observing
facilities and in theoretical front in India, in order to improve the impact of
our research in the coming decades.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04279v1' target='_blank'>OpenIN: Open-Vocabulary Instance-Oriented Navigation in Dynamic Domestic
  Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yujie Tang, Meiling Wang, Yinan Deng, Zibo Zheng, Jingchuan Deng, Yufeng Yue</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 05:01:59</h6>
<p class='card-text'>In daily domestic settings, frequently used objects like cups often have
unfixed positions and multiple instances within the same category, and their
carriers frequently change as well. As a result, it becomes challenging for a
robot to efficiently navigate to a specific instance. To tackle this challenge,
the robot must capture and update scene changes and plans continuously.
However, current object navigation approaches primarily focus on the semantic
level and lack the ability to dynamically update scene representation. In
contrast, this paper captures the relationships between frequently used objects
and their static carriers. It constructs an open-vocabulary
Carrier-Relationship Scene Graph (CRSG) and updates the carrying status during
robot navigation to reflect the dynamic changes of the scene. Based on the
CRSG, we further propose an instance navigation strategy that models the
navigation process as a Markov Decision Process. At each step, decisions are
informed by the Large Language Model's commonsense knowledge and
visual-language feature similarity. We designed a series of long-sequence
navigation tasks for frequently used everyday items in the Habitat simulator.
The results demonstrate that by updating the CRSG, the robot can efficiently
navigate to moved targets. Additionally, we deployed our algorithm on a real
robot and validated its practical effectiveness. The project page can be found
here: https://OpenIN-nav.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04158v1' target='_blank'>Detecting rotation from lensing in the CMB</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Julien Carron, Enea di Dio, Ruth Durrer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 22:11:24</h6>
<p class='card-text'>An excellent estimate of the lensing signal is expected from the availability
of deep and high-resolution polarization data in the near future. This is most
important to allow for efficient delensing, needed to detect the primordial
B-mode power and with it the famous tensor-to-scalar ratio. Here we discuss in
a joint manner estimators of the rotation of polarization, of the second order
lensing field rotation, and standard gradient lensing reconstruction. All are
most efficient when able to probe the EB power created locally, have comparable
reconstruction noise in this regime, and can benefit substantially from
delensing. We discuss several ongoing and planned CMB experiments. We determine
their noise for lensing field rotation and polarization rotation and discuss
their prospects for measuring these effects. There is an on-going controversy
on whether the lensing field rotation also rotates the polarization -- if so
this will be observed at high significance soon with already on going
observations of the South Pole Telescope, SPT-3G, in cross-correlation with
tracers of large scale structure, as we show in this paper.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04143v1' target='_blank'>Linear Optimization for the Perfect Meal: A Data-Driven Approach to
  Optimising the Perfect Meal Using Gurobi</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Utkarsh Prajapati, Tanushree Jain, Abhishek Machiraju, Divyam Kaushik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 21:12:08</h6>
<p class='card-text'>This study aims to optimize meal planning for nutritional health and cost
efficiency using linear programming. Linear optimization provides an effective
framework for addressing the problem of an optimal diet, as the composition of
food can be naturally modeled as a linearly additive system. Leveraging a
comprehensive nutrition dataset, our model minimizes meal costs while meeting
specific nutritional requirements. We explore additional complexities, such as
fractional weights and nutrient ratio constraints, enhancing the robustness of
the solution. Case studies address common nutritional challenges, providing
tailored diet plans. The significance lies in aiding individuals to form
balanced, cost-effective dietary schedules, considering fitness goals and
caloric needs. This research contributes to efficient, sustainable, and
time-sensitive meal planning, emphasizing the intersection of nutrition,
optimization, and real-world applicability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04119v1' target='_blank'>The Preparation Status and Plan for the Next Physics Run of the NINJA
  Experiment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Naoki Otani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 19:59:33</h6>
<p class='card-text'>The NINJA experiment aims to precisely measure neutrino-nucleus interactions
using a nuclear emulsion detector to reduce systematic errors in neutrino
oscillation experiments. The nuclear emulsion has a sub-micron positional
resolution, enabling the detection of low-momentum charged particles such as
protons with a threshold of 200 MeV/c. In the NINJA experiment, a muon detector
placed downstream of the emulsion detector is used to identify muons from
$\nu_{\mu}$ charged-current interactions. The majority of the tracks
accumulated in the nuclear emulsion are from cosmic rays. Although the emulsion
detector provides highly accurate positional information, it lacks timing
information. Therefore, the positional resolution of the muon detector is not
enough to identify neutrino interaction tracks that match between the muon
detector and the emulsion detector from the enormous background of cosmic rays
recorded in the emulsion detector. To address this, a scintillation tracker is
used to provide both timing and positional information for the tracks.
  The NINJA experiment is planning a third physics run with about 130 kg water
target from the autumn of 2025 to the spring of 2026. Since the target mass is
larger than previous runs, a larger scintillation tracker covering 1.3 m
$\times$ 1.4 m is needed. We are developing a newly designed scintillation
tracker, consisting of a monolithic plastic scintillator plane including
scatterers.
  In this paper, we will show the preparation status and plan for the next
physics run, focusing particularly on the development of the new scintillation
tracker.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03907v2' target='_blank'>Implicit Coordination using Active Epistemic Inference for Multi-Robot
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lauren Bramblett, Jonathan Reasoner, Nicola Bezzo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 16:22:12</h6>
<p class='card-text'>A Multi-robot system (MRS) provides significant advantages for intricate
tasks such as environmental monitoring, underwater inspections, and space
missions. However, addressing potential communication failures or the lack of
communication infrastructure in these fields remains a challenge. A significant
portion of MRS research presumes that the system can maintain communication
with proximity constraints, but this approach does not solve situations where
communication is either non-existent, unreliable, or poses a security risk.
Some approaches tackle this issue using predictions about other robots while
not communicating, but these methods generally only permit agents to utilize
first-order reasoning, which involves reasoning based purely on their own
observations. In contrast, to deal with this problem, our proposed framework
utilizes Theory of Mind (ToM), employing higher-order reasoning by shifting a
robot's perspective to reason about a belief of others observations. Our
approach has two main phases: i) an efficient runtime plan adaptation using
active inference to signal intentions and reason about a robot's own belief and
the beliefs of others in the system, and ii) a hierarchical epistemic planning
framework to iteratively reason about the current MRS mission state. The
proposed framework outperforms greedy and first-order reasoning approaches and
is validated using simulations and experiments with heterogeneous robotic
systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03865v1' target='_blank'>Truthful mechanisms for linear bandit games with private contexts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiting Hu, Lingjie Duan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 15:24:53</h6>
<p class='card-text'>The contextual bandit problem, where agents arrive sequentially with personal
contexts and the system adapts its arm allocation decisions accordingly, has
recently garnered increasing attention for enabling more personalized outcomes.
However, in many healthcare and recommendation applications, agents have
private profiles and may misreport their contexts to gain from the system. For
example, in adaptive clinical trials, where hospitals sequentially recruit
volunteers to test multiple new treatments and adjust plans based on
volunteers' reported profiles such as symptoms and interim data, participants
may misreport severe side effects like allergy and nausea to avoid perceived
suboptimal treatments. We are the first to study this issue of private context
misreporting in a stochastic contextual bandit game between the system and
non-repeated agents. We show that traditional low-regret algorithms, such as
UCB family algorithms and Thompson sampling, fail to ensure truthful reporting
and can result in linear regret in the worst case, while traditional truthful
algorithms like explore-then-commit (ETC) and $\epsilon$-greedy algorithm incur
sublinear but high regret. We propose a mechanism that uses a linear program to
ensure truthfulness while minimizing deviation from Thompson sampling, yielding
an $O(\ln T)$ frequentist regret. Our numerical experiments further demonstrate
strong performance in multiple contexts and across other distribution families.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03841v1' target='_blank'>OmniManip: Towards General Robotic Manipulation via Object-Centric
  Interaction Primitives as Spatial Constraints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingjie Pan, Jiyao Zhang, Tianshu Wu, Yinghao Zhao, Wenlong Gao, Hao Dong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 14:50:33</h6>
<p class='card-text'>The development of general robotic systems capable of manipulating in
unstructured environments is a significant challenge. While Vision-Language
Models(VLM) excel in high-level commonsense reasoning, they lack the
fine-grained 3D spatial understanding required for precise manipulation tasks.
Fine-tuning VLM on robotic datasets to create Vision-Language-Action
Models(VLA) is a potential solution, but it is hindered by high data collection
costs and generalization issues. To address these challenges, we propose a
novel object-centric representation that bridges the gap between VLM's
high-level reasoning and the low-level precision required for manipulation. Our
key insight is that an object's canonical space, defined by its functional
affordances, provides a structured and semantically meaningful way to describe
interaction primitives, such as points and directions. These primitives act as
a bridge, translating VLM's commonsense reasoning into actionable 3D spatial
constraints. In this context, we introduce a dual closed-loop, open-vocabulary
robotic manipulation system: one loop for high-level planning through primitive
resampling, interaction rendering and VLM checking, and another for low-level
execution via 6D pose tracking. This design ensures robust, real-time control
without requiring VLM fine-tuning. Extensive experiments demonstrate strong
zero-shot generalization across diverse robotic manipulation tasks,
highlighting the potential of this approach for automating large-scale
simulation data generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03824v1' target='_blank'>Online Reinforcement Learning-Based Dynamic Adaptive Evaluation Function
  for Real-Time Strategy Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weilong Yang, Jie Zhang, Xunyun Liu, Yanqing Ye</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 14:36:33</h6>
<p class='card-text'>Effective evaluation of real-time strategy tasks requires adaptive mechanisms
to cope with dynamic and unpredictable environments. This study proposes a
method to improve evaluation functions for real-time responsiveness to
battle-field situation changes, utilizing an online reinforcement
learning-based dynam-ic weight adjustment mechanism within the real-time
strategy game. Building on traditional static evaluation functions, the method
employs gradient descent in online reinforcement learning to update weights
dynamically, incorporating weight decay techniques to ensure stability.
Additionally, the AdamW optimizer is integrated to adjust the learning rate and
decay rate of online reinforcement learning in real time, further reducing the
dependency on manual parameter tun-ing. Round-robin competition experiments
demonstrate that this method signifi-cantly enhances the application
effectiveness of the Lanchester combat model evaluation function, Simple
evaluation function, and Simple Sqrt evaluation function in planning algorithms
including IDABCD, IDRTMinimax, and Port-folio AI. The method achieves a notable
improvement in scores, with the en-hancement becoming more pronounced as the
map size increases. Furthermore, the increase in evaluation function
computation time induced by this method is kept below 6% for all evaluation
functions and planning algorithms. The pro-posed dynamic adaptive evaluation
function demonstrates a promising approach for real-time strategy task
evaluation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03819v1' target='_blank'>An innovative mixed reality approach for Robotics Surgery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gabriela Rus, Nadim Al Hajjar, Ionut Zima, Calin Vaida, Corina Radu, Damien Chablat, Andra Ciocan, Doina Pîslă</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 14:32:36</h6>
<p class='card-text'>Robotic-assisted procedures offer numerous advantages over traditional
approaches, including improved dexterity, reduced fatigue, minimized trauma,
and superior outcomes. However, the main challenge of these systems remains the
poor visualization and perception of the surgical field. The goal of this paper
is to provide an innovative approach concerning an application able to improve
the surgical procedures offering assistance in both preplanning and
intraoperative steps of the surgery. The system has been designed to offer a
better understanding of the patient through techniques that provide medical
images visualization, 3D anatomical structures perception and robotic planning.
The application was designed to be intuitive and user friendly, providing an
augmented reality experience through the Hololens 2 device. It was tested in
laboratory conditions, yielding positive results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03795v1' target='_blank'>Self-Adaptive ERP: Embedding NLP into Petri-Net creation and Model
  Matching</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ahmed Maged, Gamal Kassem</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 14:01:59</h6>
<p class='card-text'>Enterprise Resource Planning (ERP) consultants play a vital role in
customizing systems to meet specific business needs by processing large amounts
of data and adapting functionalities. However, the process is
resource-intensive, time-consuming, and requires continuous adjustments as
business demands evolve. This research introduces a Self-Adaptive ERP Framework
that automates customization using enterprise process models and system usage
analysis. It leverages Artificial Intelligence (AI) & Natural Language
Processing (NLP) for Petri nets to transform business processes into adaptable
models, addressing both structural and functional matching. The framework,
built using Design Science Research (DSR) and a Systematic Literature Review
(SLR), reduces reliance on manual adjustments, improving ERP customization
efficiency and accuracy while minimizing the need for consultants.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03744v2' target='_blank'>Hydrogen Network Expansion Planning considering the Chicken-and-egg
  Dilemma and Market Uncertainty</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sezen Ece Kayacık, Beste Basciftci, Albert H. Schrotenboer, Iris F. A. Vis, Evrim Ursavas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 12:38:21</h6>
<p class='card-text'>Green hydrogen is thought to be a game changer for reaching sustainability
targets. However, the transition to a green hydrogen economy faces a critical
challenge known as the `chicken-and-egg dilemma', wherein establishing a
hydrogen supply network relies on demand, while demand only grows with reliable
supply. In addition, as the hydrogen market is in the early stage, predicting
demand distributions is challenging due to lack of data availability. This
paper addresses these complex issues through a risk-averse framework with the
introduction of a distributionally robust hydrogen network expansion planning
problem under decision-dependent demand ambiguity. The problem optimizes
location and production capacity decisions of the suppliers considering the
moments of the stochastic hydrogen demand as a function of these investment
decisions. To obtain tractable representations of this problem, we derive two
different reformulations that consider continuous and discrete hydrogen demand
support sets under different forms of decision dependencies. To efficiently
solve the reformulations, we develop a tailored algorithm based on the
column-and-constraint generation approach, and enhance the computational
performance through solving the master problems to a relative optimality gap,
decomposing the subproblems, and integrating pre-generated columns and
constraints. To validate the effectiveness of our approach, we investigate a
real case study leveraging data from the "Hydrogen Energy Applications in
Valley Environments for Northern Netherlands (HEAVENN)" project. The results
reveal that considering the chicken-and-egg dilemma under uncertain hydrogen
market conditions leads to earlier and more diverse investments, providing
critical insights for policymakers based on the degree of decision dependency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03722v1' target='_blank'>Self-adaptive vision-language model for 3D segmentation of pulmonary
  artery and vein</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaotong Guo, Deqian Yang, Dan Wang, Haochen Zhao, Yuan Li, Zhilin Sui, Tao Zhou, Lijun Zhang, Yanda Meng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 12:03:02</h6>
<p class='card-text'>Accurate segmentation of pulmonary structures iscrucial in clinical
diagnosis, disease study, and treatment planning. Significant progress has been
made in deep learning-based segmentation techniques, but most require much
labeled data for training. Consequently, developing precise segmentation
methods that demand fewer labeled datasets is paramount in medical image
analysis. The emergence of pre-trained vision-language foundation models, such
as CLIP, recently opened the door for universal computer vision tasks.
Exploiting the generalization ability of these pre-trained foundation models on
downstream tasks, such as segmentation, leads to unexpected performance with a
relatively small amount of labeled data. However, exploring these models for
pulmonary artery-vein segmentation is still limited. This paper proposes a
novel framework called Language-guided self-adaptive Cross-Attention Fusion
Framework. Our method adopts pre-trained CLIP as a strong feature extractor for
generating the segmentation of 3D CT scans, while adaptively aggregating the
cross-modality of text and image representations. We propose a s pecially
designed adapter module to fine-tune pre-trained CLIP with a self-adaptive
learning strategy to effectively fuse the two modalities of embeddings. We
extensively validate our method on a local dataset, which is the largest
pulmonary artery-vein CT dataset to date and consists of 718 labeled data in
total. The experiments show that our method outperformed other state-of-the-art
methods by a large margin. Our data and code will be made publicly available
upon acceptance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03666v1' target='_blank'>Hybrid Machine Learning Model with a Constrained Action Space for
  Trajectory Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexander Fertig, Lakshman Balasubramanian, Michael Botsch</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 10:06:59</h6>
<p class='card-text'>Trajectory prediction is crucial to advance autonomous driving, improving
safety, and efficiency. Although end-to-end models based on deep learning have
great potential, they often do not consider vehicle dynamic limitations,
leading to unrealistic predictions. To address this problem, this work
introduces a novel hybrid model that combines deep learning with a kinematic
motion model. It is able to predict object attributes such as acceleration and
yaw rate and generate trajectories based on them. A key contribution is the
incorporation of expert knowledge into the learning objective of the deep
learning model. This results in the constraint of the available action space,
thus enabling the prediction of physically feasible object attributes and
trajectories, thereby increasing safety and robustness. The proposed hybrid
model facilitates enhanced interpretability, thereby reinforcing the
trustworthiness of deep learning methods and promoting the development of safe
planning solutions. Experiments conducted on the publicly available real-world
Argoverse dataset demonstrate realistic driving behaviour, with benchmark
comparisons and ablation studies showing promising results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03594v1' target='_blank'>InclusiViz: Visual Analytics of Human Mobility Data for Understanding
  and Mitigating Urban Segregation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Yu, Yifang Wang, Yongjun Zhang, Huamin Qu, Dongyu Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 07:50:36</h6>
<p class='card-text'>Urban segregation refers to the physical and social division of people, often
driving inequalities within cities and exacerbating socioeconomic and racial
tensions. While most studies focus on residential spaces, they often neglect
segregation across "activity spaces" where people work, socialize, and engage
in leisure. Human mobility data offers new opportunities to analyze broader
segregation patterns, encompassing both residential and activity spaces, but
challenges existing methods in capturing the complexity and local nuances of
urban segregation. This work introduces InclusiViz, a novel visual analytics
system for multi-level analysis of urban segregation, facilitating the
development of targeted, data-driven interventions. Specifically, we developed
a deep learning model to predict mobility patterns across social groups using
environmental features, augmented with explainable AI to reveal how these
features influence segregation. The system integrates innovative visualizations
that allow users to explore segregation patterns from broad overviews to
fine-grained detail and evaluate urban planning interventions with real-time
feedback. We conducted a quantitative evaluation to validate the model's
accuracy and efficiency. Two case studies and expert interviews with social
scientists and urban analysts demonstrated the system's effectiveness,
highlighting its potential to guide urban planning toward more inclusive
cities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03413v1' target='_blank'>SALT: Sales Autocompletion Linked Business Tables Dataset</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tassilo Klein, Clemens Biehl, Margarida Costa, Andre Sres, Jonas Kolk, Johannes Hoffart</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 22:20:02</h6>
<p class='card-text'>Foundation models, particularly those that incorporate Transformer
architectures, have demonstrated exceptional performance in domains such as
natural language processing and image processing. Adapting these models to
structured data, like tables, however, introduces significant challenges. These
difficulties are even more pronounced when addressing multi-table data linked
via foreign key, which is prevalent in the enterprise realm and crucial for
empowering business use cases. Despite its substantial impact, research
focusing on such linked business tables within enterprise settings remains a
significantly important yet underexplored domain. To address this, we introduce
a curated dataset sourced from an Enterprise Resource Planning (ERP) system,
featuring extensive linked tables. This dataset is specifically designed to
support research endeavors in table representation learning. By providing
access to authentic enterprise data, our goal is to potentially enhance the
effectiveness and applicability of models for real-world business contexts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03009v1' target='_blank'>Equipoise calibration of clinical trial design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fabio Rigat</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 13:36:18</h6>
<p class='card-text'>Statistical methods for clinical trial design are currently unable to rely on
a sufficiently precise and general definition of what is an adequately powered
study. Operationally, this definition is needed to ensure an alignment by
design between statistical significance and clinical interpretability. To
address this gap, this paper shows how to calibrate randomised trial designs to
establishing strong clinical equipoise imbalance. Among several equipoise
models, the least informed population distribution of the pre-trial odds of the
design hypotheses is recommended here as the most practical calibrator. Under
this model, primary analysis outcomes of common phase 3 superiority designs are
shown to provide at least 90% evidence of equipoise imbalance. Designs carrying
95% power at 5% false positive rate are shown to demonstrate even stronger
equipoise imbalance, providing an operational definition of a robustly powered
study. Equipoise calibration is then applied to design of clinical development
plans comprising randomised phase 2 and phase 3 studies. Development plans
using oncology clinical endpoints are shown to provide strong equipoise
imbalance when positive outcomes are observed in phase 2 and in phase 3.
Establishing equipoise imbalance on a statistical basis when a positive phase 2
is not confirmed in phase 3 is shown to require large sample sizes unlikely to
be associated with clinically meaningful effect sizes. Equipoise calibration is
proposed as an effective clinical trial methodology ensuring that the
statistical properties of clinical trial outcomes are clinically interpretable.
Strong equipoise imbalance is achieved for designs carrying 95% power at 5%
false positive rate, regardless of whether the primary outcome is positive or
negative. Sponsors should consider raising power of their designs beyond
current practice to achieve more conclusive results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02902v1' target='_blank'>Sim-to-Real Transfer for Mobile Robots with Reinforcement Learning: from
  NVIDIA Isaac Sim to Gazebo and Real ROS 2 Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sahar Salimpour, Jorge Peña-Queralta, Diego Paez-Granados, Jukka Heikkonen, Tomi Westerlund</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 10:26:16</h6>
<p class='card-text'>Unprecedented agility and dexterous manipulation have been demonstrated with
controllers based on deep reinforcement learning (RL), with a significant
impact on legged and humanoid robots. Modern tooling and simulation platforms,
such as NVIDIA Isaac Sim, have been enabling such advances. This article
focuses on demonstrating the applications of Isaac in local planning and
obstacle avoidance as one of the most fundamental ways in which a mobile robot
interacts with its environments. Although there is extensive research on
proprioception-based RL policies, the article highlights less standardized and
reproducible approaches to exteroception. At the same time, the article aims to
provide a base framework for end-to-end local navigation policies and how a
custom robot can be trained in such simulation environment. We benchmark
end-to-end policies with the state-of-the-art Nav2, navigation stack in Robot
Operating System (ROS). We also cover the sim-to-real transfer process by
demonstrating zero-shot transferability of policies trained in the Isaac
simulator to real-world robots. This is further evidenced by the tests with
different simulated robots, which show the generalization of the learned
policy. Finally, the benchmarks demonstrate comparable performance to Nav2,
opening the door to quick deployment of state-of-the-art end-to-end local
planners for custom robot platforms, but importantly furthering the
possibilities by expanding the state and action spaces or task definitions for
more complex missions. Overall, with this article we introduce the most
important steps, and aspects to consider, in deploying RL policies for local
path planning and obstacle avoidance with Isaac Sim training, Gazebo testing,
and ROS 2 for real-time inference in real robots. The code is available at
https://github.com/sahars93/RL-Navigation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02874v1' target='_blank'>Steering Flexible Linear Objects in Planar Environments by Two Robot
  Hands Using Euler's Elastica Solutions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aharon Levin, Elon Rimon, Amir Shapiro</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 09:35:36</h6>
<p class='card-text'>The manipulation of flexible objects such as cables, wires and fresh food
items by robot hands forms a special challenge in robot grasp mechanics. This
paper considers the steering of flexible linear objects in planar environments
by two robot hands. The flexible linear object, modeled as an elastic
non-stretchable rod, is manipulated by varying the gripping endpoint positions
while keeping equal endpoint tangents. The flexible linear object shape has a
closed form solution in terms of the grasp endpoint positions and tangents,
called Euler's elastica. This paper obtains the elastica solutions under the
optimal control framework, then uses the elastica solutions to obtain
closed-form criteria for non self-intersection, stability and obstacle
avoidance of the flexible linear object. The new tools are incorporated into a
planning scheme for steering flexible linear objects in planar environments
populated by sparsely spaced obstacles. The scheme is fully implemented and
demonstrated with detailed examples.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02863v2' target='_blank'>Beyond Pass or Fail: Multi-Dimensional Benchmarking of Foundation Models
  for Goal-based Mobile UI Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dezhi Ran, Mengzhou Wu, Hao Yu, Yuetong Li, Jun Ren, Yuan Cao, Xia Zeng, Haochuan Lu, Zexin Xu, Mengqian Xu, Ting Su, Liangchao Yao, Ting Xiong, Wei Yang, Yuetang Deng, Assaf Marron, David Harel, Tao Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 09:10:11</h6>
<p class='card-text'>Recent advances of foundation models (FMs) have made navigating mobile
applications (apps) based on high-level goal instructions within reach, with
significant industrial applications such as UI testing. While existing
benchmarks evaluate FM-based UI navigation using the binary pass/fail metric,
they have two major limitations: they cannot reflect the complex nature of
mobile UI navigation where FMs may fail for various reasons (e.g.,
misunderstanding instructions and failed planning), and they lack industrial
relevance due to oversimplified tasks that poorly represent real-world
scenarios. To address the preceding limitations, we propose Sphinx, a
comprehensive benchmark for multi-dimensional evaluation of FMs in industrial
settings of UI navigation. Sphinx introduces a specialized toolkit that
evaluates five essential FM capabilities, providing detailed insights into
failure modes such as insufficient app knowledge or planning issues. Using both
popular Google Play applications and WeChat's internal UI test cases, we
evaluate 8 FMs with 20 different configurations. Our results show that existing
FMs universally struggle with goal-based testing tasks, primarily due to
insufficient UI-specific capabilities. We summarize seven lessons learned from
benchmarking FMs with Sphinx, providing clear directions for improving FM-based
mobile UI navigation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02856v1' target='_blank'>How to build an Open Science Monitor based on publications? A French
  perspective</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Laetitia Bracco, Eric Jeangirard, Anne L'Hôte, Laurent Romary</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 09:03:01</h6>
<p class='card-text'>Many countries and institutions are striving to develop tools to monitor
their open science policies. Since 2018, with the launch of its National Plan
for Open Science, France has been progressively implementing a monitoring
framework for its public policy, relying exclusively on reliable, open, and
controlled data. Currently, this monitoring focuses on research outputs,
particularly publications, as well as theses and clinical trials. Publications
serve as a basis for analyzing other dimensions, including research data, code,
and software. The metadata associated with publications is therefore
particularly valuable, but the methodology for leveraging it raises several
challenges. Here, we briefly outline how we have used this metadata to
construct the French Open Science Monitor.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02811v1' target='_blank'>First-place Solution for Streetscape Shop Sign Recognition Competition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bin Wang, Li Jing</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 07:20:36</h6>
<p class='card-text'>Text recognition technology applied to street-view storefront signs is
increasingly utilized across various practical domains, including map
navigation, smart city planning analysis, and business value assessments in
commercial districts. This technology holds significant research and commercial
potential. Nevertheless, it faces numerous challenges. Street view images often
contain signboards with complex designs and diverse text styles, complicating
the text recognition process. A notable advancement in this field was
introduced by our team in a recent competition. We developed a novel multistage
approach that integrates multimodal feature fusion, extensive self-supervised
training, and a Transformer-based large model. Furthermore, innovative
techniques such as BoxDQN, which relies on reinforcement learning, and text
rectification methods were employed, leading to impressive outcomes.
Comprehensive experiments have validated the effectiveness of these methods,
showcasing our potential to enhance text recognition capabilities in complex
urban environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02803v1' target='_blank'>Enhancing Lifelong Multi-Agent Path Finding with Cache Mechanism</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yimin Tang, Zhenghong Yu, Yi Zheng, T. K. Satish Kumar, Jiaoyang Li, Sven Koenig</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 06:44:13</h6>
<p class='card-text'>Multi-Agent Path Finding (MAPF), which focuses on finding collision-free
paths for multiple robots, is crucial in autonomous warehouse operations.
Lifelong MAPF (L-MAPF), where agents are continuously reassigned new targets
upon completing their current tasks, offers a more realistic approximation of
real-world warehouse scenarios. While cache storage systems can enhance
efficiency and reduce operational costs, existing approaches primarily rely on
expectations and mathematical models, often without adequately addressing the
challenges of multi-robot planning and execution. In this paper, we introduce a
novel mechanism called Lifelong MAPF with Cache Mechanism (L-MAPF-CM), which
integrates high-level cache storage with low-level path planning. We have
involved a new type of map grid called cache for temporary item storage.
Additionally, we involved a task assigner (TA) with a locking mechanism to
bridge the gap between the new cache grid and L-MAPF algorithm. The TA
dynamically allocates target locations to agents based on their status in
various scenarios. We evaluated L-MAPF-CM using different cache replacement
policies and task distributions. L-MAPF-CM has demonstrated performance
improvements particularly with high cache hit rates and smooth traffic
conditions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02770v2' target='_blank'>Multi-Agent Path Finding under Limited Communication Range Constraint
  via Dynamic Leading</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hoang-Dung Bui, Erion Plaku, Gregoy J. Stein</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 05:21:18</h6>
<p class='card-text'>This paper proposes a novel framework to handle a multi-agent path finding
problem under a limited communication range constraint, where all agents must
have a connected communication channel to the rest of the team. Many existing
approaches to multi-agent path finding (e.g., leader-follower platooning)
overcome computational challenges of planning in this domain by planning one
agent at a time in a fixed order. However, fixed leader-follower approaches can
become stuck during planning, limiting their practical utility in dense-clutter
environments. To overcome this limitation, we develop dynamic leading
multi-agent path finding, which allows for dynamic reselection of the leading
agent during path planning whenever progress cannot be made. The experiments
show the efficiency of our framework, which can handle up to 25 agents with
more than 90% success-rate across five environment types where baselines
routinely fail.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03287v1' target='_blank'>OpenLKA: an open dataset of lane keeping assist from market autonomous
  vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuhang Wang, Abdulaziz Alhuraish, Shengming Yuan, Shuyi Wang, Hao Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 04:46:10</h6>
<p class='card-text'>The Lane Keeping Assist (LKA) system has become a standard feature in recent
car models. While marketed as providing auto-steering capabilities, the
system's operational characteristics and safety performance remain
underexplored, primarily due to a lack of real-world testing and comprehensive
data. To fill this gap, we extensively tested mainstream LKA systems from
leading U.S. automakers in Tampa, Florida. Using an innovative method, we
collected a comprehensive dataset that includes full Controller Area Network
(CAN) messages with LKA attributes, as well as video, perception, and lateral
trajectory data from a high-quality front-facing camera equipped with advanced
vision detection and trajectory planning algorithms. Our tests spanned diverse,
challenging conditions, including complex road geometry, adverse weather,
degraded lane markings, and their combinations. A vision language model (VLM)
further annotated the videos to capture weather, lighting, and traffic
features. Based on this dataset, we present an empirical overview of LKA's
operational features and safety performance. Key findings indicate: (i) LKA is
vulnerable to faint markings and low pavement contrast; (ii) it struggles in
lane transitions (merges, diverges, intersections), often causing unintended
departures or disengagements; (iii) steering torque limitations lead to
frequent deviations on sharp turns, posing safety risks; and (iv) LKA systems
consistently maintain rigid lane-centering, lacking adaptability on tight
curves or near large vehicles such as trucks. We conclude by demonstrating how
this dataset can guide both infrastructure planning and self-driving
technology. In view of LKA's limitations, we recommend improvements in road
geometry and pavement maintenance. Additionally, we illustrate how the dataset
supports the development of human-like LKA systems via VLM fine-tuning and
Chain of Thought reasoning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03285v1' target='_blank'>Modelling noise in gravitational-wave observatories with
  transdimensional models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nir Guttman, Paul D. Lasky, Eric Thrane</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 03:45:57</h6>
<p class='card-text'>Modeling noise in gravitational-wave observatories is crucial for accurately
inferring the properties of gravitational-wave sources. We introduce a
transdimensional Bayesian approach to characterise the noise in ground-based
gravitational-wave observatories using the Bayesian inference software
$\texttt{Bilby}$. The algorithm models broadband noise with a combination of
power laws; narrowband features with Lorentzians; and shapelets to capture any
additional features in the data. We show that our noise model provides a
significantly improved fit of the LIGO and Virgo noise amplitude spectral
densities compared to currently available noise fits obtained with on-source
data segments. We perform astrophysical inference on well-known events in the
third Gravitational-Wave Transient Catalog using our noise model and observe
shifts of up to $7\%$ in the $90\%$ boundaries of credible intervals for some
parameters. We discuss plans to deploy this framework systematically for
gravitational-wave inference along with possible areas of improvement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02718v1' target='_blank'>Multi-Transmission Node DER Aggregation: Chance-Constrained Unit
  Commitment with Bounded Hetero-Dimensional Mixture Model for Uncertain
  Distribution Factors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weilun Wang, Zhentong Shao, Yikui Liu, Brent Eldridge, Abhishek Somani, Jesse T. Holzer, Lei Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 02:15:41</h6>
<p class='card-text'>To facilitate the integration of distributed energy resources (DERs) into the
wholesale market while maintaining the tractability of associated market
operation tools such as unit commitment (UC), existing DER aggregation (DERA)
studies usually consider that each DERA is presented on a single node of the
transmission network. Nevertheless, the increasing scale and geographical
distribution of DERs spur the emergence of DERAs covering multiple transmission
nodes, posing new challenges in modeling such multi-transmission-node DERAs
(M-DERAs). Indeed, assessing the aggregated impact of an M-DERA on power flows
is a non-trivial task, because the sensitivities of each transmission line to
DERs at different transmission nodes are not identical. Inspired by the
distribution factor (DF) based shift factor (SF) aggregation strategy in
industry practice, this paper proposes a novel DF-based chance-constrained UC
(CCUC) model to determine system optimal operation plans with M-DERAs. DFs,
treated as uncertain parameters to describe possible responses of DERs against
aggregated dispatch instructions from regional transmission organizations, are
modeled via a bounded hetero-dimensional mixture model (BHMM) by leveraging
historical DF records distributed on multiple hyperplanes in a bounded space.
With this, power flow limits are modeled as chance constraints in CCUC, which
is reformulated into a scenarios-based stochastic form and solved by Benders
decomposition. The proposed method is tested on an IEEE 24-bus system to
illustrate its effectiveness in managing M-DERA integration while ensuring
operational economics and mitigating the overloading of transmission lines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03283v1' target='_blank'>High count rate effects in event processing for XRISM/Resolve x-ray
  microcalorimeter: I. Ground test</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Misaki Mizumoto, Tsubasa Tamba, Masahiro Tsujimoto, Renata S. Cumbee, Megan E. Eckart, Edmund Hodges-Kluck, Yoshitaka Ishisaki, Caroline A. Kilbourne, Maurice A. Leutenegger, Frederick S. Porter, Makoto Sawada, Yoh Takei, Yuusuke Uchida, Shin'ya Yamada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 02:14:47</h6>
<p class='card-text'>The spectroscopic performance of an X-ray microcalorimeter is compromised at
high count rates. In this study, we utilize the Resolve X-ray microcalorimeter
onboard the XRISM satellite to examine the effects observed during high count
rate measurements and propose modeling approaches to mitigate them. We
specifically address the following instrumental effects that impact
performance: CPU limit, pile-up, and untriggered electrical cross talk.
Experimental data at high count rates were acquired during ground testing using
the flight model instrument and a calibration X-ray source. In the experiment,
data processing not limited by the performance of the onboard CPU was run in
parallel, which cannot be done in orbit. This makes it possible to access the
data degradation caused by limited CPU performance. We use these data to
develop models that allow for a more accurate estimation of the aforementioned
effects. To illustrate the application of these models in observation planning,
we present a simulated observation of GX 13+1. Understanding and addressing
these issues is crucial to enhancing the reliability and precision of X-ray
spectroscopy in situations characterized by elevated count rates.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02709v1' target='_blank'>Horizon Generalization in Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vivek Myers, Catherine Ji, Benjamin Eysenbach</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 01:42:46</h6>
<p class='card-text'>We study goal-conditioned RL through the lens of generalization, but not in
the traditional sense of random augmentations and domain randomization. Rather,
we aim to learn goal-directed policies that generalize with respect to the
horizon: after training to reach nearby goals (which are easy to learn), these
policies should succeed in reaching distant goals (which are quite challenging
to learn). In the same way that invariance is closely linked with
generalization is other areas of machine learning (e.g., normalization layers
make a network invariant to scale, and therefore generalize to inputs of
varying scales), we show that this notion of horizon generalization is closely
linked with invariance to planning: a policy navigating towards a goal will
select the same actions as if it were navigating to a waypoint en route to that
goal. Thus, such a policy trained to reach nearby goals should succeed at
reaching arbitrarily-distant goals. Our theoretical analysis proves that both
horizon generalization and planning invariance are possible, under some
assumptions. We present new experimental results and recall findings from prior
work in support of our theoretical results. Taken together, our results open
the door to studying how techniques for invariance and generalization developed
in other areas of machine learning might be adapted to achieve this alluring
property.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02667v1' target='_blank'>Markov Decision Processes for Satellite Maneuver Planning and Collision
  Avoidance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:William Kuhl, Jun Wang, Duncan Eddy, Mykel Kochenderfer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-05 21:26:11</h6>
<p class='card-text'>This paper presents a decentralized, online planning approach for scalable
maneuver planning for large constellations. While decentralized, rule-based
strategies have facilitated efficient scaling, optimal decision-making
algorithms for satellite maneuvers remain underexplored. As commercial
satellite constellations grow, there are benefits of online maneuver planning,
such as using real-time trajectory predictions to improve state knowledge,
thereby reducing maneuver frequency and conserving fuel. We address this gap in
the research by treating the satellite maneuver planning problem as a Markov
decision process (MDP). This approach enables the generation of optimal
maneuver policies online with low computational cost. This formulation is
applied to the low Earth orbit collision avoidance problem, considering the
problem of an active spacecraft deciding to maneuver to avoid a
non-maneuverable object. We test the policies we generate in a simulated low
Earth orbit environment, and compare the results to traditional rule-based
collision avoidance techniques.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02652v2' target='_blank'>A View of the Certainty-Equivalence Method for PAC RL as an Application
  of the Trajectory Tree Method</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shivaram Kalyanakrishnan, Sheel Shah, Santhosh Kumar Guguloth</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-05 20:37:34</h6>
<p class='card-text'>Reinforcement learning (RL) enables an agent interacting with an unknown MDP
$M$ to optimise its behaviour by observing transitions sampled from $M$. A
natural entity that emerges in the agent's reasoning is $\widehat{M}$, the
maximum likelihood estimate of $M$ based on the observed transitions. The
well-known \textit{certainty-equivalence} method (CEM) dictates that the agent
update its behaviour to $\widehat{\pi}$, which is an optimal policy for
$\widehat{M}$. Not only is CEM intuitive, it has been shown to enjoy
minimax-optimal sample complexity in some regions of the parameter space for
PAC RL with a generative model~\citep{Agarwal2020GenModel}.
  A seemingly unrelated algorithm is the ``trajectory tree method''
(TTM)~\citep{Kearns+MN:1999}, originally developed for efficient decision-time
planning in large POMDPs. This paper presents a theoretical investigation that
stems from the surprising finding that CEM may indeed be viewed as an
application of TTM. The qualitative benefits of this view are (1) new and
simple proofs of sample complexity upper bounds for CEM, in fact under a (2)
weaker assumption on the rewards than is prevalent in the current literature.
Our analysis applies to both non-stationary and stationary MDPs.
Quantitatively, we obtain (3) improvements in the sample-complexity upper
bounds for CEM both for non-stationary and stationary MDPs, in the regime that
the ``mistake probability'' $\delta$ is small. Additionally, we show (4) a
lower bound on the sample complexity for finite-horizon MDPs, which establishes
the minimax-optimality of our upper bound for non-stationary MDPs in the
small-$\delta$ regime.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02465v1' target='_blank'>EOG Communication Interface for Quadriplegics: Prototype & Signal
  Processing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aniket Raj, Amit Kumar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-05 07:24:27</h6>
<p class='card-text'>Electrooculography (EOG) is an electrophysiological signal that determines
the human eye orientation and is therefore widely used in Human Tracking
Interfaces (HCI). The purpose of this project is to develop a communication
method for quadriplegic patients using EOG signals aimed at text and voice
generation. The system consists of 3D eye movement tracking embedded using a
custom-built prototype to measure the eyeball's left-right and up-down
movements. The ESP32 board, which has a set of parameters to convert the data
into content displayed on LCDs and MP3 players, is used to capture and process
the signal. helps people by facilitating more natural and efficient symptom
expression. The blink system will be able to incorporate face masks and more
eye tests as it continues to develop. Even if it might work, more research and
clinical trials are needed to evaluate the system's usefulness and ensure that
it performs as planned in real-world scenarios. With this project, assistive
technology will make significant progress and improve the lives of many who
suffer from severe motor impairments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02460v2' target='_blank'>Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large
  Language Models in Medical Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhe Chen, Yusheng Liao, Shuyang Jiang, Pingjie Wang, Yiqiu Guo, Yanfeng Wang, Yu Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-05 07:03:14</h6>
<p class='card-text'>Large language models hold promise for addressing medical challenges, such as
medical diagnosis reasoning, research knowledge acquisition, clinical
decision-making, and consumer health inquiry support. However, they often
generate hallucinations due to limited medical knowledge. Incorporating
external knowledge is therefore critical, which necessitates multi-source
knowledge acquisition. We address this challenge by framing it as a source
planning problem, which is to formulate context-appropriate queries tailored to
the attributes of diverse sources. Existing approaches either overlook source
planning or fail to achieve it effectively due to misalignment between the
model's expectation of the sources and their actual content. To bridge this
gap, we present MedOmniKB, a repository comprising multigenre and
multi-structured medical knowledge sources. Leveraging these sources, we
propose the Source Planning Optimisation method, which enhances multi-source
utilisation. Our approach involves enabling an expert model to explore and
evaluate potential plans while training a smaller model to learn source
alignment. Experimental results demonstrate that our method substantially
improves multi-source planning performance, enabling the optimised small model
to achieve state-of-the-art results in leveraging diverse medical knowledge
sources.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02453v1' target='_blank'>Blockage-Aware UAV-Assisted Wireless Data Harvesting With Building
  Avoidance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gitae Park, Kanghyun Heo, Kisong Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-05 06:26:53</h6>
<p class='card-text'>Unmanned aerial vehicles (UAVs) offer dynamic trajectory control, enabling
them to avoid obstacles and establish line-of-sight (LoS) wireless channels
with ground nodes (GNs), unlike traditional ground-fixed base stations. This
study addresses the joint optimization of scheduling and three-dimensional (3D)
trajectory planning for UAV-assisted wireless data harvesting. The objective is
to maximize the minimum uplink throughput among GNs while accounting for signal
blockages and building avoidance. To achieve this, we first present
mathematical models designed to avoid cuboid-shaped buildings and to determine
wireless signal blockage by buildings through rigorous mathematical proof. The
optimization problem is formulated as nonconvex mixed-integer nonlinear
programming and solved using advanced techniques. Specifically, the problem is
decomposed into convex subproblems via quadratic transform and successive
convex approximation. Building avoidance and signal blockage constraints are
incorporated using the separating hyperplane method and an approximated
indicator function. These subproblems are then iteratively solved using the
block coordinate descent algorithm. Simulation results validate the
effectiveness of the proposed approach. The UAV dynamically adjusts its
trajectory and scheduling policy to maintain LoS channels with GNs,
significantly enhancing network throughput compared to existing schemes.
Moreover, the trajectory of the UAV adheres to building avoidance constraints
for its continuous trajectory, ensuring uninterrupted operation and compliance
with safety requirements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02357v1' target='_blank'>Predicting the cryogenic performance of superconducting detectors by
  their visual properties</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:K. R. Ferguson, A. N. Bender, N. Whitehorn, P. S. Barry, T. W. Cecil, K. R. Dibert, E. S Martsen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-04 18:41:14</h6>
<p class='card-text'>The testing and quality assurance of cryogenic superconducting detectors is a
time- and labor-intensive process. As experiments deploy increasingly larger
arrays of detectors, new methods are needed for performing this testing
quickly. Here, we propose a process for flagging under-performing detector
wafers before they are ever tested cryogenically. Detectors are imaged under an
optical microscope, and computer vision techniques are used to analyze the
images, searching for visual defects and other predictors of poor performance.
Pipeline performance is verified via a suite of images with simulated defects,
yielding a detection accuracy of 98.6%. Lastly, results from running the
pipeline on prototype microwave kinetic inductance detectors from the planned
SPT-3G+ experiment are presented.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02325v1' target='_blank'>Revisiting Compactness for District Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kristopher Tapp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-04 16:13:08</h6>
<p class='card-text'>Modern sampling methods create ensembles of district maps that score well on
discrete compactness scores, whereas the Polsby-Popper and other shape-based
scores remain highly relevant for building fair maps and litigating unfair
ones. The aim of this paper is twofold. First, we introduce population-weighted
versions of shape-based scores and show a precise sense in which this
interpolates between shape-based and discrete scores. Second, we introduce a
modification of the ReCom sampling method that produces ensembles of maps with
improved shape-based compactness scores.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02299v1' target='_blank'>The parenthood effect in urban mobility</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mariana Macedo, Ronaldo Menezes, Alessio Cardillo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-04 14:37:06</h6>
<p class='card-text'>The modelling of human mobility is vital for the understanding of the
complexity of urban dynamics and guiding effective interventions to improve
quality of life. Traditional modelling approaches focus on `average citizens,'
which overlook the multitude of experiences from distinct sociodemographic
groups. Recent studies have unveiled significant variations in mobility
patterns related to gender and socioeconomic status, yet the impact of
parenthood remains under-explored. Parenthood brings profound changes to daily
routines, influenced by factors such as increased caregiving responsibilities,
altered work-life balance, and the need for family-friendly environments.
Parents often prioritise considerations such as cost of living, social
wellbeing, environmental quality, and safety. Quantifying how `friendly' a city
is becomes more and more important for parents, especially in the context of
rising remote work opportunities which, in turn, reverberate on the choices on
where to settle. This work investigates whether these considerations lead to
distinct mobility patterns between parents and non-parents, also accounting for
the impact of partnership. Using extensive census data across American cities,
we analyse how parenthood and partnership reshape their urban experiences. Our
findings indicate that cities can indeed be classified by their level of
friendliness towards parents and partners. For example, Dallas and Nashville
can be more suited for single individuals, New York and Chicago can be more
accommodating to parents, while Washington and Baltimore favour married people.
These insights contribute to the growing body of research advocating for more
nuanced and equitable urban planning. By recognising the diverse needs of
different demographic groups, particularly parents, our study underscores the
importance of tailored urban design strategies over universal solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02287v1' target='_blank'>Deep Learning-Driven Segmentation of Ischemic Stroke Lesions Using
  Multi-Channel MRI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ashiqur Rahman, Muhammad E. H. Chowdhury, Md Sharjis Ibne Wadud, Rusab Sarmun, Adam Mushtak, Sohaib Bassam Zoghoul, Israa Al-Hashimi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-04 13:38:06</h6>
<p class='card-text'>Ischemic stroke, caused by cerebral vessel occlusion, presents substantial
challenges in medical imaging due to the variability and subtlety of stroke
lesions. Magnetic Resonance Imaging (MRI) plays a crucial role in diagnosing
and managing ischemic stroke, yet existing segmentation techniques often fail
to accurately delineate lesions. This study introduces a novel deep
learning-based method for segmenting ischemic stroke lesions using
multi-channel MRI modalities, including Diffusion Weighted Imaging (DWI),
Apparent Diffusion Coefficient (ADC), and enhanced Diffusion Weighted Imaging
(eDWI). The proposed architecture integrates DenseNet121 as the encoder with
Self-Organized Operational Neural Networks (SelfONN) in the decoder, enhanced
by Channel and Space Compound Attention (CSCA) and Double
Squeeze-and-Excitation (DSE) blocks. Additionally, a custom loss function
combining Dice Loss and Jaccard Loss with weighted averages is introduced to
improve model performance. Trained and evaluated on the ISLES 2022 dataset, the
model achieved Dice Similarity Coefficients (DSC) of 83.88% using DWI alone,
85.86% with DWI and ADC, and 87.49% with the integration of DWI, ADC, and eDWI.
This approach not only outperforms existing methods but also addresses key
limitations in current segmentation practices. These advancements significantly
enhance diagnostic precision and treatment planning for ischemic stroke,
providing valuable support for clinical decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02271v1' target='_blank'>Securing Integrated Sensing and Communication Against a Mobile
  Adversary: A Stackelberg Game with Deep Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Milad Tatar Mamaghani, Xiangyun Zhou, Nan Yang, A. Lee Swindlehurst</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-04 12:18:41</h6>
<p class='card-text'>In this paper, we study a secure integrated sensing and communication (ISAC)
system employing a full-duplex base station with sensing capabilities against a
mobile proactive adversarial target$\unicode{x2014}$a malicious unmanned aerial
vehicle (M-UAV). We develop a game-theoretic model to enhance communication
security, radar sensing accuracy, and power efficiency. The interaction between
the legitimate network and the mobile adversary is formulated as a
non-cooperative Stackelberg game (NSG), where the M-UAV acts as the leader and
strategically adjusts its trajectory to improve its eavesdropping ability while
conserving power and avoiding obstacles. In response, the legitimate network,
acting as the follower, dynamically allocates resources to minimize network
power usage while ensuring required secrecy rates and sensing performance. To
address this challenging problem, we propose a low-complexity successive convex
approximation (SCA) method for network resource optimization combined with a
deep reinforcement learning (DRL) algorithm for adaptive M-UAV trajectory
planning through sequential interactions and learning. Simulation results
demonstrate the efficacy of the proposed method in addressing security
challenges of dynamic ISAC systems in 6G, i.e., achieving a Stackelberg
equilibrium with robust performance while mitigating the adversary's ability to
intercept network signals.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02210v1' target='_blank'>Vulnerability Liquefaction Mapping in Padang City Based on Cloud
  Computing Using Optical Satellite Imagery Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pakhrur Razi, Amalia Putri, Josaphat Tetuko Sri Sumantyo, Akmam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-04 06:36:27</h6>
<p class='card-text'>Liquefaction is a significant geological hazard in earthquake-prone locations
like Padang City, Indonesia. The phenomenon happens when saturated soil loses
strength owing to seismic shaking, resulting in substantial infrastructure
damage. Accurate identification of sensitive locations is critical to
catastrophe mitigation. This study aims to map water distribution using optical
satellite data and estimate its importance as a crucial element in determining
liquefaction vulnerability. The Normalized Difference Water Index (NDWI) was
used to assess water and vegetation indexes, taking advantage of its
sensitivity to water content in varied land surfaces. We recommended using the
NIR (near-infrared) and SWIR (short wave infrared) bands with 832.8 nm and
2202.4 nm, respectively, which are sensitive to soil water content.
High-resolution satellite data were used to create NDWI maps, highlighting
locations with high water saturation. These findings were combined with
geological and seismic data to identify liquefaction-prone zones. The study
found that locations with high water content, as measured by NDWI, are highly
associated with greater liquefaction susceptibility. The findings highlight the
importance of water distribution in determining soil behavior during seismic
occurrences. This study highlights the value of NDWI as a low-cost and
efficient tool for measuring liquefaction vulnerability at the regional level.
The technique offers insights into Padang City's urban planning, catastrophe
risk reduction, and community preparedness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14782v1' target='_blank'>Localization of Seizure Onset Zone based on Spatio-Temporal Independent
  Component Analysis on fMRI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seyyed Mostafa Sadjadi, Elias Ebrahimzadeh, Alireza Fallahi, Jafar Mehvari Habibabadi, Mohammad-Reza Nazem-Zadeh, Hamid Soltanian-Zadeh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 22:39:02</h6>
<p class='card-text'>Localizing the seizure onset zone (SOZ) as a step of presurgical planning
leads to higher efficiency in surgical and stimulation treatments. However, the
clinical localization including structural, ictal, and invasive data
acquisition and assessment is a difficult and long procedure with increasing
challenges in patients with complex epileptic foci. The interictal methods are
proposed to assist in presurgical planning with simpler data acquisition and
higher speed. This study presents a spatiotemporal component classification for
the localization of epileptic foci using resting-state functional magnetic
resonance imaging data. This method is based on spatiotemporal independent
component analysis on rsfMRI with a component-sorting procedure upon dominant
power frequency, biophysical constraints, spatial lateralization, local
connectivity, temporal energy, and functional non-Gaussianity. This method
utilized the rs-fMRI potential to reach a high spatial accuracy in localizing
epileptic foci from interictal data while retaining the reliability of results
for clinical usage. Thirteen patients with temporal lobe epilepsy who underwent
surgical resection and had seizure-free surgical outcomes after a 12-month
follow-up were included in this study. All patients had presurgical structural
MRI and rsfMRI while postsurgical MRI images were available for ten. Based on
the relationship between the localized foci and resection, the results were
classified into three groups fully concordant, partially concordant, and
discordant. These groups had the resulting cluster aligned with, in the same
lobe with, and outside the lobe of the resection area, respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02116v1' target='_blank'>Humanoid Locomotion and Manipulation: Current Progress and Challenges in
  Control, Planning, and Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaoyuan Gu, Junheng Li, Wenlan Shen, Wenhao Yu, Zhaoming Xie, Stephen McCrory, Xianyi Cheng, Abdulaziz Shamsah, Robert Griffin, C. Karen Liu, Abderrahmane Kheddar, Xue Bin Peng, Yuke Zhu, Guanya Shi, Quan Nguyen, Gordon Cheng, Huijun Gao, Ye Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 22:00:53</h6>
<p class='card-text'>Humanoid robots have great potential to perform various human-level skills.
These skills involve locomotion, manipulation, and cognitive capabilities.
Driven by advances in machine learning and the strength of existing model-based
approaches, these capabilities have progressed rapidly, but often separately.
Therefore, a timely overview of current progress and future trends in this
fast-evolving field is essential. This survey first summarizes the model-based
planning and control that have been the backbone of humanoid robotics for the
past three decades. We then explore emerging learning-based methods, with a
focus on reinforcement learning and imitation learning that enhance the
versatility of loco-manipulation skills. We examine the potential of
integrating foundation models with humanoid embodiments, assessing the
prospects for developing generalist humanoid agents. In addition, this survey
covers emerging research for whole-body tactile sensing that unlocks new
humanoid skills that involve physical interactions. The survey concludes with a
discussion of the challenges and future trends.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02103v1' target='_blank'>Using LSDB to enable large-scale catalog distribution, cross-matching,
  and analytics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Neven Caplar, Wilson Beebe, Doug Branton, Sandro Campos, Andrew Connolly, Melissa DeLucchi, Derek Jones, Mario Juric, Jeremy Kubica, Konstantin Malanchev, Rachel Mandelbaum, Sean McGuire</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 21:09:42</h6>
<p class='card-text'>The Vera C. Rubin Observatory will generate an unprecedented volume of data,
including approximately 60 petabytes of raw data and around 30 trillion
observed sources, posing a significant challenge for large-scale and end-user
scientific analysis. As part of the LINCC Frameworks Project we are addressing
these challenges with the development of the HATS (Hierarchical Adaptive Tiling
Scheme) format and analysis package LSDB (Large Scale Database). HATS
partitions data adaptively using a hierarchical tiling system to balance the
file sizes, enabling efficient parallel analysis. Recent updates include
improved metadata consistency, support for incremental updates, and enhanced
compatibility with evolving datasets. LSDB complements HATS by providing a
scalable, user-friendly interface for large catalog analysis, integrating
spatial queries, crossmatching, and time-series tools while utilizing Dask for
parallelization. We have successfully demonstrated the use of these tools with
datasets such as ZTF and Pan-STARRS data releases on both cluster and cloud
environments. We are deeply involved in several ongoing collaborations to
ensure alignment with community needs, with future plans for IVOA
standardization and support for upcoming Rubin, Euclid and Roman data. We
provide our code and materials at lsdb.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02098v2' target='_blank'>Graph-Based Modeling and Decomposition of Hierarchical Optimization
  Problems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David L. Cole, Filippo Pecci, Omar J. Guerra, Harsha Gangammanavar, Jesse D. Jenkins, Victor M. Zavala</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 20:51:07</h6>
<p class='card-text'>We present a graph-theoretic modeling approach for hierarchical optimization
that leverages the OptiGraph abstraction implemented in the Julia package
Plasmo$.$jl. We show that the abstraction is flexible and can effectively
capture complex hierarchical connectivity that arises from decision-making over
multiple spatial and temporal scales (e.g., integration of planning,
scheduling, and operations in manufacturing and infrastructures). We also show
that the graph abstraction facilitates the conceptualization and implementation
of decomposition and approximation schemes. Specifically, we propose a
graph-based Benders decomposition (gBD) framework that enables the exploitation
of hierarchical (nested) structures and that uses graph
aggregation/partitioning procedures to discover such structures. In addition,
we provide a Julia implementation of gBD, which we call PlasmoBenders$.$jl. We
illustrate the capabilities using examples arising in the context of energy and
power systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01932v1' target='_blank'>Bridging Classification and Segmentation in Osteosarcoma Assessment via
  Foundation and Discrete Diffusion Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Manh Duong Nguyen, Dac Thai Nguyen, Trung Viet Nguyen, Homi Yamada, Huy Hieu Pham, Phi Le Nguyen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 18:06:18</h6>
<p class='card-text'>Osteosarcoma, the most common primary bone cancer, often requires accurate
necrosis assessment from whole slide images (WSIs) for effective treatment
planning and prognosis. However, manual assessments are subjective and prone to
variability. In response, we introduce FDDM, a novel framework bridging the gap
between patch classification and region-based segmentation. FDDM operates in
two stages: patch-based classification, followed by region-based refinement,
enabling cross-patch information intergation. Leveraging a newly curated
dataset of osteosarcoma images, FDDM demonstrates superior segmentation
performance, achieving up to a 10% improvement mIOU and a 32.12% enhancement in
necrosis rate estimation over state-of-the-art methods. This framework sets a
new benchmark in osteosarcoma assessment, highlighting the potential of
foundation models and diffusion-based refinements in complex medical imaging
tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01898v1' target='_blank'>Data-Driven Computation of the Accessibility Provided by
  Demand-Responsive Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pierfrancesco Leonardi, Vincenza Torrisi, Andrea Araldo, Matteo Ignaccolo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 17:04:11</h6>
<p class='card-text'>Conventional Public Transport (PT) cannot support the mobility needs in weak
demand areas. Such areas could be better served by integrating, within PT,
Demand-Responsive Transport (DRT), in which bus routes dynamically adapt to
user demand. While the literature has focused on the level of service of DRT,
it has overlooked its contribution to accessibility, which measures the ease of
accessing opportunities (e.g, schools, jobs, other residents). Therefore, the
following simple question remains unanswered: How many additional opportunities
per hour can be reached when DRT is deployed? However, no method exists to
quantify the accessibility resulting from the integration of conventional PT
and DRT. We propose a novel method to compute isochrone-based accessibility.
The main challenge is that, while accessibility isochrones are computed on top
of a graph-model of the transport system, no graph can model DRT, since its
routes are dynamic and stochastic. To overcome this issue, we propose a
data-driven method, based on the analysis of multiple days of DRT operation.
The methodology is tested on a case study in Acireale (Italy) simulated in
Visum, where a many-to-many DRT service is integrated with a metropolitan mass
transit. We show that, regarding the currently deployed conventional bus lines,
the accessibility provided by DRT is much higher and its geographical
distribution more equal. While current DRT planning is based exclusively on
level of service and cost, our approach allows DRT planners and operators to
shift their focus on accessibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03261v1' target='_blank'>Navigation Variable-based Multi-objective Particle Swarm Optimization
  for UAV Path Planning with Kinematic Constraints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thi Thuy Ngan Duong, Duy-Nam Bui, Manh Duong Phung</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 16:07:37</h6>
<p class='card-text'>Path planning is essential for unmanned aerial vehicles (UAVs) as it
determines the path that the UAV needs to follow to complete a task. This work
addresses this problem by introducing a new algorithm called navigation
variable-based multi-objective particle swarm optimization (NMOPSO). It first
models path planning as an optimization problem via the definition of a set of
objective functions that include optimality and safety requirements for UAV
operation. The NMOPSO is then used to minimize those functions through Pareto
optimal solutions. The algorithm features a new path representation based on
navigation variables to include kinematic constraints and exploit the
maneuverable characteristics of the UAV. It also includes an adaptive mutation
mechanism to enhance the diversity of the swarm for better solutions.
Comparisons with various algorithms have been carried out to benchmark the
proposed approach. The results indicate that the NMOPSO performs better than
not only other particle swarm optimization variants but also other
state-of-the-art multi-objective and metaheuristic optimization algorithms.
Experiments have also been conducted with real UAVs to confirm the validity of
the approach for practical flights. The source code of the algorithm is
available at https://github.com/ngandng/NMOPSO.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01837v1' target='_blank'>Digital Twin-based SIM Communication and Flight Control for Advanced Air
  Mobility</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kai Xiong, Zhen Chen, Juefei Xie, Supeng Leng, Chau Yuen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 14:39:00</h6>
<p class='card-text'>Electric Vertical Take-off and Landing vehicles (eVTOLs) are driving Advanced
Air Mobility (AAM) toward transforming urban transportation by extending travel
from congested ground networks to low-altitude airspace. This transition
promises to reduce traffic congestion and significantly shorten commute times.
To ensure aviation safety, eVTOLs must fly within prescribed flight corridors.
These corridors are managed by ground-based Air Traffic Control (ATCo)
stations, which oversee air-ground communication and flight scheduling.
However, one critical challenge remains: the lack of high rate air-ground
communication and safe flight planning within these corridors. The introduction
of 6G-oriented Stacked Intelligent Metasurface (SIM) technology presents a high
rate communication solution. With advanced phase-shifting capabilities, SIM
enables precise wireless signal control and supports beam-tracking
communication with eVTOLs. Leveraging this technology, we propose a Composite
Potential Field (CPF) approach. This method dynamically integrates target,
separation, and communication fields to optimize both SIM communication
efficiency and flight safety. Simulation results validate the effectiveness of
this DT-based approach. Compared to the potential field flight control
benchmark, it improves the transmission rate by 8.3\%. Additionally, it reduces
flight distance deviation from the prescribed corridor by 10\% compared to
predetermined optimization methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01835v1' target='_blank'>ASKCOS: an open source software suite for synthesis planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhengkai Tu, Sourabh J. Choure, Mun Hong Fong, Jihye Roh, Itai Levin, Kevin Yu, Joonyoung F. Joung, Nathan Morgan, Shih-Cheng Li, Xiaoqi Sun, Huiqian Lin, Mark Murnin, Jordan P. Liles, Thomas J. Struble, Michael E. Fortunato, Mengjie Liu, William H. Green, Klavs F. Jensen, Connor W. Coley</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 14:38:03</h6>
<p class='card-text'>The advancement of machine learning and the availability of large-scale
reaction datasets have accelerated the development of data-driven models for
computer-aided synthesis planning (CASP) in the past decade. Here, we detail
the newest version of ASKCOS, an open source software suite for synthesis
planning that makes available several research advances in a freely available,
practical tool. Four one-step retrosynthesis models form the basis of both
interactive planning and automatic planning modes. Retrosynthetic planning is
complemented by other modules for feasibility assessment and pathway
evaluation, including reaction condition recommendation, reaction outcome
prediction, and auxiliary capabilities such as solubility prediction and
quantum mechanical descriptor prediction. ASKCOS has assisted hundreds of
medicinal, synthetic, and process chemists in their day-to-day tasks,
complementing expert decision making. It is our belief that CASP tools like
ASKCOS are an important part of modern chemistry research, and that they offer
ever-increasing utility and accessibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01827v1' target='_blank'>The Proof is in the Almond Cookies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Remi van Trijp, Katrien Beuls, Paul Van Eecke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 14:25:35</h6>
<p class='card-text'>This paper presents a case study on how to process cooking recipes (and more
generally, how-to instructions) in a way that makes it possible for a robot or
artificial cooking assistant to support human chefs in the kitchen. Such AI
assistants would be of great benefit to society, as they can help to sustain
the autonomy of aging adults or people with a physical impairment, or they may
reduce the stress in a professional kitchen. We propose a novel approach to
computational recipe understanding that mimics the human sense-making process,
which is narrative-based. Using an English recipe for almond crescent cookies
as illustration, we show how recipes can be modelled as rich narrative
structures by integrating various knowledge sources such as language
processing, ontologies, and mental simulation. We show how such narrative
structures can be used for (a) dealing with the challenges of recipe language,
such as zero anaphora, (b) optimizing a robot's planning process, (c) measuring
how well an AI system understands its current tasks, and (d) allowing recipe
annotations to become language-independent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01806v1' target='_blank'>TRG-planner: Traversal Risk Graph-Based Path Planning in Unstructured
  Environments for Safe and Efficient Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dongkyu Lee, I Made Aswin Nahrendra, Minho Oh, Byeongho Yu, Hyun Myung</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 13:36:53</h6>
<p class='card-text'>Unstructured environments such as mountains, caves, construction sites, or
disaster areas are challenging for autonomous navigation because of terrain
irregularities. In particular, it is crucial to plan a path to avoid risky
terrain and reach the goal quickly and safely. In this paper, we propose a
method for safe and distance-efficient path planning, leveraging Traversal Risk
Graph (TRG), a novel graph representation that takes into account geometric
traversability of the terrain. TRG nodes represent stability and reachability
of the terrain, while edges represent relative traversal risk-weighted path
candidates. Additionally, TRG is constructed in a wavefront propagation manner
and managed hierarchically, enabling real-time planning even in large-scale
environments. Lastly, we formulate a graph optimization problem on TRG that
leads the robot to navigate by prioritizing both safe and short paths. Our
approach demonstrated superior safety, distance efficiency, and fast processing
time compared to the conventional methods. It was also validated in several
real-world experiments using a quadrupedal robot. Notably, TRG-planner
contributed as the global path planner of an autonomous navigation framework
for the DreamSTEP team, which won the Quadruped Robot Challenge at ICRA 2023.
The project page is available at https://trg-planner.github.io .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01732v1' target='_blank'>Combined Hyper-Extensible Extremely-Secured Zero-Trust CIAM-PAM
  architecture</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shivom Aggarwal, Shourya Mehra, Safeer Sathar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 09:49:25</h6>
<p class='card-text'>Customer Identity and Access Management (CIAM) systems play a pivotal role in
securing enterprise infrastructures. However, the complexity of implementing
these systems requires careful architectural planning to ensure positive Return
on Investment (RoI) and avoid costly delays. The proliferation of Active
Persistent cyber threats, coupled with advancements in AI, cloud computing, and
geographically distributed customer populations, necessitates a paradigm shift
towards adaptive and zero-trust security frameworks. This paper introduces the
Combined Hyper-Extensible Extremely-Secured Zero-Trust (CHEZ) CIAM-PAM
architecture, designed specifically for large-scale enterprises. The CHEZ PL
CIAM-PAM framework addresses critical security gaps by integrating federated
identity management (private and public identities), password-less
authentication, adaptive multi-factor authentication (MFA), microservice-based
PEP (Policy Entitlement Point), multi-layer RBAC (Role Based Access Control)
and multi-level trust systems. This future-proof design also includes
end-to-end data encryption, and seamless integration with state-of-the-art
AI-based threat detection systems, while ensuring compliance with stringent
regulatory standards.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01727v1' target='_blank'>Proposing Hierarchical Goal-Conditioned Policy Planning in Multi-Goal
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gavin B. Rens</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 09:37:54</h6>
<p class='card-text'>Humanoid robots must master numerous tasks with sparse rewards, posing a
challenge for reinforcement learning (RL). We propose a method combining RL and
automated planning to address this. Our approach uses short goal-conditioned
policies (GCPs) organized hierarchically, with Monte Carlo Tree Search (MCTS)
planning using high-level actions (HLAs). Instead of primitive actions, the
planning process generates HLAs. A single plan-tree, maintained during the
agent's lifetime, holds knowledge about goal achievement. This hierarchy
enhances sample efficiency and speeds up reasoning by reusing HLAs and
anticipating future actions. Our Hierarchical Goal-Conditioned Policy Planning
(HGCPP) framework uniquely integrates GCPs, MCTS, and hierarchical RL,
potentially improving exploration and planning in complex tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01559v1' target='_blank'>K-ARC: Adaptive Robot Coordination for Multi-Robot Kinodynamic Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mike Qin, Irving Solis, James Motes, Marco Morales, Nancy M. Amato</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-02 22:30:07</h6>
<p class='card-text'>This work presents Kinodynamic Adaptive Robot Coordination (K-ARC), a novel
algorithm for multi-robot kinodynamic planning. Our experimental results show
the capability of K-ARC to plan for up to 32 planar mobile robots, while
achieving up to an order of magnitude of speed-up compared to previous methods
in various scenarios. K-ARC is able to achieve this due to its two main
properties. First, K-ARC constructs its solution iteratively by planning in
segments, where initial kinodynamic paths are found through optimization-based
approaches and the inter-robot conflicts are resolved through sampling-based
approaches. The interleaving use of sampling-based and optimization-based
approaches allows K-ARC to leverage the strengths of both approaches in
different sections of the planning process where one is more suited than the
other, while previous methods tend to emphasize on one over the other. Second,
K-ARC builds on a previously proposed multi-robot motion planning framework,
Adaptive Robot Coordination (ARC), and inherits its strength of focusing on
coordination between robots only when needed, saving computation efforts. We
show how the combination of these two properties allows K-ARC to achieve
overall better performance in our simulated experiments with increasing numbers
of robots, increasing degrees of problem difficulties, and increasing
complexities of robot dynamics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01344v1' target='_blank'>Machine Learning for Modeling Wireless Radio Metrics with Crowdsourced
  Data and Local Environment Features</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifeng Qiu, Alexis Bose</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-02 16:52:08</h6>
<p class='card-text'>This paper presents a suite of machine learning models, CRC-ML-Radio Metrics,
designed for modeling RSRP, RSRQ, and RSSI wireless radio metrics in 4G
environments. These models utilize crowdsourced data with local environmental
features to enhance prediction accuracy across both indoor at elevation and
outdoor urban settings. They achieve RMSE performance of 9.76 to 11.69 dB for
RSRP, 2.90 to 3.23 dB for RSRQ, and 9.50 to 10.36 dB for RSSI, evaluated on
over 300,000 data points in the Toronto, Montreal, and Vancouver areas. These
results demonstrate the robustness and adaptability of the models, supporting
precise network planning and quality of service optimization in complex
Canadian urban environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01255v1' target='_blank'>Design of mechanisms for ensuring the execution of tasks in project
  planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oksana Mulesa, Petro Horvat, Tamara Radivilova, Volodymyr Sabadosh, Oleksii Baranovskyi, Sergii Duran</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-02 13:47:20</h6>
<p class='card-text'>This paper reports an analysis of aspects of the project planning stage. The
object of research is the decision-making processes that take place at this
stage. This work considers the problem of building a hierarchy of tasks, their
distribution among performers, taking into account restrictions on financial
costs and duration of project implementation. Verbal and mathematical models of
the task of constructing a hierarchy of tasks and other tasks that take place
at the stage of project planning were constructed. Such indicators of the
project implementation process efficiency were introduced as the time, cost,
and cost-time efficiency. In order to be able to apply these criteria, the
tasks of estimating the minimum value of the duration of the project and its
minimum required cost were considered. Appropriate methods have been developed
to solve them. The developed iterative method for assessing the minimum
duration of project implementation is based on taking into account the
possibility of simultaneous execution of various tasks. The method of
estimating the minimum cost of the project is to build and solve the problem of
Boolean programming. The values obtained as a result of solving these problems
form an {\guillemotleft}ideal point{\guillemotright}, approaching which is
enabled by the developed iterative method of constructing a hierarchy of tasks
based on the method of sequential concessions. This method makes it possible to
devise options for management decisions to obtain valid solutions to the
problem. According to them, the decision maker can introduce a concession on
the value of one or both components of the {\guillemotleft}ideal
point{\guillemotright} or change the input data to the task. The models and
methods built can be used when planning projects in education, science,
production, etc.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01129v1' target='_blank'>Compositional data analysis for modeling and forecasting mortality with
  the α-transformation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Han Ying Lim, Dharini Pathmanathan, Sophie Dabo-Niang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-02 08:07:47</h6>
<p class='card-text'>Mortality forecasting is crucial for demographic planning and actuarial
studies, particularly for predicting population ageing rates and future
longevity risks. Traditional approaches largely rely on extrapolative methods,
such as the Lee-Carter model and its variants which use mortality rates as
inputs. In recent years, compositional data analysis (CoDA), which adheres to
summability and non-negativity constraints, has gained increasing attention
from researchers for its application in mortality forecasting. This study
explores the use of the {\alpha}-transformation as an alternative to the
commonly applied centered log-ratio (CLR) transformation for converting
compositional data from the Aitchison simplex to unconstrained real space. The
{\alpha}-transformation offers greater flexibility through the inclusion of the
{\alpha} parameter, enabling better adaptation to the underlying data structure
and handling of zero values, which are the limitations inherent to the CLR
transformation. Using age-specific life table death counts for males and
females in 31 selected European countries/regions from 1983 to 2018, the
proposed method demonstrates comparable performance to the CLR transformation
in most countries with improved forecast accuracy in some cases. These findings
highlight the potential of the {\alpha}-transformation as a competitive
alternative transformation technique for real-world mortality data within a
non-functional CoDA framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01128v2' target='_blank'>Automating Work Orders and Tracking Winter Snow Plows and Patrol
  Vehicles with Telematics Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anugunj Naman, Aaron Ault, Yaguang Zhang, James Krogmeier</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-02 08:02:45</h6>
<p class='card-text'>Winter road maintenance is a critical priority for the Indiana Department of
Transportation, which manages an extensive fleet across thousands of lane
miles. The current manual tracking of snowplow workloads is inefficient and
prone to errors. To address these challenges, we developed an in-browser web
application that automates the creation and verification of work orders using a
large-scale GPS dataset from telematics systems. The application processes
millions of GPS data points from hundreds of vehicles over winter,
significantly reducing manual labor and minimizing errors. Key features include
geohashing for efficient road segment identification, detailed segment-level
work records, and robust visualization of vehicle movements, even on repeated
routes. Our proposed solution has the potential to enhance the accuracy and
granularity of work records, support more effective resource allocation, ensure
timely compensation for drivers, alleviate administrative burdens, and allow
managers to focus on strategic planning and real-time challenges. The web
application can be accessed at https://github.com/oats-center/arrtrack/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01056v1' target='_blank'>Risks of Cultural Erasure in Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rida Qadri, Aida M. Davani, Kevin Robinson, Vinodkumar Prabhakaran</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-02 04:57:50</h6>
<p class='card-text'>Large language models are increasingly being integrated into applications
that shape the production and discovery of societal knowledge such as search,
online education, and travel planning. As a result, language models will shape
how people learn about, perceive and interact with global cultures making it
important to consider whose knowledge systems and perspectives are represented
in models. Recognizing this importance, increasingly work in Machine Learning
and NLP has focused on evaluating gaps in global cultural representational
distribution within outputs. However, more work is needed on developing
benchmarks for cross-cultural impacts of language models that stem from a
nuanced sociologically-aware conceptualization of cultural impact or harm. We
join this line of work arguing for the need of metricizable evaluations of
language technologies that interrogate and account for historical power
inequities and differential impacts of representation on global cultures,
particularly for cultures already under-represented in the digital corpora. We
look at two concepts of erasure: omission: where cultures are not represented
at all and simplification i.e. when cultural complexity is erased by presenting
one-dimensional views of a rich culture. The former focuses on whether
something is represented, and the latter on how it is represented. We focus our
analysis on two task contexts with the potential to influence global cultural
production. First, we probe representations that a language model produces
about different places around the world when asked to describe these contexts.
Second, we analyze the cultures represented in the travel recommendations
produced by a set of language model applications. Our study shows ways in which
the NLP community and application developers can begin to operationalize
complex socio-cultural considerations into standard evaluations and benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00912v1' target='_blank'>AutoPresent: Designing Structured Visuals from Scratch</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaxin Ge, Zora Zhiruo Wang, Xuhui Zhou, Yi-Hao Peng, Sanjay Subramanian, Qinyue Tan, Maarten Sap, Alane Suhr, Daniel Fried, Graham Neubig, Trevor Darrell</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-01 18:09:32</h6>
<p class='card-text'>Designing structured visuals such as presentation slides is essential for
communicative needs, necessitating both content creation and visual planning
skills. In this work, we tackle the challenge of automated slide generation,
where models produce slide presentations from natural language (NL)
instructions. We first introduce the SlidesBench benchmark, the first benchmark
for slide generation with 7k training and 585 testing examples derived from 310
slide decks across 10 domains. SlidesBench supports evaluations that are
(i)reference-based to measure similarity to a target slide, and
(ii)reference-free to measure the design quality of generated slides alone. We
benchmark end-to-end image generation and program generation methods with a
variety of models, and find that programmatic methods produce higher-quality
slides in user-interactable formats. Built on the success of program
generation, we create AutoPresent, an 8B Llama-based model trained on 7k pairs
of instructions paired with code for slide generation, and achieve results
comparable to the closed-source model GPT-4o. We further explore iterative
design refinement where the model is tasked to self-refine its own output, and
we found that this process improves the slide's quality. We hope that our work
will provide a basis for future work on generating structured visuals.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00905v1' target='_blank'>White Paper on Software Infrastructure for Advanced Nuclear Physics
  Computing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:A. Boehnlein, J. Carlson, I. Cloet, J. Detwiler, M. Diefenthaler, R. Edwards, K. Godbey, R. Hix, P. M. Jacobs, K. Originos, T. Papenbrock, M. Ploskon, C. Ratti, B. Sawatzky, R. Soltz, T. Wenaus</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-01 17:38:10</h6>
<p class='card-text'>This White Paper documents the discussion and consensus conclusions of the
workshop "Software Infrastructure for Advanced Nuclear Physics Computing"
(SANPC 24), which was held at Jefferson Lab on June 20-22, 2024. The workshop
brought together members of the US Nuclear Physics community with data
scientists and funding agency representatives to discuss the challenges and
opportunities in advanced computing for Nuclear Physics in the coming decade.
Opportunities for sustainable support and growth are identified within the
context of existing and currently planned DOE and NSF programs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00856v1' target='_blank'>Advances in UAV Avionics Systems Architecture, Classification and
  Integration: A Comprehensive Review and Future Perspectives</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hashim A. Hashim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-01 14:47:01</h6>
<p class='card-text'>Avionics systems of an Unmanned Aerial Vehicle (UAV) or drone are the
critical electronic components found onboard that regulate, navigate, and
control UAV travel while ensuring public safety. Contemporary UAV avionics work
together to facilitate success of UAV missions by enabling stable
communication, secure identification protocols, novel energy solutions,
multi-sensor accurate perception and autonomous navigation, precise path
planning, that guarantees collision avoidance, reliable trajectory control, and
efficient data transfer within the UAV system. Moreover, special consideration
must be given to electronic warfare threats prevention, detection, and
mitigation, and the regulatory framework associated with UAV operations. This
review presents the role and taxonomy of each UAV avionics system while
covering shortcomings and benefits of available alternatives within each
system. UAV communication systems, antennas, and location communication
tracking are surveyed. Identification systems that respond to air-to-air or
air-to-ground interrogating signals are presented. UAV classical and more
innovative power sources are discussed. The rapid development of perception
systems improves UAV autonomous navigation and control capabilities. The paper
reviews common perception systems, navigation techniques, path planning
approaches, obstacle avoidance methods, and tracking control. Modern electronic
warfare uses advanced techniques and has to be counteracted by equally advanced
methods to keep the public safe. Consequently, this work presents a detailed
overview of common electronic warfare threats and state-of-the-art
countermeasures and defensive aids. UAV safety occurrences are analyzed in the
context of national regulatory framework and the certification process. Databus
communication and standards for UAVs are reviewed as they enable efficient and
fast real-time data transfer.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00840v1' target='_blank'>Distilled Lifelong Self-Adaptation for Configurable Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yulong Ye, Tao Chen, Miqing Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-01 13:41:57</h6>
<p class='card-text'>Modern configurable systems provide tremendous opportunities for engineering
future intelligent software systems. A key difficulty thereof is how to
effectively self-adapt the configuration of a running system such that its
performance (e.g., runtime and throughput) can be optimized under time-varying
workloads. This unfortunately remains unaddressed in existing approaches as
they either overlook the available past knowledge or rely on static
exploitation of past knowledge without reasoning the usefulness of information
when planning for self-adaptation. In this paper, we tackle this challenging
problem by proposing DLiSA, a framework that self-adapts configurable systems.
DLiSA comes with two properties: firstly, it supports lifelong planning, and
thereby the planning process runs continuously throughout the lifetime of the
system, allowing dynamic exploitation of the accumulated knowledge for rapid
adaptation. Secondly, the planning for a newly emerged workload is boosted via
distilled knowledge seeding, in which the knowledge is dynamically purified
such that only useful past configurations are seeded when necessary, mitigating
misleading information. Extensive experiments suggest that the proposed DLiSA
significantly outperforms state-of-the-art approaches, demonstrating a
performance improvement of up to 229% and a resource acceleration of up to
2.22x on generating promising adaptation configurations. All data and sources
can be found at our repository: https://github.com/ideas-labo/dlisa.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00610v1' target='_blank'>LHC and HL-LHC Bounds on Visible and Invisible Decays in the $B-L$ Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Farinaldo S. Queiroz, Jilberto Zamora-Saa, Ricardo C. Silva, Y. M. Oviedo-Torres</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 19:14:32</h6>
<p class='card-text'>In this work, we use publicly available data from ATLAS collaboration
collected at LHC run 2 at a center-of-mass energy of $\sqrt{s}=13$TeV with an
integrated luminosity of $139 fb^{-1}$ to derive lower mass limits on the
$Z^\prime$ gauge boson associated with the B-L gauge symmetry. Using dilepton
data we find that $M_{Z^\prime} > 4$TeV ($6$TeV) for $g_{BL}=0.1$
($g_{BL}=0.5$) in the absence of invisible decays. Once invisible decays are
turned on these limits are substantially relaxed. Assuming an invisible
branching ratio of $BR_{inv}=0.9$, the LHC bound is loosened up to
$M_{Z^\prime}> 4.8$TeV for $g_{BL}=0.5$. This analysis confirms that the LHC
now imposes stricter constraints than the longstanding bounds established by
LEP. We also estimate the projected HL-LHC bounds that will operate with at
$\sqrt{s}=14$TeV and a planned integrated luminosity of $\mathcal{L}=3 ab^{-1}$
that will probe $Z^\prime$ masses up to $7.5$TeV.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00601v2' target='_blank'>DreamDrive: Generative 4D Scene Modeling from Street View Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiageng Mao, Boyi Li, Boris Ivanovic, Yuxiao Chen, Yan Wang, Yurong You, Chaowei Xiao, Danfei Xu, Marco Pavone, Yue Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 18:59:57</h6>
<p class='card-text'>Synthesizing photo-realistic visual observations from an ego vehicle's
driving trajectory is a critical step towards scalable training of self-driving
models. Reconstruction-based methods create 3D scenes from driving logs and
synthesize geometry-consistent driving videos through neural rendering, but
their dependence on costly object annotations limits their ability to
generalize to in-the-wild driving scenarios. On the other hand, generative
models can synthesize action-conditioned driving videos in a more generalizable
way but often struggle with maintaining 3D visual consistency. In this paper,
we present DreamDrive, a 4D spatial-temporal scene generation approach that
combines the merits of generation and reconstruction, to synthesize
generalizable 4D driving scenes and dynamic driving videos with 3D consistency.
Specifically, we leverage the generative power of video diffusion models to
synthesize a sequence of visual references and further elevate them to 4D with
a novel hybrid Gaussian representation. Given a driving trajectory, we then
render 3D-consistent driving videos via Gaussian splatting. The use of
generative priors allows our method to produce high-quality 4D scenes from
in-the-wild driving data, while neural rendering ensures 3D-consistent video
generation from the 4D scenes. Extensive experiments on nuScenes and street
view images demonstrate that DreamDrive can generate controllable and
generalizable 4D driving scenes, synthesize novel views of driving videos with
high fidelity and 3D consistency, decompose static and dynamic elements in a
self-supervised manner, and enhance perception and planning tasks for
autonomous driving.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00510v2' target='_blank'>VinT-6D: A Large-Scale Object-in-hand Dataset from Vision, Touch and
  Proprioception</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaoliang Wan, Yonggen Ling, Senlin Yi, Lu Qi, Wangwei Lee, Minglei Lu, Sicheng Yang, Xiao Teng, Peng Lu, Xu Yang, Ming-Hsuan Yang, Hui Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 15:45:09</h6>
<p class='card-text'>This paper addresses the scarcity of large-scale datasets for accurate
object-in-hand pose estimation, which is crucial for robotic in-hand
manipulation within the ``Perception-Planning-Control" paradigm. Specifically,
we introduce VinT-6D, the first extensive multi-modal dataset integrating
vision, touch, and proprioception, to enhance robotic manipulation. VinT-6D
comprises 2 million VinT-Sim and 0.1 million VinT-Real splits, collected via
simulations in MuJoCo and Blender and a custom-designed real-world platform.
This dataset is tailored for robotic hands, offering models with whole-hand
tactile perception and high-quality, well-aligned data. To the best of our
knowledge, the VinT-Real is the largest considering the collection difficulties
in the real-world environment so that it can bridge the gap of simulation to
real compared to the previous works. Built upon VinT-6D, we present a benchmark
method that shows significant improvements in performance by fusing multi-modal
information. The project is available at https://VinT-6D.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00507v1' target='_blank'>Real-Time Sampling-Based Safe Motion Planning for Robotic Manipulators
  in Dynamic Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nermin Covic, Bakir Lacevic, Dinko Osmankovic, Tarik Uzunovic</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 15:38:21</h6>
<p class='card-text'>In this paper, we present the main features of Dynamic Rapidly-exploring
Generalized Bur Tree (DRGBT) algorithm, a sampling-based planner for dynamic
environments. We provide a detailed time analysis and appropriate scheduling to
facilitate a real-time operation. To this end, an extensive analysis is
conducted to identify the time-critical routines and their dependence on the
number of obstacles. Furthermore, information about the distance to obstacles
is used to compute a structure called dynamic expanded bubble of free
configuration space, which is then utilized to establish sufficient conditions
for a guaranteed safe motion of the robot while satisfying all kinematic
constraints. An extensive randomized simulation trial is conducted to compare
the proposed algorithm to a competing state-of-the-art method. Finally, an
experimental study on a real robot is carried out covering a variety of
scenarios including those with human presence. The results show the
effectiveness and feasibility of real-time execution of the proposed motion
planning algorithm within a typical sensor-based arrangement, using cheap
hardware and sequential architecture, without the necessity for GPUs or heavy
parallelization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00495v1' target='_blank'>Kamide is in America, Moisil and Leitgeb are in Australia</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Satoru Niki, Hitoshi Omori</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 15:14:13</h6>
<p class='card-text'>It is not uncommon for a logic to be invented multiple times, hinting at its
robustness. This trend is followed also by the expansion BD+ of Belnap-Dunn
logic by Boolean negation. Ending up in the same logic, however, does not mean
that the semantic interpretations are always the same as well. In particular,
different interpretations can bring us to different logics, once the basic
setting is moved from a classical one to an intuitionistic one. For BD+, two
such paths seem to have been taken; one (BDi) by N. Kamide along the so-called
American plan, and another (HYPE) by G. Moisil and H. Leitgeb along the
so-called Australian plan. The aim of this paper is to better understand this
divergence. This task is approached mainly by (i) formulating a semantics for
first-order BD+ that provides an Australian view of the system; (ii) showing
connections of the less explored (first-order) BDi with neighbouring systems,
including an intermediate logic and variants of Nelson's logics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00486v1' target='_blank'>Semantic Incompleteness of Liberman et al. (2020)'s Hilbert-style System
  for Term-modal Logic K with Equality and Non-rigid Terms</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Takahiro Sawasaki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 15:12:04</h6>
<p class='card-text'>In this paper, we prove the semantic incompleteness of the Hilbert-style
system for the minimal normal term-modal logic with equality and non-rigid
terms that was proposed in Liberman et al. (2020) "Dynamic Term-modal Logics
for First-order Epistemic Planning." Term-modal logic is a family of
first-order modal logics having term-modal operators indexed with terms in the
first-order language. While some first-order formula is valid over the class of
all frames in the Kripke semantics for the term-modal logic proposed there, it
is not derivable in Liberman et al. (2020)'s Hilbert-style system. We show this
fact by introducing a non-standard Kripke semantics which makes the meanings of
constants and function symbols relative to the meanings of relation symbols
combined with them.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04714v1' target='_blank'>The Forward Physics Facility at the HL-LHC and its Synergies with
  Astroparticle Physics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dennis Soldin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 13:44:13</h6>
<p class='card-text'>High-energy collisions at the high-luminosity Large Hadron Collider (HL-LHC)
will generate a vast flux of particles along the beam collision axis, a region
not accessible by current LHC experiments. The study of multi-particle
production in the far-forward region is especially important for astroparticle
physics. High-energy cosmic rays create extensive air showers (EAS) in the
atmosphere, driven by hadron-ion collisions in the non-perturbative QCD regime.
Therefore, understanding high-energy hadronic interactions in the forward
region is crucial for interpreting EAS data and estimating backgrounds for
searches of astrophysical neutrinos, among other applications. The Forward
Physics Facility (FPF) is a proposal to construct a new underground cavern at
the HL-LHC, hosting various far-forward experiments designed to detect
particles outside the current LHC acceptance. We will outline the current plans
for the FPF and highlight its synergies with astroparticle physics.
Specifically, we will discuss how FPF measurements will enhance the modeling of
high-energy interactions in the atmosphere, helping to reduce the associated
uncertainties in multi-messenger astrophysics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00254v1' target='_blank'>Automatically Planning Optimal Parallel Strategy for Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zongbiao Li, Xiezhao Li, Yinghao Cui, Yijun Chen, Zhixuan Gu, Yuxuan Liu, Wenbo Zhu, Fei Jia, Ke Liu, Qifeng Li, Junyao Zhan, Jiangtao Zhou, Chenxi Zhang, Qike Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 03:51:14</h6>
<p class='card-text'>The number of parameters in large-scale language models based on transformers
is gradually increasing, and the scale of computing clusters is also growing.
The technology of quickly mobilizing large amounts of computing resources for
parallel computing is becoming increasingly important. In this paper, we
propose an automatic parallel algorithm that automatically plans the parallel
strategy with maximum throughput based on model and hardware information. By
decoupling the training time into computation, communication, and overlap, we
established a training duration simulation model. Based on this simulation
model, we prune the parallel solution space to shorten the search time
required. The multi-node experiment results show that the algorithm can
estimate the parallel training duration in real time with an average accuracy
of 96%. In our test, the recommendation strategy provided by the algorithm is
always globally optimal.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00158v1' target='_blank'>Urban Water Consumption Forecasting Using Deep Learning and Correlated
  District Metered Areas</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kleanthis Malialis, Nefeli Mavri, Stelios G. Vrachimis, Marios S. Kyriakou, Demetrios G. Eliades, Marios M. Polycarpou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-30 22:03:54</h6>
<p class='card-text'>Accurate water consumption forecasting is a crucial tool for water utilities
and policymakers, as it helps ensure a reliable supply, optimize operations,
and support infrastructure planning. Urban Water Distribution Networks (WDNs)
are divided into District Metered Areas (DMAs), where water flow is monitored
to efficiently manage resources. This work focuses on short-term forecasting of
DMA consumption using deep learning and aims to address two key challenging
issues. First, forecasting based solely on a DMA's historical data may lack
broader context and provide limited insights. Second, DMAs may experience
sensor malfunctions providing incorrect data, or some DMAs may not be monitored
at all due to computational costs, complicating accurate forecasting. We
propose a novel method that first identifies DMAs with correlated consumption
patterns and then uses these patterns, along with the DMA's local data, as
input to a deep learning model for forecasting. In a real-world study with data
from five DMAs, we show that: i) the deep learning model outperforms a
classical statistical model; ii) accurate forecasting can be carried out using
only correlated DMAs' consumption patterns; and iii) even when a DMA's local
data is available, including correlated DMAs' data improves accuracy.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>