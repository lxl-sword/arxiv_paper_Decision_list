<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-12-24</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-12-24</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20619v1' target='_blank'>SemanticGen: Video Generation in Semantic Space</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jianhong Bai, Xiaoshi Wu, Xintao Wang, Fu Xiao, Yuanxing Zhang, Qinghe Wang, Xiaoyu Shi, Menghan Xia, Zuozhu Liu, Haoji Hu, Pengfei Wan, Kun Gai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 18:59:56</h6>
<p class='card-text'>State-of-the-art video generative models typically learn the distribution of video latents in the VAE space and map them to pixels using a VAE decoder. While this approach can generate high-quality videos, it suffers from slow convergence and is computationally expensive when generating long videos. In this paper, we introduce SemanticGen, a novel solution to address these limitations by generating videos in the semantic space. Our main insight is that, due to the inherent redundancy in videos, the generation process should begin in a compact, high-level semantic space for global planning, followed by the addition of high-frequency details, rather than directly modeling a vast set of low-level video tokens using bi-directional attention. SemanticGen adopts a two-stage generation process. In the first stage, a diffusion model generates compact semantic video features, which define the global layout of the video. In the second stage, another diffusion model generates VAE latents conditioned on these semantic features to produce the final output. We observe that generation in the semantic space leads to faster convergence compared to the VAE latent space. Our method is also effective and computationally efficient when extended to long video generation. Extensive experiments demonstrate that SemanticGen produces high-quality videos and outperforms state-of-the-art approaches and strong baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20615v1' target='_blank'>Active Intelligence in Video Avatars via Closed-loop World Modeling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuanhua He, Tianyu Yang, Ke Cao, Ruiqi Wu, Cheng Meng, Yong Zhang, Zhuoliang Kang, Xiaoming Wei, Qifeng Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 18:59:16</h6>
<p class='card-text'>Current video avatar generation methods excel at identity preservation and motion alignment but lack genuine agency, they cannot autonomously pursue long-term goals through adaptive environmental interaction. We address this by introducing L-IVA (Long-horizon Interactive Visual Avatar), a task and benchmark for evaluating goal-directed planning in stochastic generative environments, and ORCA (Online Reasoning and Cognitive Architecture), the first framework enabling active intelligence in video avatars. ORCA embodies Internal World Model (IWM) capabilities through two key innovations: (1) a closed-loop OTAR cycle (Observe-Think-Act-Reflect) that maintains robust state tracking under generative uncertainty by continuously verifying predicted outcomes against actual generations, and (2) a hierarchical dual-system architecture where System 2 performs strategic reasoning with state prediction while System 1 translates abstract plans into precise, model-specific action captions. By formulating avatar control as a POMDP and implementing continuous belief updating with outcome verification, ORCA enables autonomous multi-step task completion in open-domain scenarios. Extensive experiments demonstrate that ORCA significantly outperforms open-loop and non-reflective baselines in task success rate and behavioral coherence, validating our IWM-inspired design for advancing video avatar intelligence from passive animation to active, goal-oriented behavior.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20595v1' target='_blank'>Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dhruv Anand, Ehsan Shareghi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 18:43:05</h6>
<p class='card-text'>We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one's own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare recent MLLMs side by side as a function of scramble depth. Across seven MLLMs, accuracy drops sharply with depth; once a trajectory stalls or diverges, models rarely recover, and high face-reconstruction accuracy does not guarantee competent action selection or multi-step execution. A pronounced closed- vs open-source gap emerges: the strongest closed model leads on both single-step perception tasks and multi-step control tasks, while open-weight models cluster near chance on the hardest settings; yet even the best MLLM degrades at higher cube complexity. A simple self-correction via reflective thinking yields modest gains but can also introduce overthinking. Cube Bench offers a compact, reproducible probe of sequential spatial reasoning in MLLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20594v1' target='_blank'>The Sensitivity of PUEO to Cosmogenic Neutrinos and Exotic Physics Scenarios</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Angelina Sherman, Ke Fang, Dan Hooper</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 18:42:19</h6>
<p class='card-text'>Several observatories designed to detect ultrahigh-energy neutrinos are planned for the next decade. The most imminent of these is the Payload for Ultrahigh Energy Observations (PUEO), a long-duration balloon-based experiment that will provide unprecedented sensitivity to neutrinos with energies in the range of ~ 1 - 1000 EeV. In this work, we assess the scientific reach of PUEO. In particular, we evaluate the sensitivity of this observatory to cosmogenic neutrinos and, in turn, to the proton fraction of the ultrahigh-energy cosmic-ray spectrum. We also consider the potential of PUEO to probe scenarios in which neutrinos are produced through the decays of ultraheavy dark matter particles or are radiated from cosmic strings. We find that PUEO will be able to constrain the proton composition of ultrahigh-energy cosmic rays in scenarios that feature very strong source evolution and in which protons are accelerated to extremely high energies. Although gamma-ray observations are generally more sensitive to decaying particles than neutrino observations, PUEO is expected to set the strongest neutrino-detector constraints above 10^19 eV. PUEO will also provide the strongest constraints on some models of cosmic strings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20514v1' target='_blank'>Explainable time-series forecasting with sampling-free SHAP for Transformers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Matthias Hertel, Sebastian Pütz, Ralf Mikut, Veit Hagenmeyer, Benjamin Schäfer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 17:02:35</h6>
<p class='card-text'>Time-series forecasts are essential for planning and decision-making in many domains. Explainability is key to building user trust and meeting transparency requirements. Shapley Additive Explanations (SHAP) is a popular explainable AI framework, but it lacks efficient implementations for time series and often assumes feature independence when sampling counterfactuals. We introduce SHAPformer, an accurate, fast and sampling-free explainable time-series forecasting model based on the Transformer architecture. It leverages attention manipulation to make predictions based on feature subsets. SHAPformer generates explanations in under one second, several orders of magnitude faster than the SHAP Permutation Explainer. On synthetic data with ground truth explanations, SHAPformer provides explanations that are true to the data. Applied to real-world electrical load data, it achieves competitive predictive performance and delivers meaningful local and global insights, such as identifying the past load as the key predictor and revealing a distinct model behavior during the Christmas period.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20475v1' target='_blank'>Drift-Corrected Monocular VIO and Perception-Aware Planning for Autonomous Drone Racing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maulana Bisyir Azhari, Donghun Han, Je In You, Sungjun Park, David Hyunchul Shim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 16:12:10</h6>
<p class='card-text'>The Abu Dhabi Autonomous Racing League(A2RL) x Drone Champions League competition(DCL) requires teams to perform high-speed autonomous drone racing using only a single camera and a low-quality inertial measurement unit -- a minimal sensor set that mirrors expert human drone racing pilots. This sensor limitation makes the system susceptible to drift from Visual-Inertial Odometry (VIO), particularly during long and fast flights with aggressive maneuvers. This paper presents the system developed for the championship, which achieved a competitive performance. Our approach corrected VIO drift by fusing its output with global position measurements derived from a YOLO-based gate detector using a Kalman filter. A perception-aware planner generated trajectories that balance speed with the need to keep gates visible for the perception system. The system demonstrated high performance, securing podium finishes across multiple categories: third place in the AI Grand Challenge with top speed of 43.2 km/h, second place in the AI Drag Race with over 59 km/h, and second place in the AI Multi-Drone Race. We detail the complete architecture and present a performance analysis based on experimental data from the competition, contributing our insights on building a successful system for monocular vision-based autonomous drone flight.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20473v1' target='_blank'>Even Small Companies Can Save Lives by Reducing Emissions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Baldassare, Abby Lute, Hikari Murayama, Cora Kingdon, Christopher Schwalm</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 16:08:08</h6>
<p class='card-text'>Global warming is often framed in broad planetary numbers such as the 1.5 C and 2 C warming thresholds, creating the false impression that individual corporations efforts to reduce emissions are meaningless in the absence of collective action. This perspective causes companies to reduce ambition towards voluntarily cutting emissions, as they believe their pollution has negligible impacts on its own. Reframing the issue to focus on the life-saving potential of individual corporate actions empowers companies to act and holds them accountable for inaction. Here, we show the results from an innovative modeling technique which calculates the avoided deaths from sustainability efforts for 3,084 companies spanning a range of sizes and sectors. From the reported emissions and planned emissions reductions, we create scenarios for 2020-2049 with and without the pledged emissions cuts and calculate the resulting warming from 2020-2100 using a climate emulator. We then use temperatures from these scenarios to calculate the deaths resulting from warming by using mortality damage functions. We find that more than 97% of these companies stand to save at least one life by following through with emissions reduction plans. Additionally, if all 3,084 companies follow through with their emissions reduction plans, over 4.4 million temperature-related deaths can be avoided.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20463v1' target='_blank'>Characterization of the BIFROST spectrometer through virtual experiments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kristine M. L. Krighaar, Silas B. Schack, Nicolai L. Amin, Gregory S. Tucker, Rasmus Toft-Petersen, Kim Lefmann</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 15:56:43</h6>
<p class='card-text'>Using the Monte Carlo ray tracing package McStas, we illustrate the possibilities of creating virtual experiments of the neutron spectrometer BIFROST at the European Spallation Source, ESS. With this model, we are able to benchmark BIFROST with respect to expected intensity, $Q$- and energy-resolution. The simulations reproduce the expected resolution behavior and quantify effects that are difficult to capture analytically, including a wavelength-dependent edge enhancement arising from a combination of the long-pulsed source and the pulse-shaping chopper. Furthermore, we present an antiferromagnetic (AF) spin wave simulation, which we use to create realistic datasets at different instrument operation settings. Our virtual experiments focus on realistic dispersive dynamics and illustrate how the virtual experiment approach reveal resolution effects, not easily calculable via analytical models. This demonstrates the crucial role of numerical simulations in the planning of challenging experiments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20391v1' target='_blank'>Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Georg Schildbach</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 14:28:42</h6>
<p class='card-text'>Cooperative collision avoidance between robots in swarm operations remains an open challenge. Assuming a decentralized architecture, each robot is responsible for making its own control decisions, including motion planning. To this end, most existing approaches mostly rely some form of (wireless) communication between the agents of the swarm. In reality, however, communication is brittle. It may be affected by latency, further delays and packet losses, transmission faults, and is subject to adversarial attacks, such as jamming or spoofing. This paper proposes Contingency Model-based Control (CMC) as a communicationless alternative. It follows the implicit cooperation paradigm, under which the design of the robots is based on consensual (offline) rules, similar to traffic rules. They include the definition of a contingency trajectory for each robot, and a method for construction of mutual collision avoidance constraints. The setup is shown to guarantee the recursive feasibility and collision avoidance between all swarm members in closed-loop operation. Moreover, CMC naturally satisfies the Plug \& Play paradigm, i.e., for new robots entering the swarm. Two numerical examples demonstrate that the collision avoidance guarantee is intact and that the robot swarm operates smoothly under the CMC regime.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20335v1' target='_blank'>Status of the Muon g-2/EDM Experiment at J-PARC</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Graziano Venanzoni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 13:08:35</h6>
<p class='card-text'>The Muon g-2/EDM Experiment at J-PARC will employ a novel way to measure the muon magnetic anomaly, a_mu = (g-2)_mu/2, by using a low-emittance beam of positive muons stored in a compact muon storage magnet. The experimental method includes new technologies such as a three-dimensional spiral injection, an MRI-type storage magnet with superb field uniformity, and a positron tracking detector. The expected systematic uncertainty will be at the same level as that of the Fermilab Muon g-2 experiment, providing an important cross-check of the "storage-ring method" employed at BNL and Fermilab. I will present the current status of the experiment, ongoing tests and design optimizations, and the plans for improvements of the experimental precision.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20292v1' target='_blank'>SlideTailor: Personalized Presentation Slide Generation for Scientific Papers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenzheng Zeng, Mingyu Ouyang, Langyuan Cui, Hwee Tou Ng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 12:01:18</h6>
<p class='card-text'>Automatic presentation slide generation can greatly streamline content creation. However, since preferences of each user may vary, existing under-specified formulations often lead to suboptimal results that fail to align with individual user needs. We introduce a novel task that conditions paper-to-slides generation on user-specified preferences. We propose a human behavior-inspired agentic framework, SlideTailor, that progressively generates editable slides in a user-aligned manner. Instead of requiring users to write their preferences in detailed textual form, our system only asks for a paper-slides example pair and a visual template - natural and easy-to-provide artifacts that implicitly encode rich user preferences across content and visual style. Despite the implicit and unlabeled nature of these inputs, our framework effectively distills and generalizes the preferences to guide customized slide generation. We also introduce a novel chain-of-speech mechanism to align slide content with planned oral narration. Such a design significantly enhances the quality of generated slides and enables downstream applications like video presentations. To support this new task, we construct a benchmark dataset that captures diverse user preferences, with carefully designed interpretable metrics for robust evaluation. Extensive experiments demonstrate the effectiveness of our framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20290v1' target='_blank'>A non-compact QCD axion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Georgios K. Karananas, Mikhail Shaposhnikov, Sebastian Zell</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 12:00:03</h6>
<p class='card-text'>We investigate the cosmology of an axion that is fundamentally non-compact. During inflation, fluctuations of the effectively massless field populate many QCD vacua, thereby evading conventional isocurvature constraints while generating domain walls -- without accompanying cosmic strings. A small non-QCD contribution to the axion potential is required to trigger the timely collapse of domain walls; as a consequence, a residual amount of CP violation in the strong sector must exist, potentially within reach of planned experiments. Non-compact axions can account for the entirety of the dark matter abundance, and the collapse of domain walls sources a stochastic gravitational-wave background at nanohertz frequencies. Such axion dynamics can be embedded in top-down constructions -- such as Weyl-invariant Einstein-Cartan gravity -- where the tilting of the axion potential arises automatically.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20286v1' target='_blank'>Replacing Gas with Low-cost, Abundant Long-duration Pumped Hydro in Electricity Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Timothy Weber, Cheng Cheng, Harry Thawley, Kylie Catchpole, Andrew Blakers, Bin Lu, Jennifer Zhao, Anna Nadolny</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 11:50:08</h6>
<p class='card-text'>Fossil gas is sometimes presented as an enabler of variable solar and wind generation beyond 2050, despite being a primary source of greenhouse gas emissions from methane leakage and combustion. We find that balancing solar and wind generation with pumped hydro energy storage eliminates the need for fossil gas without incurring a cost penalty. However, many existing long-term electricity system plans are biased to rely on fossil gas due to using temporal aggregation methods that either heavily constrain storage cycling behaviour or lose track of the state-of-charge, failing to consider the potential of low-cost long-duration off-river pumped hydro, and ignoring the broad suite of near-optimal energy transition pathways. We show that a temporal aggregation method based on 'segmentation' (fitted chronology) closely resembles the full-series optimisation, captures long-duration storage behaviour (48- and 160-hour durations), and finds a near-optimal 100% renewable electricity solution. We develop a new electricity system model to rapidly evaluate millions of other near-optimal solutions, stressing the importance of modelling pumped hydro sites with a low energy volume cost (<US$50 per kilowatt-hour), long economic lifetime (~75 years), and low real discount rate akin to other natural monopolies (<=3%). Almost every region of the world has access to sufficient 50 - 5000 gigawatt-hour off-river pumped hydro options that enable them to entirely decarbonise their future electricity systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20271v1' target='_blank'>Automated Training of Learned Database Components with Generative AI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Angjela Davitkova, Sebastian Michel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 11:24:52</h6>
<p class='card-text'>The use of deep learning for database optimization has gained significant traction, offering improvements in indexing, cardinality estimation, and query optimization. However, acquiring high-quality training data remains a significant challenge. This paper explores the possibility of using generative models, such as GPT, to synthesize training data for learned database components. We present an initial feasibility study investigating their ability to produce realistic query distributions and execution plans for database workloads. Additionally, we discuss key challenges, such as data scalability and labeling, along with potential solutions. The initial results suggest that generative models can effectively augment training datasets, improving the adaptability of learned database techniques.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20083v1' target='_blank'>Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenzhao Wu, Yahui Tang, Mingfei Cheng, Wenbing Tang, Yuan Zhou, Yang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 06:27:18</h6>
<p class='card-text'>As embodied agents advance toward real-world deployment, ensuring optimal decisions becomes critical for resource-constrained applications. Current evaluation methods focus primarily on functional correctness, overlooking the non-functional optimality of generated plans. This gap can lead to significant performance degradation and resource waste. We identify and formalize the problem of Non-optimal Decisions (NoDs), where agents complete tasks successfully but inefficiently. We present NoD-DGMT, a systematic framework for detecting NoDs in embodied agent task planning via diversity-guided metamorphic testing. Our key insight is that optimal planners should exhibit invariant behavioral properties under specific transformations. We design four novel metamorphic relations capturing fundamental optimality properties: position detour suboptimality, action optimality completeness, condition refinement monotonicity, and scene perturbation invariance. To maximize detection efficiency, we introduce a diversity-guided selection strategy that actively selects test cases exploring different violation categories, avoiding redundant evaluations while ensuring comprehensive diversity coverage. Extensive experiments on the AI2-THOR simulator with four state-of-the-art planning models demonstrate that NoD-DGMT achieves violation detection rates of 31.9% on average, with our diversity-guided filter improving rates by 4.3% and diversity scores by 3.3 on average. NoD-DGMT significantly outperforms six baseline methods, with 16.8% relative improvement over the best baseline, and demonstrates consistent superiority across different model architectures and task complexities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.20052v1' target='_blank'>Learning Skills from Action-Free Videos</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hung-Chieh Fang, Kuo-Han Hung, Chu-Rong Chen, Po-Jung Chou, Chun-Kai Yang, Po-Chen Ko, Yu-Chiang Wang, Yueh-Hua Wu, Min-Hung Chen, Shao-Hua Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-23 05:03:33</h6>
<p class='card-text'>Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19914v1' target='_blank'>A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sujan Warnakulasooriya, Andreas Willig, Xiaobing Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 22:37:58</h6>
<p class='card-text'>Drone applications continue to expand across various domains, with flocking offering enhanced cooperative capabilities but introducing significant challenges during initial formation. Existing flocking algorithms often struggle with efficiency and scalability, particularly when potential collisions force drones into suboptimal trajectories. This paper presents a time-efficient prioritised scheduling algorithm that improves the initial formation process of drone flocks. The method assigns each drone a priority based on its number of potential collisions and its likelihood of reaching its target position without permanently obstructing other drones. Using this hierarchy, each drone computes an appropriate delay to ensure a collision-free path. Simulation results show that the proposed algorithm successfully generates collision-free trajectories for flocks of up to 5000 drones and outperforms the coupling-degree-based heuristic prioritised planning method (CDH-PP) in both performance and computational efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19898v1' target='_blank'>Free-Will vs Free-Wheel: Understanding Community Accessibility Requirements of Wheelchair Users through Interviews, Participatory Action, and Modeling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanna Noyce, Emily Olejniczak, Vaskar Raychoudhury, Roger O. Smith, Md Osman Gani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 21:53:53</h6>
<p class='card-text'>Community participation is an important aspect of an individuals physical and mental well-being. This participation is often limited for persons with disabilities, especially those with ambulatory impairments due to the inability to optimally navigate the community. Accessibility is a multi-faceted problem and varies from person to person. Moreover, it depends on various personal and environmental factors. Despite significant research conducted to understand challenges faced by wheelchair users, developing an accessibility model for wheelchair users by identifying various characteristic features has not been thoroughly studied. In this research, we propose a three-dimensional model of accessibility and validate it through in-depth qualitative analysis involving semi-structured interviews and participatory action research. The outcomes of our studies validated many of our hypotheses about community access for wheelchair users and identified a need for more accessible path planning tools and resources. Overall, this research strengthened our three-dimensional User-Wheelchair-Environment model of accessibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19882v1' target='_blank'>A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mahdi Mostajabdaveh, F. Sibel Salman, Walter J. Gutjahr</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 21:16:52</h6>
<p class='card-text'>The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating limited relief supplies. To balance efficiency and equity, we formulate a bi-objective problem: minimizing a Gini-index-based measure of inequity in unsatisfied demand for fair distribution and minimizing total travel time for timely delivery. We propose a Mixed Integer Programming (MIP) model and use the $ε$-constraint method to handle the bi-objective nature. By deriving mathematical properties of the optimal solution, we introduce valid inequalities and design an algorithm for optimal delivery allocations given feasible vehicle routes. A branch-and-price (B&P) algorithm is developed to solve the problem efficiently. Computational tests on realistic datasets from a past earthquake in Van, Turkey, and predicted data for Istanbul's Kartal region show that the B&P algorithm significantly outperforms commercial MIP solvers. Our bi-objective approach reduces aid distribution inequity by 34% without compromising efficiency. Results indicate that when time constraints are very loose or tight, lexicographic optimization prioritizing demand coverage over fairness is effective. For moderately restrictive time constraints, a balanced approach is essential to avoid inequitable outcomes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19841v1' target='_blank'>A Multi-Agent Retrieval-Augmented Framework for Work-in-Progress Predictio</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yousef Mehrdad Bibalan, Behrouz Far, Mohammad Moshirpour, Bahareh Ghiyasian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 19:51:59</h6>
<p class='card-text'>Work-in-Progress (WiP) prediction is critical for predictive process monitoring, enabling accurate anticipation of workload fluctuations and optimized operational planning. This paper proposes a retrieval-augmented, multi-agent framework that combines retrieval-augmented generation (RAG) and collaborative multi-agent reasoning for WiP prediction. The narrative generation component transforms structured event logs into semantically rich natural language stories, which are embedded into a semantic vector-based process memory to facilitate dynamic retrieval of historical context during inference. The framework includes predictor agents that independently leverage retrieved historical contexts and a decision-making assistant agent that extracts high-level descriptive signals from recent events. A fusion agent then synthesizes predictions using ReAct-style reasoning over agent outputs and retrieved narratives. We evaluate our framework on two real-world benchmark datasets. Results show that the proposed retrieval-augmented multi-agent approach achieves competitive prediction accuracy, obtaining a Mean Absolute Percentage Error (MAPE) of 1.50\% on one dataset, and surpassing Temporal Convolutional Networks (TCN), Long Short-Term Memory (LSTM), and persistence baselines. The results highlight improved robustness, demonstrating the effectiveness of integrating retrieval mechanisms and multi-agent reasoning in WiP prediction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19686v1' target='_blank'>Visual-Aware CoT: Achieving High-Fidelity Visual Consistency in Unified Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zixuan Ye, Quande Liu, Cong Wei, Yuanxing Zhang, Xintao Wang, Pengfei Wan, Kun Gai, Wenhan Luo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 18:59:03</h6>
<p class='card-text'>Recently, the introduction of Chain-of-Thought (CoT) has largely improved the generation ability of unified models. However, it is observed that the current thinking process during generation mainly focuses on the text consistency with the text prompt, ignoring the \textbf{visual context consistency} with the visual reference images during the multi-modal generation, e.g., multi-reference generation. The lack of such consistency results in the failure in maintaining key visual features (like human ID, object attribute, style). To this end, we integrate the visual context consistency into the reasoning of unified models, explicitly motivating the model to sustain such consistency by 1) Adaptive Visual Planning: generating structured visual check list to figure out the visual element of needed consistency keeping, and 2) Iterative Visual Correction: performing self-reflection with the guidance of check lists and refining the generated result in an iterative manner. To achieve this, we use supervised finetuning to teach the model how to plan the visual checking, conduct self-reflection and self-refinement, and use flow-GRPO to further enhance the visual consistency through a customized visual checking reward. The experiments show that our method outperforms both zero-shot unified models and those with text CoTs in multi-modal generation, demonstrating higher visual context consistency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19629v2' target='_blank'>LoGoPlanner: Localization Grounded Navigation Policy with Metric-aware Visual Geometry</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaqi Peng, Wenzhe Cai, Yuqiang Yang, Tai Wang, Yuan Shen, Jiangmiao Pang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 18:03:08</h6>
<p class='card-text'>Trajectory planning in unstructured environments is a fundamental and challenging capability for mobile robots. Traditional modular pipelines suffer from latency and cascading errors across perception, localization, mapping, and planning modules. Recent end-to-end learning methods map raw visual observations directly to control signals or trajectories, promising greater performance and efficiency in open-world settings. However, most prior end-to-end approaches still rely on separate localization modules that depend on accurate sensor extrinsic calibration for self-state estimation, thereby limiting generalization across embodiments and environments. We introduce LoGoPlanner, a localization-grounded, end-to-end navigation framework that addresses these limitations by: (1) finetuning a long-horizon visual-geometry backbone to ground predictions with absolute metric scale, thereby providing implicit state estimation for accurate localization; (2) reconstructing surrounding scene geometry from historical observations to supply dense, fine-grained environmental awareness for reliable obstacle avoidance; and (3) conditioning the policy on implicit geometry bootstrapped by the aforementioned auxiliary tasks, thereby reducing error propagation. We evaluate LoGoPlanner in both simulation and real-world settings, where its fully end-to-end design reduces cumulative error while metric-aware geometry memory enhances planning consistency and obstacle avoidance, leading to more than a 27.3\% improvement over oracle-localization baselines and strong generalization across embodiments and environments. The code and models have been made publicly available on the https://steinate.github.io/logoplanner.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19564v1' target='_blank'>Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanliang Huang, Xia Yan, Peiran Yin, Zhenduo Zhang, Zeyan Shao, Youran Wang, Haoliang Huang, Matthias Althoff</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 16:46:40</h6>
<p class='card-text'>Over the past decade, a wide range of motion planning approaches for autonomous vehicles has been developed to handle increasingly complex traffic scenarios. However, these approaches are rarely compared on standardized benchmarks, limiting the assessment of relative strengths and weaknesses. To address this gap, we present the setup and results of the 4th CommonRoad Motion Planning Competition held in 2024, conducted using the CommonRoad benchmark suite. This annual competition provides an open-source and reproducible framework for benchmarking motion planning algorithms. The benchmark scenarios span highway and urban environments with diverse traffic participants, including passenger cars, buses, and bicycles. Planner performance is evaluated along four dimensions: efficiency, safety, comfort, and compliance with selected traffic rules. This report introduces the competition format and provides a comparison of representative high-performing planners from the 2023 and 2024 editions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19534v1' target='_blank'>SlicerOrbitSurgerySim: An Open-Source Platform for Virtual Registration and Quantitative Comparison of Preformed Orbital Plates</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chi Zhang, Braedon Gunn, Andrew M. Read-Fuller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 16:21:29</h6>
<p class='card-text'>Poor adaptation of orbital implants remains a major contributor to postoperative complications and revision surgery. Although preformed orbital plates are widely used to reduce cost and operative time compared with customized implants, surgeons currently lack publicly available tools and standardized metrics to quantitatively compare plate fit across vendors, sizes, and patient anatomy. We developed SlicerOrbitSurgerySim, an open-source extension for the 3D Slicer platform that enables interactive virtual registration, evaluation, and comparison of multiple preformed orbital plates in a patient-specific virtual planning environment. The software generates reproducible quantitative plate-to-orbit distance metrics and visualization tools that support both patient-specific planning and population-level statistical analysis of plate adaptability. By facilitating objective comparison of implant designs and placement strategies, this tool aims to improve preoperative decision-making, reduce intraoperative plate modification, and promote collaborative research and surgical education. Pilot studies, sample datasets, and detailed tutorials are provided to support testing, transparency, and reproducibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19514v1' target='_blank'>Residential structure survivability to large wildfires in the United States</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mukesh Kumar, John T. Abatzoglou, Crystal A. Kolden, Mojtaba Sadegh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 16:06:56</h6>
<p class='card-text'>Wildfire impacts on US communities have escalated in recent decades, highlighting the need to better understand factors that influence wildfire outcomes. We find that 567,000 homes were exposed to wildfires across the contiguous US during 2001-2020, two-thirds of which occurred and increased five-fold in the Western US. While residential structure survivability - the percent of structures within a wildfire perimeter that survive the fire - remained stable in the Eastern US in the past two decades, it declined by 10% in the West. Survivability was explained by structural age, surrounding fuels, and fire weather. Survivability was 87% for homes built pre-1990 compared to 92% for post-1990 homes in the West. Survivability was lowest in forests compared to grasslands and shrublands. Finally, survivability was markedly lower for fires coincident with extreme fire weather. Our results suggest that modern building codes, fuel management, and proactive planning can strengthen wildfire resilience.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19457v1' target='_blank'>Spectral Shinkage of Gaussian Entropic Optimal Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ho Yun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 15:03:08</h6>
<p class='card-text'>We present a functional calculus treatment of Entropic Optimal Transport (EOT) between Gaussian measures on separable Hilbert spaces, providing a unified framework that handles infinite-dimensional degeneracy. By leveraging the notion of proper alignment and the Schur complement, we reveal that the Gaussian EOT solution operates as a precise \textit{spectral shrinkage}: the optimal coupling is uniquely determined by contracting the spectrum of the correlation operator via a universal scalar function. This geometric insight facilitates an algorithmic shift from iterative fixed-point schemes (e.g., Sinkhorn) to direct algebraic computation, enabling efficient multi-scale analysis, where a single spectral decomposition allows for the exact evaluation of entropic costs across arbitrary regularization parameters $\varepsilon > 0$ at negligible additional cost. Furthermore, we investigate the asymptotic behavior as $\varepsilon \downarrow 0$ in settings where the unregularized Optimal Transport problem admits non-unique solutions. We establish a selection principle that the regularized limit converges to the most diffusive optimal coupling --characterized as the centroid of the convex set of optimal Kantorovich plans. This demonstrates that in degenerate regimes, the entropic limit systematically rejects deterministic Monge solutions (extremal points) in favor of the optimal solution with minimal Hilbert-Schmidt correlation, effectively filtering out spurious correlations in the null space. Finally, we derive stability bounds and convergence rates, recovering established parametric rates ($\varepsilon \log(1/\varepsilon)$) in finite dimensions while identifying distinct non-parametric rates dependent on spectral decay in infinite-dimensional settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19366v1' target='_blank'>Learning General Policies with Policy Gradient Methods</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simon Ståhlberg, Blai Bonet, Hector Geffner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 13:08:58</h6>
<p class='card-text'>While reinforcement learning methods have delivered remarkable results in a number of settings, generalization, i.e., the ability to produce policies that generalize in a reliable and systematic way, has remained a challenge. The problem of generalization has been addressed formally in classical planning where provable correct policies that generalize over all instances of a given domain have been learned using combinatorial methods. The aim of this work is to bring these two research threads together to illuminate the conditions under which (deep) reinforcement learning approaches, and in particular, policy optimization methods, can be used to learn policies that generalize like combinatorial methods do. We draw on lessons learned from previous combinatorial and deep learning approaches, and extend them in a convenient way. From the former, we model policies as state transition classifiers, as (ground) actions are not general and change from instance to instance. From the latter, we use graph neural networks (GNNs) adapted to deal with relational structures for representing value functions over planning states, and in our case, policies. With these ingredients in place, we find that actor-critic methods can be used to learn policies that generalize almost as well as those obtained using combinatorial approaches while avoiding the scalability bottleneck and the use of feature pools. Moreover, the limitations of the DRL methods on the benchmarks considered have little to do with deep learning or reinforcement learning algorithms, and result from the well-understood expressive limitations of GNNs, and the tradeoff between optimality and generalization (general policies cannot be optimal in some domains). Both of these limitations are addressed without changing the basic DRL methods by adding derived predicates and an alternative cost structure to optimize.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19355v1' target='_blank'>First-Order Representation Languages for Goal-Conditioned RL</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simon Ståhlberg, Hector Geffner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 12:54:32</h6>
<p class='card-text'>First-order relational languages have been used in MDP planning and reinforcement learning (RL) for two main purposes: specifying MDPs in compact form, and representing and learning policies that are general and not tied to specific instances or state spaces. In this work, we instead consider the use of first-order languages in goal-conditioned RL and generalized planning. The question is how to learn goal-conditioned and general policies when the training instances are large and the goal cannot be reached by random exploration alone. The technique of Hindsight Experience Replay (HER) provides an answer to this question: it relabels unsuccessful trajectories as successful ones by replacing the original goal with one that was actually achieved. If the target policy must generalize across states and goals, trajectories that do not reach the original goal states can enable more data- and time-efficient learning. In this work, we show that further performance gains can be achieved when states and goals are represented by sets of atoms. We consider three versions: goals as full states, goals as subsets of the original goals, and goals as lifted versions of these subgoals. The result is that the latter two successfully learn general policies on large planning instances with sparse rewards by automatically creating a curriculum of easier goals of increasing complexity. The experiments illustrate the computational gains of these versions, their limitations, and opportunities for addressing them.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19340v1' target='_blank'>Quantum and classical algorithms for daily railway rolling stock circulation plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ewa Kędziera, Wojciech Gamon, Mátyás Koniorczyk, Zakaria Mzaouali, Andrea Galadíková, Krzysztof Domino</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 12:36:20</h6>
<p class='card-text'>We study daily rolling stock circulation planning for electric multiple units (EMUs) on a regional passenger network, focusing on services where identical EMUs may be coupled in pairs on selected routes. Motivated by the operational needs of the regional operator Silesian Railways in Poland, we formulate an acyclic mixed-integer linear program on a one-day horizon that incorporates depot balance constraints, demand-driven seat and bicycle capacity limits (which is a new aspect requested by the regional operator and local society of passengers), and simple crew availability constraints. The model is designed to support both baseline planning and disruption management under increased passenger demand. Using a graph-hypergraph representation of trips and single or coupled EMU movements, we first solve the problem with a classical ILP solver. We then derive a Quadratic Unconstrained Binary Optimization (QUBO) reformulation - which is frequently used as the input for quantum optimization - and evaluate its solution by quantum annealing on D-Wave Advantage systems and by the classical quantum-inspired VeloxQ solver. Computational experiments on real-world instances from the Silesian network, with up to 404 train trips and 11 EMU types, show that the ILP approach can obtain high-quality daily circulation plans within at most about 40 minutes, whereas current quantum and quantum-inspired solvers are restricted to substantially smaller sub-instances (up to 51 and 78 train trips, respectively) due to embedding and QUBO size limitations. These results quantify the present frontier of QUBO-based methods for rolling stock circulation and point towards hybrid decision-support architectures in which quantum or quantum-inspired optimizers address only local subproblems within a broader classical planning framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2512.19336v1' target='_blank'>GANeXt: A Fully ConvNeXt-Enhanced Generative Adversarial Network for MRI- and CBCT-to-CT Synthesis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyuan Mei, Yan Xia, Fuxin Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-12-22 12:32:16</h6>
<p class='card-text'>The synthesis of computed tomography (CT) from magnetic resonance imaging (MRI) and cone-beam CT (CBCT) plays a critical role in clinical treatment planning by enabling accurate anatomical representation in adaptive radiotherapy. In this work, we propose GANeXt, a 3D patch-based, fully ConvNeXt-powered generative adversarial network for unified CT synthesis across different modalities and anatomical regions. Specifically, GANeXt employs an efficient U-shaped generator constructed from stacked 3D ConvNeXt blocks with compact convolution kernels, while the discriminator adopts a conditional PatchGAN. To improve synthesis quality, we incorporate a combination of loss functions, including mean absolute error (MAE), perceptual loss, segmentation-based masked MAE, and adversarial loss and a combination of Dice loss and cross-entropy for multi-head segmentation discriminator. For both tasks, training is performed with a batch size of 8 using two separate AdamW optimizers for the generator and discriminator, each equipped with a warmup and cosine decay scheduler, with learning rates of $5\times10^{-4}$ and $1\times10^{-3}$, respectively. Data preprocessing includes deformable registration, foreground cropping, percentile normalization for the input modality, and linear normalization of the CT to the range $[-1024, 1000]$. Data augmentation involves random zooming within $(0.8, 1.3)$ (for MRI-to-CT only), fixed-size cropping to $32\times160\times192$ for MRI-to-CT and $32\times128\times128$ for CBCT-to-CT, and random flipping. During inference, we apply a sliding-window approach with $0.8$ overlap and average folding to reconstruct the full-size sCT, followed by inversion of the CT normalization. After joint training on all regions without any fine-tuning, the final models are selected at the end of 3000 epochs for MRI-to-CT and 1000 epochs for CBCT-to-CT using the full training dataset.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>