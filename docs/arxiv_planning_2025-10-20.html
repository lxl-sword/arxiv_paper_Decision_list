<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-10-20</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-10-20</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15831v1' target='_blank'>VISTA: A Test-Time Self-Improving Video Generation Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Do Xuan Long, Xingchen Wan, Hootan Nakhost, Chen-Yu Lee, Tomas Pfister, Sercan Ö. Arık</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 17:12:08</h6>
<p class='card-text'>Despite rapid advances in text-to-video synthesis, generated video quality
remains critically dependent on precise user prompts. Existing test-time
optimization methods, successful in other domains, struggle with the
multi-faceted nature of video. In this work, we introduce VISTA (Video
Iterative Self-improvemenT Agent), a novel multi-agent system that autonomously
improves video generation through refining prompts in an iterative loop. VISTA
first decomposes a user idea into a structured temporal plan. After generation,
the best video is identified through a robust pairwise tournament. This winning
video is then critiqued by a trio of specialized agents focusing on visual,
audio, and contextual fidelity. Finally, a reasoning agent synthesizes this
feedback to introspectively rewrite and enhance the prompt for the next
generation cycle. Experiments on single- and multi-scene video generation
scenarios show that while prior methods yield inconsistent gains, VISTA
consistently improves video quality and alignment with user intent, achieving
up to 60% pairwise win rate against state-of-the-art baselines. Human
evaluators concur, preferring VISTA outputs in 66.4% of comparisons.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15762v1' target='_blank'>Incorporating estimands into meta-analyses of clinical trials</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Antonio Remiro-Azócar, Pepa Polavieja, Emmanuelle Boutmy, Alessandro Ghiretti, Lise Lotte Nystrup Husemoen, Khadija Rerhou Rantell, Tatsiana Vaitsiakhovich, David M. Phillippo, Jay J. H. Park, Helle Lynggaard, Robert Bauer, Antonia Morga</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 15:52:04</h6>
<p class='card-text'>The estimand framework is increasingly established to pose research questions
in confirmatory clinical trials. In evidence synthesis, the uptake of estimands
has been modest, and the PICO (Population, Intervention, Comparator, Outcome)
framework is more often applied. While PICOs and estimands have overlapping
elements, the estimand framework explicitly considers different strategies for
intercurrent events. We propose a pragmatic framework for the use of estimands
in meta-analyses of clinical trials, highlighting the value of estimands to
systematically identify and mitigate key sources of quantitative heterogeneity,
and to enhance the applicability or external validity of pooled estimates.
Focus is placed on the role of strategies for intercurrent events, within the
specific context of meta-analyses for health technology assessment. We apply
the estimand framework to a network meta-analysis of clinical trials, comparing
the efficacy of semaglutide versus dulaglutide in type 2 diabetes. We explore
the impact of a treatment policy strategy for treatment discontinuation or
initiation of rescue medication versus a hypothetical strategy for the
corresponding intercurrent events. The specification of different target
estimands at the meta-analytical level allows us to be explicit about the
source of heterogeneity, the intercurrent event strategy, driving any potential
differences in results. We advocate for the integration of estimands into the
planning of meta-analyses, while acknowledging that potential challenges exist
in the absence of subject-level data. Estimands can complement PICOs to
strengthen communication between stakeholders about what evidence syntheses
seek to demonstrate, and to ensure that the generated evidence is maximally
relevant to healthcare decision-makers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15761v1' target='_blank'>QSilk: Micrograin Stabilization and Adaptive Quantile Clipping for
  Detail-Friendly Latent Diffusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Denis Rychkovskiy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 15:50:30</h6>
<p class='card-text'>We present QSilk, a lightweight, always-on stabilization layer for latent
diffusion that improves high-frequency fidelity while suppressing rare
activation spikes. QSilk combines (i) a per-sample micro clamp that gently
limits extreme values without washing out texture, and (ii) Adaptive Quantile
Clip (AQClip), which adapts the allowed value corridor per region. AQClip can
operate in a proxy mode using local structure statistics or in an attention
entropy guided mode (model confidence). Integrated into the CADE 2.5 rendering
pipeline, QSilk yields cleaner, sharper results at low step counts and
ultra-high resolutions with negligible overhead. It requires no training or
fine-tuning and exposes minimal user controls. We report consistent qualitative
improvements across SD/SDXL backbones and show synergy with CFG/Rescale,
enabling slightly higher guidance without artifacts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15749v1' target='_blank'>SEGA: A Stepwise Evolution Paradigm for Content-Aware Layout Generation
  with Design Prior</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoran Wang, Bo Zhao, Jinghui Wang, Hanzhang Wang, Huan Yang, Wei Ji, Hao Liu, Xinyan Xiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 15:36:26</h6>
<p class='card-text'>In this paper, we study the content-aware layout generation problem, which
aims to automatically generate layouts that are harmonious with a given
background image. Existing methods usually deal with this task with a
single-step reasoning framework. The lack of a feedback-based self-correction
mechanism leads to their failure rates significantly increasing when faced with
complex element layout planning. To address this challenge, we introduce SEGA,
a novel Stepwise Evolution Paradigm for Content-Aware Layout Generation.
Inspired by the systematic mode of human thinking, SEGA employs a hierarchical
reasoning framework with a coarse-to-fine strategy: first, a coarse-level
module roughly estimates the layout planning results; then, another refining
module performs fine-level reasoning regarding the coarse planning results.
Furthermore, we incorporate layout design principles as prior knowledge into
the model to enhance its layout planning ability. Besides, we present
GenPoster-100K that is a new large-scale poster dataset with rich
meta-information annotation. The experiments demonstrate the effectiveness of
our approach by achieving the state-of-the-art results on multiple benchmark
datasets. Our project page is at: https://brucew91.github.io/SEGA.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15718v1' target='_blank'>Weakening Goals in Logical Specifications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ben M. Andrew</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 15:03:37</h6>
<p class='card-text'>Logical specifications are widely used to represent software systems and
their desired properties. Under system degradation or environmental changes,
commonly seen in complex real-world robotic systems, these properties may no
longer hold and so traditional verification methods will simply fail to
construct a proof. However, weaker versions of these properties do still hold
and can be useful for understanding the system's behaviour in uncertain
conditions, as well as aiding compositional verification. We present a
counterexample-guided technique for iteratively weakening properties, apply it
to propositional logic specifications, and discuss planned extensions to
state-based representations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15717v1' target='_blank'>Detection Seizure Onset Zone Using Circadian Fluctuating Epileptic
  Biomarkers: A Signal Processing and Machine Learning Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mehdi Zekriyapanah Gashti, Mostafa Mohammadpour, Hassan Eshkiki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 15:01:52</h6>
<p class='card-text'>Epileptic biomarkers play a crucial role in identifying the origin of
seizures, an essential aspect of pre-surgical planning for epilepsy treatment.
These biomarkers can vary significantly over time. By studying these temporal
fluctuations, we can enhance their effectiveness in guiding surgical planning.
This research focuses on examining how circadian rhythms influence epilepsy
biomarkers and aims to determine the optimal times for their analysis. To
investigate the relationship between epilepsy biomarkers and circadian rhythm,
the sleep/wake states first need to be classified. After the biomarkers are
identified, they are compared across these states. A retrospective analysis was
conducted on intracranial electroencephalography data from patients with focal
epilepsy. The biomarkers spike, sequence of spikes, high-frequency oscillations
(HFOs), and pathological HFOs were identified through automatic detection. The
alpha/delta ratio was also calculated to distinguish between asleep and awake
stages. Data from 9 patients were analyzed, and the classification of sleep and
wake states was achieved with an area under the curve of 84%. All biomarker
rates were higher during the sleep stage compared to the wake stage.
Pathological HFOs and the sequence of spikes proved to be more precise
indicators regarding distance to seizure onset than spikes or HFOs. Unlike
previous studies that relied predominantly on long-term spike biomarker
analysis, this study is the first to utilize a comprehensive set of biomarkers,
including HFOs, spike sequences, and pathological HFOs, to enhance seizure
onset zone prediction. The rates of epilepsy biomarkers during sleep vary
considerably from those seen while awake, making sleep data analysis more
effective for accurately predicting the seizure onset zone.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15615v1' target='_blank'>Deep Learning Based Domain Adaptation Methods in Remote Sensing: A
  Comprehensive Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuchang Lyu, Qi Zhao, Zheng Zhou, Meng Li, You Zhou, Dingding Yao, Guangliang Cheng, Huiyu Zhou, Zhenwei Shi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 13:00:44</h6>
<p class='card-text'>Domain adaptation is a crucial and increasingly important task in remote
sensing, aiming to transfer knowledge from a source domain a differently
distributed target domain. It has broad applications across various real-world
applications, including remote sensing element interpretation, ecological
environment monitoring, and urban/rural planning. However, domain adaptation in
remote sensing poses significant challenges due to differences in data, such as
variations in ground sampling distance, imaging modes from various sensors,
geographical landscapes, and environmental conditions. In recent years, deep
learning has emerged as a powerful tool for feature representation and
cross-domain knowledge transfer, leading to widespread adoption in remote
sensing tasks. In this paper, we present a comprehensive survey of significant
advancements in deep learning based domain adaptation for remote sensing. We
first introduce the preliminary knowledge to clarify key concepts, mathematical
notations, and the taxonomy of methodologies. We then organize existing
algorithms from multiple perspectives, including task categorization, input
mode, supervision paradigm, and algorithmic granularity, providing readers with
a structured understanding of the field. Next, we review widely used datasets
and summarize the performance of state-of-the-art methods to provide an
overview of current progress. We also identify open challenges and potential
directions to guide future research in domain adaptation for remote sensing.
Compared to previous surveys, this work addresses a broader range of domain
adaptation tasks in remote sensing, rather than concentrating on a few
subfields. It also presents a systematic taxonomy, providing a more
comprehensive and organized understanding of the field. As a whole, this survey
can inspire the research community, foster understanding, and guide future work
in the field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15573v1' target='_blank'>Hypergame-based Cognition Modeling and Intention Interpretation for
  Human-Driven Vehicles in Connected Mixed Traffic</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jianguo Chen, Zhengqin Liu, Jinlong Lei, Peng Yi, Yiguang Hong, Hong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 12:11:21</h6>
<p class='card-text'>With the practical implementation of connected and autonomous vehicles
(CAVs), the traffic system is expected to remain a mix of CAVs and human-driven
vehicles (HVs) for the foreseeable future. To enhance safety and traffic
efficiency, the trajectory planning strategies of CAVs must account for the
influence of HVs, necessitating accurate HV trajectory prediction. Current
research often assumes that human drivers have perfect knowledge of all
vehicles' objectives, an unrealistic premise. This paper bridges the gap by
leveraging hypergame theory to account for cognitive and perception limitations
in HVs. We model human bounded rationality without assuming them to be merely
passive followers and propose a hierarchical cognition modeling framework that
captures cognitive relationships among vehicles. We further analyze the
cognitive stability of the system, proving that the strategy profile where all
vehicles adopt cognitively equilibrium strategies constitutes a hyper Nash
equilibrium when CAVs accurately learn HV parameters. To achieve this, we
develop an inverse learning algorithm for distributed intention interpretation
via vehicle-to-everything (V2X) communication, which extends the framework to
both offline and online scenarios. Additionally, we introduce a distributed
trajectory prediction and planning approach for CAVs, leveraging the learned
parameters in real time. Simulations in highway lane-changing scenarios
demonstrate the proposed method's accuracy in parameter learning, robustness to
noisy trajectory observations, and safety in HV trajectory prediction. The
results validate the effectiveness of our method in both offline and online
implementations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15541v1' target='_blank'>An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation
  in 2D Brain Tumor Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saumya B</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 11:19:44</h6>
<p class='card-text'>Accurate brain tumor segmentation from MRI is vital for diagnosis and
treatment planning. Although Monte Carlo (MC) Dropout is widely used to
estimate model uncertainty, its effectiveness in identifying segmentation
errors -- especially near tumor boundaries -- remains unclear. This study
empirically examines the relationship between MC Dropout--based uncertainty and
segmentation error in 2D brain tumor MRI segmentation using a U-Net trained
under four augmentation settings: none, horizontal flip, rotation, and scaling.
Uncertainty was computed from 50 stochastic forward passes and correlated with
pixel-wise errors using Pearson and Spearman coefficients. Results show weak
global correlations ($r \approx 0.30$--$0.38$) and negligible boundary
correlations ($|r| < 0.05$). Although differences across augmentations were
statistically significant ($p < 0.001$), they lacked practical relevance. These
findings suggest that MC Dropout uncertainty provides limited cues for boundary
error localization, underscoring the need for alternative or hybrid uncertainty
estimation methods in medical image segmentation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15505v1' target='_blank'>Perfect Prediction or Plenty of Proposals? What Matters Most in Planning
  for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aron Distelzweig, Faris Janjoš, Oliver Scheel, Sirish Reddy Varra, Raghu Rajan, Joschka Boedecker</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 10:17:54</h6>
<p class='card-text'>Traditionally, prediction and planning in autonomous driving (AD) have been
treated as separate, sequential modules. Recently, there has been a growing
shift towards tighter integration of these components, known as Integrated
Prediction and Planning (IPP), with the aim of enabling more informed and
adaptive decision-making. However, it remains unclear to what extent this
integration actually improves planning performance. In this work, we
investigate the role of prediction in IPP approaches, drawing on the widely
adopted Val14 benchmark, which encompasses more common driving scenarios with
relatively low interaction complexity, and the interPlan benchmark, which
includes highly interactive and out-of-distribution driving situations. Our
analysis reveals that even access to perfect future predictions does not lead
to better planning outcomes, indicating that current IPP methods often fail to
fully exploit future behavior information. Instead, we focus on high-quality
proposal generation, while using predictions primarily for collision checks. We
find that many imitation learning-based planners struggle to generate realistic
and plausible proposals, performing worse than PDM - a simple lane-following
approach. Motivated by this observation, we build on PDM with an enhanced
proposal generation method, shifting the emphasis towards producing diverse but
realistic and high-quality proposals. This proposal-centric approach
significantly outperforms existing methods, especially in out-of-distribution
and highly interactive settings, where it sets new state-of-the-art results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15446v1' target='_blank'>VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end
  Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziang Guo, Zufeng Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 09:02:18</h6>
<p class='card-text'>In autonomous driving, dynamic environment and corner cases pose significant
challenges to the robustness of ego vehicle's state understanding and decision
making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving
that explicitly models state-action mapping to address these challenges,
enabling interpretable and robust decision making. By leveraging the
advancement of the state understanding of the Vision Language Action Model
(VLA) with generative diffusion policy-based action head, our VDRive guides the
driving contextually and geometrically. Contextually, VLA predicts future
observations through token generation pre-training, where the observations are
represented as discrete codes by a Conditional Vector Quantized Variational
Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning
fine-tuning of the VLA to predict future trajectories and actions based on
current driving conditions. VLA supplies the current state tokens and predicted
state tokens for the action policy head to generate hierarchical actions and
trajectories. During policy training, a learned critic evaluates the actions
generated by the policy and provides gradient-based feedback, forming an
actor-critic framework that enables a reinforcement-based policy learning
pipeline. Experiments show that our VDRive achieves state-of-the-art
performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop
planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15434v1' target='_blank'>Semantic4Safety: Causal Insights from Zero-shot Street View Imagery
  Segmentation for Urban Road Safety</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huan Chen, Ting Han, Siyu Chen, Zhihao Guo, Yiping Chen, Meiliu Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 08:45:28</h6>
<p class='card-text'>Street-view imagery (SVI) offers a fine-grained lens on traffic risk, yet two
fundamental challenges persist: (1) how to construct street-level indicators
that capture accident-related features, and (2) how to quantify their causal
impacts across different accident types. To address these challenges, we
propose Semantic4Safety, a framework that applies zero-shot semantic
segmentation to SVIs to derive 11 interpretable streetscape indicators, and
integrates road type as contextual information to analyze approximately 30,000
accident records in Austin. Specifically, we train an eXtreme Gradient Boosting
(XGBoost) multi-class classifier and use Shapley Additive Explanations (SHAP)
to interpret both global and local feature contributions, and then apply
Generalized Propensity Score (GPS) weighting and Average Treatment Effect (ATE)
estimation to control confounding and quantify causal effects. Results uncover
heterogeneous, accident-type-specific causal patterns: features capturing scene
complexity, exposure, and roadway geometry dominate predictive power; larger
drivable area and emergency space reduce risk, whereas excessive visual
openness can increase it. By bridging predictive modeling with causal
inference, Semantic4Safety supports targeted interventions and high-risk
corridor diagnosis, offering a scalable, data-informed tool for urban road
safety planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15368v1' target='_blank'>TKHist: Cardinality Estimation for Join Queries via Histograms with
  Dominant Attribute Correlation Finding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Renrui Li, Qingzhi Ma, Jiajie Xu, Lei Zhao, An Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 07:05:38</h6>
<p class='card-text'>Cardinality estimation has long been crucial for cost-based database
optimizers in identifying optimal query execution plans, attracting significant
attention over the past decades. While recent advancements have significantly
improved the accuracy of multi-table join query estimations, these methods
introduce challenges such as higher space overhead, increased latency, and
greater complexity, especially when integrated with the binary join framework.
In this paper, we introduce a novel cardinality estimation method named TKHist,
which addresses these challenges by relaxing the uniformity assumption in
histograms. TKHist captures bin-wise non-uniformity information, enabling
accurate cardinality estimation for join queries without filter predicates.
Furthermore, we explore the attribute independent assumption, which can lead to
significant over-estimation rather than under-estimation in multi-table join
queries. To address this issue, we propose the dominating join path correlation
discovery algorithm to highlight and manage correlations between join keys and
filter predicates. Our extensive experiments on popular benchmarks demonstrate
that TKHist reduces error variance by 2-3 orders of magnitude compared to SOTA
methods, while maintaining comparable or lower memory usage.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15336v1' target='_blank'>Adaptive Cost-Map-based Path Planning in Partially Unknown Environments
  with Movable Obstacles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liviu-Mihai Stan, Ranulfo Bezerra, Shotaro Kojima, Tsige Tadesse Alemayoh, Satoshi Tadokoro, Masashi Konyo, Kazunori Ohno</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 05:57:20</h6>
<p class='card-text'>Reliable navigation in disaster-response and other unstructured indoor
settings requires robots not only to avoid obstacles but also to recognise when
those obstacles can be pushed aside. We present an adaptive, LiDAR and
odometry-based path-planning framework that embeds this capability into the
ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing
from a prior static map as tentatively movable and assigns a reduced traversal
cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to
actual velocity; when the robot slows appreciably, the local cost is raised
from light to heavy, and on a stall to lethal, prompting the global planner to
back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated
objects and cluttered corridors, show higher goal-reach rates and fewer
deadlocks than a no-layer baseline, with traversal times broadly comparable.
Because the method relies only on planar scans and CPU-level computation, it
suits resource-constrained search and rescue robots and integrates into
heterogeneous platforms with minimal engineering. Overall, the results indicate
that interaction-aware cost maps are a lightweight, ROS2-native extension for
navigating among potentially movable obstacles in unstructured settings. The
full implementation will be released as open source
athttps://costmap-namo.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15289v1' target='_blank'>QCFace: Image Quality Control for boosting Face Representation &
  Recognition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Duc-Phuong Doan-Ngo, Thanh-Dang Diep, Thanh Nguyen-Duc, Thanh-Sach LE, Nam Thoai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 04:00:20</h6>
<p class='card-text'>Recognizability, a key perceptual factor in human face processing, strongly
affects the performance of face recognition (FR) systems in both verification
and identification tasks. Effectively using recognizability to enhance feature
representation remains challenging. In deep FR, the loss function plays a
crucial role in shaping how features are embedded. However, current methods
have two main drawbacks: (i) recognizability is only partially captured through
soft margin constraints, resulting in weaker quality representation and lower
discrimination, especially for low-quality or ambiguous faces; (ii) mutual
overlapping gradients between feature direction and magnitude introduce
undesirable interactions during optimization, causing instability and confusion
in hypersphere planning, which may result in poor generalization, and entangled
representations where recognizability and identity are not cleanly separated.
To address these issues, we introduce a hard margin strategy - Quality Control
Face (QCFace), which overcomes the mutual overlapping gradient problem and
enables the clear decoupling of recognizability from identity representation.
Based on this strategy, a novel hard-margin-based loss function employs a
guidance factor for hypersphere planning, simultaneously optimizing for
recognition ability and explicit recognizability representation. Extensive
experiments confirm that QCFace not only provides robust and quantifiable
recognizability encoding but also achieves state-of-the-art performance in both
verification and identification benchmarks compared to existing
recognizability-based losses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15282v1' target='_blank'>Post-Processing Methods for Improving Accuracy in MRI Inpainting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nishad Kulkarni, Krithika Iyer, Austin Tapp, Abhijeet Parida, Daniel Capellán-Martín, Zhifan Jiang, María J. Ledesma-Carbayo, Syed Muhammad Anwar, Marius George Linguraru</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 03:42:23</h6>
<p class='card-text'>Magnetic Resonance Imaging (MRI) is the primary imaging modality used in the
diagnosis, assessment, and treatment planning for brain pathologies. However,
most automated MRI analysis tools, such as segmentation and registration
pipelines, are optimized for healthy anatomies and often fail when confronted
with large lesions such as tumors. To overcome this, image inpainting
techniques aim to locally synthesize healthy brain tissues in tumor regions,
enabling the reliable application of general-purpose tools. In this work, we
systematically evaluate state-of-the-art inpainting models and observe a
saturation in their standalone performance. In response, we introduce a
methodology combining model ensembling with efficient post-processing
strategies such as median filtering, histogram matching, and pixel averaging.
Further anatomical refinement is achieved via a lightweight U-Net enhancement
stage. Comprehensive evaluation demonstrates that our proposed pipeline
improves the anatomical plausibility and visual fidelity of inpainted regions,
yielding higher accuracy and more robust outcomes than individual baseline
models. By combining established models with targeted post-processing, we
achieve improved and more accessible inpainting outcomes, supporting broader
clinical deployment and sustainable, resource-conscious research. Our 2025
BraTS inpainting docker is available at
https://hub.docker.com/layers/aparida12/brats2025/inpt.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15244v1' target='_blank'>Planner and Executor: Collaboration between Discrete Diffusion And
  Autoregressive Models in Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lina Berrayana, Ahmed Heakl, Muhammad Abdullah Sohail, Thomas Hofmann, Salman Khan, Wei Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 02:16:19</h6>
<p class='card-text'>Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15229v1' target='_blank'>A Generalized Sylvester-Fermat-Torricelli problem with application in
  disaster relief operations by UAVs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sina Kazemdehbashi, Yanchao Liu, Boris S. Mordukhovich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 01:39:20</h6>
<p class='card-text'>Natural and human-made disasters can cause severe devastation and claim
thousands of lives worldwide. Therefore, developing efficient methods for
disaster response and management is a critical task for relief teams. One of
the most essential components of effective response is the rapid collection of
information about affected areas, damages, and victims. More data translates
into better coordination, faster rescue operations, and ultimately, more lives
saved. However, in some disasters, such as earthquakes, the communication
infrastructure is often partially or completely destroyed, making it extremely
difficult for victims to send distress signals and for rescue teams to locate
and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as
valuable tools in such scenarios. In particular, a fleet of UAVs can be
dispatched from a mobile station to the affected area to facilitate data
collection and establish temporary communication networks. Nevertheless,
real-world deployment of UAVs faces several challenges, with adverse weather
conditions--especially wind--being among the most significant. To address this,
we develop a novel mathematical framework to determine the optimal location of
a mobile UAV station while explicitly accounting for the heterogeneity of the
UAVs and the effect of wind. In particular, we generalize the Sylvester problem
to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures
complex factors such as wind influence, UAV heterogeneity, and back-and-forth
motion within a unified framework. The proposed framework enhances the
practicality of UAV-based disaster response planning by accounting for
real-world factors such as wind and UAV heterogeneity. Experimental results
demonstrate that it can reduce wasted operational time by up to 84%, making
post-disaster missions significantly more efficient and effective.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15226v1' target='_blank'>PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended
  Aerial Payload Transportation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mrunal Sarvaiya, Guanrui Li, Giuseppe Loianno</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-17 01:28:44</h6>
<p class='card-text'>Aerial transportation robots using suspended cables have emerged as versatile
platforms for disaster response and rescue operations. To maximize the
capabilities of these systems, robots need to aggressively fly through tightly
constrained environments, such as dense forests and structurally unsafe
buildings, while minimizing flight time and avoiding obstacles. Existing
methods geometrically over-approximate the vehicle and obstacles, leading to
conservative maneuvers and increased flight times. We eliminate these
restrictions by proposing PolyFly, an optimal global planner which considers a
non-conservative representation for aerial transportation by modeling each
physical component of the environment, and the robot (quadrotor, cable and
payload), as independent polytopes. We further increase the model accuracy by
incorporating the attitude of the physical components by constructing
orientation-aware polytopes. The resulting optimal control problem is
efficiently solved by converting the polytope constraints into smooth
differentiable constraints via duality theory. We compare our method against
the existing state-of-the-art approach in eight maze-like environments and show
that PolyFly produces faster trajectories in each scenario. We also
experimentally validate our proposed approach on a real quadrotor with a
suspended payload, demonstrating the practical reliability and accuracy of our
method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15196v1' target='_blank'>Analytic de Rham stacks of Fargues-Fontaine curves</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Johannes Anschütz, Guido Bosco, Arthur-César Le Bras, Juan Esteban Rodríguez Camargo, Peter Scholze</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 23:40:13</h6>
<p class='card-text'>We define and initiate the study of analytic de Rham stacks of relative
Fargues-Fontaine curves. To this end, we develop a theory of analytic de Rham
stacks with sufficiently strong descent and approximation properties.
Specializing to the de Rham stack of the Fargues-Fontaine curve attached to
$\mathbb{C}_p$, we apply the general theory to obtain a new geometric proof of
the $p$-adic monodromy theorem, avoiding any reliance on earlier results on
$p$-adic differential equations. Building on the foundations established here,
we plan in a sequel to investigate the cohomology of de Rham stacks of relative
Fargues-Fontaine curves in geometric situations and, in particular, provide a
stack-theoretic definition of Hyodo-Kato cohomology.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15177v1' target='_blank'>Finding geodesics with the Deep Ritz method</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Conor Rowan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 22:30:59</h6>
<p class='card-text'>Geodesic problems involve computing trajectories between prescribed initial
and final states to minimize a user-defined measure of distance, cost, or
energy. They arise throughout physics and engineering -- for instance, in
determining optimal paths through complex environments, modeling light
propagation in refractive media, and the study of spacetime trajectories in
control theory and general relativity. Despite their ubiquity, the scientific
machine learning (SciML) community has given relatively little attention to
investigating its methods in the context of these problems. In this work, we
argue that given their simple geometry, variational structure, and natural
nonlinearity, geodesic problems are particularly well-suited for the Deep Ritz
method. We substantiate this claim with three numerical examples drawn from
path planning, optics, and solid mechanics. Our goal is not to provide an
exhaustive study of geodesic problems, but rather to identify a promising
application of the Deep Ritz method and a fruitful direction for future SciML
research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15114v1' target='_blank'>Autonomous Reactive Masonry Construction using Collaborative
  Heterogeneous Aerial Robots with Experimental Demonstration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marios-Nektarios Stamatopoulos, Elias Small, Shridhar Velhal, Avijit Banerjee, George Nikolakopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 20:15:11</h6>
<p class='card-text'>This article presents a fully autonomous aerial masonry construction
framework using heterogeneous unmanned aerial vehicles (UAVs), supported by
experimental validation. Two specialized UAVs were developed for the task: (i)
a brick-carrier UAV equipped with a ball-joint actuation mechanism for precise
brick manipulation, and (ii) an adhesion UAV integrating a servo-controlled
valve and extruder nozzle for accurate adhesion application. The proposed
framework employs a reactive mission planning unit that combines a dependency
graph of the construction layout with a conflict graph to manage simultaneous
task execution, while hierarchical state machines ensure robust operation and
safe transitions during task execution. Dynamic task allocation allows
real-time adaptation to environmental feedback, while minimum-jerk trajectory
generation ensures smooth and precise UAV motion during brick pickup and
placement. Additionally, the brick-carrier UAV employs an onboard vision system
that estimates brick poses in real time using ArUco markers and a least-squares
optimization filter, enabling accurate alignment during construction. To the
best of the authors' knowledge, this work represents the first experimental
demonstration of fully autonomous aerial masonry construction using
heterogeneous UAVs, where one UAV precisely places the bricks while another
autonomously applies adhesion material between them. The experimental results
supported by the video showcase the effectiveness of the proposed framework and
demonstrate its potential to serve as a foundation for future developments in
autonomous aerial robotic construction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.15038v1' target='_blank'>AlignFlow: Improving Flow-based Generative Models with Semi-Discrete
  Optimal Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lingkai Kong, Molei Tao, Yang Liu, Bryan Wang, Jinmiao Fu, Chien-Chih Wang, Huidong Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 18:00:43</h6>
<p class='card-text'>Flow-based Generative Models (FGMs) effectively transform noise into complex
data distributions. Incorporating Optimal Transport (OT) to couple noise and
data during FGM training has been shown to improve the straightness of flow
trajectories, enabling more effective inference. However, existing OT-based
methods estimate the OT plan using (mini-)batches of sampled noise and data
points, which limits their scalability to large and high-dimensional datasets
in FGMs. This paper introduces AlignFlow, a novel approach that leverages
Semi-Discrete Optimal Transport (SDOT) to enhance the training of FGMs by
establishing an explicit, optimal alignment between noise distribution and data
points with guaranteed convergence. SDOT computes a transport map by
partitioning the noise space into Laguerre cells, each mapped to a
corresponding data point. During FGM training, i.i.d. noise samples are paired
with data points via the SDOT map. AlignFlow scales well to large datasets and
model architectures with negligible computational overhead. Experimental
results show that AlignFlow improves the performance of a wide range of
state-of-the-art FGM algorithms and can be integrated as a plug-and-play
component. Code is available at: https://github.com/konglk1203/AlignFlow.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.14893v1' target='_blank'>STITCHER: Constrained Trajectory Planning in Known Environments with
  Real-Time Motion Primitive Search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Helene J. Levy, Brett T. Lopez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 17:12:06</h6>
<p class='card-text'>Autonomous high-speed navigation through large, complex environments requires
real-time generation of agile trajectories that are dynamically feasible,
collision-free, and satisfy state or actuator constraints. Modern trajectory
planning techniques primarily use numerical optimization, as they enable the
systematic computation of high-quality, expressive trajectories that satisfy
various constraints. However, stringent requirements on computation time and
the risk of numerical instability can limit the use of optimization-based
planners in safety-critical scenarios. This work presents an optimization-free
planning framework called STITCHER that stitches short trajectory segments
together with graph search to compute long-range, expressive, and near-optimal
trajectories in real-time. STITCHER outperforms modern optimization-based
planners through our innovative planning architecture and several algorithmic
developments that make real-time planning possible. Extensive simulation
testing is performed to analyze the algorithmic components that make up
STITCHER, along with a thorough comparison with two state-of-the-art
optimization planners. Simulation tests show that safe trajectories can be
created within a few milliseconds for paths that span the entirety of two 50 m
x 50 m environments. Hardware tests with a custom quadrotor verify that
STITCHER can produce trackable paths in real-time while respecting nonconvex
constraints, such as limits on tilt angle and motor forces, which are otherwise
hard to include in optimization-based planners.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.14828v1' target='_blank'>RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinrui Liu, Bingyan Nie, Boyu Li, Yaran Chen, Yuze Wang, Shunsen He, Haoran Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 16:04:35</h6>
<p class='card-text'>Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.14803v1' target='_blank'>Scaling Artificial Intelligence for Multi-Tumor Early Detection with
  More Reports, Fewer Masks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pedro R. A. S. Bassi, Xinze Zhou, Wenxuan Li, Szymon Płotka, Jieneng Chen, Qi Chen, Zheren Zhu, Jakub Prządo, Ibrahim E. Hamacı, Sezgin Er, Yuhan Wang, Ashwin Kumar, Bjoern Menze, Jarosław B. Ćwikła, Yuyin Zhou, Akshay S. Chaudhari, Curtis P. Langlotz, Sergio Decherchi, Andrea Cavalli, Kang Wang, Yang Yang, Alan L. Yuille, Zongwei Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 15:35:44</h6>
<p class='card-text'>Early tumor detection save lives. Each year, more than 300 million computed
tomography (CT) scans are performed worldwide, offering a vast opportunity for
effective cancer screening. However, detecting small or early-stage tumors on
these CT scans remains challenging, even for experts. Artificial intelligence
(AI) models can assist by highlighting suspicious regions, but training such
models typically requires extensive tumor masks--detailed, voxel-wise outlines
of tumors manually drawn by radiologists. Drawing these masks is costly,
requiring years of effort and millions of dollars. In contrast, nearly every CT
scan in clinical practice is already accompanied by medical reports describing
the tumor's size, number, appearance, and sometimes, pathology
results--information that is rich, abundant, and often underutilized for AI
training. We introduce R-Super, which trains AI to segment tumors that match
their descriptions in medical reports. This approach scales AI training with
large collections of readily available medical reports, substantially reducing
the need for manually drawn tumor masks. When trained on 101,654 reports, AI
models achieved performance comparable to those trained on 723 masks. Combining
reports and masks further improved sensitivity by +13% and specificity by +8%,
surpassing radiologists in detecting five of the seven tumor types. Notably,
R-Super enabled segmentation of tumors in the spleen, gallbladder, prostate,
bladder, uterus, and esophagus, for which no public masks or AI models
previously existed. This study challenges the long-held belief that
large-scale, labor-intensive tumor mask creation is indispensable, establishing
a scalable and accessible path toward early detection across diverse tumor
types.
  We plan to release our trained models, code, and dataset at
https://github.com/MrGiovanni/R-Super</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.14790v1' target='_blank'>Active Jammer Localization via Acquisition-Aware Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luis González-Gudiño, Mariona Jaramillo-Civill, Pau Closas, Tales Imbiriba</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 15:22:24</h6>
<p class='card-text'>We propose an active jammer localization framework that combines Bayesian
optimization with acquisition-aware path planning. Unlike passive crowdsourced
methods, our approach adaptively guides a mobile agent to collect high-utility
Received Signal Strength measurements while accounting for urban obstacles and
mobility constraints. For this, we modified the A* algorithm, A-UCB*, by
incorporating acquisition values into trajectory costs, leading to
high-acquisition planned paths. Simulations on realistic urban scenarios show
that the proposed method achieves accurate localization with fewer measurements
compared to uninformed baselines, demonstrating consistent performance under
different environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.14765v1' target='_blank'>Inpainting the Red Planet: Diffusion Models for the Reconstruction of
  Martian Environments in Virtual Reality</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Giuseppe Lorenzo Catalano, Agata Marta Soccini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 15:02:05</h6>
<p class='card-text'>Space exploration increasingly relies on Virtual Reality for several tasks,
such as mission planning, multidisciplinary scientific analysis, and astronaut
training. A key factor for the reliability of the simulations is having
accurate 3D representations of planetary terrains. Extraterrestrial heightmaps
derived from satellite imagery often contain missing values due to acquisition
and transmission constraints. Mars is among the most studied planets beyond
Earth, and its extensive terrain datasets make the Martian surface
reconstruction a valuable task, although many areas remain unmapped. Deep
learning algorithms can support void-filling tasks; however, whereas Earth's
comprehensive datasets enables the use of conditional methods, such approaches
cannot be applied to Mars. Current approaches rely on simpler interpolation
techniques which, however, often fail to preserve geometric coherence. In this
work, we propose a method for reconstructing the surface of Mars based on an
unconditional diffusion model. Training was conducted on an augmented dataset
of 12000 Martian heightmaps derived from NASA's HiRISE survey. A
non-homogeneous rescaling strategy captures terrain features across multiple
scales before resizing to a fixed 128x128 model resolution. We compared our
method against established void-filling and inpainting techniques, including
Inverse Distance Weighting, kriging, and Navier-Stokes algorithm, on an
evaluation set of 1000 samples. Results show that our approach consistently
outperforms these methods in terms of reconstruction accuracy (4-15% on RMSE)
and perceptual similarity (29-81% on LPIPS) with the original data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.14696v1' target='_blank'>High-Resolution PTDF-Based Planning of Storage and Transmission Under
  High Renewables</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kevin Wu, Rabab Haider, Pascal Van Hentenryck</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 14:02:03</h6>
<p class='card-text'>Transmission Expansion Planning (TEP) optimizes power grid upgrades and
investments to ensure reliable, efficient, and cost-effective electricity
delivery while addressing grid constraints. To support growing demand and
renewable energy integration, energy storage is emerging as a pivotal asset
that provides temporal flexibility and alleviates congestion. This paper
develops a multiperiod, two-stage PTDF formulation that co-optimizes
transmission upgrades and storage siting/sizing. To ensure scalability, a
trust-region, multicut Benders scheme warm-started from per-representative-day
optima is proposed. Applied to a 2,000-bus synthetic Texas system under
high-renewable projections, the method attains final optimality gaps below 1%
and yields a plan with storage at about 180 nodes (32% of peak renewable
capacity). These results demonstrate that the proposed PTDF-based methodology
efficiently handles large distributed storage fleets, demonstrating scalability
at high spatial resolution</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.14677v1' target='_blank'>When Planners Meet Reality: How Learned, Reactive Traffic Agents Shift
  nuPlan Benchmarks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Steffen Hagedorn, Luka Donkov, Aron Distelzweig, Alexandru P. Condurache</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-16 13:34:12</h6>
<p class='card-text'>Planner evaluation in closed-loop simulation often uses rule-based traffic
agents, whose simplistic and passive behavior can hide planner deficiencies and
bias rankings. Widely used IDM agents simply follow a lead vehicle and cannot
react to vehicles in adjacent lanes, hindering tests of complex interaction
capabilities. We address this issue by integrating the state-of-the-art learned
traffic agent model SMART into nuPlan. Thus, we are the first to evaluate
planners under more realistic conditions and quantify how conclusions shift
when narrowing the sim-to-real gap. Our analysis covers 14 recent planners and
established baselines and shows that IDM-based simulation overestimates
planning performance: nearly all scores deteriorate. In contrast, many planners
interact better than previously assumed and even improve in multi-lane,
interaction-heavy scenarios like lane changes or turns. Methods trained in
closed-loop demonstrate the best and most stable driving performance. However,
when reaching their limits in augmented edge-case scenarios, all learned
planners degrade abruptly, whereas rule-based planners maintain reasonable
basic behavior. Based on our results, we suggest SMART-reactive simulation as a
new standard closed-loop benchmark in nuPlan and release the SMART agents as a
drop-in alternative to IDM at https://github.com/shgd95/InteractiveClosedLoop.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>