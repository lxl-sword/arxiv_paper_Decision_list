<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-08-11</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-08-11</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06404v1' target='_blank'>V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abdullah Zareh Andaryan, Michael G. H. Bell, Mohsen Ramezani, Glenn Geers</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 15:41:06</h6>
<p class='card-text'>Autonomous vehicle navigation in structured environments requires planners
capable of generating time-optimal, collision-free trajectories that satisfy
dynamic and kinematic constraints. We introduce V*, a graph-based motion
planner that represents speed and direction as explicit state variables within
a discretised space-time-velocity lattice. Unlike traditional methods that
decouple spatial search from dynamic feasibility or rely on post-hoc smoothing,
V* integrates both motion dimensions directly into graph construction through
dynamic graph generation during search expansion. To manage the complexity of
high-dimensional search, we employ a hexagonal discretisation strategy and
provide formal mathematical proofs establishing optimal waypoint spacing and
minimal node redundancy under constrained heading transitions for
velocity-aware motion planning. We develop a mathematical formulation for
transient steering dynamics in the kinematic bicycle model, modelling steering
angle convergence with exponential behaviour, and deriving the relationship for
convergence rate parameters. This theoretical foundation, combined with
geometric pruning strategies that eliminate expansions leading to infeasible
steering configurations, enables V* to evaluate dynamically admissible
manoeuvres, ensuring each trajectory is physically realisable without further
refinement. We further demonstrate V*'s performance in simulation studies with
cluttered and dynamic environments involving moving obstacles, showing its
ability to avoid conflicts, yield proactively, and generate safe, efficient
trajectories with temporal reasoning capabilities for waiting behaviours and
dynamic coordination.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06386v1' target='_blank'>Bridging Farm Economics and Landscape Ecology for Global Sustainability
  through Hierarchical and Bayesian Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kevin Bradley Dsouza, Graham Alexander Watt, Yuri Leonenko, Juan Moreno-Cruz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 15:16:15</h6>
<p class='card-text'>Agricultural landscapes face the dual challenge of sustaining food production
while reversing biodiversity loss. Agri-environmental policies often fall short
of delivering ecological functions such as landscape connectivity, in part due
to a persistent disconnect between farm-level economic decisions and
landscape-scale spatial planning. We introduce a novel hierarchical
optimization framework that bridges this gap. First, an Ecological
Intensification (EI) model determines the economically optimal allocation of
land to margin and habitat interventions at the individual farm level. These
farm-specific intervention levels are then passed to an Ecological Connectivity
(EC) model, which spatially arranges them across the landscape to maximize
connectivity while preserving farm-level profitability. Finally, we introduce a
Bayesian Optimization (BO) approach that translates these spatial outcomes into
simple, cost effective, and scalable policy instruments, such as subsidies and
eco-premiums, using non-spatial, farm-level policy parameters. Applying the
framework to a Canadian agricultural landscape, we demonstrate how it enhances
connectivity under real-world economic constraints. Our approach provides a
globally relevant tool for aligning farm incentives with biodiversity goals,
advancing the development of agri-environmental policies that are economically
viable and ecologically effective.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06342v1' target='_blank'>Street View Sociability: Interpretable Analysis of Urban Social Behavior
  Across 15 Cities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kieran Elrod, Katherine Flanigan, Mario Berg√©s</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 14:15:58</h6>
<p class='card-text'>Designing socially active streets has long been a goal of urban planning, yet
existing quantitative research largely measures pedestrian volume rather than
the quality of social interactions. We hypothesize that street view imagery --
an inexpensive data source with global coverage -- contains latent social
information that can be extracted and interpreted through established social
science theory. As a proof of concept, we analyzed 2,998 street view images
from 15 cities using a multimodal large language model guided by Mehta's
taxonomy of passive, fleeting, and enduring sociability -- one illustrative
example of a theory grounded in urban design that could be substituted or
complemented by other sociological frameworks. We then used linear regression
models, controlling for factors like weather, time of day, and pedestrian
counts, to test whether the inferred sociability measures correlate with
city-level place attachment scores from the World Values Survey and with
environmental predictors (e.g., green, sky, and water view indices) derived
from individual street view images. Results aligned with long-standing urban
planning theory: the sky view index was associated with all three sociability
types, the green view index predicted enduring sociability, and place
attachment was positively associated with fleeting sociability. These results
provide preliminary evidence that street view images can be used to infer
relationships between specific types of social interactions and built
environment variables. Further research could establish street view imagery as
a scalable, privacy-preserving tool for studying urban sociability, enabling
cross-cultural theory testing and evidence-based design of socially vibrant
cities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06283v1' target='_blank'>Situationally-aware Path Planning Exploiting 3D Scene Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saad Ejaz, Marco Giberna, Muhammad Shaheer, Jose Andres Millan-Romera, Ali Tourani, Paul Kremer, Holger Voos, Jose Luis Sanchez-Lopez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 13:03:44</h6>
<p class='card-text'>3D Scene Graphs integrate both metric and semantic information, yet their
structure remains underutilized for improving path planning efficiency and
interpretability. In this work, we present S-Path, a situationally-aware path
planner that leverages the metric-semantic structure of indoor 3D Scene Graphs
to significantly enhance planning efficiency. S-Path follows a two-stage
process: it first performs a search over a semantic graph derived from the
scene graph to yield a human-understandable high-level path. This also
identifies relevant regions for planning, which later allows the decomposition
of the problem into smaller, independent subproblems that can be solved in
parallel. We also introduce a replanning mechanism that, in the event of an
infeasible path, reuses information from previously solved subproblems to
update semantic heuristics and prioritize reuse to further improve the
efficiency of future planning attempts. Extensive experiments on both
real-world and simulated environments show that S-Path achieves average
reductions of 5.7x in planning time while maintaining comparable path
optimality to classical sampling-based planners and surpassing them in complex
scenarios, making it an efficient and interpretable path planner for
environments represented by indoor 3D Scene Graphs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06258v1' target='_blank'>XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur
  MRI Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Byunghyun Ko, Anning Tian, Jeongkyu Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 12:25:52</h6>
<p class='card-text'>Accurate segmentation of femur structures from Magnetic Resonance Imaging
(MRI) is critical for orthopedic diagnosis and surgical planning but remains
challenging due to the limitations of existing 2D and 3D deep learning-based
segmentation approaches. In this study, we propose XAG-Net, a novel 2.5D
U-Net-based architecture that incorporates pixel-wise cross-slice attention
(CSA) and skip attention gating (AG) mechanisms to enhance inter-slice
contextual modeling and intra-slice feature refinement. Unlike previous
CSA-based models, XAG-Net applies pixel-wise softmax attention across adjacent
slices at each spatial location for fine-grained inter-slice modeling.
Extensive evaluations demonstrate that XAG-Net surpasses baseline 2D, 2.5D, and
3D U-Net models in femur segmentation accuracy while maintaining computational
efficiency. Ablation studies further validate the critical role of the CSA and
AG modules, establishing XAG-Net as a promising framework for efficient and
accurate femur MRI segmentation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06224v1' target='_blank'>TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic
  Segmentation of Urban Remote Sensing Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guoyu Zhou, Jing Zhang, Yi Yan, Hui Zhang, Li Zhuo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 11:08:31</h6>
<p class='card-text'>Semantic segmentation of urban remote sensing images (URSIs) is crucial for
applications such as urban planning and environmental monitoring. However,
geospatial objects often exhibit subtle texture differences and similar spatial
structures, which can easily lead to semantic ambiguity and misclassification.
Moreover, challenges such as irregular object shapes, blurred boundaries, and
overlapping spatial distributions of semantic objects contribute to complex and
diverse edge morphologies, further complicating accurate segmentation. To
tackle these issues, we propose a texture-aware and edge-guided Transformer
(TEFormer) that integrates texture awareness and edge-guidance mechanisms for
semantic segmentation of URSIs. In the encoder, a texture-aware module (TaM) is
designed to capture fine-grained texture differences between visually similar
categories to enhance semantic discrimination. Then, an edge-guided tri-branch
decoder (Eg3Head) is constructed to preserve local edges and details for
multiscale context-awareness. Finally, an edge-guided feature fusion module
(EgFFM) is to fuse contextual and detail information with edge information to
realize refined semantic segmentation. Extensive experiments show that TEFormer
achieves mIoU of 88.57%, 81.46%, and 53.55% on the Potsdam, Vaihingen, and
LoveDA datasets, respectively, shows the effectiveness in URSI semantic
segmentation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06117v1' target='_blank'>A Multimodal Framework for Understanding Collaborative Design Processes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maurice Koch, Nelusa Pathmanathan, Daniel Weiskopf, Kuno Kurzhals</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 08:31:57</h6>
<p class='card-text'>An essential task in analyzing collaborative design processes, such as those
that are part of workshops in design studies, is identifying design outcomes
and understanding how the collaboration between participants formed the results
and led to decision-making. However, findings are typically restricted to a
consolidated textual form based on notes from interviews or observations. A
challenge arises from integrating different sources of observations, leading to
large amounts and heterogeneity of collected data. To address this challenge we
propose a practical, modular, and adaptable framework of workshop setup,
multimodal data acquisition, AI-based artifact extraction, and visual analysis.
Our interactive visual analysis system, reCAPit, allows the flexible
combination of different modalities, including video, audio, notes, or gaze, to
analyze and communicate important workshop findings. A multimodal streamgraph
displays activity and attention in the working area, temporally aligned topic
cards summarize participants' discussions, and drill-down techniques allow
inspecting raw data of included sources. As part of our research, we conducted
six workshops across different themes ranging from social science research on
urban planning to a design study on band-practice visualization. The latter two
are examined in detail and described as case studies. Further, we present
considerations for planning workshops and challenges that we derive from our
own experience and the interviews we conducted with workshop experts. Our
research extends existing methodology of collaborative design workshops by
promoting data-rich acquisition of multimodal observations, combined AI-based
extraction and interactive visual analysis, and transparent dissemination of
results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06096v1' target='_blank'>Bounding Distributional Shifts in World Modeling through Novelty
  Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eric Jing, Abdeslam Boularias</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 07:42:14</h6>
<p class='card-text'>Recent work on visual world models shows significant promise in latent state
dynamics obtained from pre-trained image backbones. However, most of the
current approaches are sensitive to training quality, requiring near-complete
coverage of the action and state space during training to prevent divergence
during inference. To make a model-based planning algorithm more robust to the
quality of the learned world model, we propose in this work to use a
variational autoencoder as a novelty detector to ensure that proposed action
trajectories during planning do not cause the learned model to deviate from the
training data distribution. To evaluate the effectiveness of this approach, a
series of experiments in challenging simulated robot environments was carried
out, with the proposed method incorporated into a model-predictive control
policy loop extending the DINO-WM architecture. The results clearly show that
the proposed method improves over state-of-the-art solutions in terms of data
efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06095v1' target='_blank'>Incremental Language Understanding for Online Motion Planning of Robot
  Manipulators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mitchell Abrams, Thies Oelerich, Christian Hartl-Nesic, Andreas Kugi, Matthias Scheutz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 07:36:51</h6>
<p class='card-text'>Human-robot interaction requires robots to process language incrementally,
adapting their actions in real-time based on evolving speech input. Existing
approaches to language-guided robot motion planning typically assume fully
specified instructions, resulting in inefficient stop-and-replan behavior when
corrections or clarifications occur. In this paper, we introduce a novel
reasoning-based incremental parser which integrates an online motion planning
algorithm within the cognitive architecture. Our approach enables continuous
adaptation to dynamic linguistic input, allowing robots to update motion plans
without restarting execution. The incremental parser maintains multiple
candidate parses, leveraging reasoning mechanisms to resolve ambiguities and
revise interpretations when needed. By combining symbolic reasoning with online
motion planning, our system achieves greater flexibility in handling speech
corrections and dynamically changing constraints. We evaluate our framework in
real-world human-robot interaction scenarios, demonstrating online adaptions of
goal poses, constraints, or task objectives. Our results highlight the
advantages of integrating incremental language understanding with real-time
motion planning for natural and fluid human-robot collaboration. The
experiments are demonstrated in the accompanying video at
www.acin.tuwien.ac.at/42d5.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.06076v1' target='_blank'>Towards MR-Based Trochleoplasty Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Michael Wehrli, Alicia Durrer, Paul Friedrich, Sidaty El Hadramy, Edwin Li, Luana Brahaj, Carol C. Hasler, Philippe C. Cattin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 07:15:23</h6>
<p class='card-text'>To treat Trochlear Dysplasia (TD), current approaches rely mainly on
low-resolution clinical Magnetic Resonance (MR) scans and surgical intuition.
The surgeries are planned based on surgeons experience, have limited adoption
of minimally invasive techniques, and lead to inconsistent outcomes. We propose
a pipeline that generates super-resolved, patient-specific 3D pseudo-healthy
target morphologies from conventional clinical MR scans. First, we compute an
isotropic super-resolved MR volume using an Implicit Neural Representation
(INR). Next, we segment femur, tibia, patella, and fibula with a multi-label
custom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to
generate pseudo-healthy target morphologies of the trochlear region. In
contrast to prior work producing pseudo-healthy low-resolution 3D MR images,
our approach enables the generation of sub-millimeter resolved 3D shapes
compatible for pre- and intraoperative use. These can serve as preoperative
blueprints for reshaping the femoral groove while preserving the native patella
articulation. Furthermore, and in contrast to other work, we do not require a
CT for our pipeline - reducing the amount of radiation. We evaluated our
approach on 25 TD patients and could show that our target morphologies
significantly improve the sulcus angle (SA) and trochlear groove depth (TGD).
The code and interactive visualization are available at
https://wehrlimi.github.io/sr-3d-planning/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05972v1' target='_blank'>Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land
  Bimodal Unmanned Aerial Vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaoting Liu, Zhou Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 03:09:53</h6>
<p class='card-text'>Air-land bimodal vehicles provide a promising solution for navigating complex
environments by combining the flexibility of aerial locomotion with the energy
efficiency of ground mobility. To enhance the robustness of trajectory planning
under environmental disturbances, this paper presents a disturbance-aware
planning framework that incorporates real-time disturbance estimation into both
path searching and trajectory optimization. A key component of the framework is
a disturbance-adaptive safety boundary adjustment mechanism, which dynamically
modifies the vehicle's feasible dynamic boundaries based on estimated
disturbances to ensure trajectory feasibility. Leveraging the dynamics model of
the bimodal vehicle, the proposed approach achieves adaptive and reliable
motion planning across different terrains and operating conditions. A series of
real-world experiments and benchmark comparisons on a custom-built platform
validate the effectiveness and robustness of the method, demonstrating
improvements in tracking accuracy, task efficiency, and energy performance
under both ground and aerial disturbances.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05936v1' target='_blank'>Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace
  Integration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haohui Pan, Takuya Kiyokawa, Tomoki Ishikura, Shingo Hamada, Genichiro Matsuda, Kensuke Harada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-08 02:02:50</h6>
<p class='card-text'>The disassembly of small household appliances poses significant challenges
due to their complex and curved geometries, which render traditional rigid
fixtures inadequate. In this paper, we propose a modular vacuum-based fixturing
system that leverages commercially available balloon-type soft grippers to
conform to arbitrarily shaped surfaces and provide stable support during
screw-removal tasks. To enable a reliable deployment of the system, we develop
a stability-aware planning framework that samples the bottom surface of the
target object, filters candidate contact points based on geometric continuity,
and evaluates support configurations using convex hull-based static stability
criteria. We compare the quality of object placement under different numbers
and configurations of balloon hands. In addition, real-world experiments were
conducted to compare the success rates of traditional rigid fixtures with our
proposed system. The results demonstrate that our method consistently achieves
higher success rates and superior placement stability during screw removal
tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05890v1' target='_blank'>Flow-Based Task Assignment for Large-Scale Online Multi-Agent Pickup and
  Delivery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Zhang, Zhe Chen, Daniel Harabor, Pierre Le Bodic, Peter J. Stuckey</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 22:43:22</h6>
<p class='card-text'>We study the problem of online Multi-Agent Pickup and Delivery (MAPD), where
a team of agents must repeatedly serve dynamically appearing tasks on a shared
map. Existing online methods either rely on simple heuristics, which result in
poor decisions, or employ complex reasoning, which suffers from limited
scalability under real-time constraints. In this work, we focus on the task
assignment subproblem and formulate it as a minimum-cost flow over the
environment graph. This eliminates the need for pairwise distance computations
and allows agents to be simultaneously assigned to tasks and routed toward
them. The resulting flow network also supports efficient guide path extraction
to integrate with the planner and accelerates planning under real-time
constraints. To improve solution quality, we introduce two congestion-aware
edge cost models that incorporate real-time traffic estimates. This approach
supports real-time execution and scales to over 20000 agents and 30000 tasks
within 1-second planning time, outperforming existing baselines in both
computational efficiency and assignment quality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05888v1' target='_blank'>Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles
  for Improved Tool Retrieval in Enterprise Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sahil Bansal, Sai Shruthi Sistla, Aarti Arikatala, Sebastian Schreiber</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 22:41:12</h6>
<p class='card-text'>Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05863v1' target='_blank'>Integrated Bus Fleet Electrification Planning Through Accelerated
  Logic-Based Benders Decomposition and Restriction Heuristics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Robin Legault, Filipe Cabral, Xu Andy Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 21:29:39</h6>
<p class='card-text'>To meet sustainability goals and regulatory requirements, transit agencies
worldwide are planning partial and complete transitions to electric bus fleets.
This paper presents the first comprehensive and computationally efficient
multi-period optimization framework integrating the key planning decisions
necessary to support such electrification initiatives. Our model, formulated as
a two-stage integer program with integer subproblems, jointly optimizes yearly
fleet and charging infrastructure investments as well as hourly vehicle
scheduling and charging operations. To solve instances of practical relevance
to proven optimality, we develop a logic-based Benders decomposition method
enhanced by several techniques, including preprocessing, partial decomposition,
and a range of classical and monotone Benders cuts derived from relaxations of
the operational subproblems. These accelerations yield speedups of up to three
orders of magnitude and lead to practical and theoretical insights into Benders
cut selection. We also propose a heuristic tailored for long-term, citywide
electrification planning. This approach, which imposes and progressively
relaxes additional scheduling constraints, consistently delivers high-quality
solutions with optimality gaps below 1% for instances an order of magnitude
larger than those considered in prior studies. We illustrate our model using
data from the Chicago public bus system, providing managerial insights into
optimal investment and operational policies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05827v1' target='_blank'>A United Framework for Planning Electric Vehicle Charging Accessibility</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tony Kinchen, Panagiotis Typaldos, Andreas A. Malikopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 20:05:55</h6>
<p class='card-text'>The shift towards electric vehicles (EVs) is crucial for establishing
sustainable and low-emission urban transportation systems. However, the success
of this transition depends on the strategic placement of the charging
infrastructure. This paper addresses the challenge of optimizing charging
station locations in dense urban environments while balancing efficiency with
spatial accessibility. We propose an optimization framework that integrates
traffic simulation, energy consumption modeling, and a mobility equity measure
to evaluate the social reach of each potential charging station. Using New York
City as a case study, we demonstrate consistent improvements in accessibility
(15-20% reduction in travel time variability). Our results provide a scalable
methodology for incorporating equity considerations into EV infrastructure
planning, although economic factors and grid integration remain important areas
for future development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05725v1' target='_blank'>Optimizing MV CBCT Imaging Protocols Using NTCP and Secondary Cancer
  Risk: A Multi-Site Study in Breast, Pelvic, and Head & Neck Radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thanh Tai Duong, Tien Phat Luong, Trung Kien Tran, Tuan Linh Duong, Ngoc Anh Nguyen, Quang Hung Nguyen, Peter Sandwall, Parham Alaei, David Bradley, James C. L. Chow</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 16:51:46</h6>
<p class='card-text'>Purpose: To evaluate the cumulative radiobiological impact of daily
Megavoltage Cone-Beam Computed Tomography (MV-CBCT) imaging dose based on
Normal Tissue Complication Probability (NTCP) and Excess Absolute Risk (EAR) of
secondary malignancies among radiotherapy patients treated for breast, pelvic,
and head and neck cancers. This study investigated whether MV-CBCT imaging dose
warrants protocol personalization according to patient age, anatomical
treatment site, and organ-specific radiosensitivity.
  Methods: This retrospective study included cohorts of breast (n=30), pelvic
(n=17), and head and neck (n=20) cancer patients undergoing radiotherapy with
daily MV-CBCT. Imaging plans using two common protocols (5 MU and 10 MU per
fraction) were analyzed. NTCP values were estimated using logistic and
Lyman-Kutcher-Burman (LKB) models, while EAR was calculated using Schneider's
Organ Equivalent Dose (OED)-based model. Statistical analysis used paired
t-tests, and results were further stratified by age (under 40, 40 to 60, over
60 years).
  Results: In breast cancer patients, NTCP for lung increased significantly
under the 10 MU protocol (p<0.001). EAR was elevated in younger breast patients
(under 40 years), with some exceeding 15 cases per 10,000 person-years. In
pelvic and head and neck groups, NTCP and EAR remained low (under 1 percent),
with no clinically meaningful differences between protocols. Across all sites,
younger age correlated with higher secondary cancer risk.
  Conclusion: Daily 10 MU MV-CBCT presents minimal additional risk in pelvic
and head and neck radiotherapy. For breast cancer patients under 40, however,
it significantly increases secondary cancer risk and lung NTCP. Personalized
imaging protocols are recommended based on age, treatment site, and
radiosensitivity.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05548v1' target='_blank'>Development of PANOSETI Telescopes for Ultra-High-Energy Gamma-Ray
  Astronomy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nikolas Korzoun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 16:27:57</h6>
<p class='card-text'>Ultra-High-Energy (UHE, E $>100$ TeV) gamma rays are one of the few channels
to search for and study Galactic PeVatrons. Among the most promising PeVatron
candidates are the many UHE gamma-ray sources that have recently been
identified on the Galactic Plane. Ground-based particle detectors see these
sources as extended rather than point-like, and current generation Imaging
Atmospheric Cherenkov Telescopes (IACTs) struggle to study them with effective
areas and background rejection that are suboptimal at UHE. A cost-efficient way
of constructing an array of IACTs explicitly designed for UHE sensitivity is to
sparsely separate many small telescopes. We have simulated, prototyped, and
twice deployed a pathfinder array that is instrumented with telescopes designed
by the Panoramic Search for Extraterrestrial Intelligence (PANOSETI) team.
These 0.5-meter Fresnel lens telescopes are purpose-built for imaging optical
transients on nanosecond timescales and are equipped with a
$10^\circ\times10^\circ$ silicon photomultiplier camera. Three PANOSETI
telescopes were deployed twice in the same temporary configuration at Lick
Observatory in March and October 2024. Here we give a brief description of the
instrument and present a comparison of simulations with the data collected,
including an analysis of the Crab Nebula. We also report on the ongoing
deployment of PANOSETI telescopes for the Dark100 array that is planned to
operate for five years at Palomar Observatory.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05543v1' target='_blank'>CleanUpBench: Embodied Sweeping and Grasping Benchmark</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenbo Li, Guanting Chen, Tao Zhao, Jiyao Wang, Tianxin Hu, Yuwen Liao, Weixiang Guo, Shenghai Yuan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 16:20:31</h6>
<p class='card-text'>Embodied AI benchmarks have advanced navigation, manipulation, and reasoning,
but most target complex humanoid agents or large-scale simulations that are far
from real-world deployment. In contrast, mobile cleaning robots with dual mode
capabilities, such as sweeping and grasping, are rapidly emerging as realistic
and commercially viable platforms. However, no benchmark currently exists that
systematically evaluates these agents in structured, multi-target cleaning
tasks, revealing a critical gap between academic research and real-world
applications. We introduce CleanUpBench, a reproducible and extensible
benchmark for evaluating embodied agents in realistic indoor cleaning
scenarios. Built on NVIDIA Isaac Sim, CleanUpBench simulates a mobile service
robot equipped with a sweeping mechanism and a six-degree-of-freedom robotic
arm, enabling interaction with heterogeneous objects. The benchmark includes
manually designed environments and one procedurally generated layout to assess
generalization, along with a comprehensive evaluation suite covering task
completion, spatial efficiency, motion quality, and control performance. To
support comparative studies, we provide baseline agents based on heuristic
strategies and map-based planning. CleanUpBench bridges the gap between
low-level skill evaluation and full-scene testing, offering a scalable testbed
for grounded, embodied intelligence in everyday settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05465v1' target='_blank'>F2PASeg: Feature Fusion for Pituitary Anatomy Segmentation in Endoscopic
  Surgery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lumin Chen, Zhiying Wu, Tianye Lei, Xuexue Bai, Ming Feng, Yuxi Wang, Gaofeng Meng, Zhen Lei, Hongbin Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 15:04:07</h6>
<p class='card-text'>Pituitary tumors often cause deformation or encapsulation of adjacent vital
structures. Anatomical structure segmentation can provide surgeons with early
warnings of regions that pose surgical risks, thereby enhancing the safety of
pituitary surgery. However, pixel-level annotated video stream datasets for
pituitary surgeries are extremely rare. To address this challenge, we introduce
a new dataset for Pituitary Anatomy Segmentation (PAS). PAS comprises 7,845
time-coherent images extracted from 120 videos. To mitigate class imbalance, we
apply data augmentation techniques that simulate the presence of surgical
instruments in the training data. One major challenge in pituitary anatomy
segmentation is the inconsistency in feature representation due to occlusions,
camera motion, and surgical bleeding. By incorporating a Feature Fusion module,
F2PASeg is proposed to refine anatomical structure segmentation by leveraging
both high-resolution image features and deep semantic embeddings, enhancing
robustness against intraoperative variations. Experimental results demonstrate
that F2PASeg consistently segments critical anatomical structures in real time,
providing a reliable solution for intraoperative pituitary surgery planning.
Code: https://github.com/paulili08/F2PASeg.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05454v1' target='_blank'>EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty
  Estimation for Energy Forecasting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Li, Zixin Wang, Qizheng Sun, Qixiang Gao, Fenglei Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 14:48:39</h6>
<p class='card-text'>Accurate and reliable energy time series prediction is of great significance
for power generation planning and allocation. At present, deep learning time
series prediction has become the mainstream method. However, the multi-scale
time dynamics and the irregularity of real data lead to the limitations of the
existing methods. Therefore, we propose EnergyPatchTST, which is an extension
of the Patch Time Series Transformer specially designed for energy forecasting.
The main innovations of our method are as follows: (1) multi-scale feature
extraction mechanism to capture patterns with different time resolutions; (2)
probability prediction framework to estimate uncertainty through Monte Carlo
elimination; (3) integration path of future known variables (such as
temperature and wind conditions); And (4) Pre-training and Fine-tuning examples
to enhance the performance of limited energy data sets. A series of experiments
on common energy data sets show that EnergyPatchTST is superior to other
commonly used methods, the prediction error is reduced by 7-12%, and reliable
uncertainty estimation is provided, which provides an important reference for
time series prediction in the energy field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05405v1' target='_blank'>DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinrun Xu, Pi Bu, Ye Wang, B√∂rje F. Karlsson, Ziming Wang, Tengtao Song, Qi Zhu, Jun Song, Zhiming Ding, Bo Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 13:58:19</h6>
<p class='card-text'>Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05402v1' target='_blank'>DistillDrive: End-to-End Multi-Mode Autonomous Driving Distillation by
  Isomorphic Hetero-Source Planning Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rui Yu, Xianghang Zhang, Runkai Zhao, Huaicheng Yan, Meng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 13:54:35</h6>
<p class='card-text'>End-to-end autonomous driving has been recently seen rapid development,
exerting a profound influence on both industry and academia. However, the
existing work places excessive focus on ego-vehicle status as their sole
learning objectives and lacks of planning-oriented understanding, which limits
the robustness of the overall decision-making prcocess. In this work, we
introduce DistillDrive, an end-to-end knowledge distillation-based autonomous
driving model that leverages diversified instance imitation to enhance
multi-mode motion feature learning. Specifically, we employ a planning model
based on structured scene representations as the teacher model, leveraging its
diversified planning instances as multi-objective learning targets for the
end-to-end model. Moreover, we incorporate reinforcement learning to enhance
the optimization of state-to-decision mappings, while utilizing generative
modeling to construct planning-oriented instances, fostering intricate
interactions within the latent space. We validate our model on the nuScenes and
NAVSIM datasets, achieving a 50\% reduction in collision rate and a 3-point
improvement in closed-loop performance compared to the baseline model. Code and
model are publicly available at https://github.com/YuruiAI/DistillDrive</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05360v1' target='_blank'>Building Effective Safety Guardrails in AI Education Tools</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hannah-Beth Clark, Laura Benton, Emma Searle, Margaux Dowland, Matthew Gregory, Will Gayne, John Roberts</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 13:09:47</h6>
<p class='card-text'>There has been rapid development in generative AI tools across the education
sector, which in turn is leading to increased adoption by teachers. However,
this raises concerns regarding the safety and age-appropriateness of the
AI-generated content that is being created for use in classrooms. This paper
explores Oak National Academy's approach to addressing these concerns within
the development of the UK Government's first publicly available generative AI
tool - our AI-powered lesson planning assistant (Aila). Aila is intended to
support teachers planning national curriculum-aligned lessons that are
appropriate for pupils aged 5-16 years. To mitigate safety risks associated
with AI-generated content we have implemented four key safety guardrails - (1)
prompt engineering to ensure AI outputs are generated within pedagogically
sound and curriculum-aligned parameters, (2) input threat detection to mitigate
attacks, (3) an Independent Asynchronous Content Moderation Agent (IACMA) to
assess outputs against predefined safety categories, and (4) taking a
human-in-the-loop approach, to encourage teachers to review generated content
before it is used in the classroom. Through our on-going evaluation of these
safety guardrails we have identified several challenges and opportunities to
take into account when implementing and testing safety guardrails. This paper
highlights ways to build more effective safety guardrails in generative AI
education tools including the on-going iteration and refinement of guardrails,
as well as enabling cross-sector collaboration through sharing both open-source
code, datasets and learnings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05717v1' target='_blank'>On Digital Twins in Defence: Overview and Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marco Giberna, Holger Voos, Paulo Tavares, Jo√£o Nunes, Tobias Sorg, Andrea Masini, Jose Luis Sanchez-Lopez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 12:41:27</h6>
<p class='card-text'>Digital twin technology has gained increasing attention across various
sectors due to its ability to create virtual replicas of physical systems,
enabling real-time monitoring, optimization, and simulation. This paper
explores the integration of digital twins within defence applications, focusing
on key use cases ranging from system design and development, operational
planning and training, to mission execution and debriefing. By examining the
application of digital twin technologies across defense platforms, we highlight
their key advantages such as enhanced operational performance, predictive
capabilities, and increased system uptime. Additionally, we introduce a novel
characterization framework for digital twins that aims to standardize and unify
their application across different defence domains to facilitate
interoperability. Thereafter, we discuss the main challenges, gaps and
limitations in implementing and adopting digital twins within defence
organizations by analyzing a combination of scientific literature, current
industry practices, governmental strategies, and the findings from a
comprehensive survey of industrial stakeholders and ministries of defense.
Finally, we outline future research directions and development opportunities,
emphasizing the need for robust frameworks and interdisciplinary collaborations
to fully realize the potential of digital twins in the defence sector.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05310v1' target='_blank'>ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation
  Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jelle Luijkx, Zlatan Ajanoviƒá, Laura Ferranti, Jens Kober</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 12:10:46</h6>
<p class='card-text'>Human teaching effort is a significant bottleneck for the broader
applicability of interactive imitation learning. To reduce the number of
required queries, existing methods employ active learning to query the human
teacher only in uncertain, risky, or novel situations. However, during these
queries, the novice's planned actions are not utilized despite containing
valuable information, such as the novice's capabilities, as well as
corresponding uncertainty levels. To this end, we allow the novice to say: "I
plan to do this, but I am uncertain." We introduce the Active Skill-level Data
Aggregation (ASkDAgger) framework, which leverages teacher feedback on the
novice plan in three key ways: (1) S-Aware Gating (SAG): Adjusts the gating
threshold to track sensitivity, specificity, or a minimum success rate; (2)
Foresight Interactive Experience Replay (FIER), which recasts valid and
relabeled novice action plans into demonstrations; and (3) Prioritized
Interactive Experience Replay (PIER), which prioritizes replay based on
uncertainty, novice success, and demonstration age. Together, these components
balance query frequency with failure incidence, reduce the number of required
demonstration annotations, improve generalization, and speed up adaptation to
changing domains. We validate the effectiveness of ASkDAgger through
language-conditioned manipulation tasks in both simulation and real-world
environments. Code, data, and videos are available at
https://askdagger.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05253v1' target='_blank'>Congestion Mitigation Path Planning for Large-Scale Multi-Agent
  Navigation in Dense Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Takuro Kato, Keisuke Okumura, Yoko Sasaki, Naoya Yokomachi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 10:43:19</h6>
<p class='card-text'>In high-density environments where numerous autonomous agents move
simultaneously in a distributed manner, streamlining global flows to mitigate
local congestion is crucial to maintain overall navigation efficiency. This
paper introduces a novel path-planning problem, congestion mitigation path
planning (CMPP), which embeds congestion directly into the cost function,
defined by the usage of incoming edges along agents' paths. CMPP assigns a
flow-based multiplicative penalty to each vertex of a sparse graph, which grows
steeply where frequently-traversed paths intersect, capturing the intuition
that congestion intensifies where many agents enter the same area from
different directions. Minimizing the total cost yields a set of coarse-level,
time-independent routes that autonomous agents can follow while applying their
own local collision avoidance. We formulate the problem and develop two
solvers: (i) an exact mixed-integer nonlinear programming solver for small
instances, and (ii) a scalable two-layer search algorithm, A-CMTS, which
quickly finds suboptimal solutions for large-scale instances and iteratively
refines them toward the optimum. Empirical studies show that augmenting
state-of-the-art collision-avoidance planners with CMPP significantly reduces
local congestion and enhances system throughput in both discrete- and
continuous-space scenarios. These results indicate that CMPP improves the
performance of multi-agent systems in real-world applications such as logistics
and autonomous-vehicle operations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05186v1' target='_blank'>Learning to See and Act: Task-Aware View Planning for Robotic
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yongjie Bai, Zhouxia Wang, Yang Liu, Weixing Chen, Ziliang Chen, Mingtong Dai, Yongsen Zheng, Lingbo Liu, Guanbin Li, Liang Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 09:21:20</h6>
<p class='card-text'>Recent vision-language-action (VLA) models for multi-task robotic
manipulation commonly rely on static viewpoints and shared visual encoders,
which limit 3D perception and cause task interference, hindering robustness and
generalization. In this work, we propose Task-Aware View Planning (TAVP), a
framework designed to overcome these challenges by integrating active view
planning with task-specific representation learning. TAVP employs an efficient
exploration policy, accelerated by a novel pseudo-environment, to actively
acquire informative views. Furthermore, we introduce a Mixture-of-Experts (MoE)
visual encoder to disentangle features across different tasks, boosting both
representation fidelity and task generalization. By learning to see the world
in a task-aware way, TAVP generates more complete and discriminative visual
representations, demonstrating significantly enhanced action prediction across
a wide array of manipulation challenges. Extensive experiments on RLBench tasks
show that our proposed TAVP model achieves superior performance over
state-of-the-art fixed-view approaches. Visual results and code are provided
at: https://hcplab-sysu.github.io/TAVP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05167v1' target='_blank'>PhysPatch: A Physically Realizable and Transferable Adversarial Patch
  Attack for Multimodal Large Language Models-based Autonomous Driving Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qi Guo, Xiaojun Jia, Shanmin Pang, Simeng Qin, Lin Wang, Ju Jia, Yang Liu, Qing Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 08:54:54</h6>
<p class='card-text'>Multimodal Large Language Models (MLLMs) are becoming integral to autonomous
driving (AD) systems due to their strong vision-language reasoning
capabilities. However, MLLMs are vulnerable to adversarial attacks,
particularly adversarial patch attacks, which can pose serious threats in
real-world scenarios. Existing patch-based attack methods are primarily
designed for object detection models and perform poorly when transferred to
MLLM-based systems due to the latter's complex architectures and reasoning
abilities. To address these limitations, we propose PhysPatch, a physically
realizable and transferable adversarial patch framework tailored for MLLM-based
AD systems. PhysPatch jointly optimizes patch location, shape, and content to
enhance attack effectiveness and real-world applicability. It introduces a
semantic-based mask initialization strategy for realistic placement, an
SVD-based local alignment loss with patch-guided crop-resize to improve
transferability, and a potential field-based mask refinement method. Extensive
experiments across open-source, commercial, and reasoning-capable MLLMs
demonstrate that PhysPatch significantly outperforms prior methods in steering
MLLM-based AD systems toward target-aligned perception and planning outputs.
Moreover, PhysPatch consistently places adversarial patches in physically
feasible regions of AD scenes, ensuring strong real-world applicability and
deployability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.05163v1' target='_blank'>Preparing for the worst: Long-term and short-term weather extremes in
  resource adequacy assessment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aleksander Grochowicz, Hannah C. Bloomfield, Marta Victoria</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-07 08:53:02</h6>
<p class='card-text'>Security of supply is a common and important concern when integrating
renewables in net-zero power systems. Extreme weather affects both demand and
supply leading to power system stress; in Europe this stress spreads
continentally beyond the meteorological root cause. We use an approach based on
shadow prices to identify periods of elevated stress called system-defining
events and analyse their impact on the power system. By classifying different
types of system-defining events, we identify challenges to power system
operation and planning. Crucially, we find the need for sufficient resilience
back-up (power) capacities whose financial viability is precarious due to
weather variability. Furthermore, we disentangle short- and long-term
resilience challenges with distinct metrics and stress tests to incorporate
both into future energy modelling assessments. Our methodology and
implementation in the open model PyPSA-Eur can be re-applied to other systems
and help researchers and policymakers in building more resilient and adequate
energy systems.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>