<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-08-04</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-08-04</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00822v1' target='_blank'>Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST
  Point Cloud City Datasets for 3D Deep Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexander Nikitas Dimopoulos, Joseph Grasso</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-01 17:59:02</h6>
<p class='card-text'>This study analyzes semantic segmentation performance across heterogeneously
labeled point-cloud datasets relevant to public safety applications, including
pre-incident planning systems derived from lidar scans. Using NIST's Point
Cloud City dataset (Enfield and Memphis collections), we investigate challenges
in unifying differently labeled 3D data. Our methodology employs a graded
schema with the KPConv architecture, evaluating performance through IoU metrics
on safety-relevant features. Results indicate performance variability:
geometrically large objects (e.g. stairs, windows) achieve higher segmentation
performance, suggesting potential for navigational context, while smaller
safety-critical features exhibit lower recognition rates. Performance is
impacted by class imbalance and the limited geometric distinction of smaller
objects in typical lidar scans, indicating limitations in detecting certain
safety-relevant features using current point-cloud methods. Key identified
challenges include insufficient labeled data, difficulties in unifying class
labels across datasets, and the need for standardization. Potential directions
include automated labeling and multi-dataset learning strategies. We conclude
that reliable point-cloud semantic segmentation for public safety necessitates
standardized annotation protocols and improved labeling techniques to address
data heterogeneity and the detection of small, safety-critical elements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00782v1' target='_blank'>SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware
  Video Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kien T. Pham, Yingqing He, Yazhou Xing, Qifeng Chen, Long Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-01 17:05:04</h6>
<p class='card-text'>Audio-driven video generation aims to synthesize realistic videos that align
with input audio recordings, akin to the human ability to visualize scenes from
auditory input. However, existing approaches predominantly focus on exploring
semantic information, such as the classes of sounding sources present in the
audio, limiting their ability to generate videos with accurate content and
spatial composition. In contrast, we humans can not only naturally identify the
semantic categories of sounding sources but also determine their deeply encoded
spatial attributes, including locations and movement directions. This useful
information can be elucidated by considering specific spatial indicators
derived from the inherent physical properties of sound, such as loudness or
frequency. As prior methods largely ignore this factor, we present SpA2V, the
first framework explicitly exploits these spatial auditory cues from audios to
generate videos with high semantic and spatial correspondence. SpA2V decomposes
the generation process into two stages: 1) Audio-guided Video Planning: We
meticulously adapt a state-of-the-art MLLM for a novel task of harnessing
spatial and semantic cues from input audio to construct Video Scene Layouts
(VSLs). This serves as an intermediate representation to bridge the gap between
the audio and video modalities. 2) Layout-grounded Video Generation: We develop
an efficient and effective approach to seamlessly integrate VSLs as conditional
guidance into pre-trained diffusion models, enabling VSL-grounded video
generation in a training-free manner. Extensive experiments demonstrate that
SpA2V excels in generating realistic videos with semantic and spatial alignment
to the input audios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00750v1' target='_blank'>SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of
  Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Prerana Ramkumar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-01 16:25:21</h6>
<p class='card-text'>Generative Adversarial Networks (GANs) have achieved realistic
super-resolution (SR) of images however, they lack semantic consistency and
per-pixel confidence, limiting their credibility in critical remote sensing
applications such as disaster response, urban planning and agriculture. This
paper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first
SR framework designed for satellite imagery to integrate the ESRGAN,
segmentation loss via DeepLabv3 for class detail preservation and Monte Carlo
dropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results
(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This
novel model is valuable in satellite systems or UAVs that use wide
field-of-view (FoV) cameras, trading off spatial resolution for coverage. The
modular design allows integration in UAV data pipelines for on-board or
post-processing SR to enhance imagery resulting due to motion blur, compression
and sensor limitations. Further, the model is fine-tuned to evaluate its
performance on cross domain applications. The tests are conducted on two drone
based datasets which differ in altitude and imaging perspective. Performance
evaluation of the fine-tuned models show a stronger adaptation to the Aerial
Maritime Drone Dataset, whose imaging characteristics align with the training
data, highlighting the importance of domain-aware training in SR-applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00401v1' target='_blank'>Theory of Mind Using Active Inference: A Framework for Multi-Agent
  Cooperation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Riddhi J. Pitliya, Ozan Catal, Toon Van de Maele, Corrado Pezzato, Tim Verbelen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-01 08:02:35</h6>
<p class='card-text'>We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00390v1' target='_blank'>SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV
  Vision-Language Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hengxing Cai, Jinhan Dong, Yijie Rao, Jingcheng Deng, Jingjun Tan, Qien Chen, Haidong Wang, Zhen Wang, Shiyu Huang, Agachai Sumalee, Renxin Zhong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-01 07:35:48</h6>
<p class='card-text'>Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) aims to enable
agents to accurately localize targets and plan flight paths in complex
environments based on natural language instructions, with broad applications in
intelligent inspection, disaster rescue, and urban monitoring. Recent progress
in Vision-Language Models (VLMs) has provided strong semantic understanding for
this task, while reinforcement learning (RL) has emerged as a promising
post-training strategy to further improve generalization. However, existing RL
methods often suffer from inefficient use of training data, slow convergence,
and insufficient consideration of the difficulty variation among training
samples, which limits further performance improvement. To address these
challenges, we propose \textbf{Semantic-Aware Gaussian Curriculum Scheduling
(SA-GCS)}, a novel training framework that systematically integrates Curriculum
Learning (CL) into RL. SA-GCS employs a Semantic-Aware Difficulty Estimator
(SA-DE) to quantify the complexity of training samples and a Gaussian
Curriculum Scheduler (GCS) to dynamically adjust the sampling distribution,
enabling a smooth progression from easy to challenging tasks. This design
significantly improves training efficiency, accelerates convergence, and
enhances overall model performance. Extensive experiments on the CityNav
benchmark demonstrate that SA-GCS consistently outperforms strong baselines
across all metrics, achieves faster and more stable convergence, and
generalizes well across models of different scales, highlighting its robustness
and scalability. The implementation of our approach is publicly available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00358v1' target='_blank'>Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable
  Kalman Filtering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yan Gong, Mengjun Chen, Hao Liu, Gao Yongsheng, Lei Yang, Naibang Wang, Ziying Song, Haoqun Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-01 06:42:33</h6>
<p class='card-text'>Multi-object tracking (MOT) enables autonomous vehicles to continuously
perceive dynamic objects, supplying essential temporal cues for prediction,
behavior understanding, and safe planning. However, conventional
tracking-by-detection methods typically rely on static coordinate
transformations based on ego-vehicle poses, disregarding ego-vehicle
speed-induced variations in observation noise and reference frame changes,
which degrades tracking stability and accuracy in dynamic, high-speed
scenarios. In this paper, we investigate the critical role of ego-vehicle speed
in MOT and propose a Speed-Guided Learnable Kalman Filter (SG-LKF) that
dynamically adapts uncertainty modeling to ego-vehicle speed, significantly
improving stability and accuracy in highly dynamic scenarios. Central to SG-LKF
is MotionScaleNet (MSNet), a decoupled token-mixing and channel-mixing MLP that
adaptively predicts key parameters of SG-LKF. To enhance inter-frame
association and trajectory continuity, we introduce a self-supervised
trajectory consistency loss jointly optimized with semantic and positional
constraints. Extensive experiments show that SG-LKF ranks first among all
vision-based methods on KITTI 2D MOT with 79.59% HOTA, delivers strong results
on KITTI 3D MOT with 82.03% HOTA, and outperforms SimpleTrack by 2.2% AMOTA on
nuScenes 3D MOT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00331v1' target='_blank'>Embryology of a Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:George Wang, Garrett Baker, Andrew Gordon, Daniel Murfet</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-01 05:39:41</h6>
<p class='card-text'>Understanding how language models develop their internal computational
structure is a central problem in the science of deep learning. While
susceptibilities, drawn from statistical physics, offer a promising analytical
tool, their full potential for visualizing network organization remains
untapped. In this work, we introduce an embryological approach, applying UMAP
to the susceptibility matrix to visualize the model's structural development
over training. Our visualizations reveal the emergence of a clear ``body
plan,'' charting the formation of known features like the induction circuit and
discovering previously unknown structures, such as a ``spacing fin'' dedicated
to counting space tokens. This work demonstrates that susceptibility analysis
can move beyond validation to uncover novel mechanisms, providing a powerful,
holistic lens for studying the developmental principles of complex neural
networks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00241v1' target='_blank'>Paratransit Optimization with Constraint Programming: A Case Study in
  Savannah, Georgia</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liam Jagrowski, Kevin Dalmeijer, Tinghan Ye, Pascal Van Hentenryck</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-01 00:58:56</h6>
<p class='card-text'>Paratransit services are vital for individuals who cannot use fixed-route
public transit, including those with disabilities. Optimizing these services is
essential for transit agencies to deliver high-quality service efficiently.
This paper introduces a constraint programming model to jointly optimize route
planning and shift scheduling for paratransit operations, along with practical
guidance for real-world implementation. A case study in Savannah, Georgia,
demonstrates that the new approach is competitive with the state of the art and
significantly increases the number of requests served compared to current
practices. It is also significantly easier to implement and provides an
inherently practical solution for transportation planners. An additional
advantage is that the model allows for optimizing shifts without restricting
start times to the top of the hour, yielding a further 5% improvement in
requests served when applied.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00176v1' target='_blank'>New Pilot-Study Design in Functional Data Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ping-Han Huang, Ming-Hung Kao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 21:44:22</h6>
<p class='card-text'>Efficient data collection is essential in applied studies where frequent
measurements are costly, time-consuming, or burdensome. This challenge is
especially pronounced in functional data settings, where each subject is
observed at only a few time points due to practical constraints. Most existing
design approaches focus on selecting optimal time points for individual
subjects, typically relying on model parameters estimated from a pilot study.
However, the design of the pilot study itself has received limited attention.
We propose a framework for constructing pilot-study designs that support both
accurate trajectory recovery and effective planning of future designs. A search
algorithm is developed to generate such high-quality pilot-study designs.
Simulation studies and a real data application demonstrate that our approach
outperforms commonly used alternatives, highlighting its value in
resource-limited settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00154v1' target='_blank'>Data-Driven Motion Planning for Uncertain Nonlinear Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Babak Esmaeili, Hamidreza Modares, Stefano Di Cairano</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 20:41:34</h6>
<p class='card-text'>This paper proposes a data-driven motion-planning framework for nonlinear
systems that constructs a sequence of overlapping invariant polytopes. Around
each randomly sampled waypoint, the algorithm identifies a convex admissible
region and solves data-driven linear-matrix-inequality problems to learn
several ellipsoidal invariant sets together with their local state-feedback
gains. The convex hull of these ellipsoids, still invariant under a
piece-wise-affine controller obtained by interpolating the gains, is then
approximated by a polytope. Safe transitions between nodes are ensured by
verifying the intersection of consecutive convex-hull polytopes and introducing
an intermediate node for a smooth transition. Control gains are interpolated in
real time via simplex-based interpolation, keeping the state inside the
invariant polytopes throughout the motion. Unlike traditional approaches that
rely on system dynamics models, our method requires only data to compute safe
regions and design state-feedback controllers. The approach is validated
through simulations, demonstrating the effectiveness of the proposed method in
achieving safe, dynamically feasible paths for complex nonlinear systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.00141v1' target='_blank'>INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling
  Network Prediction via Reinforcement Learning Boosted Graph Neural Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohit Gupta, Debjit Bhowmick, Rhys Newbury, Meead Saberi, Shirui Pan, Ben Beck</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 20:00:35</h6>
<p class='card-text'>Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23735v1' target='_blank'>Distributed AI Agents for Cognitive Underwater Robot Autonomy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Markus Buchholz, Ignacio Carlucho, Michele Grimaldi, Yvan R. Petillot</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 17:18:55</h6>
<p class='card-text'>Achieving robust cognitive autonomy in robots navigating complex,
unpredictable environments remains a fundamental challenge in robotics. This
paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a
groundbreaking architecture leveraging distributed Large Language Model AI
agents integrated within the Robot Operating System 2 (ROS 2) framework to
enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA
decentralises cognition into specialised AI agents responsible for multimodal
perception, adaptive reasoning, dynamic mission planning, and real-time
decision-making. Central innovations include flexible agents dynamically
adapting their roles, retrieval-augmented generation utilising vector databases
for efficient knowledge management, reinforcement learning-driven behavioural
optimisation, and autonomous on-the-fly ROS 2 node generation for runtime
functional extensibility. Extensive empirical validation demonstrates UROSA's
promising adaptability and reliability through realistic underwater missions in
simulation and real-world deployments, showing significant advantages over
traditional rule-based architectures in handling unforeseen scenarios,
environmental uncertainties, and novel mission objectives. This work not only
advances underwater autonomy but also establishes a scalable, safe, and
versatile cognitive robotics framework capable of generalising to a diverse
array of real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23607v1' target='_blank'>Deep Learning-based Prediction of Clinical Trial Enrollment with
  Uncertainty Estimates</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tien Huu Do, Antoine Masquelier, Nae Eoun Lee, Jonathan Crowther</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 14:47:16</h6>
<p class='card-text'>Clinical trials are a systematic endeavor to assess the safety and efficacy
of new drugs or treatments. Conducting such trials typically demands
significant financial investment and meticulous planning, highlighting the need
for accurate predictions of trial outcomes. Accurately predicting patient
enrollment, a key factor in trial success, is one of the primary challenges
during the planning phase. In this work, we propose a novel deep learning-based
method to address this critical challenge. Our method, implemented as a neural
network model, leverages pre-trained language models (PLMs) to capture the
complexities and nuances of clinical documents, transforming them into
expressive representations. These representations are then combined with
encoded tabular features via an attention mechanism. To account for
uncertainties in enrollment prediction, we enhance the model with a
probabilistic layer based on the Gamma distribution, which enables range
estimation. We apply the proposed model to predict clinical trial duration,
assuming site-level enrollment follows a Poisson-Gamma process. We carry out
extensive experiments on real-world clinical trial data, and show that the
proposed method can effectively predict the number of patients enrolled at a
number of sites for a given clinical trial, outperforming established baseline
models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23604v1' target='_blank'>Hierarchical Message-Passing Policies for Multi-Agent Reinforcement
  Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tommaso Marzi, Cesare Alippi, Andrea Cini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 14:42:12</h6>
<p class='card-text'>Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for
learning scalable multi-agent policies, but suffer from partial observability
and induced non-stationarity. These challenges can be addressed by introducing
mechanisms that facilitate coordination and high-level planning. Specifically,
coordination and temporal abstraction can be achieved through communication
(e.g., message passing) and Hierarchical Reinforcement Learning (HRL)
approaches to decision-making. However, optimization issues limit the
applicability of hierarchical policies to multi-agent systems. As such, the
combination of these approaches has not been fully explored. To fill this void,
we propose a novel and effective methodology for learning multi-agent
hierarchies of message-passing policies. We adopt the feudal HRL framework and
rely on a hierarchical graph structure for planning and coordination among
agents. Agents at lower levels in the hierarchy receive goals from the upper
levels and exchange messages with neighboring agents at the same level. To
learn hierarchical multi-agent policies, we design a novel reward-assignment
method based on training the lower-level policies to maximize the advantage
function associated with the upper levels. Results on relevant benchmarks show
that our method performs favorably compared to the state of the art.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23401v1' target='_blank'>Advancing Standard Load Profiles with Data-Driven Techniques and Recent
  Datasets</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jawana Gabrielski, Ulf Häger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 10:14:16</h6>
<p class='card-text'>Estimating electricity consumption accurately is essential for the planning
and operation of energy systems, as well as for billing processes. Standard
Load Profiles (SLP) are widely used to estimate consumption patterns of
different user groups. However, in Germany these SLP were formulated using
historical data from over 20 years ago and have not been adjusted since.
Changing electricity consumption behaviour, which leads to increasing
deviations between load patterns and SLP, results in a need for a revision
taking into account new data. The growing number of smart meters provides a
large measurement database, which enables more accurate load modelling. This
paper creates updated SLP using recent data. In addition, the assumptions of
the SLP method are validated and improvements are proposed, taking into account
the ease of applicability. Furthermore, a Fourier Series-based model is
proposed as an alternative SLP model. The different models are compared and
evaluated.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23396v1' target='_blank'>Energy management and flexibility quantification in a discrete event
  distribution grid simulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sebastian Peter, Daniel Feismann, Johannes Bao, Thomas Oberließen, Christian Rehtanz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 10:12:48</h6>
<p class='card-text'>Distribution grid operation faces new challenges caused by a rising share of
renewable energy sources and the introduction of additional types of loads to
the grid. With the increasing adoption of distributed generation and emerging
prosumer households, Energy Management Systems, which manage and apply
flexibility of connected devices, are gaining popularity. While potentially
beneficial to grid capacity, strategic energy management also adds to the
complexity of distribution grid operation and planning processes. Novel
approaches of time-series-based planning likewise face increasingly complex
simulation scenarios and rising computational cost. Discrete event modelling
helps facilitating simulations of such scenarios by restraining computation to
the most relevant points in simulation time. We provide an enhancement of a
discrete event distribution grid simulation software that offers fast
implementation and testing of energy management algorithms, embedded into a
feature-rich simulation environment. Physical models are specified using the
Discrete Event System Specification. Furthermore, we contribute a communication
protocol that makes use of the discrete event paradigm by only computing
flexibility potential when necessary.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23382v1' target='_blank'>MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints
  in Multimodal Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiyan Ji, Haoran Chen, Qiguang Chen, Chengyue Wu, Libo Qin, Wanxiang Che</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 09:59:17</h6>
<p class='card-text'>Multimodal planning capabilities refer to the ability to predict, reason, and
design steps for task execution with multimodal context, which is essential for
complex reasoning and decision-making across multiple steps. However, current
benchmarks face two key challenges: (1) they cannot directly assess multimodal
real-world planning capabilities, and (2) they lack constraints or implicit
constraints across modalities. To address these issues, we introduce Multimodal
Planning with Complex Constraints (MPCC), the first benchmark to systematically
evaluate MLLMs' ability to handle multimodal constraints in planning. To
address the first challenge, MPCC focuses on three real-world tasks: Flight
Planning, Calendar Planning, and Meeting Planning. To solve the second
challenge, we introduce complex constraints (e.g. budget, temporal, and
spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to
separate constraint complexity from search space expansion. Experiments on 13
advanced MLLMs reveal significant challenges: closed-source models achieve only
21.3% feasible plans, while open-source models average below 11%. Additionally,
we observe that MLLMs are highly sensitive to constraint complexity and that
traditional multimodal prompting strategies fail in multi-constraint scenarios.
Our work formalizes multimodal constraints in planning, provides a rigorous
evaluation framework, and highlights the need for advancements in
constraint-aware reasoning for real-world MLLM applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23350v1' target='_blank'>Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile
  Robots in Agricultural Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mahmoud Ghorab, Matthias Lorenzen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 08:56:24</h6>
<p class='card-text'>There is a growing demand for autonomous mobile robots capable of navigating
unstructured agricultural environments. Tasks such as weed control in meadows
require efficient path planning through an unordered set of coordinates while
minimizing travel distance and adhering to curvature constraints to prevent
soil damage and protect vegetation. This paper presents an integrated
navigation framework combining a global path planner based on the Dubins
Traveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control
(NMPC) strategy for local path planning and control. The DTSP generates a
minimum-length, curvature-constrained path that efficiently visits all targets,
while the NMPC leverages this path to compute control signals to accurately
reach each waypoint. The system's performance was validated through comparative
simulation analysis on real-world field datasets, demonstrating that the
coupled DTSP-based planner produced smoother and shorter paths, with a
reduction of about 16% in the provided scenario, compared to decoupled methods.
Based thereon, the NMPC controller effectively steered the robot to the desired
waypoints, while locally optimizing the trajectory and ensuring adherence to
constraints. These findings demonstrate the potential of the proposed framework
for efficient autonomous navigation in agricultural environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23332v1' target='_blank'>Classifying Compact Radio Emission in Nearby Galaxies: a 10GHz Study of
  Active Galactic Nuclei, Supernovae, Anomalous Microwave Emission and Star
  Forming Regions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kristen C. Dage, Eric W. Koch, Evangelia Tremou, Kwangmin Oh, Susmita Sett, Cosima Eibensteiner, Sean T. Linden, Angiraben D. Mahida, Eric J. Murphy, Muhammad Ridha Aldhalemi, Zainab Bustani, Mariam Ismail Fawaz, Hans J. Harff, Amna Khalyleh, Timothy McBride, Jesse Mason, Anthony Preston, Cortney Rinehart, Ethan Vinson, Teresa Panurach, Richard M. Plotkin, Liliana Rivera Sandoval</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 08:23:47</h6>
<p class='card-text'>We present 115 compact radio point sources in three galaxies, NGC 5474, NGC
4631 and M51, taken in the most extended (A-)configuration of the Karl G.
Jansky Very Large Array at 10GHz. Several of these compact radio point sources
have diffuse counterparts identified in previous multi-band studies of resolved
radio continuum emission. We find compact counterparts to eight star forming
regions, four anomalous microwave emission candidates, and one supernova
remnant (SN 2011dh). Nine of the compact radio sources match X-ray
counterparts, the majority of which are background galaxies. These AGN are all
within the D25 (isophotal diameter) of the host galaxy and might act as
contaminants for X-ray binary population studies, highlighting the need for
high-resolution multi-band imaging. This study showcases the broad number of
science cases that require sensitive radio facilities, like the upcoming Square
Kilometre Array and the planned next generation Very Large Array.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23325v1' target='_blank'>FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiming Yang, Hongbin Lin, Yueru Luo, Suzhong Fu, Chao Zheng, Xinrui Yan, Shuqi Mei, Kun Tang, Shuguang Cui, Zhen Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 08:12:56</h6>
<p class='card-text'>Lane segment topology reasoning provides comprehensive bird's-eye view (BEV)
road scene understanding, which can serve as a key perception module in
planning-oriented end-to-end autonomous driving systems. Existing lane topology
reasoning methods often fall short in effectively leveraging temporal
information to enhance detection and reasoning performance. Recently,
stream-based temporal propagation method has demonstrated promising results by
incorporating temporal cues at both the query and BEV levels. However, it
remains limited by over-reliance on historical queries, vulnerability to pose
estimation failures, and insufficient temporal propagation. To overcome these
limitations, we propose FASTopoWM, a novel fast-slow lane segment topology
reasoning framework augmented with latent world models. To reduce the impact of
pose estimation failures, this unified framework enables parallel supervision
of both historical and newly initialized queries, facilitating mutual
reinforcement between the fast and slow systems. Furthermore, we introduce
latent query and BEV world models conditioned on the action latent to propagate
the state representations from past observations to the current timestep. This
design substantially improves the performance of temporal perception within the
slow pipeline. Extensive experiments on the OpenLane-V2 benchmark demonstrate
that FASTopoWM outperforms state-of-the-art methods in both lane segment
detection (37.4% v.s. 33.6% on mAP) and centerline perception (46.3% v.s. 41.5%
on OLS).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23324v1' target='_blank'>Assessing the Alignment of Automated Vehicle Decisions with Human
  Reasons</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lucas Elbert Suryana, Saeed Rahmani, Simeon Craig Calvert, Arkady Zgonnikov, Bart van Arem</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 08:07:50</h6>
<p class='card-text'>A key challenge in deploying automated vehicles (AVs) is ensuring they make
appropriate decisions in ethically challenging everyday driving situations.
While much attention has been paid to rare, high-stakes dilemmas such as
trolley problems, similar tensions also arise in routine scenarios, such as
navigating empty intersections, where multiple human considerations, including
legality and comfort, often conflict. Current AV planning systems typically
rely on rigid rules, which struggle to balance these competing considerations
and can lead to behaviour that misaligns with human expectations. This paper
proposes a novel reasons-based trajectory evaluation framework that
operationalises the tracking condition of Meaningful Human Control (MHC). The
framework models the reasons of human agents, such as regulatory compliance, as
quantifiable functions and evaluates how well candidate AV trajectories align
with these reasons. By assigning adjustable weights to agent priorities and
integrating a balance function to discourage the exclusion of any agent, the
framework supports interpretable decision evaluation. Through a
real-world-inspired overtaking scenario, we show how this approach reveals
tensions, for instance between regulatory compliance, efficiency, and comfort.
The framework functions as a modular evaluation layer over existing planning
algorithms. It offers a transparent tool for assessing ethical alignment in
everyday scenarios and provides a practical step toward implementing MHC in
real-world AV deployment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23318v1' target='_blank'>FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play
  Reconstruction-based Token Pruning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiajun Cao, Qizhe Zhang, Peidong Jia, Xuhui Zhao, Bo Lan, Xiaoan Zhang, Xiaobao Wei, Sixiang Chen, Zhuo Li, Yang Wang, Liyun Li, Xianming Liu, Ming Lu, Shanghang Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 07:55:56</h6>
<p class='card-text'>Vision-Language-Action (VLA) models have demonstrated significant potential
in complex scene understanding and action reasoning, leading to their
increasing adoption in end-to-end autonomous driving systems. However, the long
visual tokens of VLA models greatly increase computational costs. Current
visual token pruning methods in Vision-Language Models (VLM) rely on either
visual token similarity or visual-text attention, but both have shown poor
performance in autonomous driving scenarios. Given that human drivers
concentrate on relevant foreground areas while driving, we assert that
retaining visual tokens containing this foreground information is essential for
effective decision-making. Inspired by this, we propose FastDriveVLA, a novel
reconstruction-based vision token pruning framework designed specifically for
autonomous driving. FastDriveVLA includes a plug-and-play visual token pruner
called ReconPruner, which prioritizes foreground information through MAE-style
pixel reconstruction. A novel adversarial foreground-background reconstruction
strategy is designed to train ReconPruner for the visual encoder of VLA models.
Once trained, ReconPruner can be seamlessly applied to different VLA models
with the same visual encoder without retraining. To train ReconPruner, we also
introduce a large-scale dataset called nuScenes-FG, consisting of 241K
image-mask pairs with annotated foreground regions. Our approach achieves
state-of-the-art results on the nuScenes closed-loop planning benchmark across
different pruning ratios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23308v1' target='_blank'>A Framework for Ethical Decision-Making in Automated Vehicles through
  Human Reasons-based Supervision</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lucas Elbert Suryana, Saeed Rahmani, Simeon Craig Calvert, Arkady Zgonnikov, Bart van Arem</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 07:41:58</h6>
<p class='card-text'>Ethical dilemmas are a common challenge in everyday driving, requiring human
drivers to balance competing priorities such as safety, efficiency, and rule
compliance. However, much of the existing research in automated vehicles (AVs)
has focused on high-stakes "trolley problems," which involve extreme and rare
situations. Such scenarios, though rich in ethical implications, are rarely
applicable in real-world AV decision-making. In practice, when AVs confront
everyday ethical dilemmas, they often appear to prioritise strict adherence to
traffic rules. By contrast, human drivers may bend the rules in
context-specific situations, using judgement informed by practical concerns
such as safety and efficiency. According to the concept of meaningful human
control, AVs should respond to human reasons, including those of drivers,
vulnerable road users, and policymakers. This work introduces a novel human
reasons-based supervision framework that detects when AV behaviour misaligns
with expected human reasons to trigger trajectory reconsideration. The
framework integrates with motion planning and control systems to support
real-time adaptation, enabling decisions that better reflect safety,
efficiency, and regulatory considerations. Simulation results demonstrate that
this approach could help AVs respond more effectively to ethical challenges in
dynamic driving environments by prompting replanning when the current
trajectory fails to align with human reasons. These findings suggest that our
approach offers a path toward more adaptable, human-centered decision-making in
AVs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23293v1' target='_blank'>Bayesian reliability acceptance sampling plan sampling plans under
  adaptive accelerated type-II censored competing risk data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rathin Das, Soumya Roy, Biswabrata Pradhan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 07:18:28</h6>
<p class='card-text'>In recent times, products have become increasingly complex and highly
reliable, so failures typically occur after long periods of operation under
normal conditions and may arise from multiple causes. This paper employs simple
step-stress partial accelerated life testing (SSSPALT) within the competing
risks framework to determine the Bayesian reliability acceptance sampling plan
(BRASP) under type-II censoring. Elevating the stress during the life test
incurs an additional cost that increases the cost of the life test. In this
context, an adaptive scenario is also considered in that sampling plan. The
adaptive scenario is as follows: the stress is increased after a certain time
if the number of failures up to that point is less than a pre-specified number
of failures. The Bayes decision function and Bayes risk are derived for the
general loss function. An optimal BRASP under that adaptive SSSPALT is obtained
for the quadratic loss function by minimizing Bayes risk. An algorithm is
provided to determine the optimal proposed BRASP. Further, comparative studies
are conducted between the proposed BRASP, the conventional non-accelerated
BRASP, and the conventional accelerated BRASP under type-II censoring to
evaluate the effectiveness of the proposed approach. Finally, the methodology
is illustrated using real data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23272v1' target='_blank'>Towards Affordable Tumor Segmentation and Visualization for 3D Breast
  MRI Using SAM2</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Solha Kang, Eugene Kim, Joris Vankerschaver, Utku Ozbulak</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 06:15:44</h6>
<p class='card-text'>Breast MRI provides high-resolution volumetric imaging critical for tumor
assessment and treatment planning, yet manual interpretation of 3D scans
remains labor-intensive and subjective. While AI-powered tools hold promise for
accelerating medical image analysis, adoption of commercial medical AI products
remains limited in low- and middle-income countries due to high license costs,
proprietary software, and infrastructure demands. In this work, we investigate
whether the Segment Anything Model 2 (SAM2) can be adapted for low-cost,
minimal-input 3D tumor segmentation in breast MRI. Using a single bounding box
annotation on one slice, we propagate segmentation predictions across the 3D
volume using three different slice-wise tracking strategies: top-to-bottom,
bottom-to-top, and center-outward. We evaluate these strategies across a large
cohort of patients and find that center-outward propagation yields the most
consistent and accurate segmentations. Despite being a zero-shot model not
trained for volumetric medical data, SAM2 achieves strong segmentation
performance under minimal supervision. We further analyze how segmentation
performance relates to tumor size, location, and shape, identifying key failure
modes. Our results suggest that general-purpose foundation models such as SAM2
can support 3D medical image analysis with minimal supervision, offering an
accessible and affordable alternative for resource-constrained settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23270v1' target='_blank'>Simulation-based planning of Motion Sequences for Automated Procedure
  Optimization in Multi-Robot Assembly Cells</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Loris Schneider, Marc Ungen, Elias Huber, Jan-Felix Klein</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-31 06:11:40</h6>
<p class='card-text'>Reconfigurable multi-robot cells offer a promising approach to meet
fluctuating assembly demands. However, the recurrent planning of their
configurations introduces new challenges, particularly in generating optimized,
coordinated multi-robot motion sequences that minimize the assembly duration.
This work presents a simulation-based method for generating such optimized
sequences. The approach separates assembly steps into task-related core
operations and connecting traverse operations. While core operations are
constrained and predetermined, traverse operations offer substantial
optimization potential. Scheduling the core operations is formulated as an
optimization problem, requiring feasible traverse operations to be integrated
using a decomposition-based motion planning strategy. Several solution
techniques are explored, including a sampling heuristic, tree-based search and
gradient-free optimization. For motion planning, a decomposition method is
proposed that identifies specific areas in the schedule, which can be solved
independently with modified centralized path planning algorithms. The proposed
method generates efficient and collision-free multi-robot assembly procedures
that outperform a baseline relying on decentralized, robot-individual motion
planning. Its effectiveness is demonstrated through simulation experiments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23161v1' target='_blank'>Mass Determination of Supermassive Black Holes Governing Evolution of
  Radio Emitters</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kimitake Hayasaki, Ryo Yamazaki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-30 23:47:53</h6>
<p class='card-text'>Tidal disruption events (TDEs) involving supermassive black holes (SMBHs)
often exhibit radio emission, yet its physical origin remains uncertain,
especially in non-jetted cases. In this Letter, we formulate a general
dynamical framework for a radio-emitting shell driven by disk winds and
expanding through a power-law ambient medium under the influence of SMBH
gravity. We derive and classify power-law-in-time solutions to the governing
equations in the adiabatic regime. In particular, a universal $t^{2/3}$ scaling
emerges naturally when gravitational energy dominates or is comparable to
thermal energy, irrespective of the ambient density profile, whereas the
classical Sedov-Taylor solution is recovered when gravity is negligible. Our
analysis reveals that, in regimes where SMBH gravity governs the shell
expansion, the SMBH mass can be inferred from radio observations of the shell.
This approach is independent of and complementary to conventional mass
estimators, with direct implications for interpreting radio-emitting TDEs and
probing SMBH demographics. Our formalism further predicts that 10-100 GHz
monitoring with existing and planned facilities can yield SMBH masses within
months of disruption, providing a time-domain analogue to reverberation
mapping.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23135v1' target='_blank'>ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language
  Models through Procedural Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ananya Sadana, Yash Kumar Lal, Jiawei Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-30 22:30:48</h6>
<p class='card-text'>Understanding causal relationships across modalities is a core challenge for
multimodal models operating in real-world environments. We introduce ISO-Bench,
a benchmark for evaluating whether models can infer causal dependencies between
visual observations and procedural text. Each example presents an image of a
task step and a text snippet from a plan, with the goal of deciding whether the
visual step occurs before or after the referenced text step. Evaluation results
on ten frontier vision-language models show underwhelming performance: the best
zero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest
gains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further
highlights concrete directions for improving causal understanding in multimodal
models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23118v1' target='_blank'>FlowETL: An Autonomous Example-Driven Pipeline for Data Engineering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mattia Di Profio, Mingjun Zhong, Yaji Sripada, Marcel Jaspars</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-30 21:46:22</h6>
<p class='card-text'>The Extract, Transform, Load (ETL) workflow is fundamental for populating and
maintaining data warehouses and other data stores accessed by analysts for
downstream tasks. A major shortcoming of modern ETL solutions is the extensive
need for a human-in-the-loop, required to design and implement
context-specific, and often non-generalisable transformations. While related
work in the field of ETL automation shows promising progress, there is a lack
of solutions capable of automatically designing and applying these
transformations. We present FlowETL, a novel example-based autonomous ETL
pipeline architecture designed to automatically standardise and prepare input
datasets according to a concise, user-defined target dataset. FlowETL is an
ecosystem of components which interact together to achieve the desired outcome.
A Planning Engine uses a paired input-output datasets sample to construct a
transformation plan, which is then applied by an ETL worker to the source
dataset. Monitoring and logging provide observability throughout the entire
pipeline. The results show promising generalisation capabilities across 14
datasets of various domains, file structures, and file sizes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.23095v1' target='_blank'>SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with
  Structural Integrity</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ishani Mondal, Meera Bharadwaj, Ayush Roy, Aparna Garimella, Jordan Lee Boyd-Graber</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-30 20:52:34</h6>
<p class='card-text'>We present SMART-Editor, a framework for compositional layout and content
editing across structured (posters, websites) and unstructured (natural images)
domains. Unlike prior models that perform local edits, SMART-Editor preserves
global coherence through two strategies: Reward-Refine, an inference-time
rewardguided refinement method, and RewardDPO, a training-time preference
optimization approach using reward-aligned layout pairs. To evaluate model
performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain,
cascading edit scenarios. SMART-Editor outperforms strong baselines like
InstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in
structured settings and Reward-Refine showing advantages on natural images.
Automatic and human evaluations confirm the value of reward-guided planning in
producing semantically consistent and visually aligned edits.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>