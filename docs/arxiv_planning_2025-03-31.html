<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-03-31</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-03-31</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22588v1' target='_blank'>Next-Best-Trajectory Planning of Robot Manipulators for Effective
  Observation and Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Heiko Renz, Maximilian Kr√§mer, Frank Hoffmann, Torsten Bertram</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 16:34:29</h6>
<p class='card-text'>Visual observation of objects is essential for many robotic applications,
such as object reconstruction and manipulation, navigation, and scene
understanding. Machine learning algorithms constitute the state-of-the-art in
many fields but require vast data sets, which are costly and time-intensive to
collect. Automated strategies for observation and exploration are crucial to
enhance the efficiency of data gathering. Therefore, a novel strategy utilizing
the Next-Best-Trajectory principle is developed for a robot manipulator
operating in dynamic environments. Local trajectories are generated to maximize
the information gained from observations along the path while avoiding
collisions. We employ a voxel map for environment modeling and utilize
raycasting from perspectives around a point of interest to estimate the
information gain. A global ergodic trajectory planner provides an optional
reference trajectory to the local planner, improving exploration and helping to
avoid local minima. To enhance computational efficiency, raycasting for
estimating the information gain in the environment is executed in parallel on
the graphics processing unit. Benchmark results confirm the efficiency of the
parallelization, while real-world experiments demonstrate the strategy's
effectiveness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22578v1' target='_blank'>Deducing Cardiorespiratory Motion of Cardiac Substructures Using a Novel
  5D-MRI Workflow for Radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chase Ruff, Tarun Naren, Oliver Wieben, Prashant Nagpal, Kevin Johnson, Jiwei Zhao, Thomas Grist, Carri Glide-Hurst</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 16:27:04</h6>
<p class='card-text'>Objective: Cardiotoxicity is a devastating complication of thoracic
radiotherapy. Current radiotherapy imaging protocols are insufficient to
decouple and quantify cardiac motion, limiting substructure-specific motion
considerations in treatment planning. We propose a 5D-MRI workflow for
substructure-specific motion analysis, with future extension to margin
calculation.
  Approach: Our 5D-MRI workflow was implemented for 10 healthy volunteers,
ranging from 23 to 65 years old, reconstructing images for end-exhale/inhale
and active-exhale/inhale for end-systole/diastole. For motion assessment,
proximal coronary arteries, chambers, great vessels, and cardiac valves/nodes
were contoured across all images and verified.Centroid/bounding box excursion
was calculated for cardiac, respiratory, and hysteresis motion. Distance
metrics were tested for statistical independence across substructure pairings.
  Main Results: 5D-MRI images were successfully acquired and contoured for all
volunteers. Cardiac motion was greatest for the coronary arteries (specifically
the right coronary) and smallest for the great vessels. Respiratory motion was
dominant in the S-I direction and largest for the inferior vena cava.
Respiratory hysteresis was generally <5 mm but exceeded 5 mm for some
volunteers. For cardiac motion, there were statistical differences between the
coronary arteries, chambers, and great vessels, and between the right/left
heart. Respiratory motion differed significantly between the base and apex of
the heart.
  Significance: Our 5D-MRI workflow successfully decouples cardiorespiratory
motion with one ~5-minute acquisition. Cardiac motion was >5mm for the coronary
arteries and chambers, while respiratory motion was >5mm for all substructures.
Statistical considerations and inter-patient variability indicate a
substructure and patient-specific approach may be needed for PRV assessment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22550v1' target='_blank'>Road-Width-Aware Network Optimisation for Bike Lane Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Riccardo Basilone, Matteo Bruno, Hygor Piaget Monteiro Melo, Michele Avalle, Vittorio Loreto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 15:51:10</h6>
<p class='card-text'>Active mobility is becoming an essential component of the green transition in
modern cities. However, the challenge of designing an efficient network of
protected bike lanes without disrupting existing road networks for motorised
vehicles remains unsolved. This paper focuses on the specific case of Milan,
using a network approach that considers street widths to optimise the placement
of dedicated bike lanes at the edges of the network. Unlike other network
approaches in this field, our method considers the actual shapes of the
streets, which introduces a realistic aspect lacking in current studies. We
used these data to simulate cycling networks that maximise connectivity while
minimising the impact of bike lane placement on the drivable network. Our mixed
simulation strategies optimise for edge betweenness and width. Furthermore, we
quantify the impact of dedicated bike lane infrastructure on the existing road
network, demonstrating that it is feasible to create highly effective cycling
networks with minimal disruption caused by lane width reductions. This paper
illustrates how realistic cycling lanes can be simulated using road width data
and discusses the challenges and benefits of moving beyond one-dimensional road
data in network studies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22522v1' target='_blank'>A Centralized Planning and Distributed Execution Method for Shape
  Filling with Homogeneous Mobile Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuqing Liu, Rong Su, Karl H. Johansson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 15:28:04</h6>
<p class='card-text'>Nature has inspired humans in different ways. The formation behavior of
animals can perform tasks that exceed individual capability. For example, army
ants could transverse gaps by forming bridges, and fishes could group up to
protect themselves from predators. The pattern formation task is essential in a
multiagent robotic system because it usually serves as the initial
configuration of downstream tasks, such as collective manipulation and
adaptation to various environments. The formation of complex shapes, especially
hollow shapes, remains an open question. Traditional approaches either require
global coordinates for each robot or are prone to failure when attempting to
close the hole due to accumulated localization errors. Inspired by the ribbon
idea introduced in the additive self-assembly algorithm by the Kilobot team, we
develop a two-stage algorithm that does not require global coordinates
information and effectively forms shapes with holes. In this paper, we
investigate the partitioning of the shape using ribbons in a hexagonal lattice
setting and propose the add-subtract algorithm based on the movement sequence
induced by the ribbon structure. This advancement opens the door to tasks
requiring complex pattern formations, such as the assembly of nanobots for
medical applications involving intricate structures and the deployment of
robots along the boundaries of areas of interest. We also provide simulation
results on complex shapes, an analysis of the robustness as well as a proof of
correctness of the proposed algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22496v1' target='_blank'>Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving
  Simulation Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luke Rowe, Roger Girgis, Anthony Gosselin, Liam Paull, Christopher Pal, Felix Heide</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 15:03:41</h6>
<p class='card-text'>We introduce Scenario Dreamer, a fully data-driven generative simulator for
autonomous vehicle planning that generates both the initial traffic scene -
comprising a lane graph and agent bounding boxes - and closed-loop agent
behaviours. Existing methods for generating driving simulation environments
encode the initial traffic scene as a rasterized image and, as such, require
parameter-heavy networks that perform unnecessary computation due to many empty
pixels in the rasterized scene. Moreover, we find that existing methods that
employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer
instead employs a novel vectorized latent diffusion model for initial scene
generation that directly operates on the vectorized scene elements and an
autoregressive Transformer for data-driven agent behaviour simulation. Scenario
Dreamer additionally supports scene extrapolation via diffusion inpainting,
enabling the generation of unbounded simulation environments. Extensive
experiments show that Scenario Dreamer outperforms existing generative
simulators in realism and efficiency: the vectorized scene-generation base
model achieves superior generation quality with around 2x fewer parameters, 6x
lower generation latency, and 10x fewer GPU training hours compared to the
strongest baseline. We confirm its practical utility by showing that
reinforcement learning planning agents are more challenged in Scenario Dreamer
environments than traditional non-generative simulation environments,
especially on long and adversarial driving environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22487v1' target='_blank'>A Multi-Objective Simultaneous Routing, Facility Location and Allocation
  Model for Earthquake Emergency Logistics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sakineh Khodadadi, Tohid Kargar Tasooji, Afshin Shariat-Mohayman, Navid Kalantari</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 14:53:09</h6>
<p class='card-text'>Emergency preparedness reduces the severity and impact of major disasters. In
the case of earthquakes, a rapid and efficient emergency response is essential
to reduce the number of fatalities. Therefore, the design and planning of an
adequate emergency transportation network are crucial in earthquake-prone
locations.
  In the context of emergency transportation modeling, the aim of emergency
routing is to find the network with the minimum length that can provide access
between the maximum number of Emergency Response Centers (ERCs) and damaged
areas. Meanwhile, the goal of the facility location and allocation problem is
to optimize the placement of temporary hospitals to increase coverage and
accessibility, particularly in remote or severely impacted areas.
  This paper proposes a multi-objective, robust, multi-modal, and
multi-time-period optimization problem that simultaneously optimizes routing,
facility location, and hospital allocation. The objective function is to
minimize unmet commodity demand, unserved injuries, and economic costs. We
adopt a fuzzy goal programming approach to solve the multi-objective
simultaneous routing, facility location, and allocation model.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22485v1' target='_blank'>SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential
  Demand Forecasting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Reza Nematirad, Anil Pahwa, Balasubramaniam Natarajan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 14:51:38</h6>
<p class='card-text'>Residential electricity demand forecasting is critical for efficient energy
management and grid stability. Accurate predictions enable utility companies to
optimize planning and operations. However, real-world residential electricity
demand data often exhibit intricate temporal variability, including multiple
seasonalities, periodicities, and abrupt fluctuations, which pose significant
challenges for forecasting models. Previous models that rely on statistical
methods, recurrent, convolutional neural networks, and transformers often
struggle to capture these intricate temporal dynamics. To address these
challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a
novel deep learning framework consisting of two main modules. The first is the
Seasonal-Trend Decomposition Module (STDM), which decomposes the input data
into trend, seasonal, and residual components. The second is the Periodical
Decomposition Module (PDM), which employs the Fast Fourier Transform to
identify the dominant periods. For each dominant period, 1D input data is
reshaped into a 2D tensor, where rows represent periods and columns correspond
to frequencies. The 2D representations are then processed through three
submodules: a 1D convolution to capture sharp fluctuations, a transformer-based
encoder to model global patterns, and a 2D convolution to capture interactions
between periods. Extensive experiments conducted on real-world residential
electricity load data demonstrate that SPDNet outperforms traditional and
advanced models in both forecasting accuracy and computational efficiency. The
code is available in this repository: https://github.com/Tims2D/SPDNet.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22461v1' target='_blank'>Charged Lepton Flavour Violations searches with muons: present and
  future</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:M. Aoki, A. M. Baldini, R. H. Bernstein, C. Carloganu, S. Mihara, S. Miscetti, T. Mori, W. Ootani, F. Renga, S. Ritt, A. Schoening</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 14:13:59</h6>
<p class='card-text'>Charged-lepton flavor violation (cLFV) is one of the most powerful probes for
New Physics (NP). Since lepton flavor conservation is an accidental symmetry in
the Standard Model (SM), it is naturally violated in many NP models, with
contributions at the level of the current experimental sensitivities. Moreover,
the negligible SM contributions would make the observation of cLFV unambiguous
evidence of NP. It makes these searches extremely sensitive and, at the same
time, extremely pure. Thanks to the intense muon beams currently available,
their intriguing upgrade programs, and the progress in the detection
techniques, cLFV muon processes are the golden channels in this field.
Experimental programs to search for $\mu^+ \to e^+ \gamma$, $\mu^+ \to e^+ e^+
e^-$ and the $\mu \to e$ conversion in the nuclear field are currently ongoing.
We review the current status and the strategic plans for future searches. This
document is an update of the prior cLFV submission to the 2018 European
Strategy for Particle Physics (ESPP); the earlier submission should be
consulted for more experimental details.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22321v1' target='_blank'>Estimation of Building Energy Demand Characteristics using Bayesian
  Statistics and Energy Signature Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Justinas Smertinas, Nicolaj Hans Nielsen, Matthias Y. C. Van Hove, Peder Bacher, Henrik Madsen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 10:55:20</h6>
<p class='card-text'>This work presents a scalable Bayesian modeling framework for evaluating
building energy performance using smart-meter data from 2,788 Danish
single-family homes. The framework leverages Bayesian statistical inference
integrated with Energy Signature (ES) models to characterize thermal
performance in buildings. This approach quantifies key parameters such as the
Heat Loss Coefficient (HLC), solar gain, and wind infiltration, while providing
full posterior distributions to reflect parameter uncertainty.
  Three model variants are developed: a baseline ES model, an auto-regressive
model (ARX-ES) to account for thermal inertia, and an auto-regressive moving
average model (ARMAX-ES) that approximates stochastic gray-box dynamics.
Results show that model complexity improves one-step-ahead predictive
performance, with the ARMAX-ES model achieving a median Bayesian R^2 of 0.94
across the building stock. At the single-building level, the Bayesian approach
yields credible intervals for yearly energy demand within $\pm1\%$, enabling
more robust diagnostics than deterministic methods.
  Beyond improved accuracy, the Bayesian framework enhances decision-making by
explicitly representing uncertainty in building performance parameters. This
provides a more realistic foundation for investment prioritization, demand
forecasting, and long-term energy planning. The method is readily applicable to
other building typologies or geographies, offering a scalable tool for
data-driven energy management under uncertainty.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22251v1' target='_blank'>Efficient Building Roof Type Classification: A Domain-Specific
  Self-Supervised Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guneet Mutreja, Ksenia Bittner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 09:04:11</h6>
<p class='card-text'>Accurate classification of building roof types from aerial imagery is crucial
for various remote sensing applications, including urban planning, disaster
management, and infrastructure monitoring. However, this task is often hindered
by the limited availability of labeled data for supervised learning approaches.
To address this challenge, this paper investigates the effectiveness of self
supervised learning with EfficientNet architectures, known for their
computational efficiency, for building roof type classification. We propose a
novel framework that incorporates a Convolutional Block Attention Module (CBAM)
to enhance the feature extraction capabilities of EfficientNet. Furthermore, we
explore the benefits of pretraining on a domain-specific dataset, the Aerial
Image Dataset (AID), compared to ImageNet pretraining. Our experimental results
demonstrate the superiority of our approach. Employing Simple Framework for
Contrastive Learning of Visual Representations (SimCLR) with EfficientNet-B3
and CBAM achieves a 95.5% accuracy on our validation set, matching the
performance of state-of-the-art transformer-based models while utilizing
significantly fewer parameters. We also provide a comprehensive evaluation on
two challenging test sets, demonstrating the generalization capability of our
method. Notably, our findings highlight the effectiveness of domain-specific
pretraining, consistently leading to higher accuracy compared to models
pretrained on the generic ImageNet dataset. Our work establishes EfficientNet
based self-supervised learning as a computationally efficient and highly
effective approach for building roof type classification, particularly
beneficial in scenarios with limited labeled data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22240v1' target='_blank'>Bimanual Regrasp Planning and Control for Eliminating Object Pose
  Uncertainty</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ryuta Nagahama, Weiwei Wan, Zhengtao Hu, Kensuke Harada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 08:42:54</h6>
<p class='card-text'>Precisely grasping an object is a challenging task due to pose uncertainties.
Conventional methods have used cameras and fixtures to reduce object
uncertainty. They are effective but require intensive preparation, such as
designing jigs based on the object geometry and calibrating cameras with
high-precision tools fabricated using lasers. In this study, we propose a
method to reduce the uncertainty of the position and orientation of a grasped
object without using a fixture or a camera. Our method is based on the concept
that the flat finger pads of a parallel gripper can reduce uncertainty along
its opening/closing direction through flat surface contact. Three orthogonal
grasps by parallel grippers with flat finger pads collectively constrain an
object's position and orientation to a unique state. Guided by the concepts, we
develop a regrasp planning and admittance control approach that sequentially
finds and leverages three orthogonal grasps of two robotic arms to eliminate
uncertainties in the object pose. We evaluated the proposed method on different
initial object uncertainties and verified that the method has satisfactory
repeatability accuracy. It outperforms an AR marker detection method
implemented using cameras and laser jet printers under standard laboratory
conditions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22162v1' target='_blank'>Cooperative Hybrid Multi-Agent Pathfinding Based on Shared Exploration
  Maps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ning Liu, Sen Shen, Xiangrui Kong, Hongtao Zhang, Thomas Br√§unl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 05:57:23</h6>
<p class='card-text'>Multi-Agent Pathfinding is used in areas including multi-robot formations,
warehouse logistics, and intelligent vehicles. However, many environments are
incomplete or frequently change, making it difficult for standard centralized
planning or pure reinforcement learning to maintain both global solution
quality and local flexibility. This paper introduces a hybrid framework that
integrates D* Lite global search with multi-agent reinforcement learning, using
a switching mechanism and a freeze-prevention strategy to handle dynamic
conditions and crowded settings. We evaluate the framework in the discrete
POGEMA environment and compare it with baseline methods. Experimental outcomes
indicate that the proposed framework substantially improves success rate,
collision rate, and path efficiency. The model is further tested on the EyeSim
platform, where it maintains feasible Pathfinding under frequent changes and
large-scale robot deployments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22125v1' target='_blank'>Semantic segmentation for building houses from wooden cubes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ivan Beleacov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 03:58:12</h6>
<p class='card-text'>Automated construction is one of the most promising areas that can improve
efficiency, reduce costs and minimize errors in the process of building
construction. In this paper, a comparative analysis of three neural network
models for semantic segmentation, U-Net(light), LinkNet and PSPNet, is
performed. Two specialized datasets with images of houses built from wooden
cubes were created for the experiments. The first dataset contains 4 classes
(background, foundation, walls, roof ) and is designed for basic model
evaluation, while the second dataset includes 44 classes where each cube is
labeled as a separate object. The models were trained with the same
hyperparameters and their accuracy was evaluated using MeanIoU and F1 Score
metrics. According to the results obtained, U-Net(light) showed the best
performance with 78% MeanIoU and 87% F1 Score on the first dataset and 17% and
25% respectively on the second dataset. The poor results on the second dataset
are due to the limited amount of data, the complexity of the partitioning and
the imbalance of classes, making it difficult to accurately select individual
cubes. In addition, overtraining was observed in all experiments, manifested by
high accuracy on the training dataset and its significant decrease on the
validation dataset. The present work is the basis for the development of
algorithms for automatic generation of staged building plans, which can be
further scaled to design complete buildings. Future research is planned to
extend the datasets and apply methods to combat overfitting (L1/L2
regularization, Early Stopping). The next stage of work will be the development
of algorithms for automatic generation of a step-by-step plan for building
houses from cubes using manipulators. Index Terms-Deep Learning, Computer
vision, CNN, Semantic segmentation, Construction materials.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22122v1' target='_blank'>REMAC: Self-Reflective and Self-Evolving Multi-Agent Collaboration for
  Long-Horizon Robot Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Puzhen Yuan, Angyuan Ma, Yunchao Yao, Huaxiu Yao, Masayoshi Tomizuka, Mingyu Ding</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 03:51:40</h6>
<p class='card-text'>Vision-language models (VLMs) have demonstrated remarkable capabilities in
robotic planning, particularly for long-horizon tasks that require a holistic
understanding of the environment for task decomposition. Existing methods
typically rely on prior environmental knowledge or carefully designed
task-specific prompts, making them struggle with dynamic scene changes or
unexpected task conditions, e.g., a robot attempting to put a carrot in the
microwave but finds the door was closed. Such challenges underscore two
critical issues: adaptability and efficiency. To address them, in this work, we
propose an adaptive multi-agent planning framework, termed REMAC, that enables
efficient, scene-agnostic multi-robot long-horizon task planning and execution
through continuous reflection and self-evolution. REMAC incorporates two key
modules: a self-reflection module performing pre-condition and post-condition
checks in the loop to evaluate progress and refine plans, and a self-evolvement
module dynamically adapting plans based on scene-specific reasoning. It offers
several appealing benefits: 1) Robots can initially explore and reason about
the environment without complex prompt design. 2) Robots can keep reflecting on
potential planning errors and adapting the plan based on task-specific
insights. 3) After iterations, a robot can call another one to coordinate tasks
in parallel, maximizing the task execution efficiency. To validate REMAC's
effectiveness, we build a multi-agent environment for long-horizon robot
manipulation and navigation based on RoboCasa, featuring 4 task categories with
27 task styles and 50+ different objects. Based on it, we further benchmark
state-of-the-art reasoning models, including DeepSeek-R1, o3-mini, QwQ, and
Grok3, demonstrating REMAC's superiority by boosting average success rates by
40% and execution efficiency by 52.7% over the single robot baseline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22091v1' target='_blank'>A Graph-native Optimization Framework for Complex Graph Queries</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bingqing Lyu, Xiaoli Zhou, Longbin Lai, Yufan Yang, Yunkai Lou, Wenyuan Yu, Jingren Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 02:12:41</h6>
<p class='card-text'>This technical report extends the SIGMOD 2025 paper "A Modular Graph-Native
Query Optimization Framework" by providing a comprehensive exposition of GOpt's
advanced technical mechanisms, implementation strategies, and extended
evaluations. While the original paper introduced GOpt's unified intermediate
representation (GIR) and demonstrated its performance benefits, this report
delves into the framework's implementation depth: (1) the full specification of
GOpt's optimization rules; (2) a systematic treatment of semantic variations
(e.g., homomorphism vs. edge-distinct matching) across query languages and
their implications for optimization; (3) the design of GOpt's Physical
integration interface, enabling seamless integration with transactional (Neo4j)
and distributed (GraphScope) backends via engine-specific operator
customization; and (4) a detailed analysis of plan transformations for LDBC
benchmark queries.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22057v1' target='_blank'>A production planning benchmark for real-world refinery-petrochemical
  complexes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenli Du, Chuan Wang, Chen Fan, Zhi Li, Yeke Zhong, Tianao Kang, Ziting Liang, Minglei Yang, Feng Qian, Xin Dai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-28 00:32:39</h6>
<p class='card-text'>To achieve digital intelligence transformation and carbon neutrality,
effective production planning is crucial for integrated refinery-petrochemical
complexes. Modern refinery planning relies on advanced optimization techniques,
whose development requires reproducible benchmark problems. However, existing
benchmarks lack practical context or impose oversimplified assumptions,
limiting their applicability to enterprise-wide optimization. To bridge the
substantial gap between theoretical research and industrial applications, this
paper introduces the first open-source, demand-driven benchmark for
industrial-scale refinery-petrochemical complexes with transparent model
formulations and comprehensive input parameters. The benchmark incorporates a
novel port-stream hybrid superstructure for modular modeling and broad
generalizability. Key secondary processing units are represented using the
delta-base approach grounded in historical data. Three real-world cases have
been constructed to encompass distinct scenario characteristics, respectively
addressing (1) a stand-alone refinery without integer variables, (2) chemical
site integration with inventory-related integer variables, and (3) multi-period
planning. All model parameters are fully accessible. Additionally, this paper
provides an analysis of computational performance, ablation experiments on
delta-base modeling, and application scenarios for the proposed benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22030v1' target='_blank'>Bayesian Inferential Motion Planning Using Heavy-Tailed Distributions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ali Vaziri, Iman Askari, Huazhen Fang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 22:54:38</h6>
<p class='card-text'>Robots rely on motion planning to navigate safely and efficiently while
performing various tasks. In this paper, we investigate motion planning through
Bayesian inference, where motion plans are inferred based on planning
objectives and constraints. However, existing Bayesian motion planning methods
often struggle to explore low-probability regions of the planning space, where
high-quality plans may reside. To address this limitation, we propose the use
of heavy-tailed distributions -- specifically, Student's-$t$ distributions --
to enhance probabilistic inferential search for motion plans. We develop a
novel sequential single-pass smoothing approach that integrates Student's-$t$
distribution with Monte Carlo sampling. A special case of this approach is
ensemble Kalman smoothing, which depends on short-tailed Gaussian
distributions. We validate the proposed approach through simulations in
autonomous vehicle motion planning, demonstrating its superior performance in
planning, sampling efficiency, and constraint satisfaction compared to ensemble
Kalman smoothing. While focused on motion planning, this work points to the
broader potential of heavy-tailed distributions in enhancing probabilistic
decision-making in robotics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.22020v1' target='_blank'>CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingqing Zhao, Yao Lu, Moo Jin Kim, Zipeng Fu, Zhuoyang Zhang, Yecheng Wu, Zhaoshuo Li, Qianli Ma, Song Han, Chelsea Finn, Ankur Handa, Ming-Yu Liu, Donglai Xiang, Gordon Wetzstein, Tsung-Yi Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 22:23:04</h6>
<p class='card-text'>Vision-language-action models (VLAs) have shown potential in leveraging
pretrained vision-language models and diverse robot demonstrations for learning
generalizable sensorimotor control. While this paradigm effectively utilizes
large-scale data from both robotic and non-robotic sources, current VLAs
primarily focus on direct input--output mappings, lacking the intermediate
reasoning steps crucial for complex manipulation tasks. As a result, existing
VLAs lack temporal planning or reasoning capabilities. In this paper, we
introduce a method that incorporates explicit visual chain-of-thought (CoT)
reasoning into vision-language-action models (VLAs) by predicting future image
frames autoregressively as visual goals before generating a short action
sequence to achieve these goals. We introduce CoT-VLA, a state-of-the-art 7B
VLA that can understand and generate visual and action tokens. Our experimental
results demonstrate that CoT-VLA achieves strong performance, outperforming the
state-of-the-art VLA model by 17% in real-world manipulation tasks and 6% in
simulation benchmarks. Project website: https://cot-vla.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21989v1' target='_blank'>Bresa: Bio-inspired Reflexive Safe Reinforcement Learning for
  Contact-Rich Robotic Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Heng Zhang, Gokhan Solak, Arash Ajoudani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 21:11:32</h6>
<p class='card-text'>Ensuring safety in reinforcement learning (RL)-based robotic systems is a
critical challenge, especially in contact-rich tasks within unstructured
environments. While the state-of-the-art safe RL approaches mitigate risks
through safe exploration or high-level recovery mechanisms, they often overlook
low-level execution safety, where reflexive responses to potential hazards are
crucial. Similarly, variable impedance control (VIC) enhances safety by
adjusting the robot's mechanical response, yet lacks a systematic way to adapt
parameters, such as stiffness and damping throughout the task. In this paper,
we propose Bresa, a Bio-inspired Reflexive Hierarchical Safe RL method inspired
by biological reflexes. Our method decouples task learning from safety
learning, incorporating a safety critic network that evaluates action risks and
operates at a higher frequency than the task solver. Unlike existing
recovery-based methods, our safety critic functions at a low-level control
layer, allowing real-time intervention when unsafe conditions arise. The
task-solving RL policy, running at a lower frequency, focuses on high-level
planning (decision-making), while the safety critic ensures instantaneous
safety corrections. We validate Bresa on multiple tasks including a
contact-rich robotic task, demonstrating its reflexive ability to enhance
safety, and adaptability in unforeseen dynamic environments. Our results show
that Bresa outperforms the baseline, providing a robust and reflexive safety
mechanism that bridges the gap between high-level planning and low-level
execution. Real-world experiments and supplementary material are available at
project website https://jack-sherman01.github.io/Bresa.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21953v1' target='_blank'>Risk-Prone and Risk-Averse Behavior in Natural Emergencies: An Appraisal
  Theory Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sorin Adam Matei, Rajesh Kalyanam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 19:59:00</h6>
<p class='card-text'>The paper examines social media content to measure and model risk behavior in
natural emergencies from an appraisal theory perspective. We calculate
individual risk behavior quotients and relate them to individual and peer
emotional and actionable cognitive responses for 774 individual Twitter users
affected by the Sandy hurricane landfall. We employ vector analysis to compute
risk behavior quotients. By utilizing geographic information associated with
the tweets, both implicitly and explicitly, we track each user's path and
determine the average vector of their movement. The risk quotient is obtained
by comparing risk exposure at the origin and destination of the average vector.
We assess risk exposure for each zone in the study area by combining
pre-hurricane evacuation plans with post-event flooding data, as reported by
the National Weather Service. By using the emotional and actionable content of
the tweets as predictors for risk, we found that sharing actionable information
relates to slightly higher risk exposure. At the same time, overall, the
subjects tended to move away from the riskiest areas of the storm. Finally,
individuals surrounded by more peers are less likely to be affected, while
those surrounded by more tweeting activity are more likely to be affected
risk-prone.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21937v1' target='_blank'>Lobster: A GPU-Accelerated Framework for Neurosymbolic Programming</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Paul Biberstein, Ziyang Li, Joseph Devietti, Mayur Naik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 19:32:58</h6>
<p class='card-text'>Neurosymbolic programs combine deep learning with symbolic reasoning to
achieve better data efficiency, interpretability, and generalizability compared
to standalone deep learning approaches. However, existing neurosymbolic
learning frameworks implement an uneasy marriage between a highly scalable,
GPU-accelerated neural component with a slower symbolic component that runs on
CPUs. We propose Lobster, a unified framework for harnessing GPUs in an
end-to-end manner for neurosymbolic learning. Lobster maps a general
neurosymbolic language based on Datalog to the GPU programming paradigm. This
mapping is implemented via compilation to a new intermediate language called
APM. The extra abstraction provided by APM allows Lobster to be both flexible,
supporting discrete, probabilistic, and differentiable modes of reasoning on
GPU hardware with a library of provenance semirings, and performant,
implementing new optimization passes. We demonstrate that Lobster programs can
solve interesting problems spanning the domains of natural language processing,
image processing, program reasoning, bioinformatics, and planning. On a suite
of 8 applications, Lobster achieves an average speedup of 5.3x over Scallop, a
state-of-the-art neurosymbolic framework, and enables scaling of neurosymbolic
solutions to previously infeasible tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21857v1' target='_blank'>CLIC Higgs coupling prospects with 100 Hz operation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:A. Robson, P. Roloff, J. de Blas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 17:32:08</h6>
<p class='card-text'>The staging scenario for CLIC has been updated following new studies of the
beam emittance through the accelerator chain, which has resulted in higher
expected luminosities, and a change in baseline to a 100 Hz repetition rate at
the initial energy stage. Here, the Higgs coupling sensitivities are updated
for the new staging plan.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21696v1' target='_blank'>Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for
  Embodied Interactive Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenqi Zhang, Mengna Wang, Gangao Liu, Xu Huixin, Yiwei Jiang, Yongliang Shen, Guiyang Hou, Zhe Zheng, Hang Zhang, Xin Li, Weiming Lu, Peng Li, Yueting Zhuang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 17:00:51</h6>
<p class='card-text'>Recent advances in deep thinking models have demonstrated remarkable
reasoning capabilities on mathematical and coding tasks. However, their
effectiveness in embodied domains which require continuous interaction with
environments through image action interleaved trajectories remains largely
-unexplored. We present Embodied Reasoner, a model that extends o1 style
reasoning to interactive embodied search tasks. Unlike mathematical reasoning
that relies primarily on logical deduction, embodied scenarios demand spatial
understanding, temporal reasoning, and ongoing self-reflection based on
interaction history. To address these challenges, we synthesize 9.3k coherent
Observation-Thought-Action trajectories containing 64k interactive images and
90k diverse thinking processes (analysis, spatial reasoning, reflection,
planning, and verification). We develop a three-stage training pipeline that
progressively enhances the model's capabilities through imitation learning,
self-exploration via rejection sampling, and self-correction through reflection
tuning. The evaluation shows that our model significantly outperforms those
advanced visual reasoning models, e.g., it exceeds OpenAI o1, o3-mini, and
Claude-3.7 by +9\%, 24\%, and +13\%. Analysis reveals our model exhibits fewer
repeated searches and logical inconsistencies, with particular advantages in
complex long-horizon tasks. Real-world environments also show our superiority
while exhibiting fewer repeated searches and logical inconsistency cases.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21677v1' target='_blank'>A tale of two goals: leveraging sequentiality in multi-goal scenarios</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Olivier Serris, St√©phane Doncieux, Olivier Sigaud</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 16:47:46</h6>
<p class='card-text'>Several hierarchical reinforcement learning methods leverage planning to
create a graph or sequences of intermediate goals, guiding a lower-level
goal-conditioned (GC) policy to reach some final goals. The low-level policy is
typically conditioned on the current goal, with the aim of reaching it as
quickly as possible. However, this approach can fail when an intermediate goal
can be reached in multiple ways, some of which may make it impossible to
continue toward subsequent goals. To address this issue, we introduce two
instances of Markov Decision Process (MDP) where the optimization objective
favors policies that not only reach the current goal but also subsequent ones.
In the first, the agent is conditioned on both the current and final goals,
while in the second, it is conditioned on the next two goals in the sequence.
We conduct a series of experiments on navigation and pole-balancing tasks in
which sequences of intermediate goals are given. By evaluating policies trained
with TD3+HER on both the standard GC-MDP and our proposed MDPs, we show that,
in most cases, conditioning on the next two goals improves stability and sample
efficiency over other approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21668v1' target='_blank'>Cognitive Science-Inspired Evaluation of Core Capabilities for Object
  Understanding in AI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Danaja Rutar, Alva Markelius, Konstantinos Voudouris, Jos√© Hern√°ndez-Orallo, Lucy Cheke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 16:35:02</h6>
<p class='card-text'>One of the core components of our world models is 'intuitive physics' - an
understanding of objects, space, and causality. This capability enables us to
predict events, plan action and navigate environments, all of which rely on a
composite sense of objecthood. Despite its importance, there is no single,
unified account of objecthood, though multiple theoretical frameworks provide
insights. In the first part of this paper, we present a comprehensive overview
of the main theoretical frameworks in objecthood research - Gestalt psychology,
enactive cognition, and developmental psychology - and identify the core
capabilities each framework attributes to object understanding, as well as what
functional roles they play in shaping world models in biological agents. Given
the foundational role of objecthood in world modelling, understanding
objecthood is also essential in AI. In the second part of the paper, we
evaluate how current AI paradigms approach and test objecthood capabilities
compared to those in cognitive science. We define an AI paradigm as a
combination of how objecthood is conceptualised, the methods used for studying
objecthood, the data utilised, and the evaluation techniques. We find that,
whilst benchmarks can detect that AI systems model isolated aspects of
objecthood, the benchmarks cannot detect when AI systems lack functional
integration across these capabilities, not solving the objecthood challenge
fully. Finally, we explore novel evaluation approaches that align with the
integrated vision of objecthood outlined in this paper. These methods are
promising candidates for advancing from isolated object capabilities toward
general-purpose AI with genuine object understanding in real-world contexts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21602v1' target='_blank'>GenEdit: Compounding Operators and Continuous Improvement to Tackle
  Text-to-SQL in the Enterprise</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karime Maamari, Connor Landy, Amine Mhedhbi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 15:22:02</h6>
<p class='card-text'>Recent advancements in Text-to-SQL, driven by large language models, are
democratizing data access. Despite these advancements, enterprise deployments
remain challenging due to the need to capture business-specific knowledge,
handle complex queries, and meet expectations of continuous improvements. To
address these issues, we designed and implemented GenEdit: our Text-to-SQL
generation system that improves with user feedback. GenEdit builds and
maintains a company-specific knowledge set, employs a pipeline of operators
decomposing SQL generation, and uses feedback to update its knowledge set to
improve future SQL generations.
  We describe GenEdit's architecture made of two core modules: (i) decomposed
SQL generation; and (ii) knowledge set edits based on user feedback. For
generation, GenEdit leverages compounding operators to improve knowledge
retrieval and to create a plan as chain-of-thought steps that guides
generation. GenEdit first retrieves relevant examples in an initial retrieval
stage where original SQL queries are decomposed into sub-statements, clauses or
sub-queries. It then also retrieves instructions and schema elements. Using the
retrieved contextual information, GenEdit then generates step-by-step plan in
natural language on how to produce the query. Finally, GenEdit uses the plan to
generate SQL, minimizing the need for model reasoning, which enhances complex
SQL generation. If necessary, GenEdit regenerates the query based on syntactic
and semantic errors. The knowledge set edits are recommended through an
interactive copilot, allowing users to iterate on their feedback and to
regenerate SQL queries as needed. Each generation uses staged edits which
update the generation prompt. Once the feedback is submitted, it gets merged
after passing regression testing and obtaining an approval, improving future
generations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21570v1' target='_blank'>HFLAV input to the 2026 update of the European Strategy for Particle
  Physics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:F. Archilli, Sw. Banerjee, E. Ben-Haim, F. U. Bernlochner, E. Bertholet, M. Bona, A. Bozek, C. Bozzi, J. Brodzicka, V. Chobanova, M. Chrzaszcz, M. Dorigo, U. Egede, A. Gaz, M. Gersabeck, T. Gershon, P. Goldenzweig, L. Grillo, K. Hayasaka, T. Humair, D. Johnson, M. Kenzie, T. Kuhr, O. Leroy, A. Lusiani, H. -L. Ma, M. Margoni, R. Mizuk, P. Naik, M. T. Prim, M. Roney, M. Rotondo, O. Schneider, C. Schwanda, A. J. Schwartz, J. Serrano, B. Shwartz, M. Veronesi, M. Whitehead, J. Yelton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 14:51:18</h6>
<p class='card-text'>Heavy-flavour physics is an essential component of the particle-physics
programme, offering critical tests of the Standard Model and far-reaching
sensitivity to physics beyond it. Experiments such as LHCb, Belle II, and
BESIII drive progress in the field, along with contributions from ATLAS and
CMS. The LHCb Upgrade II and upgraded Belle II experiments will provide unique
and highly sensitive measurements for decades, playing a key role in the
searches for new physics. Future facilities with significant heavy-flavour
capabilities will further expand these opportunities. We advocate for a
European Strategy that fully supports Upgrade II of LHCb and an upgrade of
Belle II, along with their subsequent exploitation. Additionally, we support a
long-term plan that fully integrates flavour physics in an $e^+e^-$ collider to
run as a $Z$ factory.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21548v1' target='_blank'>Combining Graph Attention Networks and Distributed Optimization for
  Multi-Robot Mixed-Integer Convex Programming</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Viet-Anh Le, Panagiotis Kounatidis, Andreas A. Malikopoulos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 14:36:45</h6>
<p class='card-text'>In this paper, we develop a fast mixed-integer convex programming (MICP)
framework for multi-robot navigation by combining graph attention networks and
distributed optimization. We formulate a mixed-integer optimization problem for
receding horizon motion planning of a multi-robot system, taking into account
the surrounding obstacles. To address the resulting multi-agent MICP problem in
real time, we propose a framework that utilizes heterogeneous graph attention
networks to learn the latent mapping from problem parameters to optimal binary
solutions. Furthermore, we apply a distributed proximal alternating direction
method of multipliers algorithm for solving the convex continuous optimization
problem. We demonstrate the effectiveness of our proposed framework through
experiments conducted on a robotic testbed.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21505v1' target='_blank'>Fine-Grained Evaluation of Large Vision-Language Models in Autonomous
  Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Li, Meng Tian, Zhenyu Lin, Jiangtong Zhu, Dechang Zhu, Haiqiang Liu, Zining Wang, Yueyi Zhang, Zhiwei Xiong, Xinhai Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 13:45:47</h6>
<p class='card-text'>Existing benchmarks for Vision-Language Model (VLM) on autonomous driving
(AD) primarily assess interpretability through open-form visual question
answering (QA) within coarse-grained tasks, which remain insufficient to assess
capabilities in complex driving scenarios. To this end, we introduce
$\textbf{VLADBench}$, a challenging and fine-grained dataset featuring
close-form QAs that progress from static foundational knowledge and elements to
advanced reasoning for dynamic on-road situations. The elaborate
$\textbf{VLADBench}$ spans 5 key domains: Traffic Knowledge Understanding,
General Element Recognition, Traffic Graph Generation, Target Attribute
Comprehension, and Ego Decision-Making and Planning. These domains are further
broken down into 11 secondary aspects and 29 tertiary tasks for a granular
evaluation. A thorough assessment of general and domain-specific (DS) VLMs on
this benchmark reveals both their strengths and critical limitations in AD
contexts. To further exploit the cognitive and reasoning interactions among the
5 domains for AD understanding, we start from a small-scale VLM and train the
DS models on individual domain datasets (collected from 1.4M DS QAs across
public sources). The experimental results demonstrate that the proposed
benchmark provides a crucial step toward a more comprehensive assessment of
VLMs in AD, paving the way for the development of more cognitively
sophisticated and reasoning-capable AD systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.21444v1' target='_blank'>Automated Analysis of Pricings in SaaS-based Information Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alejandro Garc√≠a-Fern√°ndez, Jos√© Antonio Parejo, Pablo Trinidad, Antonio Ruiz-Cort√©s</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-27 12:36:57</h6>
<p class='card-text'>Software as a Service (SaaS) pricing models, encompassing features, usage
limits, plans, and add-ons, have grown exponentially in complexity, evolving
from offering tens to thousands of configuration options. This rapid expansion
poses significant challenges for the development and operation of SaaS-based
Information Systems (IS), as manual management of such configurations becomes
time-consuming, error-prone, and ultimately unsustainable. The emerging
paradigm of Pricing-driven DevOps aims to address these issues by automating
pricing management tasks, such as transforming human-oriented pricings into
machine-oriented (iPricing) or finding the optimal subscription that matches
the requirements of a certain user, ultimately reducing human intervention.
This paper advances the field by proposing seven analysis operations that
partially or fully support these pricing management tasks, thus serving as a
foundation for defining new, more specialized operations. To achieve this, we
mapped iPricings into Constraint Satisfaction Optimization Problems (CSOP), an
approach successfully used in similar domains, enabling us to implement and
apply these operations to uncover latent, yet non-trivial insights from complex
pricing models. The proposed approach has been implemented in a reference
framework using MiniZinc, and tested with over 150 pricing models, identifying
errors in 35 pricings of the benchmark. Results demonstrate its effectiveness
in identifying errors and its potential to streamline Pricing-driven DevOps.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>