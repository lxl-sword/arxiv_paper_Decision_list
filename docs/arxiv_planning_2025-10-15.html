<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-10-15</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-10-15</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12733v1' target='_blank'>HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hang Yu, Julian Jordan, Julian Schmidt, Silvan Lindner, Alessandro Canevaro, Wilhelm Stork</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 17:11:04</h6>
<p class='card-text'>Safe and interpretable motion planning in complex urban environments needs to
reason about bidirectional multi-agent interactions. This reasoning requires to
estimate the costs of potential ego driving maneuvers. Many existing planners
generate initial trajectories with sampling-based methods and refine them by
optimizing on learned predictions of future environment states, which requires
a cost function that encodes the desired vehicle behavior. Designing such a
cost function can be very challenging, especially if a wide range of complex
urban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego
proposal-conditioned predictions, a planner that integrates multimodal
trajectory proposals from a learned proposal model as heuristic priors into a
Monte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions,
we introduce an ego-conditioned occupancy prediction model, enabling
consistent, scene-aware reasoning. Our design significantly simplifies cost
function design in refinement by considering proposal-driven guidance,
requiring only minimalistic grid-based cost terms. Evaluations on large-scale
real-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves
state-of-the-art performance, especially in safety and adaptability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12693v1' target='_blank'>ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning
  and Online Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanyang Chen, Mark Zhao, Rui Yang, Qinwei Ma, Ke Yang, Jiarui Yao, Kangrui Wang, Hao Bai, Zhenhailong Wang, Rui Pan, Mengchao Zhang, Jose Barreiros, Aykut Onol, ChengXiang Zhai, Heng Ji, Manling Li, Huan Zhang, Tong Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 16:25:46</h6>
<p class='card-text'>Recent advances in embodied AI highlight the potential of vision language
models (VLMs) as agents capable of perception, reasoning, and interaction in
complex environments. However, top-performing systems rely on large-scale
models that are costly to deploy, while smaller VLMs lack the necessary
knowledge and skills to succeed. To bridge this gap, we present
\textit{Embodied Reasoning Agent (ERA)}, a two-stage framework that integrates
prior knowledge learning and online reinforcement learning (RL). The first
stage, \textit{Embodied Prior Learning}, distills foundational knowledge from
three types of data: (1) Trajectory-Augmented Priors, which enrich existing
trajectory data with structured reasoning generated by stronger models; (2)
Environment-Anchored Priors, which provide in-environment knowledge and
grounding supervision; and (3) External Knowledge Priors, which transfer
general knowledge from out-of-environment datasets. In the second stage, we
develop an online RL pipeline that builds on these priors to further enhance
agent performance. To overcome the inherent challenges in agent RL, including
long horizons, sparse rewards, and training instability, we introduce three key
designs: self-summarization for context management, dense reward shaping, and
turn-level policy optimization. Extensive experiments on both high-level
planning (EB-ALFRED) and low-level control (EB-Manipulation) tasks demonstrate
that ERA-3B surpasses both prompting-based large models and previous
training-based baselines. Specifically, it achieves overall improvements of
8.4\% on EB-ALFRED and 19.4\% on EB-Manipulation over GPT-4o, and exhibits
strong generalization to unseen tasks. Overall, ERA offers a practical path
toward scalable embodied intelligence, providing methodological insights for
future embodied AI systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12662v1' target='_blank'>Maximal Adaptation, Minimal Guidance: Permissive Reactive Robot Task
  Planning with Humans in the Loop</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oz Gitelson, Satya Prakash Nayak, Ritam Raha, Anne-Kathrin Schmuck</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 15:58:42</h6>
<p class='card-text'>We present a novel framework for human-robot \emph{logical} interaction that
enables robots to reliably satisfy (infinite horizon) temporal logic tasks
while effectively collaborating with humans who pursue independent and unknown
tasks. The framework combines two key capabilities: (i) \emph{maximal
adaptation} enables the robot to adjust its strategy \emph{online} to exploit
human behavior for cooperation whenever possible, and (ii) \emph{minimal
tunable feedback} enables the robot to request cooperation by the human online
only when necessary to guarantee progress. This balance minimizes human-robot
interference, preserves human autonomy, and ensures persistent robot task
satisfaction even under conflicting human goals. We validate the approach in a
real-world block-manipulation task with a Franka Emika Panda robotic arm and in
the Overcooked-AI benchmark, demonstrating that our method produces rich,
\emph{emergent} cooperative behaviors beyond the reach of existing approaches,
while maintaining strong formal guarantees.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12642v1' target='_blank'>Aixel: A Unified, Adaptive and Extensible System for AI-powered Data
  Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Meihui Zhang, Liming Wang, Chi Zhang, Zhaojing Luo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 15:34:35</h6>
<p class='card-text'>A growing trend in modern data analysis is the integration of data management
with learning, guided by accuracy, latency, and cost requirements. In practice,
applications draw data of different formats from many sources. In the
meanwhile, the objectives and budgets change over time. Existing systems handle
these applications across databases, analysis libraries, and tuning services.
Such fragmentation leads to complex user interaction, limited adaptability,
suboptimal performance, and poor extensibility across components. To address
these challenges, we present Aixel, a unified, adaptive, and extensible system
for AI-powered data analysis. The system organizes work across four layers:
application, task, model, and data. The task layer provides a declarative
interface to capture user intent, which is parsed into an executable operator
plan. An optimizer compiles and schedules this plan to meet specified goals in
accuracy, latency, and cost. The task layer coordinates the execution of data
and model operators, with built-in support for reuse and caching to improve
efficiency. The model layer offers versioned storage for index, metadata,
tensors, and model artifacts. It supports adaptive construction, task-aligned
drift detection, and safe updates that reuse shared components. The data layer
provides unified data management capabilities, including indexing,
constraint-aware discovery, task-aligned selection, and comprehensive feature
management. With the above designed layers, Aixel delivers a user friendly,
adaptive, efficient, and extensible system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12585v1' target='_blank'>OCTOPUS: A Versatile, User-Friendly, and Extensible Public Code for
  General-Relativistic Ray-Tracing in Spherically Symmetric and Static
  Spacetimes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shiyang Hu, Shijie Tan, Dan Li, Lina Zhang, Chen Deng, Wenfu Cao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 14:40:57</h6>
<p class='card-text'>This paper presents OCTOPUS, a relativistic ray-tracing algorithm developed
within a Fortran-based, OpenMP-accelerated framework, designed for
asymptotically flat, spherically symmetric curved spacetimes. The code
efficiently and accurately computes key relativistic features -- including the
black hole event horizon, photon rings, critical curves, and innermost stable
circular orbits -- and simulates black hole shadows, redshift factor
distributions, accretion disk images, toroidal images, as well as gravitational
lensing, light curves, and gravitational radiation from hot-spots. OCTOPUS
provides an automated, modular solution for qualitative studies of black hole
observables and multi-messenger correlations between electromagnetic and
gravitational signals in curved spacetime. Its implementation requires only the
metric potential and its first-, second-, and third-order radial derivatives as
input, ensuring low user barriers while remaining highly extensible and
adaptable. Using a Schwarzschild black hole surrounded by a Dehnen-type dark
matter halo, we thoroughly validate the algorithm's precision, efficiency, and
functionality, and investigate how dark matter halo parameters affect
observational signatures. Our results demonstrate that increasing the scale and
density of the dark matter halo strengthens the spacetime's gravitational
field, an effect clearly reflected in black hole images and supported by
hot-spot light curve signatures. A future version of OCTOPUS, with expanded
capabilities for axisymmetric spacetimes, is planned for release.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12519v1' target='_blank'>Trading robustness: a scenario-free approach to robust Multi-Criteria
  Optimization for Treatment Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Remo Cristoforetti, Philipp Süss, Tobias Becher, Niklas Wahl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 13:43:39</h6>
<p class='card-text'>Treatment planning in radiotherapy is inherently a multi-criteria
optimization (MCO) problem. Traditionally, the treatment's robustness is not
formulated as a part of this decision making problem, but dealt with separately
through margins or robust optimization. This work facilitates integration of
robustness into multi-criteria optimization using a recently proposed efficient
scenario-free (s-f) robust optimization approach: The s-f approach relies on
the fast evaluation of the expected dose distribution and mean variance during
optimization. This is achieved by precomputation of probabilistic quantities,
which can then be used for repeated solving of subproblems in the two explored
MCO approaches: Lexicographic Ordering (LO) and Pareto Front (PF)
approximation. Different prioritization strategies within the LO approach are
used to assess the impact of variance reduction while a 3-objective PF
approximation, including a variance reduction objective, is generated to
visualize and analyze trade-offs between the competing objectives. The robust
optimization is performed including 100 scenarios modeling setup and range
errors, as well as organ motion, on 3D- and 4DCT lung cancer patient datasets.
Robustness analysis is performed to assess and explore the efficacy of all
optimization strategies. The s-f approach enabled robust optimization in MCO
with computational times comparable to nominal MCO. Both MCO strategies
highlighted the interplay between dosimetric and variance reduction objectives.
The LO approach showed how prioritization affects plan quality and robustness,
while the PF analysis revealed a clear trade-off between robustness and
organ-at-risk sparing. The reported analysis highlighted the conflicting
trade-off nature of plan robustness and dosimetric quality, demonstrating how
robust MCO supports a more informed and flexible decision-making process in
treatment planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12509v1' target='_blank'>Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot
  Manipulators: Addressing the Behavior Planning Challenge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gaoyuan Liu, Bas Boom, Naftali Slob, Yuri Durodié, Ann Nowé, Bram Vanderborght</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 13:40:40</h6>
<p class='card-text'>Pruning is an essential agricultural practice for orchards. Proper pruning
can promote healthier growth and optimize fruit production throughout the
orchard's lifespan. Robot manipulators have been developed as an automated
solution for this repetitive task, which typically requires seasonal labor with
specialized skills. While previous research has primarily focused on the
challenges of perception, the complexities of manipulation are often
overlooked. These challenges involve planning and control in both joint and
Cartesian spaces to guide the end-effector through intricate, obstructive
branches. Our work addresses the behavior planning challenge for a robotic
pruning system, which entails a multi-level planning problem in environments
with complex collisions. In this paper, we formulate the planning problem for a
high-dimensional robotic arm in a pruning scenario, investigate the system's
intrinsic redundancies, and propose a comprehensive pruning workflow that
integrates perception, modeling, and holistic planning. In our experiments, we
demonstrate that more comprehensive planning methods can significantly enhance
the performance of the robotic manipulator. Finally, we implement the proposed
workflow on a real-world robot. As a result, this work complements previous
efforts on robotic pruning and motivates future research and development in
planning for pruning applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12477v1' target='_blank'>A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe
  Human-Robot Cooperation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gaoyuan Liu, Joris de Winter, Kelly Merckaert, Denis Steckelmacher, Ann Nowe, Bram Vanderborght</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 13:11:09</h6>
<p class='card-text'>In a Human-Robot Cooperation (HRC) environment, safety and efficiency are the
two core properties to evaluate robot performance. However, safety mechanisms
usually hinder task efficiency since human intervention will cause backup
motions and goal failures of the robot. Frequent motion replanning will
increase the computational load and the chance of failure. In this paper, we
present a hybrid Reinforcement Learning (RL) planning framework which is
comprised of an interactive motion planner and a RL task planner. The RL task
planner attempts to choose statistically safe and efficient task sequences
based on the feedback from the motion planner, while the motion planner keeps
the task execution process collision-free by detecting human arm motions and
deploying new paths when the previous path is not valid anymore. Intuitively,
the RL agent will learn to avoid dangerous tasks, while the motion planner
ensures that the chosen tasks are safe. The proposed framework is validated on
the cobot in both simulation and the real world, we compare the planner with
hard-coded task motion planning methods. The results show that our planning
framework can 1) react to uncertain human motions at both joint and task
levels; 2) reduce the times of repeating failed goal commands; 3) reduce the
total number of replanning requests.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12435v1' target='_blank'>The value of storage in electricity distribution: The role of storage</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dirk Lauinger, Deepjyoti Deka, Sungho Shin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 12:13:58</h6>
<p class='card-text'>Electricity distribution companies deploy battery storage to defer grid
upgrades by reducing peak demand. In deregulated jurisdictions, such storage
often sits idle because regulatory constraints bar participation in electricity
markets. Here, we develop an optimization framework that, to our knowledge,
provides the first formal model of market participation constraints within
storage investment and operation planning. Applying the framework to a
Massachusetts case study, we find that market participation could deliver
similar savings as peak demand reduction. Under current conditions, market
participation does not increase storage investment, but at very low storage
costs, could incentivize deployment beyond local distribution needs. This might
run contrary to the separation of distribution from generation in deregulated
markets. Our framework can identify investment levels appropriate for local
distribution needs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12434v1' target='_blank'>PRoH: Dynamic Planning and Reasoning over Knowledge Hypergraphs for
  Retrieval-Augmented Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiangjun Zai, Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Wenjie Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 12:13:23</h6>
<p class='card-text'>Knowledge Hypergraphs (KHs) have recently emerged as a knowledge
representation for retrieval-augmented generation (RAG), offering a paradigm to
model multi-entity relations into a structured form. However, existing KH-based
RAG methods suffer from three major limitations: static retrieval planning,
non-adaptive retrieval execution, and superficial use of KH structure and
semantics, which constrain their ability to perform effective multi-hop
question answering. To overcome these limitations, we propose PRoH, a dynamic
Planning and Reasoning over Knowledge Hypergraphs framework. PRoH incorporates
three core innovations: (i) a context-aware planning module that sketches the
local KH neighborhood to guide structurally grounded reasoning plan generation;
(ii) a structured question decomposition process that organizes subquestions as
a dynamically evolving Directed Acyclic Graph (DAG) to enable adaptive,
multi-trajectory exploration; and (iii) an Entity-Weighted Overlap (EWO)-guided
reasoning path retrieval algorithm that prioritizes semantically coherent
hyperedge traversals. Experiments across multiple domains demonstrate that PRoH
achieves state-of-the-art performance, surpassing the prior SOTA model
HyperGraphRAG by an average of 19.73% in F1 and 8.41% in Generation Evaluation
(G-E) score, while maintaining strong robustness in long-range multi-hop
reasoning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12346v1' target='_blank'>PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair
  Climbing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bingquan Li, Ning Wang, Tianwei Zhang, Zhicheng He, Yucong Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 10:00:05</h6>
<p class='card-text'>Recently, biped robot walking technology has been significantly developed,
mainly in the context of a bland walking scheme. To emulate human walking,
robots need to step on the positions they see in unknown spaces accurately. In
this paper, we present PolyMap, a perception-based locomotion planning
framework for humanoid robots to climb stairs. Our core idea is to build a
real-time polygonal staircase plane semantic map, followed by a footstep planar
using these polygonal plane segments. These plane segmentation and visual
odometry are done by multi-sensor fusion(LiDAR, RGB-D camera and IMUs). The
proposed framework is deployed on a NVIDIA Orin, which performs 20-30 Hz
whole-body motion planning output. Both indoor and outdoor real-scene
experiments indicate that our method is efficient and robust for humanoid robot
stair climbing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12253v1' target='_blank'>Diffusion Models for Reinforcement Learning: Foundations, Taxonomy, and
  Development</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Changfu Xu, Jianxiong Guo, Yuzhu Liang, Haiyang Huang, Haodong Zou, Xi Zheng, Shui Yu, Xiaowen Chu, Jiannong Cao, Tian Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 08:03:46</h6>
<p class='card-text'>Diffusion Models (DMs), as a leading class of generative models, offer key
advantages for reinforcement learning (RL), including multi-modal
expressiveness, stable training, and trajectory-level planning. This survey
delivers a comprehensive and up-to-date synthesis of diffusion-based RL. We
first provide an overview of RL, highlighting its challenges, and then
introduce the fundamental concepts of DMs, investigating how they are
integrated into RL frameworks to address key challenges in this research field.
We establish a dual-axis taxonomy that organizes the field along two orthogonal
dimensions: a function-oriented taxonomy that clarifies the roles DMs play
within the RL pipeline, and a technique-oriented taxonomy that situates
implementations across online versus offline learning regimes. We also provide
a comprehensive examination of this progression from single-agent to
multi-agent domains, thereby forming several frameworks for DM-RL integration
and highlighting their practical utility. Furthermore, we outline several
categories of successful applications of diffusion-based RL across diverse
domains, discuss open research issues of current methodologies, and highlight
key directions for future research to advance the field. Finally, we summarize
the survey to identify promising future development directions. We are actively
maintaining a GitHub repository (https://github.com/ChangfuXu/D4RL-FTD) for
papers and other related resources to apply DMs for RL.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12200v1' target='_blank'>HackWorld: Evaluating Computer-Use Agents on Exploiting Web Application
  Vulnerabilities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaoxue Ren, Penghao Jiang, Kaixin Li, Zhiyong Huang, Xiaoning Du, Jiaojiao Jiang, Zhenchang Xing, Jiamou Sun, Terry Yue Zhuo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 06:52:15</h6>
<p class='card-text'>Web applications are prime targets for cyberattacks as gateways to critical
services and sensitive data. Traditional penetration testing is costly and
expertise-intensive, making it difficult to scale with the growing web
ecosystem. While language model agents show promise in cybersecurity, modern
web applications demand visual understanding, dynamic content handling, and
multi-step interactions that only computer-use agents (CUAs) can perform. Yet,
their ability to discover and exploit vulnerabilities through graphical
interfaces remains largely unexplored. We present HackWorld, the first
framework for systematically evaluating CUAs' capabilities to exploit web
application vulnerabilities via visual interaction. Unlike sanitized
benchmarks, HackWorld includes 36 real-world applications across 11 frameworks
and 7 languages, featuring realistic flaws such as injection vulnerabilities,
authentication bypasses, and unsafe input handling. Using a Capture-the-Flag
(CTF) setup, it tests CUAs' capacity to identify and exploit these weaknesses
while navigating complex web interfaces. Evaluation of state-of-the-art CUAs
reveals concerning trends: exploitation rates below 12% and low cybersecurity
awareness. CUAs often fail at multi-step attack planning and misuse security
tools. These results expose the current limitations of CUAs in web security
contexts and highlight opportunities for developing more security-aware agents
capable of effective vulnerability detection and exploitation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12194v1' target='_blank'>ResearStudio: A Human-Intervenable Framework for Building Controllable
  Deep-Research Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Linyi Yang, Yixuan Weng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 06:40:11</h6>
<p class='card-text'>Current deep-research agents run in a ''fire-and-forget'' mode: once started,
they give users no way to fix errors or add expert knowledge during execution.
We present ResearStudio, the first open-source framework that places real-time
human control at its core. The system follows a Collaborative Workshop design.
A hierarchical Planner-Executor writes every step to a live
''plan-as-document,'' a fast communication layer streams each action, file
change, and tool call to a web interface. At any moment, the user can pause the
run, edit the plan or code, run custom commands, and resume -- switching
smoothly between AI-led, human-assisted and human-led, AI-assisted modes. In
fully autonomous mode, ResearStudio achieves state-of-the-art results on the
GAIA benchmark, surpassing systems like OpenAI's DeepResearch and Manus. These
results show that strong automated performance and fine-grained human control
can coexist. The full code, protocol, and evaluation scripts are available at
https://github.com/ResearAI/ResearStudio. We will continue to update the
repository to encourage further work on safe and controllable research agents.
Our live demo is publicly accessible at http://ai-researcher.net:3000/. We
support the development of DeepScientist, which can be accessed at
https://github.com/ResearAI/DeepScientist.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12169v1' target='_blank'>Hybrid Terrain-Aware Path Planning: Integrating VD--RRT\(^{*}\)
  Exploration and VD--D\(^{*}\) Lite Repair</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Akshay Naik, William R. Norris, Dustin Nottage, Ahmet Soylemezoglu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 05:54:46</h6>
<p class='card-text'>Autonomous ground vehicles operating off-road must plan curvature-feasible
paths while accounting for spatially varying soil strength and slope hazards in
real time. We present a continuous state--cost metric that combines a Bekker
pressure--sinkage model with elevation-derived slope and attitude penalties.
The resulting terrain cost field is analytic, bounded, and monotonic in soil
modulus and slope, ensuring well-posed discretization and stable updates under
sensor noise. This metric is evaluated on a lattice with exact steering
primitives: Dubins and Reeds--Shepp motions for differential drive and
time-parameterized bicycle arcs for Ackermann steering. Global exploration is
performed using Vehicle-Dynamics RRT\(^{*}\), while local repair is managed by
Vehicle-Dynamics D\(^{*}\) Lite, enabling millisecond-scale replanning without
heuristic smoothing. By separating the terrain--vehicle model from the planner,
the framework provides a reusable basis for deterministic, sampling-based, or
learning-driven planning in deformable terrain. Hardware trials on an off-road
platform demonstrate real-time navigation across soft soil and slope
transitions, supporting reliable autonomy in unstructured environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12162v1' target='_blank'>CCAT: Optical Responsivity, Noise, and Readout Optimization of KIDs for
  Prime-Cam</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eliza Gazda, Quintin Meyers, James R. Burgoyne, Scott Chapman, Steve K. Choi, Cody J. Duell, Anthony I. Huber, Inchara Jagadeesh, David Faulkner Katz, Ben Keller, Lawrence T. Lin, Paul Malachuk, Michael D. Niemack, Darshan A. Patel, Gordon J. Stacey, Benjamin J. Vaughan, Eve M. Vavagiakis, Samantha Walker, Yuhan Wang, Ruixuan, Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 05:38:07</h6>
<p class='card-text'>The Prime-Cam instrument of the Fred Young Submillimeter Telescope (FYST) at
the CCAT Observatory will conduct sensitive millimeter to submillimeter surveys
for a range of astrophysical and cosmological sciences. Prime-Cam will use
kinetic inductance detectors (KIDs) sensitive to multiple frequency bands
spanning 280--850 GHz. With over 100,000 sensors under development, these KID
arrays will soon form the largest submillimeter focal plane ever built. With
fixed microwave tones probing amplitude and phase modulations in the KIDs due
to incoming radiation, challenges arise in determining the optimal readout
settings, especially under varying atmospheric loading. Realizing the science
goals of FYST requires operating the detectors at optimal performance and
determining accurate responsivities, which depend on readout tone placement and
power. To address these challenges, we present laboratory measurements of
sample pixels from the 280 GHz TiN and Al arrays using a blackbody cold load to
simulate observing conditions. These measurements probe detector responsivity
and noise across varying optical loading, tone power, and tone placement,
providing the foundation to guide in situ calibration and operation of the
$>$100,000 KIDs. We characterize detector sensitivity via the Noise Equivalent
Power (NEP) as a function of readout tone power and placement, and measure the
impact of detuning due to varying optical power on the NEP. Our test setup and
methodology will inform the commissioning of Prime-Cam, in situ detector
calibration procedures, the cadence of probe tone resetting, and potential
design refinements for future arrays, supporting FYST's planned first light in
2026.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.12088v1' target='_blank'>One Life to Learn: Inferring Symbolic World Models for Stochastic
  Environments from Unguided Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zaid Khan, Archiki Prasad, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-14 02:49:32</h6>
<p class='card-text'>Symbolic world modeling requires inferring and representing an environment's
transitional dynamics as an executable program. Prior work has focused on
largely deterministic environments with abundant interaction data, simple
mechanics, and human guidance. We address a more realistic and challenging
setting, learning in a complex, stochastic environment where the agent has only
"one life" to explore a hostile environment without human guidance. We
introduce OneLife, a framework that models world dynamics through
conditionally-activated programmatic laws within a probabilistic programming
framework. Each law operates through a precondition-effect structure,
activating in relevant world states. This creates a dynamic computation graph
that routes inference and optimization only through relevant laws, avoiding
scaling challenges when all laws contribute to predictions about a complex,
hierarchical state, and enabling the learning of stochastic dynamics even with
sparse rule activation. To evaluate our approach under these demanding
constraints, we introduce a new evaluation protocol that measures (a) state
ranking, the ability to distinguish plausible future states from implausible
ones, and (b) state fidelity, the ability to generate future states that
closely resemble reality. We develop and evaluate our framework on Crafter-OO,
our reimplementation of the Crafter environment that exposes a structured,
object-oriented symbolic state and a pure transition function that operates on
that state alone. OneLife can successfully learn key environment dynamics from
minimal, unguided interaction, outperforming a strong baseline on 16 out of 23
scenarios tested. We also test OneLife's planning ability, with simulated
rollouts successfully identifying superior strategies. Our work establishes a
foundation for autonomously constructing programmatic world models of unknown,
complex environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11950v1' target='_blank'>Digital Low-Level RF system for the Linac Electronics Modernization Plan
  at LCLS</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nashat Sawai, Jorge Diaz Cruz, Andy Benwell, Sonya Hoobler, Qiang Du, Shreeharshini Murthy, Larry Doolittle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 21:23:23</h6>
<p class='card-text'>The LCLS began operations in 2009, utilizing SLAC's normal-conducting (NC)
LINAC, which features control equipment dating back to the 1960s and 1980s. The
Linac Electronics Modernization Plan (LEMP) aims to replace the legacy control
equipment with a system based on the open-source Marble carrier board and Zest+
digitizer board, both of which are used in the LCLS-II HE LLRF system.
Adaptation of the LLRF system developed for the continuous-wave (CW)
superconducting RF (SRF) LCLS-II to the short-RF pulse NC LCLS includes
leveraging the knowledge and experience gained from recent LLRF projects at
SLAC and efficiently reusing the core functionality of the hardware and code
base developed for previous projects, in collaboration with LBNL, FNAL and
JLAB. A prototype has been deployed and tested at station 26-3, demonstrating
RF generation/control, interlocks, triggers, and waveform capture. Here, we
describe the hardware, firmware and software infrastructure, highlight key
features, and present initial test results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11910v1' target='_blank'>Simplifying Optimal Transport through Schatten-$p$ Regularization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tyler Maunu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 20:22:28</h6>
<p class='card-text'>We propose a new general framework for recovering low-rank structure in
optimal transport using Schatten-$p$ norm regularization. Our approach extends
existing methods that promote sparse and interpretable transport maps or plans,
while providing a unified and principled family of convex programs that
encourage low-dimensional structure. The convexity of our formulation enables
direct theoretical analysis: we derive optimality conditions and prove recovery
guarantees for low-rank couplings and barycentric maps in simplified settings.
To efficiently solve the proposed program, we develop a mirror descent
algorithm with convergence guarantees for $p \geq 1$. Experiments on synthetic
and real data demonstrate the method's efficiency, scalability, and ability to
recover low-rank transport structures.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11713v2' target='_blank'>Are Large Reasoning Models Interruptible?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tsung-Han Wu, Mihran Miroyan, David M. Chan, Trevor Darrell, Narges Norouzi, Joseph E. Gonzalez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 17:59:35</h6>
<p class='card-text'>Large Reasoning Models (LRMs) excel at complex reasoning but are
traditionally evaluated in static, "frozen world" settings: model responses are
assumed to be instantaneous, and the context of a request is presumed to be
immutable over the duration of the response. While generally true for
short-term tasks, the "frozen world" assumption breaks down in modern reasoning
tasks such as assistive programming, where models may take hours to think
through problems and code may change dramatically from the time the model
starts thinking to the model's final output. In this work, we challenge the
frozen world assumption and evaluate LRM robustness under two realistic dynamic
scenarios: interruptions, which test the quality of the model's partial outputs
on a limited budget, and dynamic context, which tests model adaptation to
in-flight changes. Across mathematics and programming benchmarks that require
long-form reasoning, static evaluations consistently overestimate robustness:
even state-of-the-art LRMs, which achieve high accuracy in static settings, can
fail unpredictably when interrupted or exposed to changing context, with
performance dropping by up to 60% when updates are introduced late in the
reasoning process. Our analysis further reveals several novel failure modes,
including reasoning leakage, where models fold the reasoning into their final
answer when interrupted; panic, where under time pressure models abandon
reasoning entirely and return incorrect answers; and self-doubt, where
performance degrades while incorporating updated information.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11692v1' target='_blank'>Analysis of the Geometric Heat Flow Equation: Computing Geodesics in
  Real-Time with Convergence Guarantees</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Samuel G. Gessow, Brett T. Lopez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 17:52:52</h6>
<p class='card-text'>We present an analysis on the convergence properties of the so-called
geometric heat flow equation for computing geodesics (shortest-path~curves) on
Riemannian manifolds. Computing geodesics numerically in real-time has become
an important capability in several fields, including control and motion
planning. The geometric heat flow equation involves solving a parabolic partial
differential equation whose solution is a geodesic. In practice, solving this
PDE numerically can be done efficiently, and tends to be more numerically
stable and exhibit a better rate of convergence compared to numerical
optimization. We prove that the geometric heat flow equation is globally
exponentially stable in $L_2$ if the curvature of the Riemannian manifold is
not too positive, and that asymptotic convergence in $L_2$ is always
guaranteed. We also present a pseudospectral method that leverages Chebyshev
polynomials to accurately compute geodesics in only a few milliseconds for
non-contrived manifolds. Our analysis was verified with our custom
pseudospectral method by computing geodesics on common non-Euclidean surfaces,
and in feedback for a contraction-based controller with a non-flat metric for a
nonlinear system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11683v2' target='_blank'>Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nianyi Lin, Jiajie Zhang, Lei Hou, Juanzi Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 17:47:50</h6>
<p class='card-text'>A key challenge in applying reinforcement learning (RL) to diffusion large
language models (dLLMs) lies in the intractability of their likelihood
functions, which are essential for the RL objective, necessitating
corresponding approximation in each training step. While existing methods
approximate the log-likelihoods by their evidence lower bounds (ELBOs) via
customized Monte Carlo (MC) sampling, the forward computational graphs of all
MC samples need to be retained for the gradient computation of non-linear terms
in the RL objective, resulting in significant memory overhead. This constraint
restricts feasible sample sizes, leading to imprecise likelihood approximations
and ultimately distorting the RL objective. To overcome this limitation, we
propose \emph{Boundary-Guided Policy Optimization} (BGPO), a memory-efficient
RL algorithm that maximizes a specially constructed lower bound of the
ELBO-based objective. This lower bound is carefully designed to satisfy two key
properties: (1) Linearity: it is formulated in a linear sum where each term
depends only on a single MC sample, thereby enabling gradient accumulation
across samples and ensuring constant memory usage; (2) Equivalence: Both the
value and gradient of this lower bound are equal to those of the ELBO-based
objective in on-policy training, making it also an effective approximation for
the original RL objective. These properties allow BGPO to adopt a large MC
sample size, resulting in more accurate likelihood approximations and improved
RL objective estimation, which in turn leads to enhanced performance.
Experiments show that BGPO significantly outperforms previous RL algorithms for
dLLMs in math problem solving, code generation, and planning tasks. Our codes
and models are available at
\href{https://github.com/THU-KEG/BGPO}{https://github.com/THU-KEG/BGPO}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11682v1' target='_blank'>Ego-Vision World Model for Humanoid Contact Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hang Liu, Yuman Gao, Sangli Teng, Yufeng Chi, Yakun Sophia Shao, Zhongyu Li, Maani Ghaffari, Koushil Sreenath</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 17:47:39</h6>
<p class='card-text'>Enabling humanoid robots to exploit physical contact, rather than simply
avoid collisions, is crucial for autonomy in unstructured environments.
Traditional optimization-based planners struggle with contact complexity, while
on-policy reinforcement learning (RL) is sample-inefficient and has limited
multi-task ability. We propose a framework combining a learned world model with
sampling-based Model Predictive Control (MPC), trained on a demonstration-free
offline dataset to predict future outcomes in a compressed latent space. To
address sparse contact rewards and sensor noise, the MPC uses a learned
surrogate value function for dense, robust planning. Our single, scalable model
supports contact-aware tasks, including wall support after perturbation,
blocking incoming objects, and traversing height-limited arches, with improved
data efficiency and multi-task capability over on-policy RL. Deployed on a
physical humanoid, our system achieves robust, real-time contact planning from
proprioception and ego-centric depth images. Website:
https://ego-vcp.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11660v2' target='_blank'>ManiAgent: An Agentic Framework for General Robotic Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yi Yang, Kefan Gu, Yuqing Wen, Hebei Li, Yucheng Zhao, Tiancai Wang, Xudong Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 17:34:48</h6>
<p class='card-text'>While Vision-Language-Action (VLA) models have demonstrated impressive
capabilities in robotic manipulation, their performance in complex reasoning
and long-horizon task planning is limited by data scarcity and model capacity.
To address this, we introduce ManiAgent, an agentic architecture for general
manipulation tasks that achieves end-to-end output from task descriptions and
environmental inputs to robotic manipulation actions. In this framework,
multiple agents involve inter-agent communication to perform environmental
perception, sub-task decomposition and action generation, enabling efficient
handling of complex manipulation scenarios. Evaluations show ManiAgent achieves
an 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world
pick-and-place tasks, enabling efficient data collection that yields VLA models
with performance comparable to those trained on human-annotated datasets. The
project webpage is available at https://yi-yang929.github.io/ManiAgent/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11620v1' target='_blank'>Enhancing Long Chain-of-Thought Reasoning through Multi-Path Plan
  Aggregation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siheng Xiong, Ali Payani, Faramarz Fekri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 17:02:41</h6>
<p class='card-text'>Inference-time scaling enhances the reasoning ability of a language model
(LM) by extending its chain-of-thought (CoT). However, existing approaches
typically generate the entire reasoning chain in a single forward pass, which
often leads to CoT derailment, i.e., the reasoning trajectory drifting off
course due to compounding errors. This problem is particularly severe for
smaller LMs with long CoTs due to their limited capacity. To address this, we
analyze raw long CoTs and uncover a reasoning hierarchy consisting of planning
and execution steps. Our analysis reveals that most reasoning errors stem from
incorrect planning. Motivated by this observation, we propose Multi-Path Plan
Aggregation (MPPA), a framework that augments single-pass reasoning with plan
exploration and aggregation. Following a variable interval schedule based on
the token position, MPPA generates multiple candidate plans and aggregates them
into a refined planning step. To maintain efficiency, we adopt a minimal design
in which the base LM serves as the primary policy, while a lightweight LoRA
module implements the plan aggregation policy. We further observe that
outcome-reward RL is inefficient for long trajectories (e.g., exceeding 4K
tokens). To overcome this, we introduce online Step-DPO, a process-level
preference optimization scheme that leverages Twisted Sequential Monte Carlo
(TSMC) to provide scalable stepwise supervision using small LMs. This yields
more efficient training, improved stability, and higher accuracy. Extensive
experiments on challenging math, science, and logical reasoning benchmarks
demonstrate that, with only 10% SFT data and 5% of preference pairs, our method
outperforms both the DeepSeek-R1 distillation baseline and the outcome-reward
RL baseline across multiple base models and tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11542v1' target='_blank'>NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Neil C. Janwani, Varun Madabushi, Maegan Tucker</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 15:41:38</h6>
<p class='card-text'>Reinforcement learning (RL) has emerged as a powerful method to learn robust
control policies for bipedal locomotion. Yet, it can be difficult to tune
desired robot behaviors due to unintuitive and complex reward design. In
comparison, offline trajectory optimization methods, like Hybrid Zero Dynamics,
offer more tuneable, interpretable, and mathematically grounded motion plans
for high-dimensional legged systems. However, these methods often remain
brittle to real-world disturbances like external perturbations.
  In this work, we present NaviGait, a hierarchical framework that combines the
structure of trajectory optimization with the adaptability of RL for robust and
intuitive locomotion control. NaviGait leverages a library of offline-optimized
gaits and smoothly interpolates between them to produce continuous reference
motions in response to high-level commands. The policy provides both
joint-level and velocity command residual corrections to modulate and stabilize
the reference trajectories in the gait library. One notable advantage of
NaviGait is that it dramatically simplifies reward design by encoding rich
motion priors from trajectory optimization, reducing the need for finely tuned
shaping terms and enabling more stable and interpretable learning. Our
experimental results demonstrate that NaviGait enables faster training compared
to conventional and imitation-based RL, and produces motions that remain
closest to the original reference. Overall, by decoupling high-level motion
generation from low-level correction, NaviGait offers a more scalable and
generalizable approach for achieving dynamic and robust locomotion.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11503v1' target='_blank'>People use fast, flat goal-directed simulation to reason about novel
  problems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Katherine M. Collins, Cedegao E. Zhang, Lionel Wong, Mauricio Barba da Costa, Graham Todd, Adrian Weller, Samuel J. Cheyette, Thomas L. Griffiths, Joshua B. Tenenbaum</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 15:12:08</h6>
<p class='card-text'>Games have long been a microcosm for studying planning and reasoning in both
natural and artificial intelligence, especially with a focus on expert-level or
even super-human play. But real life also pushes human intelligence along a
different frontier, requiring people to flexibly navigate decision-making
problems that they have never thought about before. Here, we use novice
gameplay to study how people make decisions and form judgments in new problem
settings. We show that people are systematic and adaptively rational in how
they play a game for the first time, or evaluate a game (e.g., how fair or how
fun it is likely to be) before they have played it even once. We explain these
capacities via a computational cognitive model that we call the "Intuitive
Gamer". The model is based on mechanisms of fast and flat (depth-limited)
goal-directed probabilistic simulation--analogous to those used in Monte Carlo
tree-search models of expert game-play, but scaled down to use very few
stochastic samples, simple goal heuristics for evaluating actions, and no deep
search. In a series of large-scale behavioral studies with over 1000
participants and 121 two-player strategic board games (almost all novel to our
participants), our model quantitatively captures human judgments and decisions
varying the amount and kind of experience people have with a game--from no
experience at all ("just thinking"), to a single round of play, to indirect
experience watching another person and predicting how they should play--and
does so significantly better than much more compute-intensive expert-level
models. More broadly, our work offers new insights into how people rapidly
evaluate, act, and make suggestions when encountering novel problems, and could
inform the design of more flexible and human-like AI systems that can determine
not just how to solve new tasks, but whether a task is worth thinking about at
all.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11401v1' target='_blank'>Path and Motion Optimization for Efficient Multi-Location Inspection
  with Humanoid Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiayang Wu, Jiongye Li, Shibowen Zhang, Zhicheng He, Zaijin Wang, Xiaokun Leng, Hangxin Liu, Jingwen Zhang, Jiayi Wang, Song-Chun Zhu, Yao Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 13:44:08</h6>
<p class='card-text'>This paper proposes a novel framework for humanoid robots to execute
inspection tasks with high efficiency and millimeter-level precision. The
approach combines hierarchical planning, time-optimal standing position
generation, and integrated \ac{mpc} to achieve high speed and precision. A
hierarchical planning strategy, leveraging \ac{ik} and \ac{mip}, reduces
computational complexity by decoupling the high-dimensional planning problem. A
novel MIP formulation optimizes standing position selection and trajectory
length, minimizing task completion time. Furthermore, an MPC system with
simplified kinematics and single-step position correction ensures
millimeter-level end-effector tracking accuracy. Validated through simulations
and experiments on the Kuavo 4Pro humanoid platform, the framework demonstrates
low time cost and a high success rate in multi-location tasks, enabling
efficient and precise execution of complex industrial operations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11400v1' target='_blank'>FedHybrid: Breaking the Memory Wall of Federated Learning via Hybrid
  Tensor Management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kahou Tam, Chunlin Tian, Li Li, Haikai Zhao, ChengZhong Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 13:43:55</h6>
<p class='card-text'>Federated Learning (FL) emerges as a new learning paradigm that enables
multiple devices to collaboratively train a shared model while preserving data
privacy. However, one fundamental and prevailing challenge that hinders the
deployment of FL on mobile devices is the memory limitation. This paper
proposes \textit{FedHybrid}, a novel framework that effectively reduces the
memory footprint during the training process while guaranteeing the model
accuracy and the overall training progress. Specifically, \textit{FedHybrid}
first selects the participating devices for each training round by jointly
evaluating their memory budget, computing capability, and data diversity. After
that, it judiciously analyzes the computational graph and generates an
execution plan for each selected client in order to meet the corresponding
memory budget while minimizing the training delay through employing a hybrid of
recomputation and compression techniques according to the characteristic of
each tensor. During the local training process, \textit{FedHybrid} carries out
the execution plan with a well-designed activation compression technique to
effectively achieve memory reduction with minimum accuracy loss. We conduct
extensive experiments to evaluate \textit{FedHybrid} on both simulation and
off-the-shelf mobile devices. The experiment results demonstrate that
\textit{FedHybrid} achieves up to a 39.1\% increase in model accuracy and a
15.5$\times$ reduction in wall clock time under various memory budgets compared
with the baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.11381v1' target='_blank'>Optimal Control of a Bioeconomic Crop-Energy System with Energy
  Reinvestment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Othman Cherkaoui Dekkaki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-13 13:23:10</h6>
<p class='card-text'>We develop an optimal control model for allocating agricultural crop residues
between bioenergy production and soil fertility restoration. The system
captures a novel circular feedback: a fraction of cumulative energy output is
reinvested into soil productivity, linking energy use with ecological
regeneration. The dynamics are governed by a nonlinear three-state system
describing soil fertility, residue biomass, and accumulated energy, with a
single control representing the proportion of biomass diverted to energy. The
objective is to maximize a discounted net benefit that accounts for energy
revenue, soil value, and operational costs. We apply the Pontryagin Maximum
Principle in current-value form to derive necessary optimality conditions and
characterize the structure of optimal controls. Numerical simulations based on
direct optimization reveal interior and switching regimes, and show how
planning horizon and reinvestment efficiency influence optimal strategies. The
results highlight the strategic role of energy reinvestment in achieving
sustainable residue management.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>