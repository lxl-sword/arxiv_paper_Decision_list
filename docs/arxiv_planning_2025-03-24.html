<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-03-24</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-03-24</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.17339v1' target='_blank'>Can AI expose tax loopholes? Towards a new generation of legal policy
  assistants</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peter Fratrič, Nils Holzenberger, David Restrepo Amariles</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 17:40:06</h6>
<p class='card-text'>The legislative process is the backbone of a state built on solid
institutions. Yet, due to the complexity of laws -- particularly tax law --
policies may lead to inequality and social tensions. In this study, we
introduce a novel prototype system designed to address the issues of tax
loopholes and tax avoidance. Our hybrid solution integrates a natural language
interface with a domain-specific language tailored for planning. We demonstrate
on a case study how tax loopholes and avoidance schemes can be exposed. We
conclude that our prototype can help enhance social welfare by systematically
identifying and addressing tax gaps stemming from loopholes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.17293v1' target='_blank'>Leveraging statistical models to improve pre-season forecasting and
  in-season management of a recreational fishery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:A. Challen Hyman, Chloe Ramsay, Tiffanie A. Cross, Beverly Sauls, Thomas K. Frazer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 16:43:02</h6>
<p class='card-text'>Effective management of recreational fisheries requires accurate forecasting
of future harvests and real-time monitoring of ongoing harvests. Traditional
methods that rely on historical catch data to predict short-term harvests can
be unreliable, particularly if changes in management regulations alter angler
behavior. In contrast, statistical modeling approaches can provide faster, more
flexible, and potentially more accurate predictions, enhancing management
outcomes. In this study, we developed and tested models to improve predictions
of Gulf of Mexico gag harvests for both pre-season planning and in-season
monitoring. Our best-fitting model outperformed traditional methods (i.e.,
estimates derived from historical average harvest) for both cumulative
pre-season projections and in-season monitoring. Notably, our modeling
framework appeared to be more accurate in more recent, shorter seasons due to
its ability to account for effort compression. A key advantage of our framework
is its ability to explicitly quantify the probability of exceeding harvest
quotas for any given season duration. This feature enables managers to evaluate
trade-offs between season duration and conservation goals. This is especially
critical for vulnerable, highly targeted stocks. Our findings also underscore
the value of statistical models to complement and advance traditional fisheries
management approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.17257v1' target='_blank'>The EnviroMapper Toolkit: an Input Physicalisation that Captures the
  Situated Experience of Environmental Comfort in Offices</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Silvia Cazacu, Stien Poncelet, Emma Feijtraij, Andrew Vande Moere</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 16:00:23</h6>
<p class='card-text'>The environmental comfort in offices is traditionally captured by surveying
an entire workforce simultaneously, which yet fails to capture the situatedness
of the different personal experiences. To address this limitation, we developed
the EnviroMapper Toolkit, a data physicalisation toolkit that allows individual
office workers to record their personal experiences of environmental comfort by
mapping the actual moments and locations these occurred. By analysing two
in-the-wild studies in existing open-plan office environments (N=14), we
demonstrate how this toolkit acts like a situated input visualisation that can
be interpreted by domain experts who were not present during its construction.
This study therefore offers four key contributions: (1) the iterative design
process of the physicalisation toolkit; (2) its preliminary deployment in two
real-world office contexts; (3) the decoding of the resulting artefacts by
domain experts; and (4) design considerations to support future input
physicalisation and visualisation constructions that capture and synthesise
data from multiple individuals.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.17194v1' target='_blank'>Curriculum RL meets Monte Carlo Planning: Optimization of a Real World
  Container Management Problem</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhijeet Pendyala, Tobias Glasmachers</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 14:43:11</h6>
<p class='card-text'>In this work, we augment reinforcement learning with an inference-time
collision model to ensure safe and efficient container management in a
waste-sorting facility with limited processing capacity. Each container has two
optimal emptying volumes that trade off higher throughput against overflow
risk. Conventional reinforcement learning (RL) approaches struggle under
delayed rewards, sparse critical events, and high-dimensional uncertainty --
failing to consistently balance higher-volume empties with the risk of
safety-limit violations. To address these challenges, we propose a hybrid
method comprising: (1) a curriculum-learning pipeline that incrementally trains
a PPO agent to handle delayed rewards and class imbalance, and (2) an offline
pairwise collision model used at inference time to proactively avert collisions
with minimal online cost. Experimental results show that our targeted
inference-time collision checks significantly improve collision avoidance,
reduce safety-limit violations, maintain high throughput, and scale effectively
across varying container-to-PU ratios. These findings offer actionable
guidelines for designing safe and efficient container-management systems in
real-world facilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.17055v1' target='_blank'>Data-Driven Optimization of EV Charging Station Placement Using Causal
  Discovery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Julius Stephan Junker, Rong Hu, Ziyue Li, Wolfgang Ketter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 11:15:02</h6>
<p class='card-text'>This paper addresses the critical challenge of optimizing electric vehicle
charging station placement through a novel data-driven methodology employing
causal discovery techniques. While traditional approaches prioritize economic
factors or power grid constraints, they often neglect empirical charging
patterns that ultimately determine station utilization. We analyze extensive
charging data from Palo Alto and Boulder (337,344 events across 100 stations)
to uncover latent relationships between station characteristics and
utilization. Applying structural learning algorithms (NOTEARS and DAGMA) to
this data reveals that charging demand is primarily determined by three
factors: proximity to amenities, EV registration density, and adjacency to
high-traffic routes. These findings, consistent across multiple algorithms and
urban contexts, challenge conventional infrastructure distribution strategies.
We develop an optimization framework that translates these insights into
actionable placement recommendations, identifying locations likely to
experience high utilization based on the discovered dependency structures. The
resulting site selection model prioritizes strategic clustering in high-amenity
areas with substantial EV populations rather than uniform spatial distribution.
Our approach contributes a framework that integrates empirical charging
behavior into infrastructure planning, potentially enhancing both station
utilization and user convenience. By focusing on data-driven insights instead
of theoretical distribution models, we provide a more effective strategy for
expanding charging networks that can adjust to various stages of EV market
development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16993v1' target='_blank'>HEAPO -- An Open Dataset for Heat Pump Optimization with Smart
  Electricity Meter Data and On-Site Inspection Protocols</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tobias Brudermueller, Elgar Fleisch, Marina González Vayá, Thorsten Staake</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 09:58:01</h6>
<p class='card-text'>Heat pumps are essential for decarbonizing residential heating but consume
substantial electrical energy, impacting operational costs and grid demand.
Many systems run inefficiently due to planning flaws, operational faults, or
misconfigurations. While optimizing performance requires skilled professionals,
labor shortages hinder large-scale interventions. However, digital tools and
improved data availability create new service opportunities for energy
efficiency, predictive maintenance, and demand-side management. To support
research and practical solutions, we present an open-source dataset of
electricity consumption from 1,408 households with heat pumps and smart
electricity meters in the canton of Zurich, Switzerland, recorded at 15-minute
and daily resolutions between 2018-11-03 and 2024-03-21. The dataset includes
household metadata, weather data from 8 stations, and ground truth data from
410 field visit protocols collected by energy consultants during system
optimizations. Additionally, the dataset includes a Python-based data loader to
facilitate seamless data processing and exploration.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16874v1' target='_blank'>MARS: A Multi-Agent Framework Incorporating Socratic Guidance for
  Automated Prompt Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jian Zhang, Zhangqi Wang, Haiping Zhu, Jun Liu, Qika Lin, Erik Cambria</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 06:19:55</h6>
<p class='card-text'>The basic question-answering format of large language models involves
inputting a prompt and receiving a response, and the quality of the prompt
directly impacts the effectiveness of the response. Automated Prompt
Optimization (APO) aims to break free from the cognitive biases of manually
designed prompts and explores a broader design space for prompts. However,
existing APO methods suffer from limited flexibility of fixed templates and
inefficient search in prompt spaces as key issues. To this end, we propose a
Multi-Agent framework Incorporating Socratic guidance (MARS), which utilizes
multi-agent fusion technology for automatic planning, with gradual continuous
optimization and evaluation. Specifically, MARS comprises seven agents, each
with distinct functionalities, which autonomously use the Planner to devise an
optimization path that ensures flexibility. Additionally, it employs a
Teacher-Critic-Student Socratic dialogue pattern to iteratively optimize the
prompts while conducting effective search. We conduct extensive experiments on
various datasets to validate the effectiveness of our method, and perform
additional analytical experiments to assess the model's advancement as well as
the interpretability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16806v1' target='_blank'>DyWA: Dynamics-adaptive World Action Model for Generalizable
  Non-prehensile Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiangran Lyu, Ziming Li, Xuesong Shi, Chaoyi Xu, Yizhou Wang, He Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 02:29:52</h6>
<p class='card-text'>Nonprehensile manipulation is crucial for handling objects that are too thin,
large, or otherwise ungraspable in unstructured environments. While
conventional planning-based approaches struggle with complex contact modeling,
learning-based methods have recently emerged as a promising alternative.
However, existing learning-based approaches face two major limitations: they
heavily rely on multi-view cameras and precise pose tracking, and they fail to
generalize across varying physical conditions, such as changes in object mass
and table friction. To address these challenges, we propose the
Dynamics-Adaptive World Action Model (DyWA), a novel framework that enhances
action learning by jointly predicting future states while adapting to dynamics
variations based on historical trajectories. By unifying the modeling of
geometry, state, physics, and robot actions, DyWA enables more robust policy
learning under partial observability. Compared to baselines, our method
improves the success rate by 31.5% using only single-view point cloud
observations in the simulation. Furthermore, DyWA achieves an average success
rate of 68% in real-world experiments, demonstrating its ability to generalize
across diverse object geometries, adapt to varying table friction, and
robustness in challenging scenarios such as half-filled water bottles and
slippery surfaces.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16776v1' target='_blank'>OpenCity3D: What do Vision-Language Models know about Urban
  Environments?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Valentin Bieri, Marco Zamboni, Nicolas S. Blumer, Qingxuan Chen, Francis Engelmann</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-21 01:11:21</h6>
<p class='card-text'>Vision-language models (VLMs) show great promise for 3D scene understanding
but are mainly applied to indoor spaces or autonomous driving, focusing on
low-level tasks like segmentation. This work expands their use to urban-scale
environments by leveraging 3D reconstructions from multi-view aerial imagery.
We propose OpenCity3D, an approach that addresses high-level tasks, such as
population density estimation, building age classification, property price
prediction, crime rate assessment, and noise pollution evaluation. Our findings
highlight OpenCity3D's impressive zero-shot and few-shot capabilities,
showcasing adaptability to new contexts. This research establishes a new
paradigm for language-driven urban analytics, enabling applications in
planning, policy, and environmental monitoring. See our project page:
opencity3d.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16715v1' target='_blank'>Ground and Flight Locomotion for Two-Wheeled Drones via Model Predictive
  Path Integral Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gosuke Kojima, Kohei Honda, Satoshi Nakano, Manabu Yamada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 21:28:36</h6>
<p class='card-text'>This paper presents a novel approach to motion planning for two-wheeled
drones that can drive on the ground and fly in the air. Conventional methods
for two-wheeled drone motion planning typically rely on gradient-based
optimization and assume that obstacle shapes can be approximated by a
differentiable form. To overcome this limitation, we propose a motion planning
method based on Model Predictive Path Integral (MPPI) control, enabling
navigation through arbitrarily shaped obstacles by switching between driving
and flight modes. To handle the instability and rapid solution changes caused
by mode switching, our proposed method switches the control space and utilizes
the auxiliary controller for MPPI. Our simulation results demonstrate that the
proposed method enables navigation in unstructured environments and achieves
effective obstacle avoidance through mode switching.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16676v1' target='_blank'>Simulating foot-and-mouth dynamics and control in Bolivia</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicolas C. Cardenas, Diego Viali dos Santos, Daniel Magalhaaes Lima, Hernan Oliver Daza Gutierrez, Daniel Rodney Gareca Vaca, Gustavo Machado</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 19:49:29</h6>
<p class='card-text'>Examining the dissemination dynamics of foot-and-mouth disease (FMD) is
critical for revising national response plans. We developed a stochastic SEIR
metapopulation model to simulate FMD outbreaks in Bolivia and explore how the
national response plan impacts the dissemination among all susceptible species.
We explored variations in the control strategies, mapped high-risk areas, and
estimated the number of vaccinated animals during the reactive ring
vaccination. Initial outbreaks ranged from 1 to 357 infected farms, with
control measures implemented for up to 100 days, including control zones, a
30-day movement ban, depopulation, and ring vaccination. Combining vaccination
(50-90 farms/day) and depopulation (1-2 farms/day) controlled 60.3% of
outbreaks, while similar vaccination but higher depopulation rates (3-5
farms/day) controlled 62.9% and eliminated outbreaks nine days faster.
Utilizing depopulation alone controlled 56.76% of outbreaks, but had a
significantly longer median duration of 63 days. Combining vaccination (25-45
farms/day) and depopulation (6-7 farms/day) was the most effective, eliminating
all outbreaks within a median of three days (maximum 79 days). Vaccination
alone controlled only 0.6% of outbreaks and had a median duration of 98 days.
Ultimately, results showed that the most effective strategy involved ring
vaccination combined with depopulation, requiring a median of 925,338 animals
to be vaccinated. Outbreaks were most frequent in high-density farming areas
such as Potosi, Cochabamba, and La Paz. Our results suggest that emergency ring
vaccination alone can not eliminate FMD if reintroduced in Bolivia, and
combining depopulation with vaccination significantly shortens outbreak
duration. These findings provide valuable insights to inform Bolivia national
FMD response plan, including vaccine requirements and the role of depopulation
in controlling outbreaks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16634v1' target='_blank'>A Schwarz-Christoffel Mapping-based Framework for Sim-to-Real Transfer
  in Autonomous Robot Operations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shijie Gao, Nicola Bezzo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 18:37:21</h6>
<p class='card-text'>Despite the remarkable acceleration of robotic development through advanced
simulation technology, robotic applications are often subject to performance
reductions in real-world deployment due to the inherent discrepancy between
simulation and reality, often referred to as the "sim-to-real gap". This gap
arises from factors like model inaccuracies, environmental variations, and
unexpected disturbances. Similarly, model discrepancies caused by system
degradation over time or minor changes in the system's configuration also
hinder the effectiveness of the developed methodologies. Effectively closing
these gaps is critical and remains an open challenge. This work proposes a
lightweight conformal mapping framework to transfer control and planning
policies from an expert teacher to a degraded less capable learner. The method
leverages Schwarz-Christoffel Mapping (SCM) to geometrically map teacher
control inputs into the learner's command space, ensuring maneuver consistency.
To demonstrate its generality, the framework is applied to two representative
types of control and planning methods in a path-tracking task: 1) a discretized
motion primitives command transfer and 2) a continuous Model Predictive Control
(MPC)-based command transfer. The proposed framework is validated through
extensive simulations and real-world experiments, demonstrating its
effectiveness in reducing the sim-to-real gap by closely transferring teacher
commands to the learner robot.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16613v1' target='_blank'>Informative Path Planning to Explore and Map Unknown Planetary Surfaces
  with Gaussian Processes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ashten Akemoto, Frances Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 18:10:13</h6>
<p class='card-text'>Many environments, such as unvisited planetary surfaces and oceanic regions,
remain unexplored due to a lack of prior knowledge. Autonomous vehicles must
sample upon arrival, process data, and either transmit findings to a
teleoperator or decide where to explore next. Teleoperation is suboptimal, as
human intuition lacks mathematical guarantees for optimality. This study
evaluates an informative path planning algorithm for mapping a scalar variable
distribution while minimizing travel distance and ensuring model convergence.
We compare traditional open loop coverage methods (e.g., Boustrophedon, Spiral)
with information-theoretic approaches using Gaussian processes, which update
models iteratively with confidence metrics. The algorithm's performance is
tested on three surfaces, a parabola, Townsend function, and lunar crater
hydration map, to assess noise, convexity, and function behavior. Results
demonstrate that information-driven methods significantly outperform naive
exploration in reducing model error and travel distance while improving
convergence potential.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16309v1' target='_blank'>Rapid patient-specific neural networks for intraoperative X-ray to
  volume registration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vivek Gopalakrishnan, Neel Dey, David-Dimitris Chlorogiannis, Andrew Abumoussa, Anna M. Larson, Darren B. Orbach, Sarah Frisken, Polina Golland</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 16:33:45</h6>
<p class='card-text'>The integration of artificial intelligence in image-guided interventions
holds transformative potential, promising to extract 3D geometric and
quantitative information from conventional 2D imaging modalities during complex
procedures. Achieving this requires the rapid and precise alignment of 2D
intraoperative images (e.g., X-ray) with 3D preoperative volumes (e.g., CT,
MRI). However, current 2D/3D registration methods fail across the broad
spectrum of procedures dependent on X-ray guidance: traditional optimization
techniques require custom parameter tuning for each subject, whereas neural
networks trained on small datasets do not generalize to new patients or require
labor-intensive manual annotations, increasing clinical burden and precluding
application to new anatomical targets. To address these challenges, we present
xvr, a fully automated framework for training patient-specific neural networks
for 2D/3D registration. xvr uses physics-based simulation to generate abundant
high-quality training data from a patient's own preoperative volumetric
imaging, thereby overcoming the inherently limited ability of supervised models
to generalize to new patients and procedures. Furthermore, xvr requires only 5
minutes of training per patient, making it suitable for emergency interventions
as well as planned procedures. We perform the largest evaluation of a 2D/3D
registration algorithm on real X-ray data to date and find that xvr robustly
generalizes across a diverse dataset comprising multiple anatomical structures,
imaging modalities, and hospitals. Across surgical tasks, xvr achieves
submillimeter-accurate registration at intraoperative speeds, improving upon
existing methods by an order of magnitude. xvr is released as open-source
software freely available at https://github.com/eigenvivek/xvr.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16275v1' target='_blank'>Loop Closure from Two Views: Revisiting PGO for Scalable Trajectory
  Estimation through Monocular Priors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tian Yi Lim, Boyang Sun, Marc Pollefeys, Hermann Blum</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 16:05:35</h6>
<p class='card-text'>(Visual) Simultaneous Localization and Mapping (SLAM) remains a fundamental
challenge in enabling autonomous systems to navigate and understand large-scale
environments. Traditional SLAM approaches struggle to balance efficiency and
accuracy, particularly in large-scale settings where extensive computational
resources are required for scene reconstruction and Bundle Adjustment (BA).
However, this scene reconstruction, in the form of sparse pointclouds of visual
landmarks, is often only used within the SLAM system because navigation and
planning methods require different map representations. In this work, we
therefore investigate a more scalable Visual SLAM (VSLAM) approach without
reconstruction, mainly based on approaches for two-view loop closures. By
restricting the map to a sparse keyframed pose graph without dense geometry
representations, our '2GO' system achieves efficient optimization with
competitive absolute trajectory accuracy. In particular, we find that recent
advancements in image matching and monocular depth priors enable very accurate
trajectory optimization from two-view edges. We conduct extensive experiments
on diverse datasets, including large-scale scenarios, and provide a detailed
analysis of the trade-offs between runtime, accuracy, and map size. Our results
demonstrate that this streamlined approach supports real-time performance,
scales well in map size and trajectory duration, and effectively broadens the
capabilities of VSLAM for long-duration deployments to large environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16164v1' target='_blank'>Asymptotically Optimal Path Planning With an Approximation of the
  Omniscient Set</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonáš Kříž, Vojtěch Vonásek</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 14:04:55</h6>
<p class='card-text'>The asymptotically optimal version of Rapidly-exploring Random Tree (RRT*) is
often used to find optimal paths in a high-dimensional configuration space. The
well-known issue of RRT* is its slow convergence towards the optimal solution.
A possible solution is to draw random samples only from a subset of the
configuration space that is known to contain configurations that can improve
the cost of the path (omniscient set). A fast convergence rate may be achieved
by approximating the omniscient with a low-volume set. In this letter, we
propose new methods to approximate the omniscient set and methods for their
effective sampling. First, we propose to approximate the omniscient set using
several (small) hyperellipsoids defined by sections of the current best
solution. The second approach approximates the omniscient set by a convex hull
computed from the current solution. Both approaches ensure asymptotical
optimality and work in a general n-dimensional configuration space. The
experiments have shown superior performance of our approaches in multiple
scenarios in 3D and 6D configuration spaces.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.16058v1' target='_blank'>Landmarks Are Alike Yet Distinct: Harnessing Similarity and
  Individuality for One-Shot Medical Landmark Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xu He, Zhen Huang, Qingsong Yao, Xiaoqian Zhou, S. Kevin Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 11:46:29</h6>
<p class='card-text'>Landmark detection plays a crucial role in medical imaging applications such
as disease diagnosis, bone age estimation, and therapy planning. However,
training models for detecting multiple landmarks simultaneously often
encounters the "seesaw phenomenon", where improvements in detecting certain
landmarks lead to declines in detecting others. Yet, training a separate model
for each landmark increases memory usage and computational overhead. To address
these challenges, we propose a novel approach based on the belief that
"landmarks are distinct" by training models with pseudo-labels and template
data updated continuously during the training process, where each model is
dedicated to detecting a single landmark to achieve high accuracy. Furthermore,
grounded on the belief that "landmarks are also alike", we introduce an
adapter-based fusion model, combining shared weights with landmark-specific
weights, to efficiently share model parameters while allowing flexible
adaptation to individual landmarks. This approach not only significantly
reduces memory and computational resource requirements but also effectively
mitigates the seesaw phenomenon in multi-landmark training. Experimental
results on publicly available medical image datasets demonstrate that the
single-landmark models significantly outperform traditional multi-point joint
training models in detecting individual landmarks. Although our adapter-based
fusion model shows slightly lower performance compared to the combined results
of all single-landmark models, it still surpasses the current state-of-the-art
methods while achieving a notable improvement in resource efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15910v1' target='_blank'>No Thing, Nothing: Highlighting Safety-Critical Classes for Robust LiDAR
  Semantic Segmentation in Adverse Weather</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junsung Park, Hwijeong Lee, Inha Kang, Hyunjung Shim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 07:40:24</h6>
<p class='card-text'>Existing domain generalization methods for LiDAR semantic segmentation under
adverse weather struggle to accurately predict "things" categories compared to
"stuff" categories. In typical driving scenes, "things" categories can be
dynamic and associated with higher collision risks, making them crucial for
safe navigation and planning. Recognizing the importance of "things"
categories, we identify their performance drop as a serious bottleneck in
existing approaches. We observed that adverse weather induces degradation of
semantic-level features and both corruption of local features, leading to a
misprediction of "things" as "stuff". To mitigate these corruptions, we suggest
our method, NTN - segmeNt Things for No-accident. To address semantic-level
feature corruption, we bind each point feature to its superclass, preventing
the misprediction of things classes into visually dissimilar categories.
Additionally, to enhance robustness against local corruption caused by adverse
weather, we define each LiDAR beam as a local region and propose a
regularization term that aligns the clean data with its corrupted counterpart
in feature space. NTN achieves state-of-the-art performance with a +2.6 mIoU
gain on the SemanticKITTI-to-SemanticSTF benchmark and +7.9 mIoU on the
SemanticPOSS-to-SemanticSTF benchmark. Notably, NTN achieves a +4.8 and +7.9
mIoU improvement on "things" classes, respectively, highlighting its
effectiveness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15865v1' target='_blank'>Active management of battery degradation in wireless sensor network
  using deep reinforcement learning for group battery replacement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jong-Hyun Jeonga, Hongki Jo, Qiang Zhou, Tahsin Afroz Hoque Nishat, Lang Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 05:36:33</h6>
<p class='card-text'>Wireless sensor networks (WSNs) have become a promising solution for
structural health monitoring (SHM), especially in hard-to-reach or remote
locations. Battery-powered WSNs offer various advantages over wired systems,
however limited battery life has always been one of the biggest obstacles in
practical use of the WSNs, regardless of energy harvesting methods. While
various methods have been studied for battery health management, existing
methods exclusively aim to extend lifetime of individual batteries, lacking a
system level view. A consequence of applying such methods is that batteries in
a WSN tend to fail at different times, posing significant difficulty on
planning and scheduling of battery replacement trip. This study investigate a
deep reinforcement learning (DRL) method for active battery degradation
management by optimizing duty cycle of WSNs at the system level. This active
management strategy effectively reduces earlier failure of battery individuals
which enable group replacement without sacrificing WSN performances. A
simulated environment based on a real-world WSN setup was developed to train a
DRL agent and learn optimal duty cycle strategies. The performance of the
strategy was validated in a long-term setup with various network sizes,
demonstrating its efficiency and scalability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15836v1' target='_blank'>APEX-MR: Multi-Robot Asynchronous Planning and Execution for Cooperative
  Assembly</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Philip Huang, Ruixuan Liu, Changliu Liu, Jiaoyang Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 04:25:38</h6>
<p class='card-text'>Compared to a single-robot workstation, a multi-robot system offers several
advantages: 1) it expands the system's workspace, 2) improves task efficiency,
and more importantly, 3) enables robots to achieve significantly more complex
and dexterous tasks, such as cooperative assembly. However, coordinating the
tasks and motions of multiple robots is challenging due to issues, e.g. system
uncertainty, task efficiency, algorithm scalability, and safety concerns. To
address these challenges, this paper studies multi-robot coordination and
proposes APEX-MR, an asynchronous planning and execution framework designed to
safely and efficiently coordinate multiple robots to achieve cooperative
assembly, e.g. LEGO assembly. In particular, APEX-MR provides a systematic
approach to post-process multi-robot tasks and motion plans to enable robust
asynchronous execution under uncertainty. Experimental results demonstrate that
APEX-MR can significantly speed up the execution time of many long-horizon LEGO
assembly tasks by 48% compared to sequential planning and 36% compared to
synchronous planning on average. To further demonstrate the performance, we
deploy APEX-MR to a dual-arm system to perform physical LEGO assembly. To our
knowledge, this is the first robotic system capable of performing customized
LEGO assembly using commercial LEGO bricks. The experiment results demonstrate
that the dual-arm system, with APEX-MR, can safely coordinate robot motions,
efficiently collaborate, and construct complex LEGO structures. Our project
website is available at https://intelligent-control-lab.github.io/APEX-MR/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15779v1' target='_blank'>MobiFuse: Learning Universal Human Mobility Patterns through
  Cross-domain Data Fusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoxuan Ma, Xishun Liao, Yifan Liu, Qinhua Jiang, Chris Stanford, Shangqing Cao, Jiaqi Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-20 01:41:28</h6>
<p class='card-text'>Human mobility modeling is critical for urban planning and transportation
management, yet existing datasets often lack the resolution and semantic
richness required for comprehensive analysis. To address this, we proposed a
cross-domain data fusion framework that integrates multi-modal data of distinct
nature and spatio-temporal resolution, including geographical, mobility,
socio-demographic, and traffic information, to construct a privacy-preserving
and semantically enriched human travel trajectory dataset. This framework is
demonstrated through two case studies in Los Angeles (LA) and Egypt, where a
domain adaptation algorithm ensures its transferability across diverse urban
contexts. Quantitative evaluation shows that the generated synthetic dataset
accurately reproduces mobility patterns observed in empirical data. Moreover,
large-scale traffic simulations for LA County based on the generated synthetic
demand align well with observed traffic. On California's I-405 corridor, the
simulation yields a Mean Absolute Percentage Error of 5.85% for traffic volume
and 4.36% for speed compared to Caltrans PeMS observations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15715v1' target='_blank'>Experience-based Optimal Motion Planning Algorithm for Solving Difficult
  Planning Problems Using a Limited Dataset</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ryota Takamido, Jun Ota</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 21:52:18</h6>
<p class='card-text'>This study aims to address the key challenge of obtaining a high-quality
solution path within a short calculation time by generalizing a limited
dataset. In the informed experience-driven random trees connect star (IERTC*)
process, the algorithm flexibly explores the search trees by morphing the micro
paths generated from a single experience while reducing the path cost by
introducing a re-wiring process and an informed sampling process. The core idea
of this algorithm is to apply different strategies depending on the complexity
of the local environment; for example, it adopts a more complex curved
trajectory if obstacles are densely arranged near the search tree, and it
adopts a simpler straight line if the local environment is sparse. The results
of experiments using a general motion benchmark test revealed that IERTC*
significantly improved the planning success rate in difficult problems in the
cluttered environment (an average improvement of 49.3% compared to the
state-of-the-art algorithm) while also significantly reducing the solution cost
(a reduction of 56.3%) when using one hundred experiences. Furthermore, the
results demonstrated outstanding planning performance even when only one
experience was available (a 43.8% improvement in success rate and a 57.8%
reduction in solution cost).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15708v1' target='_blank'>Sustainable Deep Learning-Based Breast Lesion Segmentation: Impact of
  Breast Region Segmentation on Performance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sam Narimani, Solveig Roth Hoff, Kathinka Dahli Kurz, Kjell-Inge Gjesdal, Jurgen Geisler, Endre Grovik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 21:42:33</h6>
<p class='card-text'>Purpose: Segmentation of the breast lesion in dynamic contrast-enhanced
magnetic resonance imaging (DCE-MRI) is an essential step to accurately
diagnose and plan treatment and monitor progress. This study aims to highlight
the impact of breast region segmentation (BRS) on deep learning-based breast
lesion segmentation (BLS) in breast DCE-MRI.
  Methods Using the Stavanger Dataset containing primarily 59 DCE-MRI scans and
UNet++ as deep learning models, four different process were conducted to
compare effect of BRS on BLS. These four approaches included the whole volume
without BRS and with BRS, BRS with the selected lesion slices and lastly
optimal volume with BRS. Preprocessing methods like augmentation and
oversampling were used to enhance the small dataset, data shape uniformity and
improve model performance. Optimal volume size were investigated by a precise
process to ensure that all lesions existed in slices. To evaluate the model, a
hybrid loss function including dice, focal and cross entropy along with 5-fold
cross validation method were used and lastly a test dataset which was randomly
split used to evaluate the model performance on unseen data for each of four
mentioned approaches.
  Results Results demonstrate that using BRS considerably improved model
performance and validation. Significant improvement in last approach -- optimal
volume with BRS -- compared to the approach without BRS counting around 50
percent demonstrating how effective BRS has been in BLS. Moreover, huge
improvement in energy consumption, decreasing up to 450 percent, introduces a
green solution toward a more environmentally sustainable approach for future
work on large dataset.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15678v1' target='_blank'>Cyber Threats in Financial Transactions -- Addressing the Dual Challenge
  of AI and Quantum Computing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ahmed M. Elmisery, Mirela Sertovic, Andrew Zayin, Paul Watson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 20:16:27</h6>
<p class='card-text'>The financial sector faces escalating cyber threats amplified by artificial
intelligence (AI) and the advent of quantum computing. AI is being weaponized
for sophisticated attacks like deepfakes and AI-driven malware, while quantum
computing threatens to render current encryption methods obsolete. This report
analyzes these threats, relevant frameworks, and possible countermeasures like
quantum cryptography. AI enhances social engineering and phishing attacks via
personalized content, lowers entry barriers for cybercriminals, and introduces
risks like data poisoning and adversarial AI. Quantum computing, particularly
Shor's algorithm, poses a fundamental threat to current encryption standards
(RSA and ECC), with estimates suggesting cryptographically relevant quantum
computers could emerge within the next 5-30 years. The "harvest now, decrypt
later" scenario highlights the urgency of transitioning to quantum-resistant
cryptography. This is key. Existing legal frameworks are evolving to address AI
in cybercrime, but quantum threats require new initiatives. International
cooperation and harmonized regulations are crucial. Quantum Key Distribution
(QKD) offers theoretical security but faces practical limitations. Post-quantum
cryptography (PQC) is a promising alternative, with ongoing standardization
efforts. Recommendations for international regulators include fostering
collaboration and information sharing, establishing global standards,
supporting research and development in quantum security, harmonizing legal
frameworks, promoting cryptographic agility, and raising awareness and
education. The financial industry must adopt a proactive and adaptive approach
to cybersecurity, investing in research, developing migration plans for
quantum-resistant cryptography, and embracing a multi-faceted, collaborative
strategy to build a resilient, quantum-safe, and AI-resilient financial
ecosystem</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15407v1' target='_blank'>Exploiting Prior Knowledge in Preferential Learning of Individualized
  Autonomous Vehicle Driving Styles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lukas Theiner, Sebastian Hirt, Alexander Steinke, Rolf Findeisen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 16:47:56</h6>
<p class='card-text'>Trajectory planning for automated vehicles commonly employs optimization over
a moving horizon - Model Predictive Control - where the cost function
critically influences the resulting driving style. However, finding a suitable
cost function that results in a driving style preferred by passengers remains
an ongoing challenge. We employ preferential Bayesian optimization to learn the
cost function by iteratively querying a passenger's preference. Due to
increasing dimensionality of the parameter space, preference learning
approaches might struggle to find a suitable optimum with a limited number of
experiments and expose the passenger to discomfort when exploring the parameter
space. We address these challenges by incorporating prior knowledge into the
preferential Bayesian optimization framework. Our method constructs a virtual
decision maker from real-world human driving data to guide parameter sampling.
In a simulation experiment, we achieve faster convergence of the
prior-knowledge-informed learning procedure compared to existing preferential
Bayesian optimization approaches and reduce the number of inadequate driving
styles sampled.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15394v1' target='_blank'>Advancing MG Energy Management: A Rolling Horizon Optimization Framework
  for Three-Phase Unbalanced Networks Integrating Convex Formulations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pablo Cortés, Alejandra Tabares, Fredy Franco</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 16:34:49</h6>
<p class='card-text'>Real-world three-phase microgrids face two interconnected challenges: 1.
time-varying uncertainty from renewable generation and demand, and 2.
persistent phase imbalances caused by uneven distributed energy resources DERs,
load asymmetries, and grid faults. Conventional energy management systems fail
to address these challenges holistically and static optimization methods lack
adaptability to real-time fluctuations, while balanced three-phase models
ignore critical asymmetries that degrade voltage stability and efficiency. This
work introduces a dynamic rolling horizon optimization framework specifically
designed for unbalanced three-phase microgrids. Unlike traditional two-stage
stochastic approaches that fix decisions for the entire horizon, the rolling
horizon algorithm iteratively updates decisions in response to real-time data.
By solving a sequence of shorter optimization windows, each incorporating the
latest system state and forecasts, the method achieves three key advantages:
Adaptive Uncertainty Handling by continuously re plans operations to mitigate
forecast errors. Phase Imbalance Correction by dynamically adjusts power flows
across phases to minimize voltage deviations and losses caused by asymmetries,
and computational Tractability, i.e., shorter optimization windows, combined
with the mathematical mhodel, enable better decision making holding accuracy.
For comparison purposes, we derive three optimization models: a nonlinear
nonconvex model for high-fidelity offline planning, a convex quadratic
approximation for day-ahead scheduling, and a linearized model to important for
theoretical reasons such as decomposition algorithms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15290v1' target='_blank'>Reinforcement Learning for Robust Athletic Intelligence: Lessons from
  the 2nd 'AI Olympics with RealAIGym' Competition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Felix Wiebe, Niccolò Turcato, Alberto Dalla Libera, Jean Seong Bjorn Choe, Bumkyu Choi, Tim Lukas Faust, Habib Maraqten, Erfan Aghadavoodi, Marco Cali, Alberto Sinigaglia, Giulio Giacomuzzo, Diego Romeres, Jong-kook Kim, Gian Antonio Susto, Shubham Vyas, Dennis Mronga, Boris Belousov, Jan Peters, Frank Kirchner, Shivesh Kumar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 15:10:02</h6>
<p class='card-text'>In the field of robotics many different approaches ranging from classical
planning over optimal control to reinforcement learning (RL) are developed and
borrowed from other fields to achieve reliable control in diverse tasks. In
order to get a clear understanding of their individual strengths and weaknesses
and their applicability in real world robotic scenarios is it important to
benchmark and compare their performances not only in a simulation but also on
real hardware. The '2nd AI Olympics with RealAIGym' competition was held at the
IROS 2024 conference to contribute to this cause and evaluate different
controllers according to their ability to solve a dynamic control problem on an
underactuated double pendulum system with chaotic dynamics. This paper
describes the four different RL methods submitted by the participating teams,
presents their performance in the swing-up task on a real double pendulum,
measured against various criteria, and discusses their transferability from
simulation to real hardware and their robustness to external disturbances.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15273v1' target='_blank'>Perception-aware Planning for Quadrotor Flight in Unknown and
  Feature-limited Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenxin Yu, Zihong Lu, Jie Mei, Boyu Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 14:47:44</h6>
<p class='card-text'>Various studies on perception-aware planning have been proposed to enhance
the state estimation accuracy of quadrotors in visually degraded environments.
However, many existing methods heavily rely on prior environmental knowledge
and face significant limitations in previously unknown environments with sparse
localization features, which greatly limits their practical application. In
this paper, we present a perception-aware planning method for quadrotor flight
in unknown and feature-limited environments that properly allocates perception
resources among environmental information during navigation. We introduce a
viewpoint transition graph that allows for the adaptive selection of local
target viewpoints, which guide the quadrotor to efficiently navigate to the
goal while maintaining sufficient localizability and without being trapped in
feature-limited regions. During the local planning, a novel yaw trajectory
generation method that simultaneously considers exploration capability and
localizability is presented. It constructs a localizable corridor via feature
co-visibility evaluation to ensure localization robustness in a computationally
efficient way. Through validations conducted in both simulation and real-world
experiments, we demonstrate the feasibility and real-time performance of the
proposed method. The source code will be released to benefit the community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15208v1' target='_blank'>DiST-4D: Disentangled Spatiotemporal Diffusion with Metric Depth for 4D
  Driving Scene Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiazhe Guo, Yikang Ding, Xiwu Chen, Shuo Chen, Bohan Li, Yingshuang Zou, Xiaoyang Lyu, Feiyang Tan, Xiaojuan Qi, Zhiheng Li, Hao Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 13:49:48</h6>
<p class='card-text'>Current generative models struggle to synthesize dynamic 4D driving scenes
that simultaneously support temporal extrapolation and spatial novel view
synthesis (NVS) without per-scene optimization. A key challenge lies in finding
an efficient and generalizable geometric representation that seamlessly
connects temporal and spatial synthesis. To address this, we propose DiST-4D,
the first disentangled spatiotemporal diffusion framework for 4D driving scene
generation, which leverages metric depth as the core geometric representation.
DiST-4D decomposes the problem into two diffusion processes: DiST-T, which
predicts future metric depth and multi-view RGB sequences directly from past
observations, and DiST-S, which enables spatial NVS by training only on
existing viewpoints while enforcing cycle consistency. This cycle consistency
mechanism introduces a forward-backward rendering constraint, reducing the
generalization gap between observed and unseen viewpoints. Metric depth is
essential for both accurate reliable forecasting and accurate spatial NVS, as
it provides a view-consistent geometric representation that generalizes well to
unseen perspectives. Experiments demonstrate that DiST-4D achieves
state-of-the-art performance in both temporal prediction and NVS tasks, while
also delivering competitive performance in planning-related evaluations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2503.15575v2' target='_blank'>NuPECC Long Range Plan 2024 for European Nuclear Physics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:NuPECC</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-03-19 13:09:39</h6>
<p class='card-text'>The Nuclear Physics European Collaboration Committee ( NuPECC,
http://nupecc.org/ ) hosted by the European Science Foundation represents today
a large nuclear physics community from 23 countries, 3 ESFRI (European Strategy
Forum for Research Infrastructures) nuclear physics infrastructures and ECT*
(European Centre for Theoretical Studies in Nuclear Physics and Related Areas),
as well as from 4 associated members and 10 observers.
  As stated in the NuPECC Terms of Reference one of the major objectives of the
Committee is: "on a regular basis, the Committee shall organise a consultation
of the community leading to the definition and publication of a Long Range Plan
(LRP) of European nuclear physics". To this end, NuPECC has in the past
produced five LRPs: in November 1991, December 1997, April 2004, December 2010,
and November 2017.
  The LRP, being the unique document covering the whole nuclear physics
landscape in Europe, identifies opportunities and priorities for nuclear
science in Europe and provides national funding agencies, ESFRI, and the
European Commission with a framework for coordinated advances in nuclear
science. It serves also as a reference document for the strategic plans for
nuclear physics in the European countries.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>