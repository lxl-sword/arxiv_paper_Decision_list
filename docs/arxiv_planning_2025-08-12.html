<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-08-12</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-08-12</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.08240v1' target='_blank'>ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for
  Long-Horizon Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaijun Wang, Liqin Lu, Mingyu Liu, Jianuo Jiang, Zeju Li, Bolin Zhang, Wancai Zheng, Xinyi Yu, Hao Chen, Chunhua Shen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 17:54:31</h6>
<p class='card-text'>Language-guided long-horizon mobile manipulation has long been a grand
challenge in embodied semantic reasoning, generalizable manipulation, and
adaptive locomotion. Three fundamental limitations hinder progress: First,
although large language models have improved spatial reasoning and task
planning through semantic priors, existing implementations remain confined to
tabletop scenarios, failing to address the constrained perception and limited
actuation ranges of mobile platforms. Second, current manipulation strategies
exhibit insufficient generalization when confronted with the diverse object
configurations encountered in open-world environments. Third, while crucial for
practical deployment, the dual requirement of maintaining high platform
maneuverability alongside precise end-effector control in unstructured settings
remains understudied.
  In this work, we present ODYSSEY, a unified mobile manipulation framework for
agile quadruped robots equipped with manipulators, which seamlessly integrates
high-level task planning with low-level whole-body control. To address the
challenge of egocentric perception in language-conditioned tasks, we introduce
a hierarchical planner powered by a vision-language model, enabling
long-horizon instruction decomposition and precise action execution. At the
control level, our novel whole-body policy achieves robust coordination across
challenging terrains. We further present the first benchmark for long-horizon
mobile manipulation, evaluating diverse indoor and outdoor scenarios. Through
successful sim-to-real transfer, we demonstrate the system's generalization and
robustness in real-world deployments, underscoring the practicality of legged
manipulators in unstructured environments. Our work advances the feasibility of
generalized robotic assistants capable of complex, dynamic tasks. Our project
page: https://kaijwang.github.io/odyssey.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.08216v1' target='_blank'>Cross-Subject and Cross-Montage EEG Transfer Learning via Individual
  Tangent Space Alignment and Spatial-Riemannian Feature Fusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicole Lai-Tan, Xiao Gu, Marios G. Philiastides, Fani Deligianni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 17:37:17</h6>
<p class='card-text'>Personalised music-based interventions offer a powerful means of supporting
motor rehabilitation by dynamically tailoring auditory stimuli to provide
external timekeeping cues, modulate affective states, and stabilise gait
patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for
adapting these interventions across individuals. However, inter-subject
variability in EEG signals, further compounded by movement-induced artefacts
and motor planning differences, hinders the generalisability of BCIs and
results in lengthy calibration processes. We propose Individual Tangent Space
Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific
recentering, distribution matching, and supervised rotational alignment to
enhance cross-subject generalisation. Our hybrid architecture fuses Regularised
Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and
sequential configurations, improving class separability while maintaining the
geometric structure of covariance matrices for robust statistical computation.
Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant
performance improvements across subjects and conditions. The parallel fusion
approach shows the greatest enhancement over its sequential counterpart, with
robust performance maintained across varying data conditions and electrode
configurations. The code will be made publicly available at the time of
publication.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.08177v1' target='_blank'>MedReasoner: Reinforcement Learning Drives Reasoning Grounding from
  Clinical Thought to Pixel-Level Precision</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhonghao Yan, Muxi Diao, Yuxuan Yang, Jiayuan Xu, Kaizhou Zhang, Ruoyan Jing, Lele Yang, Yanxi Liu, Kongming Liang, Zhanyu Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 16:59:06</h6>
<p class='card-text'>Accurately grounding regions of interest (ROIs) is critical for diagnosis and
treatment planning in medical imaging. While multimodal large language models
(MLLMs) combine visual perception with natural language, current
medical-grounding pipelines still rely on supervised fine-tuning with explicit
spatial hints, making them ill-equipped to handle the implicit queries common
in clinical practice. This work makes three core contributions. We first define
Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that
demands clinical reasoning and pixel-level grounding. Second, we release
U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside
implicit clinical queries and reasoning traces, spanning 10 modalities, 15
super-categories, and 108 specific categories. Finally, we introduce
MedReasoner, a modular framework that distinctly separates reasoning from
segmentation: an MLLM reasoner is optimized with reinforcement learning, while
a frozen segmentation expert converts spatial prompts into masks, with
alignment achieved through format and accuracy rewards. MedReasoner achieves
state-of-the-art performance on U-MRG-14K and demonstrates strong
generalization to unseen clinical queries, underscoring the significant promise
of reinforcement learning for interpretable medical grounding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.08108v1' target='_blank'>Capsizing-Guided Trajectory Optimization for Autonomous Navigation with
  Rough Terrain</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Zhang, Yinchuan Wang, Wangtao Lu, Pengyu Zhang, Xiang Zhang, Yue Wang, Chaoqun Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 15:47:24</h6>
<p class='card-text'>It is a challenging task for ground robots to autonomously navigate in harsh
environments due to the presence of non-trivial obstacles and uneven terrain.
This requires trajectory planning that balances safety and efficiency. The
primary challenge is to generate a feasible trajectory that prevents robot from
tip-over while ensuring effective navigation. In this paper, we propose a
capsizing-aware trajectory planner (CAP) to achieve trajectory planning on the
uneven terrain. The tip-over stability of the robot on rough terrain is
analyzed. Based on the tip-over stability, we define the traversable
orientation, which indicates the safe range of robot orientations. This
orientation is then incorporated into a capsizing-safety constraint for
trajectory optimization. We employ a graph-based solver to compute a robust and
feasible trajectory while adhering to the capsizing-safety constraint.
Extensive simulation and real-world experiments validate the effectiveness and
robustness of the proposed method. The results demonstrate that CAP outperforms
existing state-of-the-art approaches, providing enhanced navigation performance
on uneven terrains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.08063v1' target='_blank'>Flight masks of the Roman Space Telescope Coronagraph Instrument</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:A. J. Eldorado Riggs, Vanessa P. Bailey, Dwight Moody, Kunjithapatham Balasubramanian, Scott A. Basinger, Ruslan Belikov, Eduardo Bendek, John Debes, Brandon D. Dube, Jessica Gersh-Range, Tyler D. Groff, N. Jeremy Kasdin, Bertrand Mennesson, Brian Monacelli, Douglas M. Moore, Garreth Ruane, Jagmit Sandhu, Fang Shi, Erkin Sidick, Nicholas Siegler, Dan Sirbu, John Trauger, Carey L. Weisberg, Victor E. White, Daniel W. Wilson, Robert C. Wilson, Karl Y. Yee, Neil T. Zimmerman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 15:08:23</h6>
<p class='card-text'>Over the past two decades, thousands of confirmed exoplanets have been
detected. The next major challenge is to characterize these other worlds and
their stellar systems. Much information on the composition and formation of
exoplanets and circumstellar debris disks can only be achieved via direct
imaging. Direct imaging is challenging because of the small angular separations
(< 1 arcsec) and high star-to-planet flux ratios such as ~1e9 for a Jupiter
analog or ~1e10 for an Earth analog in the visible. Atmospheric turbulence
prohibits reaching such high flux ratios on the ground, so observations must be
made above the Earth's atmosphere. The Nancy Grace Roman Space Telescope
(Roman), planned to launch in late 2026, will be the first space-based
observatory to demonstrate high-contrast imaging with active wavefront control
using its Coronagraph Instrument. The instrument's main purpose is to mature
the various technologies needed for a future flagship mission to image and
characterize Earth-like exoplanets. These technologies include two
high-actuator-count deformable mirrors, photon-counting detectors, two
complementary wavefront sensing and control loops, and two different
coronagraph types. In this paper, we describe the complete set of flight masks
in the Roman Coronagraph Instrument, their intended combinations, and how they
were laid out, fabricated, and measured.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07917v1' target='_blank'>MolmoAct: Action Reasoning Models that can Reason in Space</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jason Lee, Jiafei Duan, Haoquan Fang, Yuquan Deng, Shuo Liu, Boyang Li, Bohan Fang, Jieyu Zhang, Yi Ru Wang, Sangho Lee, Winson Han, Wilbert Pumacay, Angelica Wu, Rose Hendrix, Karen Farley, Eli VanderBilt, Ali Farhadi, Dieter Fox, Ranjay Krishna</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 12:32:45</h6>
<p class='card-text'>Reasoning is central to purposeful action, yet most robotic foundation models
map perception and instructions directly to control, which limits adaptability,
generalization, and semantic grounding. We introduce Action Reasoning Models
(ARMs), a class of vision-language-action models that integrate perception,
planning, and control through a structured three-stage pipeline. Our model,
MolmoAct, encodes observations and instructions into depth-aware perception
tokens, generates mid-level spatial plans as editable trajectory traces, and
predicts precise low-level actions, enabling explainable and steerable
behavior. MolmoAct-7B-D achieves strong performance across simulation and
real-world settings: 70.5% zero-shot accuracy on SimplerEnv Visual Matching
tasks, surpassing closed-source Pi-0 and GR00T N1; 86.6% average success on
LIBERO, including an additional 6.3% gain over ThinkAct on long-horizon tasks;
and in real-world fine-tuning, an additional 10% (single-arm) and an additional
22.7% (bimanual) task progression over Pi-0-FAST. It also outperforms baselines
by an additional 23.3% on out-of-distribution generalization and achieves top
human-preference scores for open-ended instruction following and trajectory
steering. Furthermore, we release, for the first time, the MolmoAct Dataset --
a mid-training robot dataset comprising over 10,000 high quality robot
trajectories across diverse scenarios and tasks. Training with this dataset
yields an average 5.5% improvement in general performance over the base model.
We release all model weights, training code, our collected dataset, and our
action reasoning dataset, establishing MolmoAct as both a state-of-the-art
robotics foundation model and an open blueprint for building ARMs that
transform perception into purposeful action through structured reasoning.
Blogpost: https://allenai.org/blog/molmoact</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07842v1' target='_blank'>DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of
  Disentangled Experts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yutong Shen, Hangxu Liu, Penghui Liu, Ruizhe Xia, Tianyi Yao, Yitong Sun, Tongtong Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 10:54:28</h6>
<p class='card-text'>Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex
multi-step tasks that require continuous planning, sequential decision-making,
and extended execution across domains to achieve the final goal. However,
existing methods heavily rely on skill chaining by concatenating pre-trained
subtasks, with environment observations and self-state tightly coupled, lacking
the ability to generalize to new combinations of environments and skills,
failing to complete various LH tasks across domains. To solve this problem,
this paper presents DETACH, a cross-domain learning framework for LH tasks via
biologically inspired dual-stream disentanglement. Inspired by the brain's
"where-what" dual pathway mechanism, DETACH comprises two core modules: i) an
environment learning module for spatial understanding, which captures object
functions, spatial relationships, and scene semantics, achieving cross-domain
transfer through complete environment-self disentanglement; ii) a skill
learning module for task execution, which processes self-state information
including joint degrees of freedom and motor patterns, enabling cross-skill
transfer through independent motor pattern encoding. We conducted extensive
experiments on various LH tasks in HSI scenes. Compared with existing methods,
DETACH can achieve an average subtasks success rate improvement of 23% and
average execution efficiency improvement of 29%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07814v1' target='_blank'>SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of
  Heterogeneous Robots in Dynamic Warehousing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Malaika Zafar, Roohan Ahmed Khan, Faryal Batool, Yasheerah Yaqoot, Ziang Guo, Mikhail Litvinov, Aleksey Fedoseev, Dzmitry Tsetserukou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 09:56:33</h6>
<p class='card-text'>With the growing demand for efficient logistics, unmanned aerial vehicles
(UAVs) are increasingly being paired with automated guided vehicles (AGVs).
While UAVs offer the ability to navigate through dense environments and varying
altitudes, they are limited by battery life, payload capacity, and flight
duration, necessitating coordinated ground support.
  Focusing on heterogeneous navigation, SwarmVLM addresses these limitations by
enabling semantic collaboration between UAVs and ground robots through
impedance control. The system leverages the Vision Language Model (VLM) and the
Retrieval-Augmented Generation (RAG) to adjust impedance control parameters in
response to environmental changes. In this framework, the UAV acts as a leader
using Artificial Potential Field (APF) planning for real-time navigation, while
the ground robot follows via virtual impedance links with adaptive link
topology to avoid collisions with short obstacles.
  The system demonstrated a 92% success rate across 12 real-world trials. Under
optimal lighting conditions, the VLM-RAG framework achieved 8% accuracy in
object detection and selection of impedance parameters. The mobile robot
prioritized short obstacle avoidance, occasionally resulting in a lateral
deviation of up to 50 cm from the UAV path, which showcases safe navigation in
a cluttered setting.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07743v1' target='_blank'>Symmetry-Aware Transformer Training for Automated Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Markus Fritzsche, Elliot Gestrin, Jendrik Seipp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 08:23:34</h6>
<p class='card-text'>While transformers excel in many settings, their application in the field of
automated planning is limited. Prior work like PlanGPT, a state-of-the-art
decoder-only transformer, struggles with extrapolation from easy to hard
planning problems. This in turn stems from problem symmetries: planning tasks
can be represented with arbitrary variable names that carry no meaning beyond
being identifiers. This causes a combinatorial explosion of equivalent
representations that pure transformers cannot efficiently learn from. We
propose a novel contrastive learning objective to make transformers
symmetry-aware and thereby compensate for their lack of inductive bias.
Combining this with architectural improvements, we show that transformers can
be efficiently trained for either plan-generation or heuristic-prediction. Our
results across multiple planning domains demonstrate that our symmetry-aware
training effectively and efficiently addresses the limitations of PlanGPT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07686v1' target='_blank'>Risk Map As Middleware: Towards Interpretable Cooperative End-to-end
  Autonomous Driving for Risk-Aware Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingyue Lei, Zewei Zhou, Hongchen Li, Jiaqi Ma, Jia Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 07:00:52</h6>
<p class='card-text'>End-to-end paradigm has emerged as a promising approach to autonomous
driving. However, existing single-agent end-to-end pipelines are often
constrained by occlusion and limited perception range, resulting in hazardous
driving. Furthermore, their black-box nature prevents the interpretability of
the driving behavior, leading to an untrustworthiness system. To address these
limitations, we introduce Risk Map as Middleware (RiskMM) and propose an
interpretable cooperative end-to-end driving framework. The risk map learns
directly from the driving data and provides an interpretable spatiotemporal
representation of the scenario from the upstream perception and the
interactions between the ego vehicle and the surrounding environment for
downstream planning. RiskMM first constructs a multi-agent spatiotemporal
representation with unified Transformer-based architecture, then derives
risk-aware representations by modeling interactions among surrounding
environments with attention. These representations are subsequently fed into a
learning-based Model Predictive Control (MPC) module. The MPC planner
inherently accommodates physical constraints and different vehicle types and
can provide interpretation by aligning learned parameters with explicit MPC
elements. Evaluations conducted on the real-world V2XPnP-Seq dataset confirm
that RiskMM achieves superior and robust performance in risk-aware trajectory
planning, significantly enhancing the interpretability of the cooperative
end-to-end driving framework. The codebase will be released to facilitate
future research in this field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07657v1' target='_blank'>MoRoCo: Multi-operator-robot Coordination, Interaction and Exploration
  under Restricted Communication</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuoli Tian, Yuyang Zhang, Jinsheng Wei, Meng Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 06:10:38</h6>
<p class='card-text'>Fleets of autonomous robots are increasingly deployed alongside multiple
human operators to explore unknown environments, identify salient features, and
perform complex tasks in scenarios such as subterranean exploration,
reconnaissance, and search-and-rescue missions. In these contexts,
communication is often severely limited to short-range exchanges via ad-hoc
networks, posing challenges to coordination. While recent studies have
addressed multi-robot exploration under communication constraints, they largely
overlook the essential role of human operators and their real-time interaction
with robotic teams. Operators may demand timely updates on the exploration
progress and robot status, reprioritize or cancel tasks dynamically, or request
live video feeds and control access. Conversely, robots may seek human
confirmation for anomalous events or require help recovering from motion or
planning failures. To enable such bilateral, context-aware interactions under
restricted communication, this work proposes MoRoCo, a unified framework for
online coordination and exploration in multi-operator, multi-robot systems.
MoRoCo enables the team to adaptively switch among three coordination modes:
spread mode for parallelized exploration with intermittent data sharing,
migrate mode for coordinated relocation, and chain mode for maintaining
high-bandwidth connectivity through multi-hop links. These transitions are
managed through distributed algorithms via only local communication. Extensive
large-scale human-in-the-loop simulations and hardware experiments validate the
necessity of incorporating human robot interactions and demonstrate that MoRoCo
enables efficient, reliable coordination under limited communication, marking a
significant step toward robust human-in-the-loop multi-robot autonomy in
challenging environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07654v1' target='_blank'>MLego: Interactive and Scalable Topic Exploration Through Model Reuse</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fei Ye, Jiapan Liu, Yinan Jing, Zhenying He, Weirao Wang, X. Sean Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 06:06:26</h6>
<p class='card-text'>With massive texts on social media, users and analysts often rely on topic
modeling techniques to quickly extract key themes and gain insights.
Traditional topic modeling techniques, such as Latent Dirichlet Allocation
(LDA), provide valuable insights but are computationally expensive, making them
impractical for real-time data analysis. Although recent advances in
distributed training and fast sampling methods have improved efficiency,
real-time topic exploration remains a significant challenge. In this paper, we
present MLego, an interactive query framework designed to support real-time
topic modeling analysis by leveraging model materialization and reuse. Instead
of retraining models from scratch, MLego efficiently merges materialized topic
models to construct approximate results at interactive speeds. To further
enhance efficiency, we introduce a hierarchical plan search strategy for single
queries and an optimized query reordering technique for batch queries. We
integrate MLego into a visual analytics prototype system, enabling users to
explore large-scale textual datasets through interactive queries. Extensive
experiments demonstrate that MLego significantly reduces computation costs
while maintaining high-quality topic modeling results. MLego enhances existing
visual analytics approaches, which primarily focus on user-driven topic
modeling, by enabling real-time, query-driven exploration. This complements
traditional methods and bridges the gap between scalable topic modeling and
interactive data analysis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07650v1' target='_blank'>GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model
  for Robotic Manipulation with Ambiguous Instructions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Helong Huang, Min Cen, Kai Tan, Xingyue Quan, Guowei Huang, Hong Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 06:01:00</h6>
<p class='card-text'>Vision-language-action models have emerged as a crucial paradigm in robotic
manipulation. However, existing VLA models exhibit notable limitations in
handling ambiguous language instructions and unknown environmental states.
Furthermore, their perception is largely constrained to static two-dimensional
observations, lacking the capability to model three-dimensional interactions
between the robot and its environment. To address these challenges, this paper
proposes GraphCoT-VLA, an efficient end-to-end model. To enhance the model's
ability to interpret ambiguous instructions and improve task planning, we
design a structured Chain-of-Thought reasoning module that integrates
high-level task understanding and planning, failed task feedback, and low-level
imaginative reasoning about future object positions and robot actions.
Additionally, we construct a real-time updatable 3D Pose-Object graph, which
captures the spatial configuration of robot joints and the topological
relationships between objects in 3D space, enabling the model to better
understand and manipulate their interactions. We further integrates a dropout
hybrid reasoning strategy to achieve efficient control outputs. Experimental
results across multiple real-world robotic tasks demonstrate that GraphCoT-VLA
significantly outperforms existing methods in terms of task success rate and
response speed, exhibiting strong generalization and robustness in open
environments and under uncertain instructions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07552v1' target='_blank'>Decoupled Functional Evaluation of Autonomous Driving Models via Feature
  Map Quality Scoring</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ludan Zhang, Sihan Wang, Yuqi Dai, Shuofei Qiao, Lei He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 02:24:08</h6>
<p class='card-text'>End-to-end models are emerging as the mainstream in autonomous driving
perception and planning. However, the lack of explicit supervision signals for
intermediate functional modules leads to opaque operational mechanisms and
limited interpretability, making it challenging for traditional methods to
independently evaluate and train these modules. Pioneering in the issue, this
study builds upon the feature map-truth representation similarity-based
evaluation framework and proposes an independent evaluation method based on
Feature Map Convergence Score (FMCS). A Dual-Granularity Dynamic Weighted
Scoring System (DG-DWSS) is constructed, formulating a unified quantitative
metric - Feature Map Quality Score - to enable comprehensive evaluation of the
quality of feature maps generated by functional modules. A CLIP-based Feature
Map Quality Evaluation Network (CLIP-FMQE-Net) is further developed, combining
feature-truth encoders and quality score prediction heads to enable real-time
quality analysis of feature maps generated by functional modules. Experimental
results on the NuScenes dataset demonstrate that integrating our evaluation
module into the training improves 3D object detection performance, achieving a
3.89 percent gain in NDS. These results verify the effectiveness of our method
in enhancing feature representation quality and overall model performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07515v1' target='_blank'>Neuro-Symbolic Acceleration of MILP Motion Planning with Temporal Logic
  and Chance Constraints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junyang Cai, Weimin Huang, Jyotirmoy V. Deshmukh, Lars Lindemann, Bistra Dilkina</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-11 00:13:36</h6>
<p class='card-text'>Autonomous systems must solve motion planning problems subject to
increasingly complex, time-sensitive, and uncertain missions. These problems
often involve high-level task specifications, such as temporal logic or chance
constraints, which require solving large-scale Mixed-Integer Linear Programs
(MILPs). However, existing MILP-based planning methods suffer from high
computational cost and limited scalability, hindering their real-time
applicability. We propose to use a neuro-symbolic approach to accelerate
MILP-based motion planning by leveraging machine learning techniques to guide
the solver's symbolic search. Focusing on two representative classes of
planning problems, namely, those with Signal Temporal Logic (STL)
specifications and those with chance constraints formulated via Conformal
Predictive Programming (CPP). We demonstrate how graph neural network-based
learning methods can guide traditional symbolic MILP solvers in solving
challenging planning problems, including branching variable selection and
solver parameter configuration. Through extensive experiments, we show that
neuro-symbolic search techniques yield scalability gains. Our approach yields
substantial improvements, achieving an average performance gain of about 20%
over state-of-the-art solver across key metrics, including runtime and solution
quality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07507v1' target='_blank'>Intersectoral Knowledge in AI and Urban Studies: A Framework for
  Transdisciplinary Research</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rashid Mushkani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 23:35:09</h6>
<p class='card-text'>Transdisciplinary approaches are increasingly essential for addressing grand
societal challenges, particularly in complex domains such as Artificial
Intelligence (AI), urban planning, and social sciences. However, effectively
validating and integrating knowledge across distinct epistemic and ontological
perspectives poses significant difficulties. This article proposes a
six-dimensional framework for assessing and strengthening transdisciplinary
knowledge validity in AI and city studies, based on an extensive analysis of
the most cited research (2014--2024). Specifically, the framework classifies
research orientations according to ontological, epistemological,
methodological, teleological, axiological, and valorization dimensions. Our
findings show a predominance of perspectives aligned with critical realism
(ontological), positivism (epistemological), analytical methods
(methodological), consequentialism (teleological), epistemic values
(axiological), and social/economic valorization. Less common stances, such as
idealism, mixed methods, and cultural valorization, are also examined for their
potential to enrich knowledge production. We highlight how early career
researchers and transdisciplinary teams can leverage this framework to
reconcile divergent disciplinary viewpoints and promote socially accountable
outcomes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07502v1' target='_blank'>A Learning-Based Framework for Collision-Free Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mateus Salomão, Tianyü Ren, Alexander König</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 23:14:56</h6>
<p class='card-text'>This paper presents a learning-based extension to a Circular Field (CF)-based
motion planner for efficient, collision-free trajectory generation in cluttered
environments. The proposed approach overcomes the limitations of hand-tuned
force field parameters by employing a deep neural network trained to infer
optimal planner gains from a single depth image of the scene. The pipeline
incorporates a CUDA-accelerated perception module, a predictive agent-based
planning strategy, and a dataset generated through Bayesian optimization in
simulation. The resulting framework enables real-time planning without manual
parameter tuning and is validated both in simulation and on a Franka Emika
Panda robot. Experimental results demonstrate successful task completion and
improved generalization compared to classical planners.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07462v1' target='_blank'>Forecasting solar power output in Ibadan: A machine learning approach
  leveraging weather data and system specifications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Obarotu Peter Urhuerhi, Christopher Udomboso, Caston Sigauke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 19:20:16</h6>
<p class='card-text'>This study predicts hourly solar irradiance components, Global Horizontal
Irradiance (GHI), Direct Normal Irradiance (DNI), and Diffuse Horizontal
Irradiance (DHI) using meteorological data to forecast solar energy output in
Ibadan, Nigeria. The forecasting process follows a two-stage approach: first,
clear-sky irradiance values are predicted using weather variables only (e.g.,
temperature, humidity, wind speed); second, actual (cloudy-sky) irradiance
values are forecasted by integrating the predicted clear-sky irradiance with
weather variables and cloud type. Historical meteorological data were
preprocessed and used to train Random Forest, Convolutional Neural Network
(CNN), and Long Short-Term Memory (LSTM) models, with Random Forest
demonstrating the best performance. Models were developed for annual and
seasonal forecasting, capturing variations between the wet and dry seasons. The
annual Random Forest model's normalised Root Mean Square Error (nRMSE) values
were 0.22 for DHI, 0.33 for DNI, and 0.19 for GHI. For seasonal forecasts, wet
season nRMSE values were 0.27 for DHI, 0.50 for DNI, and 0.27 for GHI, while
dry season nRMSE values were 0.15 for DHI, 0.22 for DNI, and 0.12 for GHI. The
predicted actual irradiance values were combined with solar system
specifications (e.g., maximum power (Pmax), open-circuit voltage (Voc),
short-circuit current (Isc), and AC power (Pac)) using PVLib Python to estimate
the final energy output. This methodology provides a cost-effective alternative
to pyranometer-based measurements, enhances grid stability for solar energy
integration, and supports efficient planning for off-grid and grid-connected
photovoltaic systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07446v1' target='_blank'>Optimizing Districting Plans to Maximize Majority-Minority Districts via
  IPs and Local Search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Brous, David Shmoys</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 17:58:54</h6>
<p class='card-text'>In redistricting litigation, effective enforcement of the Voting Rights Act
has often involved providing the court with districting plans that display a
larger number of majority-minority districts than the current proposal (as was
true, for example, in what followed Allen v. Milligan concerning the
congressional districting plan for Alabama in 2023). Recent work by Cannon et
al. proposed a heuristic algorithm for generating plans to optimize
majority-minority districts, which they called short bursts; that algorithm
relies on a sophisticated random walk over the space of all plans,
transitioning in bursts, where the initial plan for each burst is the most
successful plan from the previous burst. We propose a method based on integer
programming, where we build upon another previous work, the stochastic
hierarchical partitioning algorithm, which heuristically generates a robust set
of potential districts (viewed as columns in a standard set partitioning
formulation); that approach was designed to optimize a different notion of
fairness across a statewide plan. We design a new column generation algorithm
to find plans via integer programming that outperforms short bursts on multiple
data sets in generating statewide plans with significantly more
majority-minority districts. These results also rely on a new local
re-optimization algorithm to iteratively improve on any baseline solution, as
well as an algorithm to increase the compactness of districts in plans
generated (without impacting the number of majority-minority districts).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07378v1' target='_blank'>A new condition for the genericity of ergodic measures on non-positively
  curved Riemannian manifolds</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Paul Mella</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 15:01:45</h6>
<p class='card-text'>This article investigates the genericity of ergodic probability measures for
the geodesic flow on non-positively curved Riemannian manifolds. We demonstrate
that the existence of an open isometric embedding of a product manifold with a
factor isometric to $S^1$ implies that the closure of the set of ergodic
measures does not encompass all invariant measures, thus the genericity of
ergodic probability measures fails. Our findings notably provide an answer to
an open question concerning a specific example of 3-manifold attributed to
Heintze.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07376v1' target='_blank'>A Multi-Model Probabilistic Framework for Seismic Risk Assessment and
  Retrofit Planning of Electric Power Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huangbin Liang, Beatriz Moya, Francisco Chinesta, Eleni Chatzi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 14:52:05</h6>
<p class='card-text'>Electric power networks are critical lifelines, and their disruption during
earthquakes can lead to severe cascading failures and significantly hinder
post-disaster recovery. Enhancing their seismic resilience requires identifying
and strengthening vulnerable components in a cost-effective and system-aware
manner. However, existing studies often overlook the systemic behavior of power
networks under seismic loading. Common limitations include isolated component
analyses that neglect network-wide interdependencies, oversimplified damage
models assuming binary states or damage independence, and the exclusion of
electrical operational constraints. These simplifications can result in
inaccurate risk estimates and inefficient retrofit decisions. This study
proposes a multi-model probabilistic framework for seismic risk assessment and
retrofit planning of electric power systems. The approach integrates: (1)
regional seismic hazard characterization with ground motion prediction and
spatial correlation models; (2) component-level damage analysis using fragility
functions and multi-state damage-functionality mappings; (3) system-level
cascading impact evaluation through graph-based island detection and
constrained optimal power flow analysis; and (4) retrofit planning via
heuristic optimization to minimize expected annual functionality loss (EAFL)
under budget constraints. Uncertainty is propagated throughout the framework
using Monte Carlo simulation. The methodology is demonstrated on the IEEE
24-bus Reliability Test System, showcasing its ability to capture cascading
failures, identify critical components, and generate effective retrofit
strategies. Results underscore the potential of the framework as a scalable,
data-informed decision-support tool for enhancing the seismic resilience of
power infrastructure.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07375v1' target='_blank'>Think Before You Talk: Enhancing Meaningful Dialogue Generation in
  Full-Duplex Speech Language Models with Planning-Inspired Text Guidance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenqian Cui, Lei Zhu, Xiaohui Li, Zhihan Guo, Haoli Bai, Lu Hou, Irwin King</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 14:49:43</h6>
<p class='card-text'>Full-Duplex Speech Language Models (FD-SLMs) are specialized foundation
models designed to enable natural, real-time spoken interactions by modeling
complex conversational dynamics such as interruptions, backchannels, and
overlapping speech, and End-to-end (e2e) FD-SLMs leverage real-world
double-channel conversational data to capture nuanced two-speaker dialogue
patterns for human-like interactions. However, they face a critical challenge
-- their conversational abilities often degrade compared to pure-text
conversation due to prolonged speech sequences and limited high-quality spoken
dialogue data. While text-guided speech generation could mitigate these issues,
it suffers from timing and length issues when integrating textual guidance into
double-channel audio streams, disrupting the precise time alignment essential
for natural interactions. To address these challenges, we propose TurnGuide, a
novel planning-inspired approach that mimics human conversational planning by
dynamically segmenting assistant speech into dialogue turns and generating
turn-level text guidance before speech output, which effectively resolves both
insertion timing and length challenges. Extensive experiments demonstrate our
approach significantly improves e2e FD-SLMs' conversational abilities, enabling
them to generate semantically meaningful and coherent speech while maintaining
natural conversational flow. Demos are available at
https://dreamtheater123.github.io/TurnGuide-Demo/. Code will be available at
https://github.com/dreamtheater123/TurnGuide.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07368v1' target='_blank'>A K-adaptability Approach to Proton Radiation Therapy Robust Treatment
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zihang Qiu, Ali Ajdari, Mislav Bobić, Thomas Bortfeld, Dick den Hertog, Jannis Kurtz, Hoyeon Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 14:36:23</h6>
<p class='card-text'>Uncertainties such as setup and range errors can significantly compromise
proton therapy. A discrete uncertainty set is often constructed to represent
different uncertainty scenarios. A min-max robust optimization approach is then
utilized to optimize the worst-case performance of a radiation therapy plan
against the uncertainty set. However, the min-max approach can be too
conservative as a single plan has to account for the entire uncertainty set.
K-adaptability is a novel approach to robust optimization which covers the
uncertainty set with multiple (K) solutions, reducing the conservativeness.
Solving K-adaptability to optimality is known to be computationally
intractable. To that end, we developed a novel and efficient K-adaptability
heuristic that iteratively clusters the scenarios based on plan-scenario
performance for the proton radiation therapy planning problem. Compared to the
conventional robust solution, the developed K-adaptability heuristic increased
the worst-case CTV Dmin dose up to 4.52 Gy on average across five head and neck
patients. The developed heuristic also demonstrated its superiority in
objective value and time-efficiency compared to the competing methods we
tested.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07323v1' target='_blank'>Collision-Free Trajectory Planning and control of Robotic Manipulator
  using Energy-Based Artificial Potential Field (E-APF)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Adeetya Uppal, Rakesh Kumar Sahoo, Manoranjan Sinha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 12:34:49</h6>
<p class='card-text'>Robotic trajectory planning in dynamic and cluttered environments remains a
critical challenge, particularly when striving for both time efficiency and
motion smoothness under actuation constraints. Traditional path planner, such
as Artificial Potential Field (APF), offer computational efficiency but suffer
from local minima issue due to position-based potential field functions and
oscillatory motion near the obstacles due to Newtonian mechanics. To address
this limitation, an Energy-based Artificial Potential Field (APF) framework is
proposed in this paper that integrates position and velocity-dependent
potential functions. E-APF ensures dynamic adaptability and mitigates local
minima, enabling uninterrupted progression toward the goal. The proposed
framework integrates E-APF with a hybrid trajectory optimizer that jointly
minimizes jerk and execution time under velocity and acceleration constraints,
ensuring geometric smoothness and time efficiency. The entire framework is
validated in simulation using the 7-degree-of-freedom Kinova Gen3 robotic
manipulator. The results demonstrate collision-free, smooth, time-efficient,
and oscillation-free trajectory in the presence of obstacles, highlighting the
efficacy of the combined trajectory optimization and real-time obstacle
avoidance approach. This work lays the foundation for future integration with
reactive control strategies and physical hardware deployment in real-world
manipulation tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07319v1' target='_blank'>A Hybrid Force-Position Strategy for Shape Control of Deformable Linear
  Objects With Graph Attention Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanzhao Yu, Haotian Yang, Junbo Tan, Xueqian Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 12:27:46</h6>
<p class='card-text'>Manipulating deformable linear objects (DLOs) such as wires and cables is
crucial in various applications like electronics assembly and medical
surgeries. However, it faces challenges due to DLOs' infinite degrees of
freedom, complex nonlinear dynamics, and the underactuated nature of the
system. To address these issues, this paper proposes a hybrid force-position
strategy for DLO shape control. The framework, combining both force and
position representations of DLO, integrates state trajectory planning in the
force space and Model Predictive Control (MPC) in the position space. We
present a dynamics model with an explicit action encoder, a property extractor
and a graph processor based on Graph Attention Networks. The model is used in
the MPC to enhance prediction accuracy. Results from both simulations and
real-world experiments demonstrate the effectiveness of our approach in
achieving efficient and stable shape control of DLOs. Codes and videos are
available at https://sites.google.com/view/dlom.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07269v1' target='_blank'>Navigation and Exploration with Active Inference: from Biology to
  Industry</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daria de Tinguy, Tim Verbelen, Bart Dhoedt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 09:51:27</h6>
<p class='card-text'>By building and updating internal cognitive maps, animals exhibit
extraordinary navigation abilities in complex, dynamic environments. Inspired
by these biological mechanisms, we present a real time robotic navigation
system grounded in the Active Inference Framework (AIF). Our model
incrementally constructs a topological map, infers the agent's location, and
plans actions by minimising expected uncertainty and fulfilling perceptual
goals without any prior training. Integrated into the ROS2 ecosystem, we
validate its adaptability and efficiency across both 2D and 3D environments
(simulated and real world), demonstrating competitive performance with
traditional and state of the art exploration approaches while offering a
biologically inspired navigation approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07267v1' target='_blank'>Bio-Inspired Topological Autonomous Navigation with Active Inference in
  Robotics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daria de Tinguy, Tim Verbelen, Emilio Gamba, Bart Dhoedt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 09:42:13</h6>
<p class='card-text'>Achieving fully autonomous exploration and navigation remains a critical
challenge in robotics, requiring integrated solutions for localisation,
mapping, decision-making and motion planning. Existing approaches either rely
on strict navigation rules lacking adaptability or on pre-training, which
requires large datasets. These AI methods are often computationally intensive
or based on static assumptions, limiting their adaptability in dynamic or
unknown environments. This paper introduces a bio-inspired agent based on the
Active Inference Framework (AIF), which unifies mapping, localisation, and
adaptive decision-making for autonomous navigation, including exploration and
goal-reaching. Our model creates and updates a topological map of the
environment in real-time, planning goal-directed trajectories to explore or
reach objectives without requiring pre-training. Key contributions include a
probabilistic reasoning framework for interpretable navigation, robust
adaptability to dynamic changes, and a modular ROS2 architecture compatible
with existing navigation systems. Our method was tested in simulated and
real-world environments. The agent successfully explores large-scale simulated
environments and adapts to dynamic obstacles and drift, proving to be
comparable to other exploration strategies such as Gbplanner, FAEL and
Frontiers. This approach offers a scalable and transparent approach for
navigating complex, unstructured environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07146v1' target='_blank'>Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Liu, Zhijie Liu, Xiao Ren, You-Fu Li, He Kong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 02:36:33</h6>
<p class='card-text'>Predicting pedestrian motion trajectories is critical for the path planning
and motion control of autonomous vehicles. Recent diffusion-based models have
shown promising results in capturing the inherent stochasticity of pedestrian
behavior for trajectory prediction. However, the absence of explicit semantic
modelling of pedestrian intent in many diffusion-based methods may result in
misinterpreted behaviors and reduced prediction accuracy. To address the above
challenges, we propose a diffusion-based pedestrian trajectory prediction
framework that incorporates both short-term and long-term motion intentions.
Short-term intent is modelled using a residual polar representation, which
decouples direction and magnitude to capture fine-grained local motion
patterns. Long-term intent is estimated through a learnable, token-based
endpoint predictor that generates multiple candidate goals with associated
probabilities, enabling multimodal and context-aware intention modelling.
Furthermore, we enhance the diffusion process by incorporating adaptive
guidance and a residual noise predictor that dynamically refines denoising
accuracy. The proposed framework is evaluated on the widely used ETH, UCY, and
SDD benchmarks, demonstrating competitive results against state-of-the-art
methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07145v1' target='_blank'>When Competition Helps: Achieving Optimal Traffic Flow with Multiple
  Autonomous Planners</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ivan Geffner, Erez Karpas, Moshe Tennenholtz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 02:32:43</h6>
<p class='card-text'>The inefficiency of selfish routing in congested networks is a classical
problem in algorithmic game theory, often captured by the Price of Anarchy
(i.e., the ratio between the social cost of decentralized decisions and that of
a centrally optimized solution.) With the advent of autonomous vehicles,
capable of receiving and executing centrally assigned routes, it is natural to
ask whether their deployment can eliminate this inefficiency. At first glance,
a central authority could simply compute an optimal traffic assignment and
instruct each vehicle to follow its assigned path. However, this vision
overlooks critical challenges: routes must be individually rational (no vehicle
has an incentive to deviate), and in practice, multiple planning agents (e.g.,
different companies) may coexist and compete. Surprisingly, we show that such
competition is not merely an obstacle but a necessary ingredient for achieving
optimal outcomes. In this work, we design a routing mechanism that embraces
competition and converges to an optimal assignment, starting from the classical
Pigou network as a foundational case.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.07133v1' target='_blank'>Computational modeling of Pulsed Field Ablation for pulmonary vein
  isolation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ashkan Bagherzadeh, Nagib T Chalfoun, Tong Gao, Lik Chuan Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-10 01:02:04</h6>
<p class='card-text'>Pulsed field ablation (PFA) has emerged as a non-thermal alternative to
traditional thermal ablation techniques for the treatment of atrial
fibrillation (AF). This study presents a patient-specific 3D computational
framework to model the effects of PFA on pulmonary vein isolation (PVI). The
modeling framework is rigorously validated against published numerical and
experimental data, demonstrating strong agreement across a range of scenarios.
Using realistic left atrial (LA) anatomy, commercially available circular,
flower, and basket catheter configurations are simulated to evaluate lesion
formation across different applied voltages. The performance of each catheter
type is quantitatively assessed using multiple metrics, including lesion
volume, energy delivery efficiency and transmurality. Simulation results show
that circular catheters provide the highest energy delivery efficiency and
target coverage at lower voltages, while basket catheters produce the largest
lesion volumes. This framework offers a useful basis for exploring catheter
design and treatment planning in PFA applications.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>