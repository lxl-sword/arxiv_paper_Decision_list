<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2026-02-22</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2026-02-22</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17640v1' target='_blank'>huff: A Python package for Market Area Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thomas Wieland</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 18:52:46</h6>
<p class='card-text'>Market area models, such as the Huff model and its extensions, are widely used to estimate regional market shares and customer flows of retail and service locations. Another, now very common, area of application is the analysis of catchment areas, supply structures and the accessibility of healthcare locations. The huff Python package provides a complete workflow for market area analysis, including data import, construction of origin-destination interaction matrices, basic model analysis, parameter estimation from empirical data, calculation of distance or travel time indicators, and map visualization. Additionally, the package provides several methods of spatial accessibility analysis. The package is modular and object-oriented. It is intended for researchers in economic geography, regional economics, spatial planning, marketing, geoinformation science, and health geography. The software is openly available via the [Python Package Index (PyPI)](https://pypi.org/project/huff/); its development and version history are managed in a public [GitHub Repository](https://github.com/geowieland/huff_official) and archived at [Zenodo](https://doi.org/10.5281/zenodo.18639559).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17582v1' target='_blank'>Building an AI-native Research Ecosystem for Experimental Particle Physics: A Community Vision</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thea Klaeboe Aarrestad, Alaa Abdelhamid, Haider Abidi, Jahred Adelman, Jennifer Adelman-McCarthy, Shuchin Aeron, Garvita Agarwal, Usman Ali, Cristiano Alpigiani, Omar Alterkait, Mohamed Aly, Oz Amram, Saeed Ansari Fard, Aram Apyan, John Arrington, Marvin Ascencio-Sosa, Mohammad Atif, Aneesha Avasthi, Muhammad Bilal Azam, Bhim Bam, Joshua Barrow, Rainer Bartoldus, Amit Bashyal, Aashwin Basnet, Ayse Bat, Lothar A. T. Bauerdick, John Beacom, Chris Bee, Michael Begel, Matthew Bellis, Rene Bellwied, Rakitha Beminiwattha, Gabriele Benelli, Douglas Benjamin, Catrin Bernius, Binod Bhandari, Avinay Bhat, Meghna Bhattacharya, Saptaparna Bhattacharya, Prajita Bhattarai, Sudip Bhattarai, Wahid Bhimji, Jianming Bian, Burak Bilki, Mary Bishai, Kevin Black, Kenneth Bloom, Brian Bockelman, Johan Sebastian Bonilla Castro, Tulika Bose, Nilay Bostan, Othmane Bouhali, Dimitri Bourilkov, Dominic Brailsford, Gustaaf Brooijmans, Elizabeth Brost, Maria Brigida Brunetti, Quentin Buat, Brendon Bullard, Jackson Burzynski, Paolo Calafiura, Rodolfo Capdevilla, Fabian Andres Castaño Usuga, Raquel Castillo Fernandez, Fabio Catalano, Viviana Cavaliere, Flavio Cavanna, Giuseppe Cerati, Aidan Chambers, Maria Chamizo-Llatas, Philip Chang, Andrew Chappell, Arghya Chattopadhyay, Sergei Chekanov, Jian-ping Chen, Yi Chen, Zhengyang Chen, J. Taylor Childers, Hector Chinchay, Yuan-Tang Chou, Tasnuva Chowdhury, Neil Christensen, Wonyong Chung, Rafael Coelho Lopes de Sa, Simon Corrodi, Kyle Cranmer, Matteo Cremonesi, Roy Cruz, Mate Csanad, Mariarosaria D'Alfonso, Carlo Dallapiccola, Daine Danielson, Sridhara Dasu, Gavin Davies, Kaushik De, Patrick de Perio, Klaus Dehmelt, Marco Del Tutto, Carlos Ruben Dell'Aquila, Sarah Demers, Paolo Desiati, Bhesha Devkota, Sparshita Dey, Ranjan Dharmapalan, Karri Folan Di Petrillo, Markus Diefenthaler, Jeff Dillon, Zelimir Djurcic, Caterina Doglioni, Francois Drielsma, Edmond Dukes, Irene Dutta, Peter Elmer, Johannes Elmsheuser, Victor Daniel Elvira, Harold Evans, Peter Fackeldey, Cristiano Fanelli, Hao Fang, Mattia Fani, Muhammad Farooq, Matthew Feickert, Ian Fisk, Sam Foreman, Alexander Friedland, Nuwan Chaminda G. W., Louis-Guillaume Gagnon, Massimiliano Galli, Abhijith Gandrakota, Sudeshna Ganguly, Arianna Garcia Caffaro, Rob Gardner, Rocky Bala Garg, Lino Gerlach, Aishik Ghosh, Romulus Godang, Julia Gonski, Loukas Gouskos, Richard Gran, Heather Gray, Andrei Gritsan, Gaia Grosso, Craig Group, Jiawei Guo, Shubham Gupta, Gajendra Gurung, Phillip Gutierrez, Oliver Gutsche, Tyler Hague, Joseph Haley, Eva Halkiadakis, Francis Halzen, Michael Hance, Philip Harris, Harry Hausner, Karsten Heeger, Lukas Heinrich, Alexander Held, Matthew Herndon, Ken Herner, Max Herrmann, David Hertzog, Christian Herwig, Aaron Higuera, Alexander Himmel, Timothy Hobbs, Stefan Hoeche, Tova Holmes, Tae Min Hong, Ben Hooberman, Walter Hopkins, Jessica N. Howard, Shih-Chieh Hsu, Fengping Hu, Patrick Huber, Dirk Hufnagel, Daniel Humphreys, Ia Iashvili, Joseph Incandela, Josh Isaacson, Wasikul Islam, Kirill Ivanov, Wooyoung Jang, Naomi Jarvis, Brij Kishor Jashal, Pratik Jawahar, Dulitha Jayakodige, Torri Jeske, Sergo Jindariani, Jay Hyun Jo, Bhishm Shankar Joshi, Xiangyang Ju, Andreas Jung, Thomas Junk, Michael Kagan, Daisy Kalra, Matthias Kaminski, Edward Karavakis, Stefan Katsarov, Stergios Kazakos, Paul King, Michael Kirby, Max Knobbe, Young Ju Ko, Dmitry Kondratyev, Rostislav Konoplich, Charis Koraka, Scott Kravitz, Lukas Kretschmann, Brandon Kriesten, Georgios K Krintiras, Iason Krommydas, Michelle Kuchera, Audrey Kvam, Martin Kwok, Theodota Lagouri, Sabine Lammers, Eric Lancon, Greg Landsberg, David Lange, Kevin Lannon, Joseph Lau, Luca Lavezzo, Benjamin Lawrence-Sanderson, Duc-Truyen Le, Matt LeBlanc, Sung-Won Lee, Trevin Lee, Charles Leggett, Kayla Leonard DeHolton, James Letts, Hao Li, Haoyang Li, Aklima Khanam Lima, Guilherme Lima, Mia Liu, Qibin Liu, Yinrui Liu, Zhen Liu, Shivani Lomte, Guillermo Loustau de Linares, Lu Lu, Pietro Lugato, Adam Lyon, Yang Ma, Christopher Madrid, Akhtar Mahmood, Kendall Mahn, Devin Mahon, Akshay Malige, Sudhir Malik, Abhishikth Mallampalli, Yurii Maravin, Ralph Marinaro, Pete Markowitz, Matthew Maroun, Kyla Martinez, Verena Ingrid Martinez Outschoorn, Sanjit Masanam, Mario Masciovecchio, Konstantin Matchev, Malek Mazouz, Simone Mazza, Thomas McCauley, Shawn McKee, Karim Mehrabi, Poonam Mehta, Andrew Melo, Mark Messier, Elias Mettner, Christopher Meyer, Jessie Micallef, Sophie Middleton, David W. Miller, Hamlet Mkrtchyan, Abdollah Mohammadi, Abhinav Mohan, Ajit Mohapatra, Farouk Mokhtar, Peter Monaghan, Claudio Silverio Montanari, Michael Mooney, Casey Morean, Eric Moreno, Alexander Moreno Briceño, Stephen Mrenna, Justin Mueller, Daniel Murnane, Benjamin Nachman, Emilio Nanni, Nitish Nayak, Miquel Nebot-Guinot, Orgho Neogi, Chris Neu, Mark Neubauer, Norbert Neumeister, Harvey Newman, Duong Nguyen, Gavin Niendorf, Paul Nilsson, Scarlet Norberg, Andrzej Novak, Sungbin Oh, Isabel Ojalvo, Olaiya Olokunboyo, Yasar Onel, Joseph Osborn, Ianna Osborne, Arantza Oyanguren, Nurcan Ozturk, Paul Padley, Simone Pagan Griso, Pritam Palit, Bishnu Pandey, Vishvas Pandey, Zisis Papandreou, Ganesh Parida, Ki Ryeong Park, Ajib Paudel, Manfred Paulini, Christoph Paus, Gregory Pawloski, Kevin Pedro, Gabriel Perdue, Troels Christian Petersen, Alexey Petrov, Deborah Pinna, Marc-André Pleier, Andrea Pocar, Prafull Purohit, Nived Puthumana Meleppattu, Mateusz Płoskoń, Sitian Qian, Xin Qian, Geting Qin, Aleena Rafique, Srini Rajagopalan, Dylan Rankin, Rebecca Rapp, Salvatore Rappoccio, Rohit Raut, Sagar Regmi, Benedikt Riedel, Andres Rios-Tascon, Stephen Roche, Jenna Roderick, Rimsky Rojas, Dmitry Romanov, Subhojit Roy, Rita Sadek, Dikshant Sagar, Nihar Ranjan Sahoo, Tai Sakuma, Juan Pablo Salas, Mayly Sanchez, Jay Sandesara, Alexander Savin, Ryan Schmitz, Kate Scholberg, Henry Schreiner, Reinhard Schwienhorst, Gabriella Sciolla, Saba Sehrish, Seon-Hee, Seo, Elizabeth Sexton-Kennedy, Oksana Shadura, Bijaya Sharma, Varun Sharma, Suyog Shrestha, Ryan Simeon, Jack Simoni, Siddharth Singh, Kim Siyeon, Louise Skinnari, Jinseop Song, Simone Sottocornola, Alexandre Sousa, Sairam Sri Vatsavai, Giordon Stark, Justin Stevens, Tyler Stokes, Nadja Strobbe, Indara Suarez, Manjukrishna Suresh, Andrew Sutton, Holly Szumila-Vance, Vardan Tadevosyan, Anyes Taffard, Buddhiman Tamang, Hirohisa Tanaka, Erdinch Tatar, Abdel Nasser Tawfik, Vikas Teotia, Kazuhiro Terao, Mitanshu Thakore, Jesse Thaler, Ameya Thete, Inar Timiryasov, Anthony Timmins, Andrew Toler, Dat Tran, Nhan Tran, Patrick Tsang, Ho Fung Tsoi, Vakho Tsulaia, Pham Tuan, Christopher Tully, Shengquan Tuo, Richard Tyson, Darren Upton, Hilary Utaegbulam, Zoya Vallari, Peter van Gemmeren, Vassil Vassilev, Nikhilesh Venkatasubramanian, Renzo Vizarreta, Emmanouil Vourliotis, Ilija Vukotic, Carl Vuosalo, Liv Våge, Tammy Walton, Linyan Wan, Biao Wang, Gensheng Wang, Michael Wang, Yuxuan Wang, Gordon Watts, Yingjie Wei, Derek Weitzel, Shawn Westerdale, Andrew White, Leigh Whitehead, Michael Wilking, Mike Williams, Stephane Willocq, Jeffery Winkler, Frank Winklmeier, Holger Witte, Peter Wittich, Douglas Wright, Yongcheng Wu, Yujun Wu, Wei Xie, Fang Xu, Barbara Yaeggy, Zhen Yan, Liang Yang, Wei Yang, Alejandro Yankelevich, Yiheng Ye, Oguzhan Yer, Efe Yigitbasi, Shin-Shan Yu, Jon Zarling, Chao Zhang, Licheng Zhang, Larry Zhao, Junjie Zhu, Jure Zupan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 18:06:13</h6>
<p class='card-text'>Experimental particle physics seeks to understand the universe by probing its fundamental particles and forces and exploring how they govern the large-scale processes that shape cosmic evolution. This whitepaper presents a vision for how Artificial Intelligence (AI) can accelerate discovery in this field. We outline grand challenges that must be addressed to enable transformative breakthroughs and describe how current and planned experimental facilities can implement this vision to advance our understanding of the vast and complex physical world from the smallest to the largest scales. We show how facilities currently under construction, such as the HL-LHC, DUNE and soon EIC, can both benefit from and serve as proving grounds for this vision, while also enabling a longer-term goal for how future experiments -- like FCC-ee at CERN, IceCube-Gen2, a Muon Collider in the U.S., and smaller to mid-scale projects -- can be fully AI-native. We describe how a truly national-scale collaboration, jointly managed across large funding partners, and involving both DOE laboratories and universities, can make this happen.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17574v1' target='_blank'>Hybrid System Planning using a Mixed-Integer ADMM Heuristic and Hybrid Zonotopes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joshua A. Robbins, Andrew F. Thompson, Jonah J. Glunt, Herschel C. Pangborn</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 17:32:37</h6>
<p class='card-text'>Embedded optimization-based planning for hybrid systems is challenging due to the use of mixed-integer programming, which is computationally intensive and often sensitive to the specific numerical formulation. To address that challenge, this article proposes a framework for motion planning of hybrid systems that pairs hybrid zonotopes - an advanced set representation - with a new alternating direction method of multipliers (ADMM) mixed-integer programming heuristic. A general treatment of piecewise affine (PWA) system reachability analysis using hybrid zonotopes is presented and extended to formulate optimal planning problems. Sets produced using the proposed identities have lower memory complexity and tighter convex relaxations than equivalent sets produced from preexisting techniques. The proposed ADMM heuristic makes efficient use of the hybrid zonotope structure. For planning problems formulated as hybrid zonotopes, the proposed heuristic achieves improved convergence rates as compared to state-of-the-art mixed-integer programming heuristics. The proposed methods for hybrid system planning on embedded hardware are experimentally applied in a combined behavior and motion planning scenario for autonomous driving.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17558v1' target='_blank'>RetouchIQ: MLLM Agents for Instruction-Based Image Retouching with Generalist Reward</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qiucheng Wu, Jing Shi, Simon Jenni, Kushal Kafle, Tianyu Wang, Shiyu Chang, Handong Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 17:11:59</h6>
<p class='card-text'>Recent advances in multimodal large language models (MLLMs) have shown great potential for extending vision-language reasoning to professional tool-based image editing, enabling intuitive and creative editing. A promising direction is to use reinforcement learning (RL) to enable MLLMs to reason about and execute optimal tool-use plans within professional image-editing software. However, training remains challenging due to the lack of reliable, verifiable reward signals that can reflect the inherently subjective nature of creative editing. In this work, we introduce RetouchIQ, a framework that performs instruction-based executable image editing through MLLM agents guided by a generalist reward model. RetouchIQ interprets user-specified editing intentions and generates corresponding, executable image adjustments, bridging high-level aesthetic goals with precise parameter control. To move beyond conventional, rule-based rewards that compute similarity against a fixed reference image using handcrafted metrics, we propose a generalist reward model, an RL fine-tuned MLLM that evaluates edited results through a set of generated metrics on a case-by-case basis. Then, the reward model provides scalar feedback through multimodal reasoning, enabling reinforcement learning with high-quality, instruction-consistent gradients. We curate an extended dataset with 190k instruction-reasoning pairs and establish a new benchmark for instruction-based image editing. Experiments show that RetouchIQ substantially improves both semantic consistency and perceptual quality over previous MLLM-based and diffusion-based editing systems. Our findings demonstrate the potential of generalist reward-driven MLLM agents as flexible, explainable, and executable assistants for professional image editing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17515v1' target='_blank'>RA-Nav: A Risk-Aware Navigation System Based on Semantic Segmentation for Aerial Robots in Unpredictable Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziyi Zong, Xin Dong, Jinwu Xiang, Daochun Li, Zhan Tu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 16:26:43</h6>
<p class='card-text'>Existing aerial robot navigation systems typically plan paths around static and dynamic obstacles, but fail to adapt when a static obstacle suddenly moves. Integrating environmental semantic awareness enables estimation of potential risks posed by suddenly moving obstacles. In this paper, we propose RA- Nav, a risk-aware navigation framework based on semantic segmentation. A lightweight multi-scale semantic segmentation network identifies obstacle categories in real time. These obstacles are further classified into three types: stationary, temporarily static, and dynamic. For each type, corresponding risk estimation functions are designed to enable real-time risk prediction, based on which a complete local risk map is constructed. Based on this map, the risk-informed path search algorithm is designed to guarantee planning that balances path efficiency and safety. Trajectory optimization is then applied to generate trajectories that are safe, smooth, and dynamically feasible. Comparative simulations demonstrate that RA-Nav achieves higher success rates than baselines in sudden obstacle state transition scenarios. Its effectiveness is further validated in simulations using real- world data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17512v1' target='_blank'>Dodging the Moose: Experimental Insights in Real-Life Automated Collision Avoidance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Leila Gharavi, Simone Baldi, Yuki Hosomi, Tona Sato, Bart De Schutter, Binh-Minh Nguyen, Hiroshi Fujimoto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 16:24:40</h6>
<p class='card-text'>The sudden appearance of a static obstacle on the road, i.e. the moose test, is a well-known emergency scenario in collision avoidance for automated driving. Model Predictive Control (MPC) has long been employed for planning and control of automated vehicles in the state of the art. However, real-time implementation of automated collision avoidance in emergency scenarios such as the moose test remains unaddressed due to the high computational demand of MPC for evasive action in such hazardous scenarios. This paper offers new insights into real-time collision avoidance via the experimental imple- mentation of MPC for motion planning after a sudden and unexpected appearance of a static obstacle. As the state-of-the-art nonlinear MPC shows limited capability to provide an acceptable solution in real-time, we propose a human-like feed-forward planner to assist when the MPC optimization problem is either infeasible or unable to find a suitable solution due to the poor quality of its initial guess. We introduce the concept of maximum steering maneuver to design the feed-forward planner and mimic a human-like reaction after detecting the static obstacle on the road. Real-life experiments are conducted across various speeds and level of emergency using FPEV2-Kanon electric vehicle. Moreover, we demonstrate the effectiveness of our planning strategy via comparison with the state-of- the-art MPC motion planner.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17434v1' target='_blank'>Multi-Agent Temporal Logic Planning via Penalty Functions and Block-Coordinate Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eleftherios E. Vlahakis, Arash Bahari Kordabad, Lars Lindemann, Pantelis Sopasakis, Sadegh Soudjani, Dimos V. Dimarogonas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 15:05:16</h6>
<p class='card-text'>Multi-agent planning under Signal Temporal Logic (STL) is often hindered by collaborative tasks that lead to computational challenges due to the inherent high-dimensionality of the problem, preventing scalable synthesis with satisfaction guarantees. To address this, we formulate STL planning as an optimization program under arbitrary multi-agent constraints and introduce a penalty-based unconstrained relaxation that can be efficiently solved via a Block-Coordinate Gradient Descent (BCGD) method, where each block corresponds to a single agent's decision variables, thereby mitigating complexity. By utilizing a quadratic penalty function defined via smooth STL semantics, we show that BCGD iterations converge to a stationary point of the penalized problem under standard regularity assumptions. To enforce feasibility, the BCGD solver is embedded within a two-layer optimization scheme: inner BCGD updates are performed for a fixed penalty parameter, which is then increased in an outer loop to progressively improve multi-agent STL robustness. The proposed framework enables scalable computations and is validated through various complex multi-robot planning scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17415v1' target='_blank'>Distributed Virtual Model Control for Scalable Human-Robot Collaboration in Shared Workspace</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yi Zhang, Omar Faris, Chapa Sirithunge, Kai-Fung Chu, Fumiya Iida, Fulvio Forni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 14:45:10</h6>
<p class='card-text'>We present a decentralized, agent agnostic, and safety-aware control framework for human-robot collaboration based on Virtual Model Control (VMC). In our approach, both humans and robots are embedded in the same virtual-component-shaped workspace, where motion is the result of the interaction with virtual springs and dampers rather than explicit trajectory planning. A decentralized, force-based stall detector identifies deadlocks, which are resolved through negotiation. This reduces the probability of robots getting stuck in the block placement task from up to 61.2% to zero in our experiments. The framework scales without structural changes thanks to the distributed implementation: in experiments we demonstrate safe collaboration with up to two robots and two humans, and in simulation up to four robots, maintaining inter-agent separation at around 20 cm. Results show that the method shapes robot behavior intuitively by adjusting control parameters and achieves deadlock-free operation across team sizes in all tested scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17392v1' target='_blank'>Stackelberg Dynamic Location Planning under Cumulative Demand</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Warley Almeida Silva, Margarida Carvalho, Sanjay Dominik Jena</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 14:17:26</h6>
<p class='card-text'>Dynamic facility location problems predominantly suppose a monopoly over the service or product provided. Nonetheless, this premise can be a severe oversimplification in the presence of market competitors, as customers may prefer facilities installed by one of them. The monopolistic assumption can particularly worsen planning performance when demand depends on prior location decisions of the market participants, namely, when unmet demand from one period carries over to the next. Such a demand behaviour creates an intrinsic relationship between customer demand and location decisions of all market participants, and requires the decision-maker to anticipate the competitor's response. This work studies a novel competitive facility location problem that combines cumulative demand and market competition to devise high-quality solutions. We propose bilevel mixed-integer programming formulations for two variants of our problem, prove that the optimistic variant is $Σ^{p}_{2}$-hard, and develop branch-and-cut algorithms with tightened value-function cuts that significantly outperform general-purpose bilevel solvers. Our results quantify the severe cost of planning under a monopolistic assumption (profit drops by half on average) and the gains from cooperation over competition (6% more joint profit), while drawing managerial guidelines on how instance attributes and duopolistic modelling choices shape robust location schedules.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17375v1' target='_blank'>MDP Planning as Policy Inference</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David Tolpin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 13:56:31</h6>
<p class='card-text'>We cast episodic Markov decision process (MDP) planning as Bayesian inference over _policies_. A policy is treated as the latent variable and is assigned an unnormalized probability of optimality that is monotone in its expected return, yielding a posterior distribution whose modes coincide with return-maximizing solutions while posterior dispersion represents uncertainty over optimal behavior. To approximate this posterior in discrete domains, we adapt variational sequential Monte Carlo (VSMC) to inference over deterministic policies under stochastic dynamics, introducing a sweep that enforces policy consistency across revisited states and couples transition randomness across particles to avoid confounding from simulator noise. Acting is performed by posterior predictive sampling, which induces a stochastic control policy through a Thompson-sampling interpretation rather than entropy regularization. Across grid worlds, Blackjack, Triangle Tireworld, and Academic Advising, we analyze the structure of inferred policy distributions and compare the resulting behavior to discrete Soft Actor-Critic, highlighting qualitative and statistical differences that arise from policy-level uncertainty.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17365v1' target='_blank'>Computer-Using World Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiming Guan, Rui Yu, John Zhang, Lu Wang, Chaoyun Zhang, Liqun Li, Bo Qiao, Si Qin, He Huang, Fangkai Yang, Pu Zhao, Lukas Wutschitz, Samuel Kessler, Huseyin A Inan, Robert Sim, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 13:48:29</h6>
<p class='card-text'>Agents operating in complex software environments benefit from reasoning about the consequences of their actions, as even a single incorrect user interface (UI) operation can derail long, artifact-preserving workflows. This challenge is particularly acute for computer-using scenarios, where real execution does not support counterfactual exploration, making large-scale trial-and-error learning and planning impractical despite the environment being fully digital and deterministic. We introduce the Computer-Using World Model (CUWM), a world model for desktop software that predicts the next UI state given the current state and a candidate action. CUWM adopts a two-stage factorization of UI dynamics: it first predicts a textual description of agent-relevant state changes, and then realizes these changes visually to synthesize the next screenshot. CUWM is trained on offline UI transitions collected from agents interacting with real Microsoft Office applications, and further refined with a lightweight reinforcement learning stage that aligns textual transition predictions with the structural requirements of computer-using environments. We evaluate CUWM via test-time action search, where a frozen agent uses the world model to simulate and compare candidate actions before execution. Across a range of Office tasks, world-model-guided test-time scaling improves decision quality and execution robustness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17199v1' target='_blank'>Nonlinear Predictive Control of the Continuum and Hybrid Dynamics of a Suspended Deformable Cable for Aerial Pick and Place</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Antonio Rapuano, Yaolei Shen, Federico Califano, Chiara Gabellieri, Antonio Franchi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 09:38:32</h6>
<p class='card-text'>This paper presents a framework for aerial manipulation of an extensible cable that combines a high-fidelity model based on partial differential equations (PDEs) with a reduced-order representation suitable for real-time control. The PDEs are discretised using a finite-difference method, and proper orthogonal decomposition is employed to extract a reduced-order model (ROM) that retains the dominant deformation modes while significantly reducing computational complexity. Based on this ROM, a nonlinear model predictive control scheme is formulated, capable of stabilizing cable oscillations and handling hybrid transitions such as payload attachment and detachment. Simulation results confirm the stability, efficiency, and robustness of the ROM, as well as the effectiveness of the controller in regulating cable dynamics under a range of operating conditions. Additional simulations illustrate the application of the ROM for trajectory planning in constrained environments, demonstrating the versatility of the proposed approach. Overall, the framework enables real-time, dynamics-aware control of unmanned aerial vehicles (UAVs) carrying suspended flexible cables.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17112v1' target='_blank'>Multi-Ecosystem Modeling of OSS Project Sustainability</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arjun Ashok, Nafiz Imtiaz Khan, Swati Singhvi, Stefan Stanciulescu, Zhouhao Wang, Vladimir Filkov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 06:17:54</h6>
<p class='card-text'>Many OSS projects join foundations such as Apache, Eclipse, and OSGeo, to aid their immediate plans and improve long-term prospects by getting governance advice, incubation support, and community-building mechanisms. But foundations differ in their policies, funding models, and support strategies. Moreover, since projects joining these foundations are diverse, coming at different lifecycle stages and having different needs, it can be challenging to decide on the appropriate project-foundation match and on the project-specific plan for sustainability.
  Here, we present an empirical study and quantitative analysis of the sustainability of incubator projects in the Apache, Eclipse, and OSGeo foundations, and, additionally, of OSS projects from GitHub outside of foundations. We develop foundation-specific sustainability models and a project triage, based on projects' sociotechnical trace profiles, and demonstrate their effectiveness across the foundations. Our results show that our models with triage can effectively forecast sustainability outcomes not only within but across foundations. In addition, the generalizability of the framework allows us to apply the approach to GitHub projects outside the foundations. We complement our findings with actionable recovery strategies from previous work and apply them to case studies of failed incubator projects. Our study highlights the value of sociotechnical frameworks in characterizing and addressing software project sustainability issues.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17098v1' target='_blank'>Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Srijan Sood, Kassiani Papasotiriou, Marius Vaiciulis, Tucker Balch</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 05:47:23</h6>
<p class='card-text'>Portfolio Management is the process of overseeing a group of investments, referred to as a portfolio, with the objective of achieving predetermined investment goals. Portfolio optimization is a key component that involves allocating the portfolio assets so as to maximize returns while minimizing risk taken. It is typically carried out by financial professionals who use a combination of quantitative techniques and investment expertise to make decisions about the portfolio allocation.
  Recent applications of Deep Reinforcement Learning (DRL) have shown promising results when used to optimize portfolio allocation by training model-free agents on historical market data. Many of these methods compare their results against basic benchmarks or other state-of-the-art DRL agents but often fail to compare their performance against traditional methods used by financial professionals in practical settings. One of the most commonly used methods for this task is Mean-Variance Portfolio Optimization (MVO), which uses historical time series information to estimate expected asset returns and covariances, which are then used to optimize for an investment objective.
  Our work is a thorough comparison between model-free DRL and MVO for optimal portfolio allocation. We detail the specifics of how to make DRL for portfolio optimization work in practice, also noting the adjustments needed for MVO. Backtest results demonstrate strong performance of the DRL agent across many metrics, including Sharpe ratio, maximum drawdowns, and absolute returns.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17049v1' target='_blank'>IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seoyoung Lee, Seobin Yoon, Seongbeen Lee, Yoojung Chun, Dayoung Park, Doyeon Kim, Joo Yong Sim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 03:42:15</h6>
<p class='card-text'>Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate over shared memory that abstracts raw interaction traces into multi-view intent representations and reusable skills. At runtime, intent prototypes retrieve subgroup-aligned skills and inject them into partial plans, reducing redundant re-planning and mitigating error propagation across desktop applications. In end-to-end evaluations, IntentCUA achieved a 74.83% task success rate with a Step Efficiency Ratio of 0.91, outperforming RL-based and trajectory-centric baselines. Ablations show that multi-view intent abstraction and shared plan memory jointly improve execution stability, with the cooperative multi-agent loop providing the largest gains on long-horizon tasks. These results highlight that system-level intent abstraction and memory-grounded coordination are key to reliable and efficient desktop automation in large, dynamic environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.17034v1' target='_blank'>Using Time Series Measures to Explore Family Planning Survey Data and Model-based Estimates</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oluwayomi Akinfenwa, Niamh Cahill, Catherine Hurley</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 03:01:17</h6>
<p class='card-text'>Family planning is a global development priority and a key indicator of reproductive health. Monitoring progress is challenged by gaps in survey data across countries. The United Nations Population Division addresses this with the Family Planning Estimation Model (FPEM), a Bayesian hierarchical time series model producing annual estimates of modern contraceptive use while sharing information across countries and regions. This paper evaluates how well FPEM estimates align with survey data using time series diagnostic indices from the wdiexplorer R package, which account for countries nested within sub-regions. Visualisation of survey data, modelled trajectories, and diagnostics enables assessment of model performance, highlighting where trends align and where discrepancies occur.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16969v1' target='_blank'>Robust and Extensible Measurement of Broadband Plans with BQT+</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Laasya Koduru, Sylee Beltiukov, Alexander Nguyen, Eugene Vuong, Jaber Daneshamooz, Tejas Narechania, Elizabeth Belding, Arpit Gupta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-19 00:15:33</h6>
<p class='card-text'>Independent, street address-level broadband data is essential for evaluating Internet infrastructure investments, such as the $42B Broadband Equity, Access, and Deployment (BEAD) program. Evaluating these investments requires longitudinal visibility into broadband availability, quality, and affordability, including data on pre-disbursement baselines and changes in providers' advertised plans. While such data can be obtained through Internet Service Provider (ISP) web interfaces, these workloads impose three fundamental system requirements: robustness to frequent interface evolution, extensibility across hundreds of providers, and low technical overhead for non-expert users. Existing systems fail to meet these three essential requirements.
  We present BQT+, a broadband plan measurement framework that replaces monolithic workflows with declarative state/action specifications. BQT+ models querying intent as an interaction state space, formalized as an abstract nondeterministic finite automaton (NFA), and selects execution paths at runtime to accommodate alternative interaction flows and localized interface changes. We show that BQT+ sustains longitudinal monitoring of 64 ISPs, supporting querying for over 100 ISPs. We apply it to two policy studies: constructing a BEAD pre-disbursement baseline and benchmarking broadband affordability across over 124,000 addresses in four states.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16964v1' target='_blank'>SAGE: Structure Aware Graph Expansion for Retrieval of Heterogeneous Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Prasham Titiya, Rohit Khoja, Tomer Wolfson, Vivek Gupta, Dan Roth</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 23:57:19</h6>
<p class='card-text'>Retrieval-augmented question answering over heterogeneous corpora requires connected evidence across text, tables, and graph nodes. While entity-level knowledge graphs support structured access, they are costly to construct and maintain, and inefficient to traverse at query time. In contrast, standard retriever-reader pipelines use flat similarity search over independently chunked text, missing multi-hop evidence chains across modalities. We propose SAGE (Structure Aware Graph Expansion) framework that (i) constructs a chunk-level graph offline using metadata-driven similarities with percentile-based pruning, and (ii) performs online retrieval by running an initial baseline retriever to obtain k seed chunks, expanding first-hop neighbors, and then filtering the neighbors using dense+sparse retrieval, selecting k' additional chunks. We instantiate the initial retriever using hybrid dense+sparse retrieval for implicit cross-modal corpora and SPARK (Structure Aware Planning Agent for Retrieval over Knowledge Graphs) an agentic retriever for explicit schema graphs. On OTT-QA and STaRK, SAGE improves retrieval recall by 5.7 and 8.5 points over baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16893v1' target='_blank'>CalmReminder: A Design Probe for Parental Engagement with Children with Hyperactivity, Augmented by Real-Time Motion Sensing with a Watch</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Riku Arakawa, Shreya Bali, Anupama Sitaraman, Woosuk Seo, Sam Shaaban, Oliver Lindheim, Traci M. Kennedy, Mayank Goel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 21:20:24</h6>
<p class='card-text'>Families raising children with ADHD often experience heightened stress and reactive parenting. While digital interventions promise personalization, many remain one-size-fits-all and fail to reflect parents' lived practices. We present CalmReminder, a watch-based system that detects children's calm moments and delivers just-in-time prompts to parents. Through a four-week deployment with 16 families (twelve completed) of children with ADHD, we compared notification strategies ranging from hourly to random to only when the child was inferred to be calm. Our sensing-based notifications were frequently perceived as arriving during calm moments. More importantly, parents adopted the system in diverse ways: using notifications for praise, mindfulness, activity planning, or conversation. These findings show that parents are not passive recipients but active designers, reshaping interventions to fit their parenting styles. We contribute a calm detection pipeline, empirical insights into families' flexible appropriation of notifications, and design implications for intervention systems that foster agency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16866v1' target='_blank'>On the Tightness of the Second-Order Cone Relaxation of the Optimal Power Flow with Angles Recovery in Meshed Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ginevra Larroux, Matthieu Jacobs, Mario Paolone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 20:49:15</h6>
<p class='card-text'>This letter investigates properties of the second-order cone relaxation of the optimal power flow (OPF) problem, with emphasis on relaxation tightness, nodal voltage angles recovery, and alternating-current-OPF feasibility in meshed networks. The theoretical discussion is supported by numerical experiments on standard IEEE test cases. Implications for power system planning are briefly outlined.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16858v1' target='_blank'>GDEV-AI: A Generalized Evaluation of Deep Learning Inference Scaling and Architectural Saturation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kathiravan Palaniappan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 20:34:45</h6>
<p class='card-text'>The deployment of deep learning inference in production environments continues to grow, where throughput, latency, and hardware efficiency are critical. Although specialized accelerators are increasingly adopted, many inference workloads still run on CPU-only systems, particularly in legacy data centers and cost-sensitive environments. This study investigates the scalability limits of CPU-based inference for convolutional neural networks by benchmarking ResNet models across varying batch sizes on two hardware tiers: a legacy Intel Xeon E5-2403 v2 processor and a modern Intel Xeon 6 "Granite Rapids" platform.
  Results show that legacy CPUs quickly reach throughput saturation, with limited scaling beyond small batch sizes due to instruction-level and memory constraints. In contrast, the Granite Rapids system leverages Intel Advanced Matrix Extensions (AMX) to achieve substantially higher throughput. However, oversubscription beyond physical core limits introduces execution contention and tail-latency amplification, revealing a performance degradation regime in modern architectures.
  We introduce GDEV-AI, a reproducible benchmarking framework for analyzing scalability behavior and architectural saturation in CPU-based inference. By establishing a vendor-neutral baseline, this work provides empirical insight into performance bottlenecks and informs capacity planning in heterogeneous data center environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16825v1' target='_blank'>RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ahmad Ahmad, Shuo Liu, Roberto Tron, Calin Belta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 19:45:43</h6>
<p class='card-text'>Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-dimensional configuration spaces. When combined with Signal Temporal Logic (STL), a temporal logic widely used for formalizing interpretable robotic tasks, these methods can address complex spatiotemporal constraints. However, traditional approaches rely on min-max robustness measures that focus only on critical time points and subformulae, creating non-smooth optimization landscapes with sharp decision boundaries that hinder efficient tree exploration.
  We propose RRT$^η$, a sampling-based planning framework that integrates the Arithmetic-Geometric Mean (AGM) robustness measure to evaluate satisfaction across all time points and subformulae. Our key contributions include: (1) AGM robustness interval semantics for reasoning about partial trajectories during tree construction, (2) an efficient incremental monitoring algorithm computing these intervals, and (3) enhanced Direction of Increasing Satisfaction vectors leveraging Fulfillment Priority Logic (FPL) for principled objective composition. Our framework synthesizes dynamically feasible control sequences satisfying STL specifications with high robustness while maintaining the probabilistic completeness and asymptotic optimality of RRT$^\ast$. We validate our approach on three robotic systems. A double integrator point robot, a unicycle mobile robot, and a 7-DOF robot arm, demonstrating superior performance over traditional STL robustness-based planners in multi-constraint scenarios with limited guidance signals.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16669v1' target='_blank'>PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bo Lang, Nirav Savaliya, Zhihao Zheng, Jinglun Feng, Zheng-Hang Yeh, Mooi Choo Chuah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 18:08:26</h6>
<p class='card-text'>High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16534v1' target='_blank'>Quantum Estimation Theory Limits in Neutrino Oscillation Experiments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Claudia Frugiuele, Marco G. Genoni, Michela Ignoti, Matteo G. A. Paris</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 15:25:56</h6>
<p class='card-text'>Measurements of the Pontecorvo-Maki-Nakagawa-Sakata (PMNS) neutrino mixing parameters have entered a precision era, enabling increasingly stringent tests of neutrino oscillations. Within the framework of quantum estimation theory, we investigate whether flavor measurements, the only observables currently accessible experimentally, are optimal for extracting the oscillation parameters. We compute the Quantum Fisher Information (QFI) and the classical Fisher Information (FI) associated with ideal flavor projections for all oscillation parameters, considering accelerator muon (anti)neutrino and reactor electron antineutrino beams propagating in vacuum. Two main results emerge. First, flavor measurements saturate the QFI at the first oscillation maximum for $θ_{13}$, $θ_{23}$, and $θ_{12}$, demonstrating their information-theoretic optimality for these parameters. In contrast, they are far from optimal for $δ_{CP}$. In particular, only a small fraction of the available information on $δ_{CP}$ is extracted at the first maximum; the sensitivity improves at the second maximum, in line with the strategy of ESS$ν$SB, a planned facility. Second, the QFI associated with $δ_{CP}$ is approximately one order of magnitude smaller than that of the mixing angles, indicating that the neutrino state intrinsically encodes less information about CP violation. Nevertheless, this quantum bound lies well below current experimental uncertainties, implying that the present precision on $δ_{CP}$ is not fundamentally limited. Our results provide a quantitative framework to disentangle fundamental from practical limitations and establish a benchmark for optimizing future neutrino facilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16462v1' target='_blank'>Reactive Motion Generation With Particle-Based Perception in Dynamic Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiyuan Zhao, Huijun Li, Lifeng Zhu, Zhikai Wei, Xianyi Zhu, Aiguo Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 13:48:54</h6>
<p class='card-text'>Reactive motion generation in dynamic and unstructured scenarios is typically subject to essentially static perception and system dynamics. Reliably modeling dynamic obstacles and optimizing collision-free trajectories under perceptive and control uncertainty are challenging. This article focuses on revealing tight connection between reactive planning and dynamic mapping for manipulators from a model-based perspective. To enable efficient particle-based perception with expressively dynamic property, we present a tensorized particle weight update scheme that explicitly maintains obstacle velocities and covariance meanwhile. Building upon this dynamic representation, we propose an obstacle-aware MPPI-based planning formulation that jointly propagates robot-obstacle dynamics, allowing future system motion to be predicted and evaluated under uncertainty. The model predictive method is shown to significantly improve safety and reactivity with dynamic surroundings. By applying our complete framework in simulated and noisy real-world environments, we demonstrate that explicit modeling of robot-obstacle dynamics consistently enhances performance over state-of-the-art MPPI-based perception-planning baselines avoiding multiple static and dynamic obstacles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16415v1' target='_blank'>The Astronomical Telescope of the University of Stuttgart (ATUS): Development, Optimization, and Lessons Learned</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karsten Schindler, Jürgen Wolf, Alfred Krabbe</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 12:46:01</h6>
<p class='card-text'>ATUS, the Astronomical Telescope of the University of Stuttgart, is a fully remote-controlled 0.6 m f/8.17 Ritchey-Chrétien telescope optimized for high-cadence, high-fidelity photometry of transient sources. Observations are time-referenced with very high accuracy and precision, making it an ideal platform for time-domain astronomy and space situational awareness. Initially conceived to support instrument developments and operations of SOFIA, the Stratospheric Observatory for Infrared Astronomy, it evolved into a scientific instrument for various use cases in instrument development, astronomical research, and teaching. This paper presents an overview of its development and optimization to achieve diffraction-limited images and highly accurate pointing and tracking, even at high speeds. The findings and lessons learned are universally applicable to other telescopes that are currently at the planning stage, or where similar issues might be encountered.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16321v1' target='_blank'>End-user validation of BRIGHT with custom-developed graphical user interface applied to cervical cancer brachytherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Leah R. M. Dickhoff, Ellen M. Kerkhof, Heloisa H. Deuzeman, Laura A. Velema, Stephanie M. de Boer, Lavinia A. L. Verhagen, Danique L. J. Barten, Bradley R. Pieters, Lukas J. A. Stalpers, Renzo J. Scholman, Pedro M. Matos, Anton Bouter, Carien L. Creutzberg, Peter A. N. Bosman, Tanja Alderliesten</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 10:01:21</h6>
<p class='card-text'>Multi-objective optimisation using BRIGHT has proven insightful and effective in prostate cancer brachytherapy treatment planning. BRachytherapy via artificially Intelligent GOMEA-Heuristic based Treatment planning (BRIGHT) generates multiple treatment plans, each with a different trade-off between tumour coverage and organs-at-risk sparing. BRIGHT was recently extended to cervical cancer brachytherapy. In this study, we present a novel, custom-developed graphical user interface (GUI) that enables plan navigation, pairwise comparisons, dose distribution visualisation, and possibility for adjustments - essential for efficient clinical use of BRIGHT. End-user validation of BRIGHT with the dedicated GUI was conducted for cervical cancer brachytherapy by emulating clinical practice in ten previously treated patients. A multidisciplinary brachytherapy team used BRIGHT to create new treatment plans. GUI usability was assessed using the System Usability Scale (SUS). BRIGHT plan quality was compared to clinical practice via blinded one-on-one comparisons. The GUI offered helpful features for plan navigation and evaluation, giving users quick insight into whether planning aims are achievable and what treatment options are available. The overall SUS score was 83.3, indicating an 'excellent' system. BRIGHT outperformed clinical practice in five out of ten patients regarding the coverage-sparing trade-off and performed equally well in the remaining five. The BRIGHT plan was preferred over the clinical plan in eight out of ten patients, four of which showed clinically relevant differences. The clinical plan was preferred in two patients, neither with clinically relevant differences. In conclusion, BRIGHT, with its dedicated GUI, is a clinically viable and user-friendly tool for treatment planning in cervical cancer brachytherapy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16313v1' target='_blank'>MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zexue He, Yu Wang, Churan Zhi, Yuanzhe Hu, Tzu-Ping Chen, Lang Yin, Ze Chen, Tong Arthur Wu, Siru Ouyang, Zihan Wang, Jiaxin Pei, Julian McAuley, Yejin Choi, Alex Pentland</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 09:49:14</h6>
<p class='card-text'>Existing evaluations of agents with memory typically assess memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past conversations or text but fails to capture how memory is used to guide future decisions. Another class focuses on agents acting in single-session tasks without the need for long-term memory. However, in realistic settings, memorization and action are tightly coupled: agents acquire memory while interacting with the environment, and subsequently rely on that memory to solve future tasks. To capture this setting, we introduce MemoryArena, a unified evaluation gym for benchmarking agent memory in multi-session Memory-Agent-Environment loops. The benchmark consists of human-crafted agentic tasks with explicitly interdependent subtasks, where agents must learn from earlier actions and feedback by distilling experiences into memory, and subsequently use that memory to guide later actions to solve the overall task. MemoryArena supports evaluation across web navigation, preference-constrained planning, progressive information search, and sequential formal reasoning, and reveals that agents with near-saturated performance on existing long-context memory benchmarks like LoCoMo perform poorly in our agentic setting, exposing a gap in current evaluations for agents with memory.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16265v2' target='_blank'>On sparsity, extremal structure, and monotonicity properties of Wasserstein and Gromov-Wasserstein optimal transport plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Titouan Vayer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 08:35:36</h6>
<p class='card-text'>This note gives a self-contained overview of some important properties of the Gromov-Wasserstein (GW) distance, compared with the standard linear optimal transport (OT) framework. More specifically, I explore the following questions: are GW optimal transport plans sparse? Under what conditions are they supported on a permutation? Do they satisfy a form of cyclical monotonicity? In particular, I present the conditionally negative semi-definite property and show that, when it holds, there are GW optimal plans that are sparse and supported on a permutation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2602.16238v1' target='_blank'>EasyControlEdge: A Foundation-Model Fine-Tuning for Edge Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hiroki Nakamura, Hiroto Iino, Masashi Okada, Tadahiro Taniguchi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2026-02-18 07:28:09</h6>
<p class='card-text'>We propose EasyControlEdge, adapting an image-generation foundation model to edge detection. In real-world edge detection (e.g., floor-plan walls, satellite roads/buildings, and medical organ boundaries), crispness and data efficiency are crucial, yet producing crisp raw edge maps with limited training samples remains challenging. Although image-generation foundation models perform well on many downstream tasks, their pretrained priors for data-efficient transfer and iterative refinement for high-frequency detail preservation remain underexploited for edge detection. To enable crisp and data-efficient edge detection using these capabilities, we introduce an edge-specialized adaptation of image-generation foundation models. To better specialize the foundation model for edge detection, we incorporate an edge-oriented objective with an efficient pixel-space loss. At inference, we introduce guidance based on unconditional dynamics, enabling a single model to control the edge density through a guidance scale. Experiments on BSDS500, NYUDv2, BIPED, and CubiCasa compare against state-of-the-art methods and show consistent gains, particularly under no-post-processing crispness evaluation and with limited training data.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>