<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-07-14</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-07-14</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08724v1' target='_blank'>Computing optimal trajectories for a tethered pursuer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aurelio Barrera-Vicent, José Miguel Díaz-Báñez, Fabio Rodríguez, Vanesa Sánchez-Canales</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 16:24:23</h6>
<p class='card-text'>In this paper, we introduce a trajectory planning problem for a marsupial
robotics system consisting of a ground robot, a drone, and a taut tether of
bounded length connecting the two robots. This problem can be framed within the
context of a pursuit-evasion game. Using a geometric modeling approach, we
present an optimal algorithm to compute a minimum-link path for the pursuer
(ground robot), given the known path of the evader (drone). Furthermore, we
address and solve three related geometric optimization problems, leveraging the
intrinsic connections between them.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08688v1' target='_blank'>Rapid MRI-Based Synthetic CT Simulations for Precise tFUS Targeting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hengyu Gao, Shaodong Ding, Ziyang Liu, Jiefu Zhang, Bolun Li, Zhiwu An, Li Wang, Jing Jing, Tao Liu, Yubo Fan, Zhongtao Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 15:38:19</h6>
<p class='card-text'>Accurate targeting is critical for the effectiveness of transcranial focused
ultrasound (tFUS) neuromodulation. While CT provides accurate skull acoustic
properties, its ionizing radiation and poor soft tissue contrast limit clinical
applicability. In contrast, MRI offers superior neuroanatomical visualization
without radiation exposure but lacks skull property mapping. This study
proposes a novel, fully CT free simulation framework that integrates
MRI-derived synthetic CT (sCT) with efficient modeling techniques for rapid and
precise tFUS targeting. We trained a deep-learning model to generate sCT from
T1-weighted MRI and integrated it with both full-wave (k-Wave) and accelerated
simulation methods, hybrid angular spectrum (kWASM) and Rayleigh-Sommerfeld ASM
(RSASM). Across five skull models, both full-wave and hybrid pipelines using
sCT demonstrated sub-millimeter targeting deviation, focal shape consistency
(FWHM ~3.3-3.8 mm), and <0.2 normalized pressure error compared to CT-based
gold standard. Notably, the kW-ASM and RS-ASM pipelines reduced simulation time
from ~3320 s to 187 s and 34 s respectively, achieving ~94% and ~90% time
savings. These results confirm that MRI-derived sCT combined with innovative
rapid simulation techniques enables fast, accurate, and radiation-free tFUS
planning, supporting its feasibility for scalable clinical applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08667v1' target='_blank'>The IceCube-Gen2 Collaboration -- Contributions to the 39th
  International Cosmic Ray Conference (ICRC2025)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:R. Abbasi, M. Ackermann, J. Adams, S. K. Agarwalla, J. A. Aguilar, M. Ahlers, J. M. Alameddine, S. Ali, N. M. Amin, K. Andeen, G. Anton, C. Argüelles, Y. Ashida, S. Athanasiadou, J. Audehm, S. N. Axani, R. Babu, X. Bai, A. Balagopal V., M. Baricevic, S. W. Barwick, V. Basu, R. Bay, J. Becker Tjus, P. Behrens, J. Beise, C. Bellenghi, B. Benkel, S. BenZvi, D. Berley, E. Bernardini, D. Z. Besson, A. Bishop, E. Blaufuss, L. Bloom, S. Blot, M. Bohmer, F. Bontempo, J. Y. Book Motzkin, J. Borowka, C. Boscolo Meneguolo, S. Böser, O. Botner, J. Böttcher, S. Bouma, J. Braun, B. Brinson, Z. Brisson-Tsavoussis, R. T. Burley, M. Bustamante, D. Butterfield, M. A. Campana, K. Carloni, M. Cataldo, S. Chattopadhyay, N. Chau, Z. Chen, D. Chirkin, S. Choi, B. A. Clark, R. Clark, A. Coleman, P. Coleman, G. H. Collin, D. A. Coloma Borja, J. M. Conrad, R. Corley, D. F. Cowen, C. Deaconu, C. De Clercq, S. De Kockere, J. J. DeLaunay, D. Delgado, T. Delmeulle, S. Deng, A. Desai, P. Desiati, K. D. de Vries, G. de Wasseige, J. C. Díaz-Vélez, S. DiKerby, M. Dittmer, G. Do, A. Domi, L. Draper, L. Dueser, H. Dujmovic, D. Durnford, K. Dutta, M. A. DuVernois, T. Egby, T. Ehrhardt, L. Eidenschink, A. Eimer, P. Eller, E. Ellinger, D. Elsässer, R. Engel, H. Erpenbeck, W. Esmail, S. Eulig, J. Evans, J. J. Evans, P. A. Evenson, K. L. Fan, K. Fang, K. Farrag, A. R. Fazely, A. Fedynitch, N. Feigl, C. Finley, L. Fischer, B. Flaggs, D. Fox, A. Franckowiak, T. Fujii, S. Fukami, P. Fürst, J. Gallagher, E. Ganster, A. Garcia, G. Garg, E. Genton, L. Gerhardt, A. Ghadimi, P. Giri, C. Glaser, T. Glüsenkamp, S. Goswami, A. Granados, D. Grant, S. J. Gray, S. Griffin, S. Griswold, D. Guevel, C. Günther, P. Gutjahr, C. Ha, C. Haack, A. Hallgren, S. Hallmann, L. Halve, F. Halzen, L. Hamacher, M. Ha Minh, M. Handt, K. Hanson, J. Hardin, A. A. Harnisch, P. Hatch, A. Haungs, J. Häußler, D. Heinen, K. Helbing, J. Hellrung, B. Hendricks, B. Henke, L. Hennig, F. Henningsen, J. Henrichs, L. Heuermann, N. Heyer, S. Hickford, A. Hidvegi, C. Hill, G. C. Hill, K. D. Hoffman, B. Hoffmann, D. Hooper, S. Hori, K. Hoshina, M. Hostert, W. Hou, T. Huber, T. Huege, E. Huesca Santiago, K. Hultqvist, R. Hussain, K. Hymon, A. Ishihara, T. Ishii, W. Iwakiri, M. Jacquart, S. Jain, A. Jaitly, O. Janik, M. Jansson, M. Jeong, M. Jin, O. Kalekin, N. Kamp, D. Kang, W. Kang, X. Kang, A. Kappes, L. Kardum, T. Karg, M. Karl, A. Karle, A. Katil, T. Katori, U. Katz, M. Kauer, J. L. Kelley, M. Khanal, A. Khatee Zathul, A. Kheirandish, J. Kiryluk, M. Kleifges, C. Klein, S. R. Klein, T. Kobayashi, Y. Kobayashi, A. Kochocki, H. Kolanoski, T. Kontrimas, L. Köpke, C. Kopper, D. J. Koskinen, P. Koundal, M. Kowalski, T. Kozynets, I. Kravchenko, N. Krieger, J. Krishnamoorthi, T. Krishnan, E. Krupczak, A. Kumar, E. Kun, N. Kurahashi, N. Lad, L. Lallement Arnaud, M. J. Larson, F. Lauber, K. Leonard DeHolton, A. Leszczyńska, J. Liao, M. Liu, M. Liubarska, M. Lohan, J. LoSecco, C. Love, L. Lu, F. Lucarelli, Y. Lyu, J. Madsen, E. Magnus, K. B. M. Mahn, Y. Makino, E. Manao, S. Mancina, S. Mandalia, W. Marie Sainte, I. C. Mariş, S. Marka, Z. Marka, M. Marsee, L. Marten, I. Martinez-Soler, R. Maruyama, F. Mayhew, F. McNally, J. V. Mead, K. Meagher, S. Mechbal, A. Medina, M. Meier, Y. Merckx, L. Merten, Z. Meyers, M. Mikhailova, A. Millsop, J. Mitchell, T. Montaruli, R. W. Moore, Y. Morii, R. Morse, A. Mosbrugger, M. Moulai, D. Mousadi, T. Mukherjee, M. Muzio, R. Naab, M. Nakos, A. Narayan, U. Naumann, J. Necker, A. Nelles, L. Neste, M. Neumann, H. Niederhausen, M. U. Nisa, K. Noda, A. Noell, A. Novikov, E. Oberla, A. Obertacke Pollmann, V. O'Dell, A. Olivas, R. Orsoe, J. Osborn, E. O'Sullivan, V. Palusova, L. Papp, A. Parenti, N. Park, E. N. Paudel, L. Paul, C. Pérez de los Heros, T. Pernice, T. C. Petersen, J. Peterson, A. Pizzuto, M. Plum, A. Pontén, Y. Popovych, M. Prado Rodriguez, B. Pries, R. Procter-Murphy, G. T. Przybylski, L. Pyras, J. Rack-Helleis, N. Rad, M. Rameez, M. Ravn, K. Rawlins, Z. Rechav, A. Rehman, E. Resconi, S. Reusch, C. D. Rho, W. Rhode, B. Riedel, M. Riegel, A. Rifaie, E. J. Roberts, S. Robertson, M. Rongen, C. Rott, T. Ruhe, L. Ruohan, D. Ryckbosch, I. Safa, J. Saffer, D. Salazar-Gallegos, P. Sampathkumar, A. Sandrock, P. Sandstrom, G. Sanger-Johnson, M. Santander, S. Sarkar, J. Savelberg, P. Savina, P. Schaile, M. Schaufel, H. Schieler, S. Schindler, L. Schlickmann, B. Schlüter, F. Schlüter, N. Schmeisser, T. Schmidt, F. G. Schröder, L. Schumacher, S. Schwirn, S. Sclafani, D. Seckel, L. Seen, M. Seikh, Z. Selcuk, S. Seunarine, M. H. Shaevitz, R. Shah, S. Shefali, N. Shimizu, M. Silva, B. Skrzypek, R. Snihur, J. Soedingrekso, A. Søgaard, D. Soldin, P. Soldin, G. Sommani, C. Spannfellner, G. M. Spiczak, C. Spiering, J. Stachurska, M. Stamatikos, T. Stanev, T. Stezelberger, J. Stoffels, T. Stürwald, T. Stuttard, G. W. Sullivan, I. Taboada, A. Taketa, T. Tamang, H. K. M. Tanaka, S. Ter-Antonyan, A. Terliuk, M. Thiesmeyer, W. G. Thompson, J. Thwaites, S. Tilav, K. Tollefson, J. Torres, S. Toscano, D. Tosi, A. Trettin, Y. Tsunesada, J. P. Twagirayezu, A. K. Upadhyay, K. Upshaw, A. Vaidyanathan, N. Valtonen-Mattila, J. Valverde, J. Vandenbroucke, T. van Eeden, N. van Eijndhoven, L. van Rootselaar, J. van Santen, F. J. Vara Carbonell, F. Varsi, D. Veberic, J. Veitch-Michaelis, M. Venugopal, S. Vergara Carrasco, S. Verpoest, A. Vieregg, A. Vijai, J. Villarreal, C. Walck, A. Wang, D. Washington, C. Weaver, P. Weigel, A. Weindl, J. Weldert, A. Y. Wen, C. Wendt, J. Werthebach, M. Weyrauch, N. Whitehorn, C. H. Wiebusch, D. R. Williams, S. Wissel, L. Witthaus, M. Wolf, G. Wörner, G. Wrede, S. Wren, X. W. Xu, J. P. Yañez, Y. Yao, E. Yildizci, S. Yoshida, R. Young, F. Yu, S. Yu, T. Yuan, A. Zegarelli, S. Zhang, Z. Zhang, P. Zhelnin, S. Zierke, P. Zilberman, M. Zimmerman, IceCube-Gen2 Collaboration</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 15:06:48</h6>
<p class='card-text'>IceCube-Gen2 is a planned next-generation neutrino observatory at the South
Pole that builds upon the successful design of IceCube. Integrating two
complementary detection technologies for neutrinos, optical and radio Cherenkov
emission, in combination with a surface array for cosmic-ray air shower
detection, IceCube-Gen2 will cover a broad neutrino energy range from MeV to
EeV. This index of contributions to the 39th International Cosmic Ray
Conference in Geneva, Switzerland (July 15-24, 2025) describes research and
development efforts for IceCube-Gen2. Included are summaries of the design,
status, and sensitivity of the IceCube-Gen2 optical, surface, and radio
components; performance studies of next-generation surface detectors and in-ice
optical sensors; advanced reconstruction techniques of cosmic-ray air showers
and neutrino events; sustainability and environmental impact; and sensitivity
studies of astrophysical neutrino fluxes and cosmic-ray physics. Contributions
related to IceCube and the scheduled IceCube Upgrade are available in a
separate collection.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08666v1' target='_blank'>The IceCube Collaboration -- Contributions to the 39th International
  Cosmic Ray Conference (ICRC2025)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:R. Abbasi, M. Ackermann, J. Adams, S. K. Agarwalla, J. A. Aguilar, M. Ahlers, J. M. Alameddine, S. Ali, N. M. Amin, K. Andeen, C. Argüelles, Y. Ashida, S. Athanasiadou, S. N. Axani, R. Babu, X. Bai, J. Baines-Holmes, A. Balagopal V., S. W. Barwick, S. Bash, V. Basu, R. Bay, J. J. Beatty, J. Becker Tjus, P. Behrens, J. Beise, C. Bellenghi, B. Benkel, S. BenZvi, D. Berley, E. Bernardini, D. Z. Besson, E. Blaufuss, L. Bloom, S. Blot, I. Bodo, F. Bontempo, J. Y. Book Motzkin, C. Boscolo Meneguolo, S. Böser, O. Botner, J. Böttcher, J. Braun, B. Brinson, Z. Brisson-Tsavoussis, R. T. Burley, D. Butterfield, M. A. Campana, K. Carloni, J. Carpio, S. Chattopadhyay, N. Chau, Z. Chen, D. Chirkin, S. Choi, B. A. Clark, A. Coleman, P. Coleman, G. H. Collin, D. A. Coloma Borja, A. Connolly, J. M. Conrad, R. Corley, D. F. Cowen, C. De Clercq, J. J. DeLaunay, D. Delgado, T. Delmeulle, S. Deng, P. Desiati, K. D. de Vries, G. de Wasseige, T. DeYoung, J. C. Díaz-Vélez, S. DiKerby, M. Dittmer, A. Domi, L. Draper, L. Dueser, D. Durnford, K. Dutta, M. A. DuVernois, T. Ehrhardt, L. Eidenschink, A. Eimer, P. Eller, E. Ellinger, D. Elsässer, R. Engel, H. Erpenbeck, W. Esmail, S. Eulig, J. Evans, P. A. Evenson, K. L. Fan, K. Fang, K. Farrag, A. R. Fazely, A. Fedynitch, N. Feigl, C. Finley, L. Fischer, D. Fox, A. Franckowiak, S. Fukami, P. Fürst, J. Gallagher, E. Ganster, A. Garcia, M. Garcia, G. Garg, E. Genton, L. Gerhardt, A. Ghadimi, C. Glaser, T. Glüsenkamp, J. G. Gonzalez, S. Goswami, A. Granados, D. Grant, S. J. Gray, S. Griffin, S. Griswold, K. M. Groth, D. Guevel, C. Günther, P. Gutjahr, C. Ha, C. Haack, A. Hallgren, L. Halve, F. Halzen, L. Hamacher, M. Ha Minh, M. Handt, K. Hanson, J. Hardin, A. A. Harnisch, P. Hatch, A. Haungs, J. Häußler, K. Helbing, J. Hellrung, B. Henke, L. Hennig, F. Henningsen, L. Heuermann, R. Hewett, N. Heyer, S. Hickford, A. Hidvegi, C. Hill, G. C. Hill, R. Hmaid, K. D. Hoffman, D. Hooper, S. Hori, K. Hoshina, M. Hostert, W. Hou, T. Huber, K. Hultqvist, K. Hymon, A. Ishihara, W. Iwakiri, M. Jacquart, S. Jain, O. Janik, M. Jansson, M. Jeong, M. Jin, N. Kamp, D. Kang, W. Kang, X. Kang, A. Kappes, L. Kardum, T. Karg, M. Karl, A. Karle, A. Katil, M. Kauer, J. L. Kelley, M. Khanal, A. Khatee Zathul, A. Kheirandish, H. Kimku, J. Kiryluk, C. Klein, S. R. Klein, Y. Kobayashi, A. Kochocki, R. Koirala, H. Kolanoski, T. Kontrimas, L. Köpke, C. Kopper, D. J. Koskinen, P. Koundal, M. Kowalski, T. Kozynets, N. Krieger, J. Krishnamoorthi, T. Krishnan, K. Kruiswijk, E. Krupczak, A. Kumar, E. Kun, N. Kurahashi, N. Lad, C. Lagunas Gualda, L. Lallement Arnaud, M. Lamoureux, M. J. Larson, F. Lauber, J. P. Lazar, K. Leonard DeHolton, A. Leszczyńska, J. Liao, C. Lin, Y. T. Liu, M. Liubarska, C. Love, L. Lu, F. Lucarelli, W. Luszczak, Y. Lyu, J. Madsen, E. Magnus, K. B. M. Mahn, Y. Makino, E. Manao, S. Mancina, A. Mand, I. C. Mariş, S. Marka, Z. Marka, L. Marten, I. Martinez-Soler, R. Maruyama, J. Mauro, F. Mayhew, F. McNally, J. V. Mead, K. Meagher, S. Mechbal, A. Medina, M. Meier, Y. Merckx, L. Merten, J. Mitchell, L. Molchany, T. Montaruli, R. W. Moore, Y. Morii, A. Mosbrugger, M. Moulai, D. Mousadi, E. Moyaux, T. Mukherjee, R. Naab, M. Nakos, U. Naumann, J. Necker, L. Neste, M. Neumann, H. Niederhausen, M. U. Nisa, K. Noda, A. Noell, A. Novikov, A. Obertacke Pollmann, V. O'Dell, A. Olivas, R. Orsoe, J. Osborn, E. O'Sullivan, V. Palusova, H. Pandya, A. Parenti, N. Park, V. Parrish, E. N. Paudel, L. Paul, C. Pérez de los Heros, T. Pernice, J. Peterson, M. Plum, A. Pontén, V. Poojyam, Y. Popovych, M. Prado Rodriguez, B. Pries, R. Procter-Murphy, G. T. Przybylski, L. Pyras, C. Raab, J. Rack-Helleis, N. Rad, M. Ravn, K. Rawlins, Z. Rechav, A. Rehman, I. Reistroffer, E. Resconi, S. Reusch, C. D. Rho, W. Rhode, L. Ricca, B. Riedel, A. Rifaie, E. J. Roberts, S. Robertson, M. Rongen, A. Rosted, C. Rott, T. Ruhe, L. Ruohan, D. Ryckbosch, J. Saffer, D. Salazar-Gallegos, P. Sampathkumar, A. Sandrock, G. Sanger-Johnson, M. Santander, S. Sarkar, J. Savelberg, M. Scarnera, P. Schaile, M. Schaufel, H. Schieler, S. Schindler, L. Schlickmann, B. Schlüter, F. Schlüter, N. Schmeisser, T. Schmidt, F. G. Schröder, L. Schumacher, S. Schwirn, S. Sclafani, D. Seckel, L. Seen, M. Seikh, S. Seunarine, P. A. Sevle Myhr, R. Shah, S. Shefali, N. Shimizu, B. Skrzypek, R. Snihur, J. Soedingrekso, A. Søgaard, D. Soldin, P. Soldin, G. Sommani, C. Spannfellner, G. M. Spiczak, C. Spiering, J. Stachurska, M. Stamatikos, T. Stanev, T. Stezelberger, T. Stürwald, T. Stuttard, G. W. Sullivan, I. Taboada, S. Ter-Antonyan, A. Terliuk, A. Thakuri, M. Thiesmeyer, W. G. Thompson, J. Thwaites, S. Tilav, K. Tollefson, S. Toscano, D. Tosi, A. Trettin, A. K. Upadhyay, K. Upshaw, A. Vaidyanathan, N. Valtonen-Mattila, J. Valverde, J. Vandenbroucke, T. van Eeden, N. van Eijndhoven, L. van Rootselaar, J. van Santen, F. J. Vara Carbonell, F. Varsi, M. Venugopal, M. Vereecken, S. Vergara Carrasco, S. Verpoest, D. Veske, A. Vijai, J. Villarreal, C. Walck, A. Wang, E. Warrick, C. Weaver, P. Weigel, A. Weindl, J. Weldert, A. Y. Wen, C. Wendt, J. Werthebach, M. Weyrauch, N. Whitehorn, C. H. Wiebusch, D. R. Williams, L. Witthaus, M. Wolf, G. Wrede, X. W. Xu, J. P. Yañez, Y. Yao, E. Yildizci, S. Yoshida, R. Young, F. Yu, S. Yu, T. Yuan, A. Zegarelli, S. Zhang, Z. Zhang, P. Zhelnin, P. Zilberman, IceCube Collaboration</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 15:06:43</h6>
<p class='card-text'>The IceCube Observatory at the South Pole has been operating in its full
configuration since May 2011 with a duty cycle of about 99%. Its main component
consists of a cubic-kilometer array of optical sensors deployed deep in the
Glacial ice designed for the detection of high-energy astrophysical neutrinos.
A surface array for cosmic ray air shower detection, IceTop, and a denser inner
subdetector, DeepCore, significantly enhance the capabilities of the
observatory, making it a multipurpose facility. This list of contributions to
the 39th International Cosmic Ray Conference in Geneva, Switzerland (July
15-24, 2025) summarizes the latest results from IceCube covering a broad set of
key questions in physics and astrophysics. The papers in this index are grouped
topically to highlight IceCube contributions related to high-energy neutrino
and multi-messenger astrophysics, atmospheric fluxes, cosmic-ray physics,
low-energy neutrino transients, physics beyond the Standard Model, detector
calibration and event reconstruction, and the status and performance of the
IceCube Upgrade, a dense sensor infill complemented by calibration devices to
be deployed by the end of 2025. Contributions related to IceCube-Gen2, the
planned future extension of IceCube, are available in a separate collection.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08602v1' target='_blank'>Proposal from the NA61/SHINE Collaboration for update of European
  Strategy for Particle Physics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:NA61/SHINE Collaboration, :, H. Adhikary, P. Adrich, K. K. Allison, N. Amin, E. V. Andronov, I. -C. Arsene, M. Bajda, Y. Balkova, D. Battaglia, A. Bazgir, S. Bhosale, M. Bielewicz, A. Blondel, M. Bogomilov, Y. Bondar, W. Brylinski, J. Brzychczyk, M. Buryakov, A. F. Camino, Y. D. Chandak, M. Csanad, J. Cybowska, T. Czopowicz, C. Dalmazzone, N. Davis, A. Dmitriev, P. von Doetinchem, W. Dominik, J. Dumarchez, R. Engel, G. A. Feofilov, L. Fields, Z. Fodor, M. Friend, M. Gazdzicki, K. E. Gollwitzer, O. Golosov, V. Golovatyuk, M. Golubeva, K. Grebieszkow, F. Guber, P. G. Hurh, S. Ilieva, A. Ivashkin, N. Karpushkin, M. Kiełbowicz, V. A. Kireyeu, R. Kolesnikov, D. Kolev, Y. Koshio, S. Kowalski, B. Kozłowski, A. Krasnoperov, W. Kucewicz, M. Kuchowicz, P. Lasko, A. Laszlo, M. Lewicki, G. Lykasov, J. R. Lyon, V. V. Lyubushkin, M. Mackowiak-Pawłowska, B. Maksiak, A. I. Malakhov, A. Marcinek, A. D. Marino, T. Matulewicz, V. Matveev, G. L. Melkumov, A. Merzlaya, L. Mik, S. Morozov, Y. Nagai, R. Nagy, T. Nakadaira, S. Nishimori, A. Olivier, V. Ozvenchuk, O. Panova, V. Paolone, I. Pidhurskyi, R. Płaneta, P. Podlaski, B. A. Popov, B. Pórfy, D. S. Prokhorova, D. Pszczel, S. Puławski, L. Ren, V. Z. Reyna Ortiz, D. Röhrich, M. Roth, L. Rozpłochowski, M. Rumyantsev, A. Rustamov, M. Rybczynski, A. Rybicki, D. Rybka, K. Sakashita, K. Schmidt, P. Seyboth, U. A. Shah, Y. Shiraishi, A. Shukla, M. Słodkowski, P. Staszel, G. Stefanek, J. Stepaniak, L. Swiderski, J. Szewinski, R. Szukiewicz, A. Taranenko, A. Tefelska, D. Tefelski, V. Tereshchenko, R. Tsenov, L. Turko, T. S. Tveter, M. Unger, M. Urbaniak, D. Veberic, O. Vitiuk, A. Wickremasinghe, K. Witek, K. Wojcik, O. Wyszynski, A. Zaitsev, E. Zherebtsova, E. D. Zimmerman, A. Zviagina</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 13:53:39</h6>
<p class='card-text'>Building on the current program's success and driven by new physics
challenges, the NA61/SHINE Collaboration proposes to continue measuring hadron
production properties in reactions induced by hadron and ion beams after CERN
Long Shutdown 3. These measurements are of significant interest to the
heavy-ion, cosmic-ray, and neutrino physics communities and will focus on: -
Investigating hadron production in the light-ion systems to explore the diagram
of high-energy nuclear collisions, and to obtain new insight into the
unexpected violation of isospin (flavor) symmetry recently observed by the
experiment; - Measuring charm-anticharm correlations to gain unique insights
into the production locality of charm and anticharm quark pairs; - Examining
strangeness and multi-strangeness production to improve our understanding of
the early Universe's evolution and neutron star formation; - Measuring cross
sections relevant for cosmic-ray measurements, significantly boosting searches
for new physics in our Galaxy; - Conducting hadron production measurements with
proton, pion, and kaon beams for neutrino physics, enhancing the precision of
hadron production data needed for initial neutrino flux predictions in neutrino
oscillation experiments; - Measuring hadron production processes relevant for
understanding the flux of atmospheric neutrinos, as well as neutrinos and muons
from spallation sources. To achieve these objectives, a detector upgrade and a
beam upgrade are required, with data-taking planned for the period 2029-2032
and beyond.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08546v1' target='_blank'>RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval
  Using Radiomics Features</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Inye Na, Nejung Rue, Jiwon Chung, Hyunjin Park</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 12:48:25</h6>
<p class='card-text'>Medical image retrieval is a valuable field for supporting clinical
decision-making, yet current methods primarily support 2D images and require
fully annotated queries, limiting clinical flexibility. To address this, we
propose RadiomicsRetrieval, a 3D content-based retrieval framework bridging
handcrafted radiomics descriptors with deep learning-based embeddings at the
tumor level. Unlike existing 2D approaches, RadiomicsRetrieval fully exploits
volumetric data to leverage richer spatial context in medical images. We employ
a promptable segmentation model (e.g., SAM) to derive tumor-specific image
embeddings, which are aligned with radiomics features extracted from the same
tumor via contrastive learning. These representations are further enriched by
anatomical positional embedding (APE). As a result, RadiomicsRetrieval enables
flexible querying based on shape, location, or partial feature sets. Extensive
experiments on both lung CT and brain MRI public datasets demonstrate that
radiomics features significantly enhance retrieval specificity, while APE
provides global anatomical context essential for location-based searches.
Notably, our framework requires only minimal user prompts (e.g., a single
point), minimizing segmentation overhead and supporting diverse clinical
scenarios. The capability to query using either image embeddings or selected
radiomics attributes highlights its adaptability, potentially benefiting
diagnosis, treatment planning, and research on large-scale medical imaging
repositories. Our code is available at
https://github.com/nainye/RadiomicsRetrieval.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08517v1' target='_blank'>Transcranial Focused Ultrasound for Identifying the Neural Substrate of
  Conscious Perception</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel K. Freeman, Brian Odegaard, Seung-Schik Yoo, Matthias Michel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 12:05:01</h6>
<p class='card-text'>Identifying what aspects of brain activity are responsible for conscious
perception remains one of the most challenging problems in science. While
progress has been made through psychophysical studies employing EEG and fMRI,
research would greatly benefit from improved methods for stimulating the brain
in healthy human subjects. Traditional techniques for neural stimulation
through the skull, including electrical or magnetic stimulation, suffer from
coarse spatial resolution and have limited ability to target deep brain
structures with high spatial selectivity. Over the past decade, a new tool has
emerged known as transcranial focused ultrasound (tFUS), which enables the
human brain to be stimulated safely and non-invasively through the skull with
millimeter-scale spatial resolution, including cortical as well as deep brain
structures. This tool offers an exciting opportunity for breakthroughs in
consciousness research. Given the extensive preparation and regulatory
approvals associated with tFUS testing, careful experimental planning is
essential. Therefore, our goal here is to provide a roadmap for using tFUS in
humans for exploring the neural substrate of conscious perception.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08504v1' target='_blank'>Expanding the Pierre Auger Observatory Open Data program</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:V. Scherini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 11:27:37</h6>
<p class='card-text'>Since 2021, the Open Data Portal has provided access to the Pierre Auger
Observatory's data for both the scientific community and the general public.
The data release process has been in place since the Observatory's foundation.
It continues to be strengthened as outlined in the approved policy and the
Observatory's Data Management Plan. More than 80 000 cosmic-ray events above
$10^{17}$ eV, detected with the surface and fluorescence detectors, have been
released at various levels, from calibrated traces to high-level reconstruction
parameters. Additionally, atmospheric data and low-energy particle counting
rates have been made available for space weather studies. The Collaboration is
committed to releasing FAIR (Findable, Accessible, Interoperable, and Reusable)
data, along with accompanying software and detailed documentation, enabling
users to perform their own queries and analyses for both research and
educational purposes. These datasets have already served as a basis for several
scientific papers and have been widely used in various outreach activities.
After 20 years of stable data acquisition, the Pierre Auger Collaboration will
disclose 30% of the cosmic ray events above $2.5 \cdot 10^{18}$ eV collected
with the main surface detector array between 2004 and 2022, corresponding to an
exposure of about 24 000 km$^2$ sr yr, together with events detected with the
fluorescence detector and used for energy calibration. This release will
provide an unprecedented public dataset for ultra-high-energy cosmic rays,
enabling in-depth studies of their properties. Together with the published
catalog of the 100 most energetic events recorded, this initiative represents
the Pierre Auger Collaboration's strong commitment to distributed and
collective knowledge, sharing progress with the entire scientific community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08430v1' target='_blank'>A co-deployed dust-logging instrument for the IceCube Upgrade and
  IceCube-Gen2</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anna Eimer, Martin Rongen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 09:17:05</h6>
<p class='card-text'>A precise understanding of the optical properties of the instrumented
Antarctic ice sheet is crucial to the performance of optical Cherenkov
telescopes such as the IceCube Neutrino Observatory and its planned successor,
IceCube-Gen2. One complication arising from the large envisioned footprint of
IceCube-Gen2 is the larger impact of the so-called ice tilt. It describes the
undulation of ice layers of constant optical properties within the detector. In
this contribution, we will describe the project to build a co-deployed laser
dust logger. This is a device to measure the stratigraphy of impurities in the
ice to derive the ice tilt. It consists of a light source that will be
co-deployed with the photosensor modules, meaning it is part of the deployment
string and operated during the deployment of the detector. The newly developed
device will be tested during the deployment of the IceCube Upgrade in the
2025/26 austral summer to pave the way for IceCube-Gen2.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08420v1' target='_blank'>LiDAR, GNSS and IMU Sensor Alignment through Dynamic Time Warping to
  Construct 3D City Maps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haitian Wang, Hezam Albaqami, Xinyu Wang, Muhammad Ibrahim, Zainy M. Malakan, Abdullah M. Algamdi, Mohammed H. Alghamdi, Ajmal Mian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 09:06:14</h6>
<p class='card-text'>LiDAR-based 3D mapping suffers from cumulative drift causing global
misalignment, particularly in GNSS-constrained environments. To address this,
we propose a unified framework that fuses LiDAR, GNSS, and IMU data for
high-resolution city-scale mapping. The method performs velocity-based temporal
alignment using Dynamic Time Warping and refines GNSS and IMU signals via
extended Kalman filtering. Local maps are built using Normal Distributions
Transform-based registration and pose graph optimization with loop closure
detection, while global consistency is enforced using GNSS-constrained anchors
followed by fine registration of overlapping segments. We also introduce a
large-scale multimodal dataset captured in Perth, Western Australia to
facilitate future research in this direction. Our dataset comprises 144{,}000
frames acquired with a 128-channel Ouster LiDAR, synchronized RTK-GNSS
trajectories, and MEMS-IMU measurements across 21 urban loops. To assess
geometric consistency, we evaluated our method using alignment metrics based on
road centerlines and intersections to capture both global and local accuracy.
Our method reduces the average global alignment error from 3.32\,m to 1.24\,m,
achieving a 61.4\% improvement. The constructed high-fidelity map supports a
wide range of applications, including smart city planning, geospatial data
integration, infrastructure monitoring, and GPS-free navigation. Our method,
and dataset together establish a new benchmark for evaluating 3D city mapping
in GNSS-constrained environments. The dataset and code will be released
publicly.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08415v1' target='_blank'>The Optical Sensor for IceCube-Gen2</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexander Kappes</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 08:56:10</h6>
<p class='card-text'>An innovative optical module (OM) with segmented light-sensitive area has
been developed for IceCube-Gen2 that will take neutrino astronomy at the South
Pole to the next level. It builds on the successful features of the mDOM and
D-Egg modules of IceCube Upgrade while adapting to the smaller borehole
diameter of IceCube-Gen2. The newly developed OM, which is being tested in
IceCube Upgrade, serves as a prototype for the planned mass production of about
10,000 OMs for IceCube-Gen2. To simplify the assembly process, important
changes were made to the design, in particular to integrate the new gel pad
concept. This replaces the 3D-printed support structure of the mDOM while
maintaining through total internal reflection the increased light collection
efficiency of the reflector rings. In addition, the design features local
generation of high voltage for each photomultiplier tube (PMT) via a
Cockcroft-Walton circuit and the full digitization of the signal on each PMT
base with a sampling rate of 60 MSpS. This significantly reduces the complexity
of the mainboard so that it fits into the limited space available. This article
describes the development status and presents the performance of the first
prototypes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08365v1' target='_blank'>Prediction of Lane Change Intentions of Human Drivers using an LSTM, a
  CNN and a Transformer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Francesco De Cristofaro, Felix Hofbaur, Aixi Yang, Arno Eichberger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 07:26:33</h6>
<p class='card-text'>Lane changes of preceding vehicles have a great impact on the motion planning
of automated vehicles especially in complex traffic situations. Predicting them
would benefit the public in terms of safety and efficiency. While many research
efforts have been made in this direction, few concentrated on predicting
maneuvers within a set time interval compared to predicting at a set prediction
time. In addition, there exist a lack of comparisons between different
architectures to try to determine the best performing one and to assess how to
correctly choose the input for such models. In this paper the structure of an
LSTM, a CNN and a Transformer network are described and implemented to predict
the intention of human drivers to perform a lane change. We show how the data
was prepared starting from a publicly available dataset (highD), which features
were used, how the networks were designed and finally we compare the results of
the three networks with different configurations of input data. We found that
transformer networks performed better than the other networks and was less
affected by overfitting. The accuracy of the method spanned from $82.79\%$ to
$96.73\%$ for different input configurations and showed overall good
performances considering also precision and recall.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08362v1' target='_blank'>Leveraging Machine Learning and Enhanced Parallelism Detection for BPMN
  Model Generation from Text</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Phuong Nam Lê, Charlotte Schneider-Depré, Alexandre Goossens, Alexander Stevens, Aurélie Leribaux, Johannes De Smedt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 07:25:55</h6>
<p class='card-text'>Efficient planning, resource management, and consistent operations often rely
on converting textual process documents into formal Business Process Model and
Notation (BPMN) models. However, this conversion process remains time-intensive
and costly. Existing approaches, whether rule-based or machine-learning-based,
still struggle with writing styles and often fail to identify parallel
structures in process descriptions.
  This paper introduces an automated pipeline for extracting BPMN models from
text, leveraging the use of machine learning and large language models. A key
contribution of this work is the introduction of a newly annotated dataset,
which significantly enhances the training process. Specifically, we augment the
PET dataset with 15 newly annotated documents containing 32 parallel gateways
for model training, a critical feature often overlooked in existing datasets.
This addition enables models to better capture parallel structures, a common
but complex aspect of process descriptions. The proposed approach demonstrates
adequate performance in terms of reconstruction accuracy, offering a promising
foundation for organizations to accelerate BPMN model creation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08361v1' target='_blank'>Access graph: a novel graph representation of public transport networks
  for accessibility analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tina Šfiligoj, Aljoša Peperko, Oded Cats</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 07:25:43</h6>
<p class='card-text'>Accessibility, defined as travel impedance between spatially dispersed
opportunities for activity, is one of the main determinants of public transport
(PT) use. In-depth understanding of its properties is crucial for optimal
public transport systems planning and design. Although the concept has been
around for decades and there is a large body of literature on accessibility
operationalisation and measurement, a unified approach is lacking. To this end,
we introduce a novel graph representation of public transport networks, termed
the access graph, based on the shortest paths between nodes. Shortest paths are
calculated using the in-vehicle time-weighted L- and frequency-weighted P-space
representations to determine generalised travel times. Then there is an edge
between two nodes in the access graph if the travel time between them is below
a certain threshold time budget. In this representation, node degree directly
measures the number of nodes reachable within a predetermined time. We study
the threshold-dependent evolution of the access graph, focusing on average
degree and degree distributions. Based on the topological properties of the
access graph, we define a set of accessibility indicators. In addition, we
propose indicators of access equity. We apply the methodology to a dataset of
51 metro networks worldwide. In all cases, a logistic-like growth of average
degree with time budget is observed, indicating universal behaviour of
accessibility and exhibiting the value of the proposed representation for
unified accessibility studies and its potential for comparative analyses. We
see a great potential for the access graph to drive in-depth studies of
accessibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08335v1' target='_blank'>MK2 at PBIG Competition: A Prompt Generation Solution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuzheng Xu, Tosho Hirasawa, Seiya Kawano, Shota Kato, Tadashi Kozuno</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 06:27:42</h6>
<p class='card-text'>The Patent-Based Idea Generation task asks systems to turn real patents into
product ideas viable within three years. We propose MK2, a prompt-centric
pipeline: Gemini 2.5 drafts and iteratively edits a prompt, grafting useful
fragments from weaker outputs; GPT-4.1 then uses this prompt to create one idea
per patent, and an Elo loop judged by Qwen3-8B selects the best prompt-all
without extra training data. Across three domains, two evaluator types, and six
criteria, MK2 topped the automatic leaderboard and won 25 of 36 tests. Only the
materials-chemistry track lagged, indicating the need for deeper domain
grounding; yet, the results show that lightweight prompt engineering has
already delivered competitive, commercially relevant ideation from patents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08251v1' target='_blank'>Recoil-Constrained Scheduling of Non-Propulsive Payload Deployment for
  Mega-Constellations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Li Zhengrui, Li wenhao, Feng Guanhua, Yue Yuxian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-11 01:42:13</h6>
<p class='card-text'>This paper addresses the significant challenge of recoil momentum
accumulation during non-propulsive payload deployment for low-Earth-orbit
mega-constellations. An efficient phase-based approximation algorithm is
introduced, leading to over 90% faster computation while maintaining maximum
ejection velocity errors below 1%. The analysis highlights that cumulative
recoil velocity is the primary factor governing deployment capability, with
excess velocity being approximately half of the cumulative recoil velocity. An
analytical expression for predicting the maximum ejection velocity is derived,
enabling rapid mission planning with less than 2% error. This framework
establishes crucial operational boundaries concerning altitude differences,
mass ratios, and deployment quantities for near-Earth orbits (up to 2,000 km),
providing essential tools for the sustainable servicing of future
constellations comprising over 200 satellites per orbital plane.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08214v1' target='_blank'>Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification
  Mapping on Non-Contrast CT</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiangjian Hou, Ebru Yaman Akcicek, Xin Wang, Kazem Hashemizadeh, Scott Mcnally, Chun Yuan, Xiaodong Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 23:12:12</h6>
<p class='card-text'>While total intracranial carotid artery calcification (ICAC) volume is an
established stroke biomarker, growing evidence shows this aggregate metric
ignores the critical influence of plaque location, since calcification in
different segments carries distinct prognostic and procedural risks. However, a
finer-grained, segment-specific quantification has remained technically
infeasible. Conventional 3D models are forced to process downsampled volumes or
isolated patches, sacrificing the global context required to resolve anatomical
ambiguity and render reliable landmark localization. To overcome this, we
reformulate the 3D challenge as a \textbf{Parallel Probabilistic Landmark
Localization} task along the 1D axial dimension. We propose the
\textbf{Depth-Sequence Transformer (DST)}, a framework that processes
full-resolution CT volumes as sequences of 2D slices, learning to predict $N=6$
independent probability distributions that pinpoint key anatomical landmarks.
Our DST framework demonstrates exceptional accuracy and robustness. Evaluated
on a 100-patient clinical cohort with rigorous 5-fold cross-validation, it
achieves a Mean Absolute Error (MAE) of \textbf{0.1 slices}, with \textbf{96\%}
of predictions falling within a $\pm1$ slice tolerance. Furthermore, to
validate its architectural power, the DST backbone establishes the best result
on the public Clean-CC-CCII classification benchmark under an end-to-end
evaluation protocol. Our work delivers the first practical tool for automated
segment-specific ICAC analysis. The proposed framework provides a foundation
for further studies on the role of location-specific biomarkers in diagnosis,
prognosis, and procedural planning. Our code will be made publicly available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08193v1' target='_blank'>Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk
  Factors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiayi Guo, Zhiyun Quan, Linfeng Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 22:04:00</h6>
<p class='card-text'>The lack of high-quality public cyber incident data limits empirical research
and predictive modeling for cyber risk assessment. This challenge persists due
to the reluctance of companies to disclose incidents that could damage their
reputation or investor confidence. Therefore, from an actuarial perspective,
potential resolutions conclude two aspects: the enhancement of existing cyber
incident datasets and the implementation of advanced modeling techniques to
optimize the use of the available data. A review of existing data-driven
methods highlights a significant lack of entity-specific organizational
features in publicly available datasets. To address this gap, we propose a
novel InsurTech framework that enriches cyber incident data with
entity-specific attributes. We develop various machine learning (ML) models: a
multilabel classification model to predict the occurrence of cyber incident
types (e.g., Privacy Violation, Data Breach, Fraud and Extortion, IT Error, and
Others) and a multioutput regression model to estimate their annual
frequencies. While classifier and regressor chains are implemented to explore
dependencies among cyber incident types as well, no significant correlations
are observed in our datasets. Besides, we apply multiple interpretable ML
techniques to identify and cross-validate potential risk factors developed by
InsurTech across ML models. We find that InsurTech empowered features enhance
prediction occurrence and frequency estimation robustness compared to only
using conventional risk factors. The framework generates transparent,
entity-specific cyber risk profiles, supporting customized underwriting and
proactive cyber risk mitigation. It provides insurers and organizations with
data-driven insights to support decision-making and compliance planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.08145v1' target='_blank'>AI-Augmented Visible Light Communication: A Framework for Noise
  Mitigation and Secure Data Transmission</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:A. A. Nutfaji, Moustafa Hassan Elmallah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 20:05:46</h6>
<p class='card-text'>This paper presents a proposed AI Deep Learning model that addresses common
challenges encountered in Visible Light Communication (VLC) systems. In this
work, we run a Python simulation that models a basic VLC system primarily
affected by Additive White Gaussian Noise (AWGN). A Deep Neural Network (DNN)
is then trained to equalize the noisy signal received and improve signal
integrity. The system evaluates and compares the Bit Error Rate (BER) before
and after equalization to demonstrate the effectiveness of the proposed model.
This paper starts by introducing the concept of visible light communication,
then it dives deep into some details about the process of VLC and the
challenges it faces, shortly after we propose our project which helps overcome
these challenges. We finally conclude with a lead for future work, highlighting
the areas that are most suitable for future improvements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07917v1' target='_blank'>Convergence rates for regularized unbalanced optimal transport: the
  discrete case</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luca Nenna, Paul Pegon, Louis Tocquec</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 16:58:59</h6>
<p class='card-text'>Unbalanced optimal transport (UOT) is a natural extension of optimal
transport (OT) allowing comparison between measures of different masses. It
arises naturally in machine learning by offering a robustness against outliers.
The aim of this work is to provide convergence rates of the regularized
transport cost and plans towards their original solution when both measures are
weighted sums of Dirac masses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07894v1' target='_blank'>Complexity Analysis of a Bicriteria Directed Multimodal Transportation
  Network Design Problem</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dominik Leib, Susanne Fritzler, Neele Leithäuser</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 16:23:09</h6>
<p class='card-text'>In this paper, we address a bicriteria network design problem that arises
from practical applications in urban and rural public transportation planning.
We establish the problem's complexity and demonstrate inapproximability
results, highlighting the inherent difficulties in finding optimal solutions.
Additionally, we identify special cases where approximability can be achieved,
providing valuable insights for practitioners. Our proofs leverage complexity
results related to directed network design problems, an area that has received
limited attention in the existing literature. By investigating these complexity
results, we aim to fill a critical gap and enhance the understanding of the
interplay between bicriteria decision-making and network design challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07844v1' target='_blank'>Machine Learning Tools for the IceCube-Gen2 Optical Array</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Francisco Javier Vara Carbonell, Jonas Selter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 15:21:34</h6>
<p class='card-text'>Neural networks (NNs) have a great potential for future neutrino telescopes
such as IceCube-Gen2, the planned high-energy extension of the IceCube
observatory. IceCube-Gen2 will feature new optical sensors with multiple
photomultiplier tubes (PMTs) designed to provide omnidirectional sensitivity.
Neural networks excel at handling high-dimensional problems and can naturally
incorporate the increased complexity of these new sensors. Additionally, their
fast inference time makes them promising candidates for handling the high event
rates expected from IceCube-Gen2.
  This contribution presents potential applications of neural networks in the
IceCube-Gen2 in-ice optical array. First, we introduce a method to simulate the
IceCube-Gen2 optical modules' photon acceptance using a NN that leverages the
modules' inherent symmetries. Secondly, we present the status of neutrino
NN-based reconstruction efforts, including the adaptation of a novel IceCube
technique that combines normalizing flows with transformer NNs. Finally, we
describe current progress in noise cleaning applications based on node
classification with graph neural networks (GNNs), a method that has already
shown promising results for the forthcoming low-energy extension,
IceCube-Upgrade.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07832v1' target='_blank'>Flying Base Stations for Offshore Wind Farm Monitoring and Control:
  Holistic Performance Evaluation and Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyi Lin, Peizheng Li, Adnan Aijaz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 15:03:52</h6>
<p class='card-text'>Ensuring reliable and low-latency communication in offshore wind farms is
critical for efficient monitoring and control, yet remains challenging due to
the harsh environment and lack of infrastructure. This paper investigates a
flying base station (FBS) approach for wide-area monitoring and control in the
UK Hornsea offshore wind farm project. By leveraging mobile, flexible FBS
platforms in the remote and harsh offshore environment, the proposed system
offers real-time connectivity for turbines without the need for deploying
permanent infrastructure at the sea. We develop a detailed and practical
end-to-end latency model accounting for five key factors: flight duration,
connection establishment, turbine state information upload, computational
delay, and control transmission, to provide a holistic perspective often
missing in prior studies. Furthermore, we combine trajectory planning,
beamforming, and resource allocation into a multi-objective optimization
framework for the overall latency minimization, specifically designed for
large-scale offshore wind farm deployments. Simulation results verify the
effectiveness of our proposed method in minimizing latency and enhancing
efficiency in FBS-assisted offshore monitoring across various power levels,
while consistently outperforming baseline designs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07813v1' target='_blank'>Probing ultra-high-energy neutrinos with the IceCube-Gen2 in-ice radio
  array</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christian Glaser</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 14:44:19</h6>
<p class='card-text'>The next generation neutrino telescope, IceCube-Gen2, will be sensitive to
the astrophysical and cosmogenic flux of neutrinos across a broad energy range,
from the TeV to the EeV scale. The planned design includes 8 cubic kilometers
of ice instrumented with approximately 10,000 optical sensors, a surface array,
and a radio array of antennas embedded in the ice laid out sparsely over 500
km^2. The radio array provides sensitivity to ultra-high energy neutrinos using
independent radio stations that can trigger on Askaryan emission from neutrino
interactions in the ice. In this contribution, we present the design for the
radio array along with its planned implementation, which is expected to
increase sensitivity to neutrinos with energies beyond 100PeV by at least an
order of magnitude over existing arrays. Furthermore, we will quantify the
expected science output by presenting measurement forecasts for the main
science cases of diffuse flux and point source discovery, as well as
cross-section and flavor measurements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07811v1' target='_blank'>Patient-specific vs Multi-Patient Vision Transformer for Markerless
  Tumor Motion Forecasting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gauthier Rotsart de Hertaing, Dani Manjah, Benoit Macq</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 14:40:52</h6>
<p class='card-text'>Background: Accurate forecasting of lung tumor motion is essential for
precise dose delivery in proton therapy. While current markerless methods
mostly rely on deep learning, transformer-based architectures remain unexplored
in this domain, despite their proven performance in trajectory forecasting.
  Purpose: This work introduces a markerless forecasting approach for lung
tumor motion using Vision Transformers (ViT). Two training strategies are
evaluated under clinically realistic constraints: a patient-specific (PS)
approach that learns individualized motion patterns, and a multi-patient (MP)
model designed for generalization. The comparison explicitly accounts for the
limited number of images that can be generated between planning and treatment
sessions.
  Methods: Digitally reconstructed radiographs (DRRs) derived from planning
4DCT scans of 31 patients were used to train the MP model; a 32nd patient was
held out for evaluation. PS models were trained using only the target patient's
planning data. Both models used 16 DRRs per input and predicted tumor motion
over a 1-second horizon. Performance was assessed using Average Displacement
Error (ADE) and Final Displacement Error (FDE), on both planning (T1) and
treatment (T2) data.
  Results: On T1 data, PS models outperformed MP models across all training set
sizes, especially with larger datasets (up to 25,000 DRRs, p < 0.05). However,
MP models demonstrated stronger robustness to inter-fractional anatomical
variability and achieved comparable performance on T2 data without retraining.
  Conclusions: This is the first study to apply ViT architectures to markerless
tumor motion forecasting. While PS models achieve higher precision, MP models
offer robust out-of-the-box performance, well-suited for time-constrained
clinical settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07809v1' target='_blank'>DT4PCP: A Digital Twin Framework for Personalized Care Planning Applied
  to Type 2 Diabetes Management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Javad M Alizadeh, Mukesh K Patel, Huanmei Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 14:39:32</h6>
<p class='card-text'>Digital Twin (DT) technology has emerged as a transformative approach in
healthcare, but its application in personalized patient care remains limited.
This paper aims to present a practical implementation of DT in the management
of chronic diseases. We introduce a general DT framework for personalized care
planning (DT4PCP), with the core components being a real-time virtual
representation of a patient's health and emerging predictive models to enable
adaptive, personalized care. We implemented the DT4PCP framework for managing
Type 2 Diabetes (DT4PCP-T2D), enabling real-time collection of behavioral data
from patients with T2D, predicting emergency department (ED) risks, simulating
the effects of different interventions, and personalizing care strategies to
reduce ED visits. The DT4PCP-T2D also integrates social determinants of health
(SDoH) and other contextual data, offering a comprehensive view of the
patient's health to ensure that care recommendations are tailored to individual
needs. Through retrospective simulations, we demonstrate that integrating DTs
in T2D management can lead to significant advancements in personalized
medicine. This study underscores the potential of DT technology to
revolutionize chronic disease care.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07804v1' target='_blank'>Deep Survival Analysis in Multimodal Medical Data: A Parametric and
  Probabilistic Approach with Competing Risks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alba Garrido, Alejandro Almodóvar, Patricia A. Apellániz, Juan Parras, Santiago Zazo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 14:29:48</h6>
<p class='card-text'>Accurate survival prediction is critical in oncology for prognosis and
treatment planning. Traditional approaches often rely on a single data
modality, limiting their ability to capture the complexity of tumor biology. To
address this challenge, we introduce a multimodal deep learning framework for
survival analysis capable of modeling both single and competing risks
scenarios, evaluating the impact of integrating multiple medical data sources
on survival predictions. We propose SAMVAE (Survival Analysis Multimodal
Variational Autoencoder), a novel deep learning architecture designed for
survival prediction that integrates six data modalities: clinical variables,
four molecular profiles, and histopathological images. SAMVAE leverages
modality specific encoders to project inputs into a shared latent space,
enabling robust survival prediction while preserving modality specific
information. Its parametric formulation enables the derivation of clinically
meaningful statistics from the output distributions, providing patient-specific
insights through interactive multimedia that contribute to more informed
clinical decision-making and establish a foundation for interpretable,
data-driven survival analysis in oncology. We evaluate SAMVAE on two cancer
cohorts breast cancer and lower grade glioma applying tailored preprocessing,
dimensionality reduction, and hyperparameter optimization. The results
demonstrate the successful integration of multimodal data for both standard
survival analysis and competing risks scenarios across different datasets. Our
model achieves competitive performance compared to state-of-the-art multimodal
survival models. Notably, this is the first parametric multimodal deep learning
architecture to incorporate competing risks while modeling continuous time to a
specific event, using both tabular and image data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07794v1' target='_blank'>Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy:
  Optical Tracking based Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhe Han, Huanyu Tian, Tom Vercauteren, Da Liu, Changsheng Li, Xingguang Duan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 14:20:34</h6>
<p class='card-text'>Mandibular Angle Split Osteotomy (MASO) is a significant procedure in oral
and maxillofacial surgery. Despite advances in technique and instrumentation,
its success still relies heavily on the surgeon's experience. In this work, a
human-robot collaborative system is proposed to perform MASO according to a
preoperative plan and under guidance of a surgeon. A task decomposition
methodology is used to divide the collaborative surgical procedure into three
subtasks: (1) positional control and (2) orientation control, both led by the
robot for precise alignment; and (3) force-control, managed by surgeon to
ensure safety. Additionally, to achieve patient tracking without the need for a
skull clamp, an optical tracking system (OTS) is utilized. Movement of the
patient mandibular is measured with an optical-based tracker mounted on a
dental occlusal splint. A registration method and Robot-OTS calibration method
are introduced to achieve reliable navigation within our framework. The
experiments of drilling were conducted on the realistic phantom model, which
demonstrated that the average error between the planned and actual drilling
points is 1.85mm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07727v1' target='_blank'>Beyond Connectivity: Higher-Order Network Framework for Capturing
  Memory-Driven Mobility Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chen Zhang, Jürgen Hackl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 13:02:26</h6>
<p class='card-text'>Understanding and predicting mobility dynamics in transportation networks is
critical for infrastructure planning, resilience analysis, and traffic
management. Traditional graph-based models typically assume memoryless
movement, limiting their ability to capture sequential dependencies inherent in
real-world mobility patterns. In this study, we introduce a novel higher-order
network framework for modeling memory-dependent dynamics in transportation
systems. By extending classical graph representations through higher-order
Markov chains and de Bruijn graph structures, our framework encodes the spatial
and temporal ordering of traversed paths, enabling the analysis of structurally
and functionally critical components with improved fidelity. We generalize key
network analytics, including betweenness centrality, PageRank, and next-step
prediction, to this higher-order setting and validate our approach on the Sioux
Falls transportation network using agent-based trajectory data generated with
MATSim. Experimental results demonstrate that higher-order models outperform
first-order baselines across multiple tasks, with the third-order model
achieving an optimal balance between predictive accuracy and model complexity.
These findings highlight the importance of incorporating memory effects into
network-based transportation analysis and offer a scalable, data-driven
methodology for capturing complex mobility behaviors in infrastructure systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2507.07602v1' target='_blank'>Advancing Medical Image Segmentation via Self-supervised
  Instance-adaptive Prototype Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guoyan Liang, Qin Zhou, Jingyuan Chen, Zhe Wang, Chang Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-07-10 10:04:03</h6>
<p class='card-text'>Medical Image Segmentation (MIS) plays a crucial role in medical therapy
planning and robot navigation. Prototype learning methods in MIS focus on
generating segmentation masks through pixel-to-prototype comparison. However,
current approaches often overlook sample diversity by using a fixed prototype
per semantic class and neglect intra-class variation within each input. In this
paper, we propose to generate instance-adaptive prototypes for MIS, which
integrates a common prototype proposal (CPP) capturing common visual patterns
and an instance-specific prototype proposal (IPP) tailored to each input. To
further account for the intra-class variation, we propose to guide the IPP
generation by re-weighting the intermediate feature map according to their
confidence scores. These confidence scores are hierarchically generated using a
transformer decoder. Additionally we introduce a novel self-supervised
filtering strategy to prioritize the foreground pixels during the training of
the transformer decoder. Extensive experiments demonstrate favorable
performance of our method.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>