<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-08-28</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-08-28</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.20096v1' target='_blank'>CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer
  Use Agent with Decoupled Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeyi Sun, Yuhang Cao, Jianze Liang, Qiushi Sun, Ziyu Liu, Zhixiong Zhang, Yuhang Zang, Xiaoyi Dong, Kai Chen, Dahua Lin, Jiaqi Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 17:59:50</h6>
<p class='card-text'>Autonomous agents for Graphical User Interfaces (GUIs) face significant
challenges in specialized domains such as scientific computing, where both
long-horizon planning and precise execution are required. Existing approaches
suffer from a trade-off: generalist agents excel at planning but perform poorly
in execution, while specialized agents demonstrate the opposite weakness.
Recent compositional frameworks attempt to bridge this gap by combining a
planner and an actor, but they are typically static and non-trainable, which
prevents adaptation from experience. This is a critical limitation given the
scarcity of high-quality data in scientific domains. To address these
limitations, we introduce CODA, a novel and trainable compositional framework
that integrates a generalist planner (Cerebrum) with a specialist executor
(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,
Specialization, we apply a decoupled GRPO approach to train an expert planner
for each scientific application individually, bootstrapping from a small set of
task trajectories. In the second stage, Generalization, we aggregate all
successful trajectories from the specialized experts to build a consolidated
dataset, which is then used for supervised fine-tuning of the final planner.
This equips CODA with both robust execution and cross-domain generalization.
Evaluated on four challenging applications from the ScienceBoard benchmark,
CODA significantly outperforms baselines and establishes a new state of the art
among open-source models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.20095v1' target='_blank'>Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinhao Liang, Sven Koenig, Ferdinando Fioretto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 17:59:36</h6>
<p class='card-text'>Multi-Robot Motion Planning (MRMP) involves generating collision-free
trajectories for multiple robots operating in a shared continuous workspace.
While discrete multi-agent path finding (MAPF) methods are broadly adopted due
to their scalability, their coarse discretization severely limits trajectory
quality. In contrast, continuous optimization-based planners offer
higher-quality paths but suffer from the curse of dimensionality, resulting in
poor scalability with respect to the number of robots. This paper tackles the
limitations of these two approaches by introducing a novel framework that
integrates discrete MAPF solvers with constrained generative diffusion models.
The resulting framework, called Discrete-Guided Diffusion (DGD), has three key
characteristics: (1) it decomposes the original nonconvex MRMP problem into
tractable subproblems with convex configuration spaces, (2) it combines
discrete MAPF solutions with constrained optimization techniques to guide
diffusion models capture complex spatiotemporal dependencies among robots, and
(3) it incorporates a lightweight constraint repair mechanism to ensure
trajectory feasibility. The proposed method sets a new state-of-the-art
performance in large-scale, complex environments, scaling to 100 robots while
achieving planning efficiency and high success rates.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.20064v1' target='_blank'>Patch Progression Masked Autoencoder with Fusion CNN Network for
  Classifying Evolution Between Two Pairs of 2D OCT Slices</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Philippe Zhang, Weili Jiang, Yihao Li, Jing Zhang, Sarah Matta, Yubo Tan, Hui Lin, Haoshen Wang, Jiangtian Pan, Hui Xu, Laurent Borderie, Alexandre Le Guilcher, Béatrice Cochener, Chubin Ou, Gwenolé Quellec, Mathieu Lamard</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 17:18:30</h6>
<p class='card-text'>Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting
visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments
have been effective in slowing the progression of neovascular AMD, with better
outcomes achieved through timely diagnosis and consistent monitoring. Tracking
the progression of neovascular activity in OCT scans of patients with exudative
AMD allows for the development of more personalized and effective treatment
plans. This was the focus of the Monitoring Age-related Macular Degeneration
Progression in Optical Coherence Tomography (MARIO) challenge, in which we
participated. In Task 1, which involved classifying the evolution between two
pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN
network with model ensembling to further enhance the model's performance. For
Task 2, which focused on predicting progression over the next three months
based on current exam data, we proposed the Patch Progression Masked
Autoencoder that generates an OCT for the next exam and then classifies the
evolution between the current OCT and the one generated using our solution from
Task 1. The results we achieved allowed us to place in the Top 10 for both
tasks. Some team members are part of the same organization as the challenge
organizers; therefore, we are not eligible to compete for the prize.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.20034v1' target='_blank'>FlyMeThrough: Human-AI Collaborative 3D Indoor Mapping with Commodity
  Drones</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xia Su, Ruiqi Chen, Jingwei Ma, Chu Li, Jon E. Froehlich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 16:36:47</h6>
<p class='card-text'>Indoor mapping data is crucial for routing, navigation, and building
management, yet such data are widely lacking due to the manual labor and
expense of data collection, especially for larger indoor spaces. Leveraging
recent advancements in commodity drones and photogrammetry, we introduce
FlyMeThrough -- a drone-based indoor scanning system that efficiently produces
3D reconstructions of indoor spaces with human-AI collaborative annotations for
key indoor points-of-interest (POI) such as entrances, restrooms, stairs, and
elevators. We evaluated FlyMeThrough in 12 indoor spaces with varying sizes and
functionality. To investigate use cases and solicit feedback from target
stakeholders, we also conducted a qualitative user study with five building
managers and five occupants. Our findings indicate that FlyMeThrough can
efficiently and precisely create indoor 3D maps for strategic space planning,
resource management, and navigation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.20018v1' target='_blank'>SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in
  Mobile GUI Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Quanfeng Lu, Zhantao Ma, Shuai Zhong, Jin Wang, Dahai Yu, Michael K. Ng, Ping Luo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 16:27:19</h6>
<p class='card-text'>The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19945v1' target='_blank'>Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of
  Local Nash Interactions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhouyu Zhang, Chih-Yuan Chiu, Glen Chou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 15:01:09</h6>
<p class='card-text'>We present an inverse dynamic game-based algorithm to learn parametric
constraints from a given dataset of local generalized Nash equilibrium
interactions between multiple agents. Specifically, we introduce mixed-integer
linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the
interacting agents, which recover constraints consistent with the Nash
stationarity of the interaction demonstrations. We establish theoretical
guarantees that our method learns inner approximations of the true safe and
unsafe sets, as well as limitations of constraint learnability from
demonstrations of Nash equilibrium interactions. We also use the interaction
constraints recovered by our method to design motion plans that robustly
satisfy the underlying constraints. Across simulations and hardware
experiments, our methods proved capable of inferring constraints and designing
interactive motion plans for various classes of constraints, both convex and
non-convex, from interaction demonstrations of agents with nonlinear dynamics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19933v1' target='_blank'>Combined Stochastic and Robust Optimization for Electric Autonomous
  Mobility-on-Demand with Nested Benders Decomposition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sten Elling Tingstad Jacobsen, Balázs Kulcsár, Anders Lindman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 14:48:34</h6>
<p class='card-text'>The electrification and automation of mobility are reshaping how cities
operate on-demand transport systems. Managing Electric Autonomous
Mobility-on-Demand (EAMoD) fleets effectively requires coordinating dispatch,
rebalancing, and charging decisions under multiple uncertainties, including
travel demand, travel time, energy consumption, and charger availability. We
address this challenge with a combined stochastic and robust model predictive
control (MPC) framework. The framework integrates spatio-temporal Bayesian
neural network forecasts with a multi-stage stochastic optimization model,
formulated as a large-scale mixed-integer linear program. To ensure real-time
applicability, we develop a tailored Nested Benders Decomposition that exploits
the scenario tree structure and enables efficient parallelized solution.
Stochastic optimization is employed to anticipate demand and infrastructure
variability, while robust constraints on energy consumption and travel times
safeguard feasibility under worst-case realizations. We evaluate the framework
using high-fidelity simulations of San Francisco and Chicago. Compared with
deterministic, reactive, and robust baselines, the combined stochastic and
robust approach reduces median passenger waiting times by up to 36% and
95th-percentile delays by nearly 20%, while also lowering rebalancing distance
by 27% and electricity costs by more than 35%. We also conduct a sensitivity
analysis of battery size and vehicle efficiency, finding that energy-efficient
vehicles maintain stable performance even with small batteries, whereas less
efficient vehicles require larger batteries and greater infrastructure support.
Our results emphasize the importance of jointly optimizing predictive control,
vehicle capabilities, and infrastructure planning to enable scalable,
cost-efficient EAMoD operations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19921v1' target='_blank'>An assessment of estimation models and investment gaps for the
  deployment of high-speed broadband networks in NUTS3 regions to meet the
  objectives of the European Gigabit Society</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ferrandis Jesus, Ramos Sergio, Feijoo Claudio</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 14:27:00</h6>
<p class='card-text'>This paper analyses the deployment of high speed broadband networks in the
European Union (EU). Its aim is to assess the investment required to meet the
targets set by the European Commission (EC) for 2025, within the framework of
the European Gigabit Society (EGS). This plan aims to ensure the availability
and take up of very high capacity fixed and wireless networks, in both urban
and rural areas, among households and the main socioeconomic drivers. The
estimation model presented here uses a methodology supported by data at the
local (NUTS3) level to give a bottom up estimation of the investment gap for
each of the EGS objectives, using three different scenarios depending on the
mix of wired and wireless technologies offered. The methodology and estimation
model used in the paper are examined against other examples and assumptions
available in the literature. We also offer a dynamic perspective on the
analysis of the evolution of this investment gap over the years 2017 2019,
which includes an assessment of the usefulness of these estimation models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19852v1' target='_blank'>Ego-centric Predictive Model Conditioned on Hand Trajectories</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Binjie Zhang, Mike Zheng Shou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 13:09:55</h6>
<p class='card-text'>In egocentric scenarios, anticipating both the next action and its visual
outcome is essential for understanding human-object interactions and for
enabling robotic planning. However, existing paradigms fall short of jointly
modeling these aspects. Vision-Language-Action (VLA) models focus on action
prediction but lack explicit modeling of how actions influence the visual
scene, while video prediction models generate future frames without
conditioning on specific actions, often resulting in implausible or
contextually inconsistent outcomes. To bridge this gap, we propose a unified
two-stage predictive framework that jointly models action and visual future in
egocentric scenarios, conditioned on hand trajectories. In the first stage, we
perform consecutive state modeling to process heterogeneous inputs (visual
observations, language, and action history) and explicitly predict future hand
trajectories. In the second stage, we introduce causal cross-attention to fuse
multi-modal cues, leveraging inferred action signals to guide an image-based
Latent Diffusion Model (LDM) for frame-by-frame future video generation. Our
approach is the first unified model designed to handle both egocentric human
activity understanding and robotic manipulation tasks, providing explicit
predictions of both upcoming actions and their visual consequences. Extensive
experiments on Ego4D, BridgeData, and RLBench demonstrate that our method
outperforms state-of-the-art baselines in both action prediction and future
video synthesis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19790v1' target='_blank'>APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated
  Elliptical R-Nearest Neighbors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liding Zhang, Sicheng Wang, Kuanqi Cai, Zhenshan Bing, Fan Wu, Chaoqun Wang, Sami Haddadin, Alois Knoll</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 11:16:36</h6>
<p class='card-text'>Optimal path planning aims to determine a sequence of states from a start to
a goal while accounting for planning objectives. Popular methods often
integrate fixed batch sizes and neglect information on obstacles, which is not
problem-specific. This study introduces Adaptively Prolated Trees (APT*), a
novel sampling-based motion planner that extends based on Force Direction
Informed Trees (FDIT*), integrating adaptive batch-sizing and elliptical
$r$-nearest neighbor modules to dynamically modulate the path searching process
based on environmental feedback. APT* adjusts batch sizes based on the
hypervolume of the informed sets and considers vertices as electric charges
that obey Coulomb's law to define virtual forces via neighbor samples, thereby
refining the prolate nearest neighbor selection. These modules employ
non-linear prolate methods to adaptively adjust the electric charges of
vertices for force definition, thereby improving the convergence rate with
lower solution costs. Comparative analyses show that APT* outperforms existing
single-query sampling-based planners in dimensions from $\mathbb{R}^4$ to
$\mathbb{R}^{16}$, and it was further validated through a real-world robot
manipulation task. A video showcasing our experimental results is available at:
https://youtu.be/gCcUr8LiEw4</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19776v1' target='_blank'>Tree-Based Grafting Approach for Bidirectional Motion Planning with
  Local Subsets Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liding Zhang, Yao Ling, Zhenshan Bing, Fan Wu, Sami Haddadin, Alois Knoll</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 11:00:25</h6>
<p class='card-text'>Bidirectional motion planning often reduces planning time compared to its
unidirectional counterparts. It requires connecting the forward and reverse
search trees to form a continuous path. However, this process could fail and
restart the asymmetric bidirectional search due to the limitations of
lazy-reverse search. To address this challenge, we propose Greedy GuILD
Grafting Trees (G3T*), a novel path planner that grafts invalid edge
connections at both ends to re-establish tree-based connectivity, enabling
rapid path convergence. G3T* employs a greedy approach using the minimum
Lebesgue measure of guided incremental local densification (GuILD) subsets to
optimize paths efficiently. Furthermore, G3T* dynamically adjusts the sampling
distribution between the informed set and GuILD subsets based on historical and
current cost improvements, ensuring asymptotic optimality. These features
enhance the forward search's growth towards the reverse tree, achieving faster
convergence and lower solution costs. Benchmark experiments across dimensions
from R^2 to R^8 and real-world robotic evaluations demonstrate G3T*'s superior
performance compared to existing single-query sampling-based planners. A video
showcasing our experimental results is available at:
https://youtu.be/3mfCRL5SQIU</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19771v1' target='_blank'>Elliptical K-Nearest Neighbors -- Path Optimization via Coulomb's Law
  and Invalid Vertices in C-space Obstacles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liding Zhang, Zhenshan Bing, Yu Zhang, Kuanqi Cai, Lingyun Chen, Fan Wu, Sami Haddadin, Alois Knoll</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 10:57:50</h6>
<p class='card-text'>Path planning has long been an important and active research area in
robotics. To address challenges in high-dimensional motion planning, this study
introduces the Force Direction Informed Trees (FDIT*), a sampling-based planner
designed to enhance speed and cost-effectiveness in pathfinding. FDIT* builds
upon the state-of-the-art informed sampling planner, the Effort Informed Trees
(EIT*), by capitalizing on often-overlooked information in invalid vertices. It
incorporates principles of physical force, particularly Coulomb's law. This
approach proposes the elliptical $k$-nearest neighbors search method, enabling
fast convergence navigation and avoiding high solution cost or infeasible paths
by exploring more problem-specific search-worthy areas. It demonstrates
benefits in search efficiency and cost reduction, particularly in confined,
high-dimensional environments. It can be viewed as an extension of nearest
neighbors search techniques. Fusing invalid vertex data with physical dynamics
facilitates force-direction-based search regions, resulting in an improved
convergence rate to the optimum. FDIT* outperforms existing single-query,
sampling-based planners on the tested problems in R^4 to R^16 and has been
demonstrated on a real-world mobile manipulation task.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19608v1' target='_blank'>Autonomous Aerial Manipulation at Arbitrary Pose in SE(3) with Robust
  Control and Whole-body Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dongjae Lee, Byeongjun Kim, H. Jin Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 06:44:23</h6>
<p class='card-text'>Aerial manipulators based on conventional multirotors can conduct
manipulation only in small roll and pitch angles due to the underactuatedness
of the multirotor base. If the multirotor base is capable of hovering at
arbitrary orientation, the robot can freely locate itself at any point in
$\mathsf{SE}(3)$, significantly extending its manipulation workspace and
enabling a manipulation task that was originally not viable. In this work, we
present a geometric robust control and whole-body motion planning framework for
an omnidirectional aerial manipulator (OAM). To maximize the strength of OAM,
we first propose a geometric robust controller for a floating base. Since the
motion of the robotic arm and the interaction forces during manipulation affect
the stability of the floating base, the base should be capable of mitigating
these adverse effects while controlling its 6D pose. We then design a two-step
optimization-based whole-body motion planner, jointly considering the pose of
the floating base and the joint angles of the robotic arm to harness the entire
configuration space. The devised two-step approach facilitates real-time
applicability and enhances convergence of the optimization problem with
non-convex and non-Euclidean search space. The proposed approach enables the
base to be stationary at any 6D pose while autonomously carrying out
sophisticated manipulation near obstacles without any collision. We demonstrate
the effectiveness of the proposed framework through experiments in which an OAM
performs grasping and pulling of an object in multiple scenarios, including
near $90^\circ$ and even $180^\circ$ pitch angles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19595v1' target='_blank'>A Lightweight Crowd Model for Robot Social Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maryam Kazemi Eskeri, Thomas Wiedemann, Ville Kyrki, Dominik Baumann, Tomasz Piotr Kucner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 06:13:43</h6>
<p class='card-text'>Robots operating in human-populated environments must navigate safely and
efficiently while minimizing social disruption. Achieving this requires
estimating crowd movement to avoid congested areas in real-time. Traditional
microscopic models struggle to scale in dense crowds due to high computational
cost, while existing macroscopic crowd prediction models tend to be either
overly simplistic or computationally intensive. In this work, we propose a
lightweight, real-time macroscopic crowd prediction model tailored for human
motion, which balances prediction accuracy and computational efficiency. Our
approach simplifies both spatial and temporal processing based on the inherent
characteristics of pedestrian flow, enabling robust generalization without the
overhead of complex architectures. We demonstrate a 3.6 times reduction in
inference time, while improving prediction accuracy by 3.1 %. Integrated into a
socially aware planning framework, the model enables efficient and socially
compliant robot navigation in dynamic environments. This work highlights that
efficient human crowd modeling enables robots to navigate dense environments
without costly computations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19577v1' target='_blank'>Gravitational Microlensing of the Galactic Centre $γ$-Ray Excess: A
  New Test for Point-Like or Extended Emission?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nada Salama, Florian List, Geraint Lewis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 05:22:11</h6>
<p class='card-text'>We present a potential test of the origin of the $\gamma$-ray Galactic Centre
Excess (GCE). We demonstrate how gravitational microlensing by stellar mass
objects along the line of sight to the Galactic Bulge can distinguish between
the possibility of extensive emission due to dark matter self-annihilation from
more prosaic astrophysical sources, namely millisecond pulsars. Such an
astrophysical origin would result in emission from a population of small,
currently unresolved point-like sources - in contrast to the expected smoother
emission resulting from dark matter annihilation. Given that the scale of
gravitational microlensing, that is, the Einstein radius for stellar mass
lenses, and hence, the degree of induced magnification, is sensitive to the
size of the emitting region, such microlensing will induce time variability in
the emission of astrophysical sources, whereas $\gamma$-ray emission from dark
matter annihilation will effectively be immune to such influences. However, we
find that detecting microlensing-induced variability requires significantly
greater sensitivity than that of current or planned $\gamma$-ray detectors. For
a small population of bright GCE sources, more than an order-of-magnitude
increase in effective area over Fermi-LAT would be required, with events
remaining extremely rare. For a large population of faint sources, events would
occur multiple times a year, but would only be detectable with a
four-order-of-magnitude improvement. Whilst microlensing might not be a
definitive test of the origin of the GCE, in future observations, it may prove
useful in determining the properties of any point-like source population.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19513v1' target='_blank'>Spatial-temporal risk field-based coupled dynamic-static driving risk
  assessment and trajectory planning in weaving segments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guodong Ma, Baofeng Sun, Hongchao Liang, Wenyu Yang, Huxing Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 01:59:35</h6>
<p class='card-text'>In this paper, we first propose a spatial-temporal coupled risk assessment
paradigm by constructing a three-dimensional spatial-temporal risk field
(STRF). Specifically, we introduce spatial-temporal distances to quantify the
impact of future trajectories of dynamic obstacles. We also incorporate a
geometrically configured specialized field for the weaving segment to constrain
vehicle movement directionally. To enhance the STRF's accuracy, we further
developed a parameter calibration method using real-world aerial video data,
leveraging YOLO-based machine vision and dynamic risk balance theory. A
comparative analysis with the traditional risk field demonstrates the STRF's
superior situational awareness of anticipatory risk. Building on these results,
we final design a STRF-based CAV trajectory planning method in weaving
segments. We integrate spatial-temporal risk occupancy maps, dynamic iterative
sampling, and quadratic programming to enhance safety, comfort, and efficiency.
By incorporating both dynamic and static risk factors during the sampling
phase, our method ensures robust safety performance. Additionally, the proposed
method simultaneously optimizes path and speed using a parallel computing
approach, reducing computation time. Real-world cases show that, compared to
the dynamic planning + quadratic programming schemes, and real human driving
trajectories, our method significantly improves safety, reduces lane-change
completion time, and minimizes speed fluctuations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19499v1' target='_blank'>Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow
  Generation from Satellite Imagery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiangxu Wang, Tianhong Zhao, Wei Tu, Bowen Zhang, Guanzhou Chen, Jinzhou Cao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-27 01:05:37</h6>
<p class='card-text'>Origin-Destination (OD) flow matrices are essential for urban mobility
analysis, underpinning applications in traffic forecasting, infrastructure
planning, and policy design. However, existing methods suffer from two critical
limitations: (1) reliance on auxiliary features (e.g., Points of Interest,
socioeconomic statistics) that are costly to collect and have limited spatial
coverage; and (2) sensitivity to spatial topology, where minor index reordering
of urban regions (e.g., census tract relabeling) disrupts structural coherence
in generated flows. To address these challenges, we propose Sat2Flow, a latent
structure-aware diffusion-based framework that generates structurally coherent
OD flows using solely satellite imagery as input. Our approach introduces a
multi-kernel encoder to capture diverse regional interactions and employs a
permutation-aware diffusion process that aligns latent representations across
different regional orderings. Through a joint contrastive training objective
that bridges satellite-derived features with OD patterns, combined with
equivariant diffusion training that enforces structural consistency, Sat2Flow
ensures topological robustness under arbitrary regional reindexing.
Experimental results on real-world urban datasets demonstrate that Sat2Flow
outperforms both physics-based and data-driven baselines in numerical accuracy
while preserving empirical distributions and spatial structures under index
permutations. Sat2Flow offers a globally scalable solution for OD flow
generation in data-scarce urban environments, eliminating region-specific
auxiliary data dependencies while maintaining structural invariance for robust
mobility modeling.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19429v1' target='_blank'>An Iterative Approach for Heterogeneous Multi-Agent Route Planning with
  Resource Transportation Uncertainty and Temporal Logic Goals</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gustavo A. Cardona, Kaier Liang, Cristian-Ioan Vasile</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 20:52:11</h6>
<p class='card-text'>This paper presents an iterative approach for heterogeneous multi-agent route
planning in environments with unknown resource distributions. We focus on a
team of robots with diverse capabilities tasked with executing missions
specified using Capability Temporal Logic (CaTL), a formal framework built on
Signal Temporal Logic to handle spatial, temporal, capability, and resource
constraints. The key challenge arises from the uncertainty in the initial
distribution and quantity of resources in the environment. To address this, we
introduce an iterative algorithm that dynamically balances exploration and task
fulfillment. Robots are guided to explore the environment, identifying resource
locations and quantities while progressively refining their understanding of
the resource landscape. At the same time, they aim to maximally satisfy the
mission objectives based on the current information, adapting their strategies
as new data is uncovered. This approach provides a robust solution for planning
in dynamic, resource-constrained environments, enabling efficient coordination
of heterogeneous teams even under conditions of uncertainty. Our method's
effectiveness and performance are demonstrated through simulated case studies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19387v1' target='_blank'>Climate-Resilient Ports and Waterborne Transport Systems: Current Status
  and Future Prospects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nadia Pourmohammad-Zia, Mark van Koningsveld</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 19:28:59</h6>
<p class='card-text'>The increasing challenges posed by climate change necessitate a comprehensive
examination of the resilience of waterborne transport systems. This paper
explores the nexus of climate resilience, and waterborne transport, addressing
the challenges faced by ports and their connecting waterborne transport
systems. It provides an in-depth analysis of the current status of
climate-resilient infrastructure and operations while emphasizing the
transformative potential of emerging technologies. Through a systematic review,
the paper identifies critical gaps and opportunities. Research predominantly
emphasizes port infrastructure over supply chain resilience, neglecting the
interconnected vulnerabilities of maritime networks. There is limited focus on
specific climate-induced disruptions, such as drought and compounded events,
which complicate resilience planning. Methodologically, risk assessments and
case studies dominate the field, while advanced technologies such as digital
twins, artificial intelligence, and satellite monitoring remain underutilized.
Geographic disparities in research output and a tendency toward short- to
medium-term planning further constrain global and long-term resilience efforts.
To address these gaps, the study advocates for systems-based approaches that
integrate infrastructure, operations, and supply chains. It highlights
collaborative frameworks and advanced tools, including digital twins, machine
learning, and participatory modeling, as crucial for enabling predictive and
adaptive risk management. This study stands as one of the first comprehensive
reviews exclusively focused on climate resilience in ports and waterborne
transport systems. It provides actionable insights for policymakers,
researchers, and industry stakeholders, proposing a future research agenda to
advance waterborne transport systems capable of withstanding multifaceted
climate impacts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19355v1' target='_blank'>Bifrost Models of the Quiet Sun. I. Comparison with Solar Observations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Milan Gošić, Viggo H. Hansteen, Alberto Sainz Dalda, Bart De Pontieu, Luc H. M. Rouppe van der Voort</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 18:33:35</h6>
<p class='card-text'>Studying the emergence of magnetic fields is essential for understanding the
physical mechanisms behind various phenomena in the solar atmosphere. Most
importantly, the emerging fields offer valuable insights into how energy and
mass are transferred to the upper solar atmosphere. As a result, they have
garnered significant attention from both observational and theoretical
perspectives. In this article, we present two models of quiet-Sun-like magnetic
fields generated by the Bifrost code. We compare these models with observations
from the Swedish 1-meter Solar Telescope (SST) and the Interface Region Imaging
Spectrograph (IRIS). By tracking the magnetic features in both the SST and
Bifrost data, we determine the similarities and differences between the fields
identified in the models and those observed. We conduct a quantitative
comparison of various properties, such as flux content, flux densities,
horizontal and line-of-sight velocities, lifetimes, sizes, and surface
interactions. Additionally, we identify and analyze the properties of the
largest emerging bipoles in the SST and Bifrost data. Our findings indicate
that the magnetic bipoles in the Bifrost simulations are generally stronger
than those observed with the SST. However, a qualitative comparison of the
chromospheric and transition region responses to the emerging fields in the
Bifrost models, SST, and IRIS observations shows similar heating processes
occurring above and around the emerging fields. Finally, we outline our plans
for future work aimed at studying the emergence of magnetic fields in the quiet
Sun, with a particular focus on the chromosphere and upper atmospheric layers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19220v1' target='_blank'>The 2025 Roadmaps for the US Magnet Development Program</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lance Cooley, Paolo Ferracin, Steve Gourlay, David Larbalestier, Mark Palmer, Soren Prestemon, George Velev, Giorgio Ambrosio, Diego Arbelaez, Karie Badgley, Lucas Brouwer, Daniel Davis, Jose Luis Fernandez, Vadim Kashikhin, Steven Krave, Maxim Marchevsky, Igor Novitski, Ian Pong, Tengming Shen, Stoyan Stoynev, Reed Teyber, Giorgio Vallone, Xiaorong Wang, Xingchen Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 17:36:52</h6>
<p class='card-text'>The US Physics community completed the Snowmass planning process in 2022,
culminating in the HEPAP Particle Physics Project Prioritization Panel (P5)
publishing its summary report at the end of 2023. Building on this, the US
Magnet Development Program, a national accelerator magnet R&D program
established by DOE-OHEP in 2016, has updated its strategic plan to align with
the 2023 P5 report, resulting in this roadmap document.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19199v1' target='_blank'>Planning-Query-Guided Model Generation for Model-Based Deformable Object
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alex LaGrassa, Zixuan Huang, Dmitry Berenson, Oliver Kroemer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 17:03:39</h6>
<p class='card-text'>Efficient planning in high-dimensional spaces, such as those involving
deformable objects, requires computationally tractable yet sufficiently
expressive dynamics models. This paper introduces a method that automatically
generates task-specific, spatially adaptive dynamics models by learning which
regions of the object require high-resolution modeling to achieve good task
performance for a given planning query. Task performance depends on the complex
interplay between the dynamics model, world dynamics, control, and task
requirements. Our proposed diffusion-based model generator predicts per-region
model resolutions based on start and goal pointclouds that define the planning
query. To efficiently collect the data for learning this mapping, a two-stage
process optimizes resolution using predictive dynamics as a prior before
directly optimizing using closed-loop performance. On a tree-manipulation task,
our method doubles planning speed with only a small decrease in task
performance over using a full-resolution model. This approach informs a path
towards using previous planning and control data to generate computationally
efficient yet sufficiently expressive dynamics models for new tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19186v1' target='_blank'>Real-Time Model Checking for Closed-Loop Robot Reactive Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christopher Chandler, Bernd Porr, Giulia Lafratta, Alice Miller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 16:49:30</h6>
<p class='card-text'>We present a new application of model checking which achieves real-time
multi-step planning and obstacle avoidance on a real autonomous robot. We have
developed a small, purpose-built model checking algorithm which generates plans
in situ based on "core" knowledge and attention as found in biological agents.
This is achieved in real-time using no pre-computed data on a low-powered
device. Our approach is based on chaining temporary control systems which are
spawned to counteract disturbances in the local environment that disrupt an
autonomous agent from its preferred action (or resting state). A novel
discretization of 2D LiDAR data sensitive to bounded variations in the local
environment is used. Multi-step planning using model checking by forward
depth-first search is applied to cul-de-sac and playground scenarios. Both
empirical results and informal proofs of two fundamental properties of our
approach demonstrate that model checking can be used to create efficient
multi-step plans for local obstacle avoidance, improving on the performance of
a reactive agent which can only plan one step. Our approach is an instructional
case study for the development of safe, reliable and explainable planning in
the context of autonomous vehicles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19175v1' target='_blank'>Development and Potential of new Micro-Mirror Devices Optimized for
  Astronomy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Massimo Robberto, Cuiling Gong, Jim Huffman, Zoran Ninkov, Ivan Puchades, Mario Gennaro, Susan A. Kassin, Steven A. Smee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 16:27:16</h6>
<p class='card-text'>We introduce our new program to develop two-dimensional MEMS arrays of
individually addressable micro-mirrors (''Micro-Mirror Devices'', MMDs)
specifically optimized for astronomy, multi-slit spectroscopy in particular.
After reviewing the main characteristics and performance of the currently
available options, Micro Shutter Arrays by NASA/Goddard and Digital Micromirror
Devices by Texas Instruments, we present our planned first generation/baseline
devices with 30 micron x 30 miron pixel size arranged in a 1K x 1K format with
tilt angle 15 degrees. Our goal is to bring to maturity a technology capable of
delivering arrays of 2K x 2K element of 100 micron x 100 micron, buttable on
two sides to achieve even larger formats. In additions to MEMS design, we will
develop the associated device packaging and electronic control circuitry
leveraging on the extensive expertise gained in the last 30+ years by leading
experts from digital imaging industry.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19168v1' target='_blank'>Direction Informed Trees (DIT*): Optimal Path Planning via Direction
  Filter and Direction Cost Heuristic</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liding Zhang, Kejia Chen, Kuanqi Cai, Yu Zhang, Yixuan Dang, Yansong Wu, Zhenshan Bing, Fan Wu, Sami Haddadin, Alois Knoll</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 16:16:18</h6>
<p class='card-text'>Optimal path planning requires finding a series of feasible states from the
starting point to the goal to optimize objectives. Popular path planning
algorithms, such as Effort Informed Trees (EIT*), employ effort heuristics to
guide the search. Effective heuristics are accurate and computationally
efficient, but achieving both can be challenging due to their conflicting
nature. This paper proposes Direction Informed Trees (DIT*), a sampling-based
planner that focuses on optimizing the search direction for each edge,
resulting in goal bias during exploration. We define edges as generalized
vectors and integrate similarity indexes to establish a directional filter that
selects the nearest neighbors and estimates direction costs. The estimated
direction cost heuristics are utilized in edge evaluation. This strategy allows
the exploration to share directional information efficiently. DIT* convergence
faster than existing single-query, sampling-based planners on tested problems
in R^4 to R^16 and has been demonstrated in real-world environments with
various planning tasks. A video showcasing our experimental results is
available at: https://youtu.be/2SX6QT2NOek</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19150v1' target='_blank'>Uncertainty-Resilient Active Intention Recognition for Robotic
  Assistants</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Juan Carlos Saborío, Marc Vinci, Oscar Lima, Sebastian Stock, Lennart Niecksch, Martin Günther, Alexander Sung, Joachim Hertzberg, Martin Atzmüller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 16:00:38</h6>
<p class='card-text'>Purposeful behavior in robotic assistants requires the integration of
multiple components and technological advances. Often, the problem is reduced
to recognizing explicit prompts, which limits autonomy, or is oversimplified
through assumptions such as near-perfect information. We argue that a critical
gap remains unaddressed -- specifically, the challenge of reasoning about the
uncertain outcomes and perception errors inherent to human intention
recognition. In response, we present a framework designed to be resilient to
uncertainty and sensor noise, integrating real-time sensor data with a
combination of planners. Centered around an intention-recognition POMDP, our
approach addresses cooperative planning and acting under uncertainty. Our
integrated framework has been successfully tested on a physical robot with
promising results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19126v1' target='_blank'>Probing the HI distribution at small scales using 21-cm Intensity
  Mapping at large scales</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minal Chhabra, Somnath Bharadwaj</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 15:24:57</h6>
<p class='card-text'>Neutral hydrogen (HI) 21-cm Intensity Mapping (IM) holds the potential to map
the large-scale structures in the Universe over a wide redshift range $(z
\lesssim 5.5)$, measure cosmological parameters, and shed light on the nature
of dark energy. In addition, the signal is also sensitive to how the HI is
distributed among the dark matter haloes, this being quantified through the
HIHM relation, which relates the HI mass to the halo mass. In this work, we
investigate whether measurements of the 21-cm power spectrum (PS) and
bispectrum (BS) at large scales can be used to estimate the HIHM relation,
which quantifies the HI distribution at small scales. As a proof of concept, we
consider the simulated 21-cm IM signal at $z=1$. We find that the measured
21-cm PS and BS at large scales $(k \le k_{ul} = 0.32 \, {\rm Mpc}^{-1})$ are
well modeled using perturbation theory, with only two free parameters namely
$[\Omega_{\rm HI} b_1]$ and $\gamma = b_2/b_1$. Combining the measured 21-cm PS
and BS with an independent measurement of $\Omega_{\rm HI} $, we show that it
is possible to estimate the three parameters that quantify the HIHM relation.
We expect observational estimates of the HIHM relation to shed light on galaxy
formation and the evolution of the ISM. Our preliminary analysis ignores
redshift space distortion and the system noise in IM observations, which we
plan to address in future work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19119v1' target='_blank'>Enhancing Kinematics Understanding through a Video Game Based on
  Real-Time Motion Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mateo Dutra, Marcos Abreu, Martín Monteiro, Silvia Sguilla, Cecilia Stari, Álvaro Suárez, Arturo C. Marti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 15:20:38</h6>
<p class='card-text'>Interpreting kinematic graphs remains a significant challenge in physics
education. The MissionMotion Project addresses this issue by providing a
gamified physical-computational environment combining low-cost sensors,
physical activity, computational thinking, and real-time visualization of
motion graphs. This paper presents the design, development, and implementation
of the project, with a particular focus on the pilot phase conducted with high
school students in Uruguay. During this phase, we primarily used the MEEGA+
questionnaire to evaluate the gaming experience, usability, and motivation of
the participants. Our analysis of the results shows high levels of
satisfaction, perceived learning, and engagement, supporting the proposal's
viability. Finally, we plan to conduct a large-scale conceptual evaluation to
analyze how the proposal impacts understanding of kinematic graphs using
standardized assessment tools.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19112v1' target='_blank'>Random forest-based out-of-distribution detection for robust lung cancer
  segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aneesh Rangnekar, Harini Veeraraghavan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 15:14:29</h6>
<p class='card-text'>Accurate detection and segmentation of cancerous lesions from computed
tomography (CT) scans is essential for automated treatment planning and cancer
treatment response assessment. Transformer-based models with self-supervised
pretraining can produce reliably accurate segmentation from in-distribution
(ID) data but degrade when applied to out-of-distribution (OOD) datasets. We
address this challenge with RF-Deep, a random forest classifier that utilizes
deep features from a pretrained transformer encoder of the segmentation model
to detect OOD scans and enhance segmentation reliability. The segmentation
model comprises a Swin Transformer encoder, pretrained with masked image
modeling (SimMIM) on 10,432 unlabeled 3D CT scans covering cancerous and
non-cancerous conditions, with a convolution decoder, trained to segment lung
cancers in 317 3D scans. Independent testing was performed on 603 3D CT public
datasets that included one ID dataset and four OOD datasets comprising chest
CTs with pulmonary embolism (PE) and COVID-19, and abdominal CTs with kidney
cancers and healthy volunteers. RF-Deep detected OOD cases with a FPR95 of
18.26%, 27.66%, and less than 0.1% on PE, COVID-19, and abdominal CTs,
consistently outperforming established OOD approaches. The RF-Deep classifier
provides a simple and effective approach to enhance reliability of cancer
segmentation in ID and OOD scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.19077v1' target='_blank'>"Where does it hurt?" -- Dataset and Study on Physician Intent
  Trajectories in Doctor Patient Dialogues</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tom Röhr, Soumyadeep Roy, Fares Al Mohamad, Jens-Michalis Papaioannou, Wolfgang Nejdl, Felix Gers, Alexander Löser</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-26 14:38:17</h6>
<p class='card-text'>In a doctor-patient dialogue, the primary objective of physicians is to
diagnose patients and propose a treatment plan. Medical doctors guide these
conversations through targeted questioning to efficiently gather the
information required to provide the best possible outcomes for patients. To the
best of our knowledge, this is the first work that studies physician intent
trajectories in doctor-patient dialogues. We use the `Ambient Clinical
Intelligence Benchmark' (Aci-bench) dataset for our study. We collaborate with
medical professionals to develop a fine-grained taxonomy of physician intents
based on the SOAP framework (Subjective, Objective, Assessment, and Plan). We
then conduct a large-scale annotation effort to label over 5000 doctor-patient
turns with the help of a large number of medical experts recruited using
Prolific, a popular crowd-sourcing platform. This large labeled dataset is an
important resource contribution that we use for benchmarking the
state-of-the-art generative and encoder models for medical intent
classification tasks. Our findings show that our models understand the general
structure of medical dialogues with high accuracy, but often fail to identify
transitions between SOAP categories. We also report for the first time common
trajectories in medical dialogue structures that provide valuable insights for
designing `differential diagnosis' systems. Finally, we extensively study the
impact of intent filtering for medical dialogue summarization and observe a
significant boost in performance. We make the codes and data, including
annotation guidelines, publicly available at
https://github.com/DATEXIS/medical-intent-classification.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>