<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-08-20</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-08-20</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.14006v1' target='_blank'>ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor
  Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohamed Abouagour, Eleftherios Garyfallidis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 17:07:47</h6>
<p class='card-text'>We introduce ResPlan, a large-scale dataset of 17,000 detailed, structurally
rich, and realistic residential floor plans, created to advance spatial AI
research. Each plan includes precise annotations of architectural elements
(walls, doors, windows, balconies) and functional spaces (such as kitchens,
bedrooms, and bathrooms). ResPlan addresses key limitations of existing
datasets such as RPLAN (Wu et al., 2019) and MSD (van Engelenburg et al., 2024)
by offering enhanced visual fidelity and greater structural diversity,
reflecting realistic and non-idealized residential layouts. Designed as a
versatile, general-purpose resource, ResPlan supports a wide range of
applications including robotics, reinforcement learning, generative AI, virtual
and augmented reality, simulations, and game development. Plans are provided in
both geometric and graph-based formats, enabling direct integration into
simulation engines and fast 3D conversion. A key contribution is an open-source
pipeline for geometry cleaning, alignment, and annotation refinement.
Additionally, ResPlan includes structured representations of room connectivity,
supporting graph-based spatial reasoning tasks. Finally, we present comparative
analyses with existing benchmarks and outline several open benchmark tasks
enabled by ResPlan. Ultimately, ResPlan offers a significant advance in scale,
realism, and usability, providing a robust foundation for developing and
benchmarking next-generation spatial intelligence systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13995v1' target='_blank'>Self-Supervised Sparse Sensor Fusion for Long Range Perception</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Edoardo Palladin, Samuel Brucker, Filippo Ghilotti, Praveen Narayanan, Mario Bijelic, Felix Heide</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 16:40:29</h6>
<p class='card-text'>Outside of urban hubs, autonomous cars and trucks have to master driving on
intercity highways. Safe, long-distance highway travel at speeds exceeding 100
km/h demands perception distances of at least 250 m, which is about five times
the 50-100m typically addressed in city driving, to allow sufficient planning
and braking margins. Increasing the perception ranges also allows to extend
autonomy from light two-ton passenger vehicles to large-scale forty-ton trucks,
which need a longer planning horizon due to their high inertia. However, most
existing perception approaches focus on shorter ranges and rely on Bird's Eye
View (BEV) representations, which incur quadratic increases in memory and
compute costs as distance grows. To overcome this limitation, we built on top
of a sparse representation and introduced an efficient 3D encoding of
multi-modal and temporal features, along with a novel self-supervised
pre-training scheme that enables large-scale learning from unlabeled
camera-LiDAR data. Our approach extends perception distances to 250 meters and
achieves an 26.6% improvement in mAP in object detection and a decrease of
30.5% in Chamfer Distance in LiDAR forecasting compared to existing methods,
reaching distances up to 250 meters. Project Page:
https://light.princeton.edu/lrs4fusion/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13982v1' target='_blank'>The Social Context of Human-Robot Interactions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sydney Thompson, Kate Candon, Marynel VÃ¡zquez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 16:15:58</h6>
<p class='card-text'>The Human-Robot Interaction (HRI) community often highlights the social
context of an interaction as a key consideration when designing, implementing,
and evaluating robot behavior. Unfortunately, researchers use the term "social
context" in varied ways. This can lead to miscommunication, making it
challenging to draw connections between related work on understanding and
modeling the social contexts of human-robot interactions. To address this gap,
we survey the HRI literature for existing definitions and uses of the term
"social context". Then, we propose a conceptual model for describing the social
context of a human-robot interaction. We apply this model to existing work, and
we discuss a range of attributes of social contexts that can help researchers
plan for interactions, develop behavior models for robots, and gain insights
after interactions have taken place. We conclude with a discussion of open
research questions in relation to understanding and modeling the social
contexts of human-robot interactions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13981v1' target='_blank'>Multi-User Contextual Cascading Bandits for Personalized Recommendation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiho Park, Huiwen Jia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 16:14:33</h6>
<p class='card-text'>We introduce a Multi-User Contextual Cascading Bandit model, a new
combinatorial bandit framework that captures realistic online advertising
scenarios where multiple users interact with sequentially displayed items
simultaneously. Unlike classical contextual bandits, MCCB integrates three key
structural elements: (i) cascading feedback based on sequential arm exposure,
(ii) parallel context sessions enabling selective exploration, and (iii)
heterogeneous arm-level rewards. We first propose Upper Confidence Bound with
Backward Planning (UCBBP), a UCB-style algorithm tailored to this setting, and
prove that it achieves a regret bound of $\widetilde{O}(\sqrt{THN})$ over $T$
episodes, $H$ session steps, and $N$ contexts per episode. Motivated by the
fact that many users interact with the system simultaneously, we introduce a
second algorithm, termed Active Upper Confidence Bound with Backward Planning
(AUCBBP), which shows a strict efficiency improvement in context scaling, i.e.,
user scaling, with a regret bound of $\widetilde{O}(\sqrt{T+HN})$. We validate
our theoretical findings via numerical experiments, demonstrating the empirical
effectiveness of both algorithms under various settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13947v1' target='_blank'>Real-Time, Population-Based Reconstruction of 3D Bone Models via
  Very-Low-Dose Protocols</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiqun Lin, Haoran Sun, Yongqing Li, Rabia Aslam, Lung Fung Tse, Tiange Cheng, Chun Sing Chui, Wing Fung Yau, Victorine R. Le Meur, Meruyert Amangeldy, Kiho Cho, Yinyu Ye, James Zou, Wei Zhao, Xiaomeng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 15:36:58</h6>
<p class='card-text'>Patient-specific bone models are essential for designing surgical guides and
preoperative planning, as they enable the visualization of intricate anatomical
structures. However, traditional CT-based approaches for creating bone models
are limited to preoperative use due to the low flexibility and high radiation
exposure of CT and time-consuming manual delineation. Here, we introduce
Semi-Supervised Reconstruction with Knowledge Distillation (SSR-KD), a fast and
accurate AI framework to reconstruct high-quality bone models from biplanar
X-rays in 30 seconds, with an average error under 1.0 mm, eliminating the
dependence on CT and manual work. Additionally, high tibial osteotomy
simulation was performed by experts on reconstructed bone models, demonstrating
that bone models reconstructed from biplanar X-rays have comparable clinical
applicability to those annotated from CT. Overall, our approach accelerates the
process, reduces radiation exposure, enables intraoperative guidance, and
significantly improves the practicality of bone models, offering transformative
applications in orthopedics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13914v1' target='_blank'>Development of a defacing algorithm to protect the privacy of head and
  neck cancer patients in publicly-accessible radiotherapy datasets</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kayla O'Sullivan-Steben, Luc Galarneau, John Kildea</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 15:14:16</h6>
<p class='card-text'>Introduction: The rise in public medical imaging datasets has raised concerns
about patient reidentification from head CT scans. However, existing defacing
algorithms often remove or distort Organs at Risk (OARs) and Planning Target
Volumes (PTVs) in head and neck cancer (HNC) patients, and ignore DICOM-RT
Structure Set and Dose data. Therefore, we developed and validated a novel
automated defacing algorithm that preserves these critical structures while
removing identifiable features from HNC CTs and DICOM-RT data.
  Methods: Eye contours were used as landmarks to automate the removal of CT
pixels above the inferior-most eye slice and anterior to the eye midpoint.
Pixels within PTVs were retained if they intersected with the removed region.
The body contour and dose map were reshaped to reflect the defaced image. We
validated our approach on 829 HNC CTs from 622 patients. Privacy protection was
evaluated by applying the FaceNet512 facial recognition algorithm before and
after defacing on 3D-rendered CT pairs from 70 patients. Research utility was
assessed by examining the impact of defacing on autocontouring performance
using LimbusAI and analyzing PTV locations relative to the defaced regions.
  Results: Before defacing, FaceNet512 matched 97% of patients' CTs. After
defacing, this rate dropped to 4%. LimbusAI effectively autocontoured organs in
the defaced CTs, with perfect Dice scores of 1 for OARs below the defaced
region, and excellent scores exceeding 0.95 for OARs on the same slices as the
crop. We found that 86% of PTVs were entirely below the cropped region, 9.1%
were on the same slice as the crop without overlap, and only 4.9% extended into
the cropped area.
  Conclusions: We developed a novel defacing algorithm that anonymizes HNC CT
scans and related DICOM-RT data while preserving essential structures, enabling
the sharing of HNC imaging datasets for Big Data and AI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13877v1' target='_blank'>Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided
  Decision Transformer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rathnam Vidushika Rasanji, Jin Wei-Kocsis, Jiansong Zhang, Dongming Gan, Ragu Athinarayanan, Paul Asunda</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 14:42:18</h6>
<p class='card-text'>Reinforcement learning (RL) has demonstrated great potential in robotic
operations. However, its data-intensive nature and reliance on the Markov
Decision Process (MDP) assumption limit its practical deployment in real-world
scenarios involving complex dynamics and long-term temporal dependencies, such
as multi-robot manipulation. Decision Transformers (DTs) have emerged as a
promising offline alternative by leveraging causal transformers for sequence
modeling in RL tasks. However, their applications to multi-robot manipulations
still remain underexplored. To address this gap, we propose a novel framework,
Symbolically-Guided Decision Transformer (SGDT), which integrates a
neuro-symbolic mechanism with a causal transformer to enable deployable
multi-robot collaboration. In the proposed SGDT framework, a neuro-symbolic
planner generates a high-level task-oriented plan composed of symbolic
subgoals. Guided by these subgoals, a goal-conditioned decision transformer
(GCDT) performs low-level sequential decision-making for multi-robot
manipulation. This hierarchical architecture enables structured, interpretable,
and generalizable decision making in complex multi-robot collaboration tasks.
We evaluate the performance of SGDT across a range of task scenarios, including
zero-shot and few-shot scenarios. To our knowledge, this is the first work to
explore DT-based technology for multi-robot manipulation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13738v1' target='_blank'>Eliminating Rasterization: Direct Vector Floor Plan Generation with
  DiffPlanner</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shidong Wang, Renato Pajarola</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 11:20:35</h6>
<p class='card-text'>The boundary-constrained floor plan generation problem aims to generate the
topological and geometric properties of a set of rooms within a given boundary.
Recently, learning-based methods have made significant progress in generating
realistic floor plans. However, these methods involve a workflow of converting
vector data into raster images, using image-based generative models, and then
converting the results back into vector data. This process is complex and
redundant, often resulting in information loss. Raster images, unlike vector
data, cannot scale without losing detail and precision. To address these
issues, we propose a novel deep learning framework called DiffPlanner for
boundary-constrained floor plan generation, which operates entirely in vector
space. Our framework is a Transformer-based conditional diffusion model that
integrates an alignment mechanism in training, aligning the optimization
trajectory of the model with the iterative design processes of designers. This
enables our model to handle complex vector data, better fit the distribution of
the predicted targets, accomplish the challenging task of floor plan layout
design, and achieve user-controllable generation. We conduct quantitative
comparisons, qualitative evaluations, ablation experiments, and perceptual
studies to evaluate our method. Extensive experiments demonstrate that
DiffPlanner surpasses existing state-of-the-art methods in generating floor
plans and bubble diagrams in the creative stages, offering more controllability
to users and producing higher-quality results that closely match the ground
truths.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13723v1' target='_blank'>Parametric feedback cooling of librations of a nanodiamond in a Paul
  trap: Towards matter-wave interferometry with massive objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maria Muretova, Yonathan Japha, Marko Toros, Ron Folman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 10:44:39</h6>
<p class='card-text'>Quantum mechanics (QM) and General relativity (GR), also known as the theory
of gravity, are the two pillars of modern physics. A matter-wave interferometer
with a massive particle can test numerous fundamental ideas, including the
spatial superposition principle - a foundational concept in QM - in completely
new regimes, as well as the interface between QM and GR, e.g., testing the
quantization of gravity. Consequently, there exists an intensive effort to
realize such an interferometer. While several paths are being pursued, we focus
on utilizing nanodiamonds (NDs) as our particle, and a spin embedded in the ND
together with Stern-Gerlach forces, to achieve a closed loop in space-time.
There is a growing community of groups pursuing this path [1]. We are posting
this technical note (as part of a series of seven such notes) to highlight our
plans and solutions concerning various challenges in this ambitious endeavor,
hoping this will support this growing community. Here, we present a theoretical
study concerning the impact of rotations of the ND on the interferometric
contrast. We have previously shown that for a first-generation Stern-Gerlach
interferometer with an ND composed of 10^7 atoms, it is sufficient to cool the
center of mass to milli-Kelvin temperatures. In this work, we similarly show
that rotation does not have to be cooled to the ground state, and cooling to
hundreds of rotational phonons is good enough. We describe and simulate
parametric feedback cooling of librational modes of a charged ND levitated in a
Paul trap. The cooling is performed by modulating the electric field of the
trap. We examine the dependence of the efficiency of cooling on the electric
potential and the shape of the object. We show that the required libration
temperatures should be within reach in the very near future. We would be happy
to make more details available upon request.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13662v1' target='_blank'>Fabrication of nano-diamonds with a single NV center: Towards
  matter-wave interferometry with massive objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Menachem Givon, Yaniv Bar-Haim, David Groswasser, Asi Solodar, Nadav Aharon, Michael Belman, Amit Yosefi, Erez Golan, Jurgen Jopp, Ron Folman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 09:08:59</h6>
<p class='card-text'>Quantum mechanics (QM) and General relativity (GR), also known as the theory
of gravity, are the two pillars of modern physics. A matter-wave interferometer
with a massive particle can test numerous fundamental ideas, including the
spatial superposition principle - a foundational concept in QM - in previously
unexplored regimes. It also opens the possibility of probing the interface
between QM and GR, such as testing the quantization of gravity. Consequently,
there exists an intensive effort to realize such an interferometer. While
several approaches are being explored, we focus on utilizing nanodiamonds with
embedded spins as test particles which, in combination with Stern-Gerlach
forces, enable the realization of a closed-loop matter-wave interferometer in
space-time. There is a growing community of groups pursuing this path [1]. We
are posting this technical note (as part of a series of seven such notes), to
highlight our plans and solutions concerning various challenges in this
ambitious endeavor, hoping this will support this growing community. Here we
discuss the design considerations for a high-precision enhanced-coherence
nanodiamond source, review the fabrication processes used to produce
nanodiamond pillars measuring 40 x 65 x 80 nm, summarize the characterization
work completed to date, and conclude with an outlook on the remaining steps
needed to finalize the source fabrication. We would be happy to make available
more details upon request.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13531v1' target='_blank'>A Three-Level Whole-Body Disturbance Rejection Control Framework for
  Dynamic Motions in Legged Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bolin Li, Gewei Zuo, Zhixiang Wang, Xiaotian Ke, Lijun Zhu, Han Ding</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 05:43:54</h6>
<p class='card-text'>This paper presents a control framework designed to enhance the stability and
robustness of legged robots in the presence of uncertainties, including model
uncertainties, external disturbances, and faults. The framework enables the
full-state feedback estimator to estimate and compensate for uncertainties in
whole-body dynamics of the legged robots. First, we propose a novel moving
horizon extended state observer (MH-ESO) to estimate uncertainties and mitigate
noise in legged systems, which can be integrated into the framework for
disturbance compensation. Second, we introduce a three-level whole-body
disturbance rejection control framework (T-WB-DRC). Unlike the previous
two-level approach, this three-level framework considers both the plan based on
whole-body dynamics without uncertainties and the plan based on dynamics with
uncertainties, significantly improving payload transportation, external
disturbance rejection, and fault tolerance. Third, simulations of both humanoid
and quadruped robots in the Gazebo simulator demonstrate the effectiveness and
versatility of T-WB-DRC. Finally, extensive experimental trials on a quadruped
robot validate the robustness and stability of the system when using T-WB-DRC
under various disturbance conditions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13469v1' target='_blank'>Fundamentals of Next-generation Network Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:M. Umar Khan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 02:56:25</h6>
<p class='card-text'>The fifth-generation (5G) of cellular communications is expected to be
deployed in the next years to support a wide range of services with different
demands of peak data rates, latency and quality of experience (QoE). To support
higher data rates and latency requirements third-generation partnership project
(3GPP) has introduced numerology and bandwidth parts (BWPs), via new radio (NR)
for service-tailored resource allocation. Legacy 4G networks have generated
extensive data, which combined with crowd-sourced LTE infrastructure insights,
enables identification of high-traffic 5G deployment area (5GDA) for planning
new services. Given the mission-critical nature of 5G services, QoE is a big
challenge for MNOs to guarantee peak data rates for a defined percentage of
time. This work studies the fundamentals of 5G network planning methods that
reconciles coverage-capacity trade-offs through balanced radio network
dimensioning (RND), leveraging pragmatic NR modeling, and data-driven
strategies to minimize deployment costs and reduce cost-per-bit.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13440v1' target='_blank'>Consumer Autonomy or Illusion? Rethinking Consumer Agency in the Age of
  Algorithms</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pegah Nokhiz, Aravinda Kanchana Ruwanpathirana</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-19 01:48:12</h6>
<p class='card-text'>Consumer agency in the digital age is increasingly constrained by systemic
barriers and algorithmic manipulation, raising concerns about the authenticity
of consumption choices. Nowadays, financial decisions are shaped by external
pressures like obligatory consumption, algorithmic persuasion, and unstable
work schedules that erode financial autonomy. Obligatory consumption (like
hidden fees) is intensified by digital ecosystems. Algorithmic tactics like
personalized recommendations lead to impulsive purchases. Unstable work
schedules also undermine financial planning. Thus, it is important to study how
these factors impact consumption agency. To do so, we examine formal models
grounded in discounted consumption with constraints that bound agency. We
construct analytical scenarios in which consumers face obligatory payments,
algorithm-influenced impulsive expenses, or unpredictable income due to
temporal instability. Using this framework, we demonstrate that even rational,
utility-maximizing agents can experience early financial ruin when agency is
limited across structural, behavioral, or temporal dimensions and how
diminished autonomy impacts long-term financial well-being. Our central
argument is that consumer agency must be treated as a value (not a given)
requiring active cultivation, especially in digital ecosystems. The connection
between our formal modeling and this argument allows us to indicate that
limitations on agency (whether structural, behavioral, or temporal) can be
rigorously linked to measurable risks like financial instability. This
connection is also a basis for normative claims about consumption as a value,
by anchoring them in a formally grounded analysis of consumer behavior. As
solutions, we study systemic interventions and consumer education to support
value deliberation and informed choices. We formally demonstrate how these
measures strengthen agency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13407v1' target='_blank'>Accelerating Signal-Temporal-Logic-Based Task and Motion Planning of
  Bipedal Navigation using Benders Decomposition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiming Ren, Xuan Lin, Roman Mineyev, Karen M. Feigh, Samuel Coogan, Ye Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 23:58:22</h6>
<p class='card-text'>Task and motion planning under Signal Temporal Logic constraints is known to
be NP-hard. A common class of approaches formulates these hybrid problems,
which involve discrete task scheduling and continuous motion planning, as
mixed-integer programs (MIP). However, in applications for bipedal locomotion,
introduction of non-convex constraints such as kinematic reachability and
footstep rotation exacerbates the computational complexity of MIPs. In this
work, we present a method based on Benders Decomposition to address scenarios
where solving the entire monolithic optimization problem is prohibitively
intractable. Benders Decomposition proposes an iterative cutting-plane
technique that partitions the problem into a master problem to prototype a plan
that meets the task specification, and a series of subproblems for kinematics
and dynamics feasibility checks. Our experiments demonstrate that this method
achieves faster planning compared to alternative algorithms for solving the
resulting optimization program with nonlinear constraints.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13392v1' target='_blank'>Incremental Generalized Hybrid A*</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sidharth Talia, Oren Salzman, Siddhartha Srinivasa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 22:41:28</h6>
<p class='card-text'>We address the problem of efficiently organizing search over very large
trees, which arises in many applications ranging from autonomous driving to
aerial vehicles. Here, we are motivated by off-road autonomy, where real-time
planning is essential. Classical approaches use graphs of motion primitives and
exploit dominance to mitigate the curse of dimensionality and prune expansions
efficiently. However, for complex dynamics, repeatedly solving two-point
boundary-value problems makes graph construction too slow for fast kinodynamic
planning. Hybrid A* (HA*) addressed this challenge by searching over a tree of
motion primitives and introducing approximate pruning using a grid-based
dominance check. However, choosing the grid resolution is difficult: too coarse
risks failure, while too fine leads to excessive expansions and slow planning.
We propose Incremental Generalized Hybrid A* (IGHA*), an anytime tree-search
framework that dynamically organizes vertex expansions without rigid pruning.
IGHA* provably matches or outperforms HA*. For both on-road kinematic and
off-road kinodynamic planning queries for a car-like robot, variants of IGHA*
use 6x fewer expansions to the best solution compared to an optimized version
of HA*. In simulated off-road experiments in a high fidelity simulator, IGHA*
outperforms HA*M when both are used in the loop with a model predictive
controller. We demonstrate real-time performance both in simulation and on a
small-scale off-road vehicle, enabling fast, robust planning under complex
dynamics. Code: https://github.com/personalrobotics/IGHAStar</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13363v1' target='_blank'>Automated Assessment of Aesthetic Outcomes in Facial Plastic Surgery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pegah Varghaei, Kiran Abraham-Aggarwal, Manoj T. Abraham, Arun Ross</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 21:15:11</h6>
<p class='card-text'>We introduce a scalable, interpretable computer-vision framework for
quantifying aesthetic outcomes of facial plastic surgery using frontal
photographs. Our pipeline leverages automated landmark detection, geometric
facial symmetry computation, deep-learning-based age estimation, and nasal
morphology analysis. To perform this study, we first assemble the largest
curated dataset of paired pre- and post-operative facial images to date,
encompassing 7,160 photographs from 1,259 patients. This dataset includes a
dedicated rhinoplasty-only subset consisting of 732 images from 366 patients,
96.2% of whom showed improvement in at least one of the three nasal
measurements with statistically significant group-level change. Among these
patients, the greatest statistically significant improvements (p < 0.001)
occurred in the alar width to face width ratio (77.0%), nose length to face
height ratio (41.5%), and alar width to intercanthal ratio (39.3%). Among the
broader frontal-view cohort, comprising 989 rigorously filtered subjects, 71.3%
exhibited significant enhancements in global facial symmetry or perceived age
(p < 0.01). Importantly, our analysis shows that patient identity remains
consistent post-operatively, with True Match Rates of 99.5% and 99.6% at a
False Match Rate of 0.01% for the rhinoplasty-specific and general patient
cohorts, respectively. Additionally, we analyze inter-practitioner variability
in improvement rates. By providing reproducible, quantitative benchmarks and a
novel dataset, our pipeline facilitates data-driven surgical planning, patient
counseling, and objective outcome evaluation across practices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13350v1' target='_blank'>Adaptive Strategies for Pension Fund Management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Raphael Chinchilla, Thomas D. Rueter, Timothy R. McDade, Peter R. Fisher, Emmanuel Candes, Trevor Hastie, Stephen Boyd</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 20:19:42</h6>
<p class='card-text'>This paper proposes a simulation-based framework for assessing and improving
the performance of a pension fund management scheme. This framework is modular
and allows the definition of customized performance metrics that are used to
assess and iteratively improve asset and liability management policies. We
illustrate our framework with a simple implementation that showcases the power
of including adaptable features. We show that it is possible to dissipate
longevity and volatility risks by permitting adaptability in asset allocation
and payout levels. The numerical results show that by including a small amount
of flexibility, there can be a substantial reduction in the cost to run the
pension plan as well as a substantial decrease in the probability of
defaulting.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13306v1' target='_blank'>Stochastic Black Start Resource Allocation to Enable Dynamic Formation
  of Networked Microgrids and DER-aided Restoration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cong Bai, Salish Maharjan, Han Wang, Zhaoyu Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 18:50:42</h6>
<p class='card-text'>Extended outages in distributed systems (DSs) dominated by distributed energy
resources (DERs) require innovative strategies to efficiently and securely
deploy black start (BS) resources. To address the need, this paper proposes a
two-stage stochastic resource allocation method within synchronizing dynamic
microgrids (MGs) for black start (SDMG-BS), enabling risk-averse and adaptive
restoration across various scenarios while ensuring frequency security. Virtual
synchronous generator (VSG)-controlled grid-forming inverters (GFMIs) equipped
with primary frequency governors (PFGs) are modeled as BS resources. Their
frequency response is characterized by three transient indices, which are
deployed as frequency dynamic constraints on load pick-up events to ensure
frequency stability during the BS process. SDMG-BS framework facilitates
location-independent synchronization among restored MGs and with the
transmission grid (TG) with the help of smart switches (SSWs). The model
incorporates scenario-based stochastic programming to address multi-source
uncertainties, including season-dependent operational conditions and
unpredictable TG outage durations, ensuring a resilient allocation plan. The
proposed approach is validated on a modified IEEE 123-node feeder with three
study cases designed across sixteen uncertainty scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13295v1' target='_blank'>Time Profile of U.S. Neighborhoods: Datasets of Time Use at Social
  Infrastructure Places</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yan Wang, Ziyi Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 18:22:04</h6>
<p class='card-text'>Social infrastructure plays a critical role in shaping neighborhood
well-being by fostering social and cultural interaction, enabling service
provision, and encouraging exposure to diverse environments. Despite the
growing knowledge of its spatial accessibility, time use at social
infrastructure places is underexplored due to the lack of a spatially resolved
national dataset. We address this gap by developing scalable
Social-Infrastructure Time Use measures (STU) that capture length and depth of
engagement, activity diversity, and spatial inequality, supported by
first-of-their-kind datasets spanning multiple geographic scales from census
tracts to metropolitan areas. Our datasets leverage anonymized and aggregated
foot traffic data collected between 2019 and 2024 across 49 continental U.S.
states. The data description reveals variances in STU across time, space, and
differing neighborhood sociodemographic characteristics. Validation
demonstrates generally robust population representation, consistent with
established national survey findings while revealing more nuanced patterns.
Future analyses could link STU with public health outcomes and environmental
factors to inform targeted interventions aimed at enhancing population
well-being and guiding social infrastructure planning and usage.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13138v1' target='_blank'>Human Digital Twin: Data, Models, Applications, and Challenges</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rong Pan, Hongyue Sun, Xiaoyu Chen, Giulia Pedrielli, Jiapeng Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 17:50:25</h6>
<p class='card-text'>Human digital twins (HDTs) are dynamic, data-driven virtual representations
of individuals, continuously updated with multimodal data to simulate, monitor,
and predict health trajectories. By integrating clinical, physiological,
behavioral, and environmental inputs, HDTs enable personalized diagnostics,
treatment planning, and anomaly detection. This paper reviews current
approaches to HDT modeling, with a focus on statistical and machine learning
techniques, including recent advances in anomaly detection and failure
prediction. It also discusses data integration, computational methods, and
ethical, technological, and regulatory challenges in deploying HDTs for
precision healthcare.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13113v1' target='_blank'>Contrastive Representations for Temporal Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alicja Ziarko, Michal Bortkiewicz, Michal Zawalski, Benjamin Eysenbach, Piotr Milos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 17:20:08</h6>
<p class='card-text'>In classical AI, perception relies on learning state-based representations,
while planning, which can be thought of as temporal reasoning over action
sequences, is typically achieved through search. We study whether such
reasoning can instead emerge from representations that capture both perceptual
and temporal structure. We show that standard temporal contrastive learning,
despite its popularity, often fails to capture temporal structure due to its
reliance on spurious features. To address this, we introduce Combinatorial
Representations for Temporal Reasoning (CRTR), a method that uses a negative
sampling scheme to provably remove these spurious features and facilitate
temporal reasoning. CRTR achieves strong results on domains with complex
temporal structure, such as Sokoban and Rubik's Cube. In particular, for the
Rubik's Cube, CRTR learns representations that generalize across all initial
states and allow it to solve the puzzle using fewer search steps than BestFS,
though with longer solutions. To our knowledge, this is the first method that
efficiently solves arbitrary Cube states using only learned representations,
without relying on an external search algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13073v1' target='_blank'>Large VLM-based Vision-Language-Action Models for Robotic Manipulation:
  A Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rui Shao, Wei Li, Lingsen Zhang, Renshan Zhang, Zhiyang Liu, Ran Chen, Liqiang Nie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 16:45:48</h6>
<p class='card-text'>Robotic manipulation, a key frontier in robotics and embodied AI, requires
precise motor control and multimodal understanding, yet traditional rule-based
methods fail to scale or generalize in unstructured, novel environments. In
recent years, Vision-Language-Action (VLA) models, built upon Large
Vision-Language Models (VLMs) pretrained on vast image-text datasets, have
emerged as a transformative paradigm. This survey provides the first
systematic, taxonomy-oriented review of large VLM-based VLA models for robotic
manipulation. We begin by clearly defining large VLM-based VLA models and
delineating two principal architectural paradigms: (1) monolithic models,
encompassing single-system and dual-system designs with differing levels of
integration; and (2) hierarchical models, which explicitly decouple planning
from execution via interpretable intermediate representations. Building on this
foundation, we present an in-depth examination of large VLM-based VLA models:
(1) integration with advanced domains, including reinforcement learning,
training-free optimization, learning from human videos, and world model
integration; (2) synthesis of distinctive characteristics, consolidating
architectural traits, operational strengths, and the datasets and benchmarks
that support their development; (3) identification of promising directions,
including memory mechanisms, 4D perception, efficient adaptation, multi-agent
cooperation, and other emerging capabilities. This survey consolidates recent
advances to resolve inconsistencies in existing taxonomies, mitigate research
fragmentation, and fill a critical gap through the systematic integration of
studies at the intersection of large VLMs and robotic manipulation. We provide
a regularly updated project page to document ongoing progress:
https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13070v1' target='_blank'>Reinforced Context Order Recovery for Adaptive Reasoning and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Long Ma, Fangwei Zhong, Yizhou Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 16:42:55</h6>
<p class='card-text'>Modern causal language models, followed by rapid developments in discrete
diffusion models, can now produce a wide variety of interesting and useful
content. However, these families of models are predominantly trained to output
tokens with a fixed (left-to-right) or random order, which may deviate from the
logical order in which tokens are generated originally. In this paper, we
observe that current causal and diffusion models encounter difficulties in
problems that require adaptive token generation orders to solve tractably,
which we characterize with the $\mathcal{V}$-information framework. Motivated
by this, we propose Reinforced Context Order Recovery (ReCOR), a
reinforcement-learning-based framework to extract adaptive, data-dependent
token generation orders from text data without annotations. Self-supervised by
token prediction statistics, ReCOR estimates the hardness of predicting every
unfilled token and adaptively selects the next token during both training and
inference. Experiments on challenging reasoning and planning datasets
demonstrate the superior performance of ReCOR compared with baselines,
sometimes outperforming oracle models supervised with the ground-truth order.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13057v1' target='_blank'>Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for
  Optimizing Demand Forecasting Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Adolfo GonzÃ¡lez, VÃ­ctor Parada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 16:25:49</h6>
<p class='card-text'>Demand forecasting is essential for strategic planning in competitive
environments, enabling resource optimization and improved responsiveness to
market dynamics. However, multivariate time series modeling faces challenges
due to data complexity, uncertainty, and frequent regime shifts. Traditional
evaluation metrics can introduce biases and limit generalization. This work
compares two custom evaluation functions: FMAE (Focused Mean Absolute Error),
focused on minimizing absolute errors, and HEF (Hierarchical Evaluation
Function), designed to weight global metrics and penalize large deviations.
Experiments were conducted under different data splits (91:9, 80:20, 70:30)
using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative
accuracy, robustness, and computational efficiency. Results show that HEF
consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,
RMSSE), enhancing model robustness and explanatory power. These findings were
confirmed via visualizations and statistical tests. Conversely, FMAE offers
advantages in local metrics (MAE, MASE) and execution time, making it suitable
for short-term scenarios. The study highlights a methodological trade-off: HEF
is ideal for strategic planning, while FMAE is better suited for operational
efficiency. A replicable framework is proposed for optimizing predictive models
in dynamic environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13052v1' target='_blank'>BOW: Bayesian Optimization over Windows for Motion Planning in Complex
  Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sourav Raxit, Abdullah Al Redwan Newaz, Paulo Padrao, Jose Fuentes, Leonardo Bobadilla</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 16:19:28</h6>
<p class='card-text'>This paper introduces the BOW Planner, a scalable motion planning algorithm
designed to navigate robots through complex environments using constrained
Bayesian optimization (CBO). Unlike traditional methods, which often struggle
with kinodynamic constraints such as velocity and acceleration limits, the BOW
Planner excels by concentrating on a planning window of reachable velocities
and employing CBO to sample control inputs efficiently. This approach enables
the planner to manage high-dimensional objective functions and stringent safety
constraints with minimal sampling, ensuring rapid and secure trajectory
generation. Theoretical analysis confirms the algorithm's asymptotic
convergence to near-optimal solutions, while extensive evaluations in cluttered
and constrained settings reveal substantial improvements in computation times,
trajectory lengths, and solution times compared to existing techniques.
Successfully deployed across various real-world robotic systems, the BOW
Planner demonstrates its practical significance through exceptional sample
efficiency, safety-aware optimization, and rapid planning capabilities, making
it a valuable tool for advancing robotic applications. The BOW Planner is
released as an open-source package and videos of real-world and simulated
experiments are available at https://bow-web.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13256v1' target='_blank'>CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for
  Cardiac Care Support</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuting Zhang, Karina V. Bunting, Asgher Champsi, Xiaoxia Wang, Wenqi Lu, Alexander Thorley, Sandeep S Hothi, Zhaowen Qiu, Dipak Kotecha, Jinming Duan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 16:17:12</h6>
<p class='card-text'>Cardiovascular diseases (CVDs) remain the foremost cause of mortality
worldwide, a burden worsened by a severe deficit of healthcare workers.
Artificial intelligence (AI) agents have shown potential to alleviate this gap
via automated early detection and proactive screening, yet their clinical
application remains limited by: 1) prompt-based clinical role assignment that
relies on intrinsic model capabilities without domain-specific tool support; or
2) rigid sequential workflows, whereas clinical care often requires adaptive
reasoning that orders specific tests and, based on their results, guides
personalised next steps; 3) general and static knowledge bases without
continuous learning capability; and 4) fixed unimodal or bimodal inputs and
lack of on-demand visual outputs when further clarification is needed. In
response, a multimodal framework, CardAIc-Agents, was proposed to augment
models with external tools and adaptively support diverse cardiac tasks.
Specifically, a CardiacRAG agent generated general plans from updatable cardiac
knowledge, while the chief agent integrated tools to autonomously execute these
plans and deliver decisions. To enable adaptive and case-specific
customization, a stepwise update strategy was proposed to dynamically refine
plans based on preceding execution results, once the task was assessed as
complex. In addition, a multidisciplinary discussion tool was introduced to
interpret challenging cases, thereby supporting further adaptation. When
clinicians raised concerns, visual review panels were provided to assist final
validation. Experiments across three datasets showed the efficiency of
CardAIc-Agents compared to mainstream Vision-Language Models (VLMs),
state-of-the-art agentic systems, and fine-tuned VLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13032v2' target='_blank'>On the complexity of constrained reconfiguration and motion planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicolas Bousquet, Remy El Sabeh, Amer E. Mouawad, Naomi Nishimura</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 15:50:57</h6>
<p class='card-text'>Coordinating the motion of multiple agents in constrained environments is a
fundamental challenge in robotics, motion planning, and scheduling. A
motivating example involves $n$ robotic arms, each represented as a line
segment. The objective is to rotate each arm to its vertical orientation, one
at a time (clockwise or counterclockwise), without collisions nor rotating any
arm more than once. This scenario is an example of the more general
$k$-Compatible Ordering problem, where $n$ agents, each capable of $k$
state-changing actions, must transition to specific target states under
constraints encoded as a set $\mathcal{G}$ of $k$ pairs of directed graphs.
  We show that $k$-Compatible Ordering is $\mathsf{NP}$-complete, even when
$\mathcal{G}$ is planar, degenerate, or acyclic. On the positive side, we
provide polynomial-time algorithms for cases such as when $k = 1$ or
$\mathcal{G}$ has bounded treewidth. We also introduce generalized variants
supporting multiple state-changing actions per agent, broadening the
applicability of our framework. These results extend to a wide range of
scheduling, reconfiguration, and motion planning applications in constrained
environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.13021v2' target='_blank'>PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked
  Diffusion Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pengcheng Huang, Shuhao Liu, Zhenghao Liu, Yukun Yan, Shuo Wang, Zulong Chen, Tong Xiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 15:38:37</h6>
<p class='card-text'>Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.12998v1' target='_blank'>Vitamin N: Benefits of Different Forms of Public Greenery for Urban
  Health</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sanja Å ÄepanoviÄ, Sagar Joglekar, Stephen Law, Daniele Quercia, Ke Zhou, Alice Battiston, Rossano Schifanella</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 15:17:33</h6>
<p class='card-text'>Urban greenery is often linked to better health, yet findings from past
research have been inconsistent. One reason is that official greenery metrics
measure the amount or nearness of greenery but ignore how often people actually
may potentially see or use it in daily life. To address this gap, we introduced
a new classification that separates on-road greenery, which people see while
walking through streets, from off-road greenery, which requires planned visits.
We did so by combining aerial imagery of Greater London and greenery data from
OpenStreetMap with quantified greenery from over 100,000 Google Street View
images and accessibility estimates based on 160,000 road segments. We linked
these measures to 7.45 billion medical prescriptions issued by the National
Health Service and processed through our methodology. These prescriptions cover
five conditions: diabetes, hypertension, asthma, depression, and anxiety, as
well as opioid use. As hypothesized, we found that green on-road was more
strongly linked to better health than four widely used official measures. For
example, hypertension prescriptions dropped by 3.68% in wards with on-road
greenery above the median citywide level compared to those below it. If all
below-median wards reached the citywide median in on-road greenery,
prescription costs could fall by up to {\pounds}3.15 million each year. These
results suggest that greenery seen in daily life may be more relevant than
public yet secluded greenery, and that official metrics commonly used in the
literature have important limitations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2508.12980v1' target='_blank'>Scaling Whole-body Multi-contact Manipulation with Contact Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Victor LevÃ©, JoÃ£o Moura, Sachiya Fujita, Tamon Miyake, Steve Tonneau, Sethu Vijayakumar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-08-18 14:56:37</h6>
<p class='card-text'>Daily tasks require us to use our whole body to manipulate objects, for
instance when our hands are unavailable. We consider the issue of providing
humanoid robots with the ability to autonomously perform similar whole-body
manipulation tasks. In this context, the infinite possibilities for where and
how contact can occur on the robot and object surfaces hinder the scalability
of existing planning methods, which predominantly rely on discrete sampling.
Given the continuous nature of contact surfaces, gradient-based optimization
offers a more suitable approach for finding solutions. However, a key remaining
challenge is the lack of an efficient representation of robot surfaces. In this
work, we propose (i) a representation of robot and object surfaces that enables
closed-form computation of proximity points, and (ii) a cost design that
effectively guides whole-body manipulation planning. Our experiments
demonstrate that the proposed framework can solve problems unaddressed by
existing methods, and achieves a 77% improvement in planning time over the
state of the art. We also validate the suitability of our approach on real
hardware through the whole-body manipulation of boxes by a humanoid robot.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>