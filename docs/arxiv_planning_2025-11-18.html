<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-11-18</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-11-18</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13712v1' target='_blank'>From Black Box to Insight: Explainable AI for Extreme Event Preparedness</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kiana Vu, İsmet Selçuk Özer, Phung Lai, Zheng Wu, Thilanka Munasinghe, Jennifer Wei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 18:57:15</h6>
<p class='card-text'>As climate change accelerates the frequency and severity of extreme events such as wildfires, the need for accurate, explainable, and actionable forecasting becomes increasingly urgent. While artificial intelligence (AI) models have shown promise in predicting such events, their adoption in real-world decision-making remains limited due to their black-box nature, which limits trust, explainability, and operational readiness. This paper investigates the role of explainable AI (XAI) in bridging the gap between predictive accuracy and actionable insight for extreme event forecasting. Using wildfire prediction as a case study, we evaluate various AI models and employ SHapley Additive exPlanations (SHAP) to uncover key features, decision pathways, and potential biases in model behavior. Our analysis demonstrates how XAI not only clarifies model reasoning but also supports critical decision-making by domain experts and response teams. In addition, we provide supporting visualizations that enhance the interpretability of XAI outputs by contextualizing feature importance and temporal patterns in seasonality and geospatial characteristics. This approach enhances the usability of AI explanations for practitioners and policymakers. Our findings highlight the need for AI systems that are not only accurate but also interpretable, accessible, and trustworthy, essential for effective use in disaster preparedness, risk mitigation, and climate resilience planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13707v1' target='_blank'>OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaoyu Liang, Ziang Liu, Kelvin Lin, Edward Gu, Ruolin Ye, Tam Nguyen, Cynthia Hsu, Zhanxin Wu, Xiaoman Yang, Christy Sum Yu Cheung, Harold Soh, Katherine Dimitropoulou, Tapomayukh Bhattacharjee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 18:55:12</h6>
<p class='card-text'>We present OpenRoboCare, a multimodal dataset for robot caregiving, capturing expert occupational therapist demonstrations of Activities of Daily Living (ADLs). Caregiving tasks involve complex physical human-robot interactions, requiring precise perception under occlusions, safe physical contact, and long-horizon planning. While recent advances in robot learning from demonstrations have shown promise, there is a lack of a large-scale, diverse, and expert-driven dataset that captures real-world caregiving routines. To address this gap, we collect data from 21 occupational therapists performing 15 ADL tasks on two manikins. The dataset spans five modalities: RGB-D video, pose tracking, eye-gaze tracking, task and action annotations, and tactile sensing, providing rich multimodal insights into caregiver movement, attention, force application, and task execution strategies. We further analyze expert caregiving principles and strategies, offering insights to improve robot efficiency and task feasibility. Additionally, our evaluations demonstrate that OpenRoboCare presents challenges for state-of-the-art robot perception and human activity recognition methods, both critical for developing safe and adaptive assistive robots, highlighting the value of our contribution. See our website for additional visualizations: https://emprise.cs.cornell.edu/robo-care/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13698v1' target='_blank'>Resilient Distribution Network Planning against Dynamic Malicious Power Injection Attacks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hampei Sasahara, Tatsuya Yamada, Jun-ichi Imura, Henrik Sandberg</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 18:51:50</h6>
<p class='card-text'>Active distribution networks facilitating bidirectional power exchange with renewable energy resources are susceptible to cyberattacks due to integration of a diverse array of cyber components. This study introduces a grid-level defense strategy aimed at enhancing attack resiliency based on distribution network planning. Our proposed framework imposes a security requirement into existing planning methodologies, ensuring that voltage deviation from its rated value remains within a tolerable range against dynamically and maliciously injected power at end-user nodes. Unfortunately, the formulated problem in its original form is intractable because it is an infinite-dimensional bi-level optimization problem over a function space. To address this complexity, we develop an equivalent transformation into a tractable form as mixed-integer linear program leveraging linear dynamical system theory and graph theory. Notably, our investigation reveals that the severity of potential attacks hinges solely on the cumulative reactances over the path from the substation to the targeted node, thereby reducing the problem to a finite-dimensional problem. Further, the bi-level optimization problem is reduced to a single-level optimization problem by using a technique utilized in solving the shortest path problem. Through extensive numerical simulations conducted on a 54-node distribution network benchmark, our proposed methodology exhibits a noteworthy 29.3% enhancement in the resiliency, with a mere 2.1% uptick in the economic cost.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13647v1' target='_blank'>Part-X-MLLM: Part-aware 3D Multimodal Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chunshi Wang, Junliang Ye, Yunhan Yang, Yang Li, Zizhuo Lin, Jun Zhu, Zhuo Chen, Yawei Luo, Chunchao Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 17:59:52</h6>
<p class='card-text'>We introduce Part-X-MLLM, a native 3D multimodal large language model that unifies diverse 3D tasks by formulating them as programs in a structured, executable grammar. Given an RGB point cloud and a natural language prompt, our model autoregressively generates a single, coherent token sequence encoding part-level bounding boxes, semantic descriptions, and edit commands. This structured output serves as a versatile interface to drive downstream geometry-aware modules for part-based generation and editing. By decoupling the symbolic planning from the geometric synthesis, our approach allows any compatible geometry engine to be controlled through a single, language-native frontend. We pre-train a dual-encoder architecture to disentangle structure from semantics and instruction-tune the model on a large-scale, part-centric dataset. Experiments demonstrate that our model excels at producing high-quality, structured plans, enabling state-of-the-art performance in grounded Q\&A, compositional generation, and localized editing through one unified interface. Project page: https://chunshi.wang/Part-X-MLLM/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13639v1' target='_blank'>Subgame Perfect Methods in Nonsmooth Convex Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benjamin Grimmer, Alex L. Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 17:52:09</h6>
<p class='card-text'>This paper considers nonsmooth convex optimization with either a subgradient or proximal operator oracle. In both settings, we identify algorithms that achieve the recently introduced game-theoretic optimality notion for algorithms known as subgame perfection. Subgame perfect algorithms meet a more stringent requirement than just minimax optimality. Not only must they provide optimal uniform guarantees on the entire problem class, but also on any subclass determined by information revealed during the execution of the algorithm. In the setting of nonsmooth convex optimization with a subgradient oracle, we show that the Kelley cutting plane-Like Method due to Drori and Teboulle [1] is subgame perfect. For nonsmooth convex optimization with a proximal operator oracle, we develop a new algorithm, the Subgame Perfect Proximal Point Algorithm, and establish that it is subgame perfect. Both of these methods solve a history-aware second-order cone program within each iteration, independent of the ambient problem dimension, to plan their next steps. This yields performance guarantees that are never worse than the minimax optimal guarantees and often substantially better.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13507v1' target='_blank'>Mapping the Vanishing and Transformation of Urban Villages in China</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenyu Zhang, Yao Tong, Yiqiu Liu, Rui Cao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 15:42:41</h6>
<p class='card-text'>Urban villages (UVs), informal settlements embedded within China's urban fabric, have undergone widespread demolition and redevelopment in recent decades. However, there remains a lack of systematic evaluation of whether the demolished land has been effectively reused, raising concerns about the efficacy and sustainability of current redevelopment practices. To address the gap, this study proposes a deep learning-based framework to monitor the spatiotemporal changes of UVs in China. Specifically, semantic segmentation of multi-temporal remote sensing imagery is first used to map evolving UV boundaries, and then post-demolition land use is classified into six categories based on the "remained-demolished-redeveloped" phase: incomplete demolition, vacant land, construction sites, buildings, green spaces, and others. Four representative cities from China's four economic regions were selected as the study areas, i.e., Guangzhou (East), Zhengzhou (Central), Xi'an (West), and Harbin (Northeast). The results indicate: 1) UV redevelopment processes were frequently prolonged; 2) redevelopment transitions primarily occurred in peripheral areas, whereas urban cores remained relatively stable; and 3) three spatiotemporal transformation pathways, i.e., synchronized redevelopment, delayed redevelopment, and gradual optimization, were revealed. This study highlights the fragmented, complex and nonlinear nature of UV redevelopment, underscoring the need for tiered and context-sensitive planning strategies. By linking spatial dynamics with the context of redevelopment policies, the findings offer valuable empirical insights that support more inclusive, efficient, and sustainable urban renewal, while also contributing to a broader global understanding of informal settlement transformations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13429v1' target='_blank'>Handover-Aware URLLC UAV Trajectory Planning: A Continuous-Time Trajectory Optimization via Graphs of Convex Sets</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuqi Ping, Tingting Zhang, Tianhao Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 14:41:36</h6>
<p class='card-text'>In this paper, we study a cellular-connected unmanned aerial vehicle (UAV) which aims to fly between two predetermined locations while maintaining ultra-reliable low-latency communications (URLLC) for command-and-control (C2) links with terrestrial base stations (BSs). Long-range flights often trigger frequent inter-cell handovers, which may introduce delays and synchronization overhead. We jointly optimize the continuous trajectory and BS association to minimize handovers, path length, and flying time, subject to communication reliability and kinematic constraints. To address this problem, we reformulate it as an optimization based on the graph of convex sets (GCS). First, the URLLC requirement is translated into spatially feasible regions in the flight plane for each BS. And an intersection graph is constructed including the start and goal points. Each graph node is associated with a smooth and dynamically feasible trajectory segment. The trajectory is parameterized in space by Bézier curves and in time by a monotonic Bézier scaling, together with convex constraints that ensure continuity and enforce speed bounds. Next, we impose unit-flow constraints to enforce a single path, and by coupling the resulting binary edge-selection variables with the convex constraints, we obtain a mixed-integer convex program (MICP). Applying a convex relaxation and rounding to the mixed-integer convex program produces nearly globally optimal routes, and a final refinement yields smooth, dynamically feasible trajectories. Simulations verify that the method preserves URLLC connectivity while achieving a clear trade-off between fewer handovers and flight efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13411v1' target='_blank'>An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Przemyslaw Chojecki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 14:24:27</h6>
<p class='card-text'>We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing "baby AGI" becomes Superintelligence intuition.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13371v1' target='_blank'>Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Caroline Baumgartner, Eleanor Spens, Neil Burgess, Petru Manescu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 13:46:19</h6>
<p class='card-text'>How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13320v1' target='_blank'>Mosco-convergence of Cheeger energies on varying spaces satisfying curvature dimension conditions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Francesco Nobili, Federico Renzi, Federico Vitillaro</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 12:58:00</h6>
<p class='card-text'>We study the Mosco-convergence of Cheeger energies on Gromov-Hausdorff converging spaces satisfying different types of curvature dimension conditions. The case of functions of bounded variation is also considered. Our method, covering possibly infinite dimensional settings, is based on a Lagrangian approach and combines the stability properties of Wasserstein geodesics with the characterization of the nonsmooth calculus in duality with test plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13311v1' target='_blank'>Congestionamento Aeroportuario, Escassez de Capacidade e Planejamento na Macrometropole Paulista</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thayla M. G. Iglesias, Alessandro V. M. Oliveira</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 12:46:12</h6>
<p class='card-text'>This article presents an analytical account of the capacity limits and operational challenges of the main airports in the São Paulo Macrometropolis. Drawing on international examples, such as London Heathrow, it discusses how large hubs combine high traffic generation with severe physical constraints, highlighting how saturation intensifies delays, operating costs, and pressures for expansion. It analyzes capacity scarcity as a central economic problem, in which runways, aprons, boarding gates, and terminals become critical resources whose use requires administrative and market mechanisms, including slot coordination, prioritization rules, and regulatory incentives. It discusses the limitations imposed by high earthmoving costs, environmental impacts, and expropriation costs, which restrict the physical expansion of central airports such as Congonhas and increase dependence on efficiency gains. Demand projections indicate that the combined capacity of Congonhas, Guarulhos, and Viracopos is likely to be exceeded, even in conservative scenarios, reinforcing the urgency of integrated planning. The effects of regulatory restrictions on Congonhas, the challenges of expanding Guarulhos, and the structural difficulties of Viracopos are evaluated, highlighting the strategic relevance of this multi-airport system for sustaining national connectivity.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13306v1' target='_blank'>DAP: A Discrete-token Autoregressive Planner for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bowen Ye, Bin Zhang, Hang Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 12:31:33</h6>
<p class='card-text'>Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13297v1' target='_blank'>CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Enhui Ma, Lijun Zhou, Tao Tang, Jiahuan Zhang, Junpeng Jiang, Zhan Zhang, Dong Han, Kun Zhan, Xueyang Zhang, XianPeng Lang, Haiyang Sun, Xia Zhou, Di Lin, Kaicheng Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 12:21:03</h6>
<p class='card-text'>End-to-end planning methods are the de facto standard of the current autonomous driving system, while the robustness of the data-driven approaches suffers due to the notorious long-tail problem (i.e., rare but safety-critical failure cases). In this work, we explore whether recent diffusion-based video generation methods (a.k.a. world models), paired with structured 3D layouts, can enable a fully automated pipeline to self-correct such failure cases. We first introduce an agent to simulate the role of product manager, dubbed PM-Agent, which formulates data requirements to collect data similar to the failure cases. Then, we use a generative model that can simulate both data collection and annotation. However, existing generative models struggle to generate high-fidelity data conditioned on 3D layouts. To address this, we propose DriveSora, which can generate spatiotemporally consistent videos aligned with the 3D annotations requested by PM-Agent. We integrate these components into our self-correcting agentic system, CorrectAD. Importantly, our pipeline is an end-to-end model-agnostic and can be applied to improve any end-to-end planner. Evaluated on both nuScenes and a more challenging in-house dataset across multiple end-to-end planners, CorrectAD corrects 62.5% and 49.8% of failure cases, reducing collision rates by 39% and 27%, respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13226v1' target='_blank'>Informative Communication of Robot Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Michele Persiani, Thomas Hellstrom</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 10:44:25</h6>
<p class='card-text'>When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13171v1' target='_blank'>Autonomous Sensing UAV for Accurate Multi-User Identification and Localization in Cellular Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Niccolò Paglierani, Francesco Linsalata, Vineeth Teeda, Davide Scazzoli, Maurizio Magarini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 09:20:08</h6>
<p class='card-text'>This paper presents an autonomous sensing frame- work for identifying and localizing multiple users in Fifth Generation (5G) networks using an Unmanned Aerial Vehicle (UAV) that is not part of the serving access network. Unlike conventional aerial serving nodes, the proposed UAV operates passively and is dedicated solely to sensing. It captures Uplink (UL) Sounding Reference Signals (SRS), and requires virtually no coordination with the network infrastructure. A complete signal processing chain is proposed and developed, encompassing synchronization, user identification, and localization, all executed onboard UAV during flight. The system autonomously plans and adapts its mission workflow to estimate multiple user positions within a single deployment, integrating flight control with real-time sensing. Extensive simulations and a full-scale low- altitude experimental campaign validate the approach, showing localization errors below 3 m in rural field tests and below 8 m in urban simulation scenarios, while reliably identifying each user. The results confirm the feasibility of infrastructure-independent sensing UAVs as a core element of the emerging Low Altitude Economy (LAE), supporting situational awareness and rapid deployment in emergency or connectivity-limited environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13148v1' target='_blank'>Prospects for detecting periodic or sharp fast-time features in the supernova neutrino lightcurve with IceCube</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jakob Beise, María Durán de las Heras, Segev BenZvi, Spencer Griswold, Nora Valtonen-Mattila, Evan O'Connor, David Barba-González, Erin O'Sullivan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 08:57:07</h6>
<p class='card-text'>Neutrinos produced in core-collapse supernova offer a direct probe into the hydrodynamics and energy transport mechanisms during the collapse and play a pivotal role in the shock revival and success of the supernova explosion. Fast-time features of the neutrino luminosity and energy spectrum encode information about phenomena such as turbulence, convection, shock revival and potential quark-hadron phase transitions. In this study, we explore the detection capabilities of large-volume neutrino telescopes with a focus on IceCube and the planned extension IceCube-Gen2. Furthermore, we consider the effect on the detection sensitivity from wavelength shifters through enhanced light collection.
  A variety of models predict periodic fast-time features in supernova light curves; to quantify their detectability without relying on specific models, we investigate the detector response to a generic parameterisation of such features. We find that independent of feature frequency, IceCube-Gen2 instrumented with wavelength shifters has sensitivity to weaker modulations ($>25\%$ amplitude) as compared to only the strongest modulations ($>50\%$ amplitude) with IceCube. In addition, we examine the sensitivity of the neutrino lightcurve to sharp features from a quark-hadron phase transition. Phase transitions leading to a quark star remnant are detectable with IceCube at $5σ$ up to the edge of the Galaxy, and throughout the Small Magellanic Cloud with IceCube-Gen2 equipped with wavelength-shifters. In contrast, models collapsing into a black hole are observable only within the Galaxy, covering $41\%$ of the CCSNe population for IceCube and nearly all ($91\%$) for IceCube-Gen2 complemented by wavelength shifters. These results highlight the potential of IceCube-Gen2 for detecting Galactic sources more reliably and with greater reach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13082v1' target='_blank'>Real-time prediction of breast cancer sites using deformation-aware graph neural network</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kyunghyun Lee, Yong-Min Shin, Minwoo Shin, Jihun Kim, Sunghwan Lim, Won-Yong Shin, Kyungho Yoon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 07:32:28</h6>
<p class='card-text'>Early diagnosis of breast cancer is crucial, enabling the establishment of appropriate treatment plans and markedly enhancing patient prognosis. While direct magnetic resonance imaging-guided biopsy demonstrates promising performance in detecting cancer lesions, its practical application is limited by prolonged procedure times and high costs. To overcome these issues, an indirect MRI-guided biopsy that allows the procedure to be performed outside of the MRI room has been proposed, but it still faces challenges in creating an accurate real-time deformable breast model. In our study, we tackled this issue by developing a graph neural network (GNN)-based model capable of accurately predicting deformed breast cancer sites in real time during biopsy procedures. An individual-specific finite element (FE) model was developed by incorporating magnetic resonance (MR) image-derived structural information of the breast and tumor to simulate deformation behaviors. A GNN model was then employed, designed to process surface displacement and distance-based graph data, enabling accurate prediction of overall tissue displacement, including the deformation of the tumor region. The model was validated using phantom and real patient datasets, achieving an accuracy within 0.2 millimeters (mm) for cancer node displacement (RMSE) and a dice similarity coefficient (DSC) of 0.977 for spatial overlap with actual cancerous regions. Additionally, the model enabled real-time inference and achieved a speed-up of over 4,000 times in computational cost compared to conventional FE simulations. The proposed deformation-aware GNN model offers a promising solution for real-time tumor displacement prediction in breast biopsy, with high accuracy and real-time capability. Its integration with clinical procedures could significantly enhance the precision and efficiency of breast cancer diagnosis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13079v1' target='_blank'>Decoupling Scene Perception and Ego Status: A Multi-Context Fusion Approach for Enhanced Generalization in End-to-End Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiacheng Tang, Mingyue Feng, Jiachao Liu, Yaonong Wang, Jian Pu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 07:27:55</h6>
<p class='card-text'>Modular design of planning-oriented autonomous driving has markedly advanced end-to-end systems. However, existing architectures remain constrained by an over-reliance on ego status, hindering generalization and robust scene understanding. We identify the root cause as an inherent design within these architectures that allows ego status to be easily leveraged as a shortcut. Specifically, the premature fusion of ego status in the upstream BEV encoder allows an information flow from this strong prior to dominate the downstream planning module. To address this challenge, we propose AdaptiveAD, an architectural-level solution based on a multi-context fusion strategy. Its core is a dual-branch structure that explicitly decouples scene perception and ego status. One branch performs scene-driven reasoning based on multi-task learning, but with ego status deliberately omitted from the BEV encoder, while the other conducts ego-driven reasoning based solely on the planning task. A scene-aware fusion module then adaptively integrates the complementary decisions from the two branches to form the final planning trajectory. To ensure this decoupling does not compromise multi-task learning, we introduce a path attention mechanism for ego-BEV interaction and add two targeted auxiliary tasks: BEV unidirectional distillation and autoregressive online mapping. Extensive evaluations on the nuScenes dataset demonstrate that AdaptiveAD achieves state-of-the-art open-loop planning performance. Crucially, it significantly mitigates the over-reliance on ego status and exhibits impressive generalization capabilities across diverse scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13048v1' target='_blank'>Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yong Li, Hui Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 06:52:41</h6>
<p class='card-text'>Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13042v1' target='_blank'>APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yong Li, Hui Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 06:42:37</h6>
<p class='card-text'>Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.13006v1' target='_blank'>Cooperative ISAC for LAE: Joint Trajectory Planning, Power allocation, and Dynamic Time Division</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fangzhi Li, Zhichu Ren, Cunhua Pan, Hong Ren, Jing Jin, Qixing Wang, Jiangzhou Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 06:00:17</h6>
<p class='card-text'>To enhance the performance of aerial-ground networks, this paper proposes an integrated sensing and communication (ISAC) framework for multi-UAV systems. In our model, ground base stations (BSs) cooperatively serve multiple unmanned aerial vehicles (UAVs), and employ a time-division strategy in which beam scanning for sensing comes before data communication in each time slot. To maximize the sum communication rate while satisfying the total sensing mutual information (MI) requirement, we jointly optimize the UAV trajectories, communication and sensing power allocation, and the dynamic time-division ratio. The resulting non-convex optimization problem is efficiently solved using an alternating optimization (AO) framework. Simulation results demonstrate that our proposed joint design significantly outperforms benchmark schemes with static or partially optimized resources. The findings also reveal the critical importance of dynamic trajectory and resource management for effectively navigating the sensing-communication trade-off, especially under stringent power or sensing constraints.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12878v1' target='_blank'>Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junyi Ma, Wentao Bao, Jingyi Xu, Guanzhong Sun, Yu Zheng, Erhang Zhang, Xieyuanli Chen, Hesheng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 02:14:13</h6>
<p class='card-text'>Analyzing hand-object interaction in egocentric vision facilitates VR/AR applications and human-robot policy transfer. Existing research has mostly focused on modeling the behavior paradigm of interactive actions (i.e., "how to interact"). However, the more challenging and fine-grained problem of capturing the critical moments of contact and separation between the hand and the target object (i.e., "when to interact") is still underexplored, which is crucial for immersive interactive experiences in mixed reality and robotic motion planning. Therefore, we formulate this problem as temporal interaction localization (TIL). Some recent works extract semantic masks as TIL references, but suffer from inaccurate object grounding and cluttered scenarios. Although current temporal action localization (TAL) methods perform well in detecting verb-noun action segments, they rely on category annotations during training and exhibit limited precision in localizing hand-object contact/separation moments. To address these issues, we propose a novel zero-shot approach dubbed EgoLoc to localize hand-object contact and separation timestamps in egocentric videos. EgoLoc introduces hand-dynamics-guided sampling to generate high-quality visual prompts. It exploits the vision-language model to identify contact/separation attributes, localize specific timestamps, and provide closed-loop feedback for further refinement. EgoLoc eliminates the need for object masks and verb-noun taxonomies, leading to generalizable zero-shot implementation. Comprehensive experiments on the public dataset and our novel benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric videos. It is also validated to effectively facilitate multiple downstream applications in egocentric vision and robotic manipulation tasks. Code and relevant data will be released at https://github.com/IRMVLab/EgoLoc.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12853v1' target='_blank'>BrainNormalizer: Anatomy-Informed Pseudo-Healthy Brain Reconstruction from Tumor MRI via Edge-Guided ControlNet</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Min Gu Kwak, Yeonju Lee, Hairong Wang, Jing Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-17 00:48:30</h6>
<p class='card-text'>Brain tumors are among the most clinically significant neurological diseases and remain a major cause of morbidity and mortality due to their aggressive growth and structural heterogeneity. As tumors expand, they induce substantial anatomical deformation that disrupts both local tissue organization and global brain architecture, complicating diagnosis, treatment planning, and surgical navigation. Yet a subject-specific reference of how the brain would appear without tumor-induced changes is fundamentally unobtainable in clinical practice. We present BrainNormalizer, an anatomy-informed diffusion framework that reconstructs pseudo-healthy MRIs directly from tumorous scans by conditioning the generative process on boundary cues extracted from the subject's own anatomy. This boundary-guided conditioning enables anatomically plausible pseudo-healthy reconstruction without requiring paired non-tumorous and tumorous scans. BrainNormalizer employs a two-stage training strategy. The pretrained diffusion model is first adapted through inpainting-based fine-tuning on tumorous and non-tumorous scans. Next, an edge-map-guided ControlNet branch is trained to inject fine-grained anatomical contours into the frozen decoder while preserving learned priors. During inference, a deliberate misalignment strategy pairs tumorous inputs with non-tumorous prompts and mirrored contralateral edge maps, leveraging hemispheric correspondence to guide reconstruction. On the BraTS2020 dataset, BrainNormalizer achieves strong quantitative performance and qualitatively produces anatomically plausible reconstructions in tumor-affected regions while retaining overall structural coherence. BrainNormalizer provides clinically reliable anatomical references for treatment planning and supports new research directions in counterfactual modeling and tumor-induced deformation analysis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12801v1' target='_blank'>Enhancing Neuro-Oncology Through Self-Assessing Deep Learning Models for Brain Tumor Unified Model for MRI Segmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrew Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-16 22:13:45</h6>
<p class='card-text'>Accurate segmentation of brain tumors is vital for diagnosis, surgical planning, and treatment monitoring. Deep learning has advanced on benchmarks, but two issues limit clinical use: no uncertainty estimates for errors and no segmentation of healthy brain structures around tumors for surgery. Current methods fail to unify tumor localization with anatomical context and lack confidence scores. This study presents an uncertainty-aware framework augmenting nnUNet with a channel for voxel-wise uncertainty. Trained on BraTS2023, it yields a correlation of 0.750 and RMSD of 0.047 for uncertainty without hurting tumor accuracy. It predicts uncertainty in one pass, with no extra networks or inferences, aiding clinical decisions. For whole-brain context, a unified model combines normal and cancer datasets, achieving a DSC of 0.81 for brain structures and 0.86 for tumor, with robust key-region performance. Combining both innovations gives the first model outputting tumor in natural surroundings plus an overlaid uncertainty map. Visual checks of outputs show uncertainty offers key insights to evaluate predictions and fix errors, helping informed surgical decisions from AI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12792v1' target='_blank'>Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohamad A. Hady, Siyi Hu, Mahardhika Pratama, Zehong Cao, Ryszard Kowalczyk</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-16 21:47:04</h6>
<p class='card-text'>This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12778v1' target='_blank'>DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vignesh Rajagopal, Kasun Weerakoon Kulathun Mudiyanselage, Gershom Devake Seneviratne, Pon Aswin Sankaralingam, Mohamed Elnoor, Jing Liang, Rohan Chandra, Dinesh Manocha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-16 21:04:08</h6>
<p class='card-text'>We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12763v1' target='_blank'>Impact by design: translating Lead times in flux into an R handbook with code</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Harrison Katz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-16 20:13:27</h6>
<p class='card-text'>This commentary translates the central ideas in Lead times in flux into a practice ready handbook in R. The original article measures change in the full distribution of booking lead times with a normalized L1 distance and tracks that divergence across months relative to year over year and to a fixed 2018 reference. It also provides a bound that links divergence and remaining horizon to the relative error of pickup forecasts. We implement these ideas end to end in R, using a minimal data schema and providing runnable scripts, simulated examples, and a prespecified evaluation plan. All results use synthetic data so the exposition is fully reproducible without reference to proprietary sources.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12704v1' target='_blank'>Offensive tool determination strategy R.I.D.D.L.E. + (C)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Herman Errico</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-16 17:44:21</h6>
<p class='card-text'>Intentional threats are a major risk factor related to vulnerabilities in critical infrastructure assets, and an accurate risk assessment is necessary to analyze threats, assess vulnerabilities, and evaluate potential impacts on assets and systems. This research proposes a methodology that can be added as an additional phase in the risk assessment process. The method introduces an extra analytical parameter concerning offensive tool characteristics, improving the understanding of intentional threats.
  The methodology is presented using clear and accessible language suitable for a broad audience. It is based on an approach described as an "offensive tool determination strategy," summarized by the acronym R.I.D.D.L.E.+C, which refers to the variables used in the analysis: resistance, intrusion timing, damage, disruption timing, latency, efficiency, and cost. These variables are evaluated using open-source intelligence.
  Each variable is assigned a specific range of values according to its potential impact on the targeted asset. A matrix is then provided for practical application, which can reveal unexpected vulnerabilities and offer a more granular framework for decision-making and security planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12677v1' target='_blank'>Dynamic Tree Databases in Automated Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oliver Joergensen, Dominik Drexler, Jendrik Seipp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-16 16:34:19</h6>
<p class='card-text'>A central challenge in scaling up explicit state-space search for large tasks is compactly representing the set of generated states. Tree databases, a data structure from model checking, require constant space per generated state in the best case, but they need a large preallocation of memory. We propose a novel dynamic variant of tree databases for compressing state sets over propositional and numeric variables and prove that it maintains the desirable properties of the static counterpart. Our empirical evaluation of state compression techniques for grounded and lifted planning on classical and numeric planning tasks reveals compression ratios of several orders of magnitude, often with negligible runtime overhead.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='https://arxiv.org/abs/2511.12634v1' target='_blank'>Approximate Tracking Controllability of Systems with Quadratic Nonlinearities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Manuel Rissel, Marius Tucsnak</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-11-16 15:03:31</h6>
<p class='card-text'>Given a finite-dimensional time continuous control system and $\varepsilon>0$, we address the question of the existence of controls that maintain the corresponding state trajectories in the $\varepsilon$-neighborhood of any prescribed path in the state space. We investigate this property, called approximate tracking controllability, for linear and quadratic time invariant systems. Concerning linear systems, our answers are negative: by developing a systematic approach, we demonstrate that approximate tracking controllability of the full state is impossible even in a certain weak sense, except for the trivial situation where the control space is isomorphic to the state space. Motivated by these negative findings for linear systems, we focus on nonlinear dynamics. In particular, we prove weak approximate tracking controllability on any time horizon for a general class of systems with arbitrary linear part and quadratic nonlinear terms. The considered weak notion of approximate tracking controllability involves the relaxation metric. We underline the relevance of this weak setting by developing applications to coupled systems (including motion planning problems) and by remarking obstructions that would arise for natural stronger norms. The exposed framework yields global results even if the uncontrolled dynamics might exhibit singularities in finite time.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>