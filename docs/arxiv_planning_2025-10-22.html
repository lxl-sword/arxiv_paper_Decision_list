<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-10-22</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-10-22</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18818v1' target='_blank'>Comparison of Simulation-Guided Design to Closed-Form Power Calculations
  in Planning a Cluster Randomized Trial with Covariate-Constrained
  Randomization: A Case Study in Rural Chad</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jay JH Park, Rebecca K. Metcalfe, Nathaniel Dyrkton, Yichen Yan, Shomoita Alam, Kevin Phelan, Ibrahim Sana, Susan Shepherd</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 17:18:35</h6>
<p class='card-text'>Current practices for designing cluster-randomized trials (cRCTs) typically
rely on closed-form formulas for power calculations. For cRCTs using
covariate-constrained randomization, the utility of conventional calculations
might be limited, particularly when data is nested. We compared
simulation-based planning of a nested cRCT using covariate-constrained
randomization to conventional power calculations using OptiMAx-Chad as a case
study. OptiMAx-Chad will examine the impact of embedding mass distribution of
small-quantity lipid-based nutrient supplements within an expanded programme on
immunization on first-dose measles-containing vaccine (MCV1) coverage among
children aged 12-24 months in rural villages in Ngouri. Within the 12 health
areas to be randomized, a random subset of villages will be selected for
outcome collection. 1,000,000 assignments of health areas with different
possible village selections were generated using covariate-constrained
randomization to balance baseline village characteristics. The empirically
estimated intracluster correlation coefficient (ICC) and the World Health
Organization (WHO) recommended values of 1/3 and 1/6 were considered. The
desired operating characteristics were 80% power at 0.05 one-sided type I error
rate. Using conventional calculations target power for a realistic treatment
effect could not be achieved with the WHO recommended values. Conventional
calculations also showed a plateau in power after a certain cluster size. Our
simulations matched the design of OptiMAx-Chad with covariate adjustment and
random selection, and showed that power did not plateau. Instead, power
increased with increasing cluster size. Planning complex cRCTs with covariate
constrained randomization and a multi-nested data structure with conventional
closed-form formulas can be misleading. Simulations can improve the planning of
cRCTs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18773v1' target='_blank'>Detection and Simulation of Urban Heat Islands Using a Fine-Tuned
  Geospatial Foundation Model for Microclimate Impact Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jannis Fleckenstein, David Kreismann, Tamara Rosemary Govindasamy, Thomas Brunschwiler, Etienne Vos, Mattia Rigotti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 16:21:15</h6>
<p class='card-text'>As urbanization and climate change progress, urban heat island effects are
becoming more frequent and severe. To formulate effective mitigation plans,
cities require detailed air temperature data, yet conventional machine learning
models with limited data often produce inaccurate predictions, particularly in
underserved areas. Geospatial foundation models trained on global unstructured
data offer a promising alternative by demonstrating strong generalization and
requiring only minimal fine-tuning. In this study, an empirical ground truth of
urban heat patterns is established by quantifying cooling effects from green
spaces and benchmarking them against model predictions to evaluate the model's
accuracy. The foundation model is subsequently fine-tuned to predict land
surface temperatures under future climate scenarios, and its practical value is
demonstrated through a simulated inpainting that highlights its role for
mitigation support. The results indicate that foundation models offer a
powerful way for evaluating urban heat island mitigation strategies in
data-scarce regions to support more climate-resilient cities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18600v1' target='_blank'>Quadrupeds for Planetary Exploration: Field Testing Control Algorithms
  on an Active Volcano</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shubham Vyas, Franek Stark, Rohit Kumar, Hannah Isermann, Jonas Haack, Mihaela Popescu, Jakob Middelberg, Dennis Mronga, Frank Kirchner</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 12:59:36</h6>
<p class='card-text'>Missions such as the Ingenuity helicopter have shown the advantages of using
novel locomotion modes to increase the scientific return of planetary
exploration missions. Legged robots can further expand the reach and capability
of future planetary missions by traversing more difficult terrain than wheeled
rovers, such as jumping over cracks on the ground or traversing rugged terrain
with boulders. To develop and test algorithms for using quadruped robots, the
AAPLE project was carried out at DFKI. As part of the project, we conducted a
series of field experiments on the Volcano on the Aeolian island of Vulcano, an
active stratovolcano near Sicily, Italy. The experiments focused on validating
newly developed state-of-the-art adaptive optimal control algorithms for
quadrupedal locomotion in a high-fidelity analog environment for Lunar and
Martian surfaces. This paper presents the technical approach, test plan,
software architecture, field deployment strategy, and evaluation results from
the Vulcano campaign.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18548v1' target='_blank'>Interval Prediction of Annual Average Daily Traffic on Local Roads via
  Quantile Random Forest with High-Dimensional Spatial Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ying Yao, Daniel J. Graham</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 11:56:57</h6>
<p class='card-text'>Accurate annual average daily traffic (AADT) data are vital for transport
planning and infrastructure management. However, automatic traffic detectors
across national road networks often provide incomplete coverage, leading to
underrepresentation of minor roads. While recent machine learning advances have
improved AADT estimation at unmeasured locations, most models produce only
point predictions and overlook estimation uncertainty. This study addresses
that gap by introducing an interval prediction approach that explicitly
quantifies predictive uncertainty. We integrate a Quantile Random Forest model
with Principal Component Analysis to generate AADT prediction intervals,
providing plausible traffic ranges bounded by estimated minima and maxima.
Using data from over 2,000 minor roads in England and Wales, and evaluated with
specialized interval metrics, the proposed method achieves an interval coverage
probability of 88.22%, a normalized average width of 0.23, and a Winkler Score
of 7,468.47. By combining machine learning with spatial and high-dimensional
analysis, this framework enhances both the accuracy and interpretability of
AADT estimation, supporting more robust and informed transport planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18543v1' target='_blank'>Characterizing primary atomization of cryogenic LOX/Nitrogen and
  LOX/Helium sprays by visualizations coupled to Phase Doppler Interferometry</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicolas Fdida, Yves Mauriot, Lucien Vingert, Arnaud Ristori, Marie Théron</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 11:46:31</h6>
<p class='card-text'>There is a need for experimental data in conditions representative injection
in rocket engines to validate or initiate droplet formation models used in
numerical simulations. A new cryogenic vessel was built upon the MASCOTTE test
bench to study the atomization of a single oxygen liquid jet, under
non-reactive conditions, with simultaneous optical diagnostics. A test plan was
built to explore the fiber-type regime occurring in liquid rocket injection
systems, with a fixed Reynolds number and a large range of Weber number and
momentum flux ratio, compared to existing studies. High-speed images are used
to describe qualitatively the fiber-type regime and to visualize were droplets
are present, in order to prepare the drop-size measurements. A Phase Doppler
Interferometer is used to measure the size and velocity of droplets produced by
atomization of a liquid oxygen jet by a co-flowing gas. Droplet size and
velocity measurements were performed with a PDI close to the nozzle exit in
order to provide data on droplets produced by the primary atomization process,
which can be useful for numerical simulations initialisation. The radial
evolutions of the axial velocity and of the drop size distribution show similar
trends as observed in the literature. The axial velocity is investigated for
different operating conditions with helium or nitrogen as atomizing gas,
showing an increase on the side of the spray. The radial evolution of the
droplet size shows a translation of the drop size distribution on the edge of
the spray towards the smaller sizes, indicating that the biggest liquid
elements stay close to the LOX jet.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18515v1' target='_blank'>Socialized Learning and Emergent Behaviors in Multi-Agent Systems based
  on Multimodal Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sureyya Akin, Shruti T. Tiwari, Ram Bhattacharya, Sagar A. Raman, Kiran Mohanty, Sita Krishnan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 10:57:39</h6>
<p class='card-text'>This search introduces the Multimodal Socialized Learning Framework (M-S2L),
designed to foster emergent social intelligence in AI agents by integrating
Multimodal Large Language Models (M-LLMs) with social learning mechanisms. The
framework equips agents with multimodal perception (vision and text) and
structured action capabilities, enabling physical manipulation and grounded
multimodal communication (e.g., text with visual pointers). M-S2L combines
direct reinforcement learning with two novel social learning pathways:
multimodal observational learning and communication-driven learning from
feedback, augmented by an episodic memory system for long-term social context.
  We evaluate M-S2L in a Collaborative Assembly Environment (CAE), where agent
teams must construct complex devices from ambiguous blueprints under
informational asymmetry. Across tasks of increasing complexity, M-S2L agents
consistently outperform Text-Only and No-Social-Learning baselines in Task
Completion Rate and Time to Completion, particularly in dynamic problem-solving
scenarios. Ablation studies confirm the necessity of both multimodality and
socialized learning. Our analysis reveals the emergence of efficient
communication protocols integrating visual pointers with concise text,
alongside rapid role specialization leading to stable labor division.
Qualitative case studies demonstrate agents' abilities for shared awareness,
dynamic re-planning, and adaptive problem-solving, suggesting a nascent form of
machine social cognition. These findings indicate that integrating multimodal
perception with explicit social learning is critical for developing human-like
collaborative intelligence in multi-agent systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18485v1' target='_blank'>Learning to Navigate Under Imperfect Perception: Conformalised
  Segmentation for Safe Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Bethell, Simos Gerasimou, Radu Calinescu, Calum Imrie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 10:07:04</h6>
<p class='card-text'>Reliable navigation in safety-critical environments requires both accurate
hazard perception and principled uncertainty handling to strengthen downstream
safety handling. Despite the effectiveness of existing approaches, they assume
perfect hazard detection capabilities, while uncertainty-aware perception
approaches lack finite-sample guarantees. We present COPPOL, a conformal-driven
perception-to-policy learning approach that integrates distribution-free,
finite-sample safety guarantees into semantic segmentation, yielding calibrated
hazard maps with rigorous bounds for missed detections. These maps induce
risk-aware cost fields for downstream RL planning. Across two satellite-derived
benchmarks, COPPOL increases hazard coverage (up to 6x) compared to comparative
baselines, achieving near-complete detection of unsafe regions while reducing
hazardous violations during navigation (up to approx 50%). More importantly,
our approach remains robust to distributional shift, preserving both safety and
efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18402v1' target='_blank'>MPC-based motion planning for non-holonomic systems in non-convex
  domains</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Matthias Lorenzen, Teodoro Alamo, Martina Mammarella, Fabrizio Dabbene</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 08:22:56</h6>
<p class='card-text'>Motivated by the application of using model predictive control (MPC) for
motion planning of autonomous mobile robots, a form of output tracking MPC for
non-holonomic systems and with non-convex constraints is studied. Although the
advantages of using MPC for motion planning have been demonstrated in several
papers, in most of the available fundamental literature on output tracking MPC
it is assumed, often implicitly, that the model is holonomic and generally the
state or output constraints must be convex. Thus, in application-oriented
publications, empirical results dominate and the topic of proving completeness,
in particular under which assumptions the target is always reached, has
received comparatively little attention. To address this gap, we present a
novel MPC formulation that guarantees convergence to the desired target under
realistic assumptions, which can be verified in relevant real-world scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18337v1' target='_blank'>MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenhui Huang, Changhe Chen, Han Qi, Chen Lv, Yilun Du, Heng Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 06:39:34</h6>
<p class='card-text'>Integrating visual-language instructions into visuomotor policies is gaining
momentum in robot learning for enhancing open-world generalization. Despite
promising advances, existing approaches face two challenges: limited language
steerability when no generated reasoning is used as a condition, or significant
inference latency when reasoning is incorporated.In this work, we introduce
MoTVLA, a mixture-of-transformers (MoT)-based vision-language-action (VLA)
model that integrates fast-slow unified reasoning with behavior policy
learning. MoTVLA preserves the general intelligence of pre-trained VLMs
(serving as the generalist) for tasks such as perception, scene understanding,
and semantic planning, while incorporating a domain expert, a second
transformer that shares knowledge with the pretrained VLM, to generate
domain-specific fast reasoning (e.g., robot motion decomposition), thereby
improving policy execution efficiency. By conditioning the action expert on
decomposed motion instructions, MoTVLA can learn diverse behaviors and
substantially improve language steerability. Extensive evaluations across
natural language processing benchmarks, robotic simulation environments, and
real-world experiments confirm the superiority of MoTVLA in both fast-slow
reasoning and manipulation task performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18210v1' target='_blank'>Applying voxel-based analysis to oropharyngeal cancer proton therapy
  patients: a correlation study on radiation-induced acute dysphagia</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qianxia Wang, Alexander Stanforth, William Andrew LePain, Edgar Gelover, Haijian Chen, Mingyao Zhu, Katja M. Langen, Mark McDonald, James Edward Bates, Stella Flampouri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 01:26:45</h6>
<p class='card-text'>Background: Voxel-based analysis (VBA) is an analytic approach to evaluate
correlations between local dose and the development of different toxicities.
DVHs are used for toxicity prediction as well. Compared with DVH, no contours
are required for VBA technique and results tell specific voxels that may be
related to the toxicity instead of the whole contoured area. The VBA has been
used on different cancer sites and for different toxicities. Most of these
studies included patients treated with photon, all published studies were based
on planned dose and VBA tools used were developed in house. In our study,
patient cohort were treated with proton, our VBA tool was developed based on
RayStation and doses fed to the VBA tool were delivered doses with constant and
two variable RBE models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18185v1' target='_blank'>Enhancing Urban Data Exploration: Layer Toggling and
  Visibility-Preserving Lenses for Multi-Attribute Spatial Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karelia Salinas, Luis Gustavo Nonato, Jean-Daniel Fekete, Fernanda Bartolo dos Santos Saran</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-21 00:24:21</h6>
<p class='card-text'>We propose two novel interaction techniques for visualization-assisted
exploration of urban data: Layer Toggling and Visibility-Preserving Lenses.
Layer Toggling mitigates visual overload by organizing information into
separate layers while enabling comparisons through controlled overlays. This
technique supports focused analysis without losing spatial context and allows
users to switch layers using a dedicated button. Visibility-Preserving Lenses
adapt their size and transparency dynamically, enabling detailed inspection of
dense spatial regions and temporal attributes. These techniques facilitate
urban data exploration and improve prediction. Understanding complex phenomena
related to crime, mobility, and residents' behavior is crucial for informed
urban planning. Yet navigating such data often causes cognitive overload and
visual clutter due to overlapping layers. We validate our visualization tool
through a user study measuring performance, cognitive load, and interaction
efficiency. Using real-world data from Sao Paulo, we demonstrate how our
approach enhances exploratory and analytical tasks and provides guidelines for
future interactive systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18136v1' target='_blank'>Deep Synoptic Array Science: Searching for Long Duration Radio
  Transients with the DSA-110</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Myles B. Sherman, Nikita Kosogorov, Casey Law, Vikram Ravi, Jakob T. Faber, Stella K. Ocker, Liam Connor, Yuanhong Qu, Kaitlyn Shin, Kritti Sharma, Pranav Sanghavi, Gregg Hallinan, Mark Hodges</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 22:10:15</h6>
<p class='card-text'>We describe the design and commissioning tests for the DSA-110 Not-So-Fast
Radio Burst (NSFRB) search pipeline, a 1.4 GHz image-plane single-pulse search
sensitive to 134 ms-160.8 s radio bursts. Extending the pulse width range of
the Fast Radio Burst (FRB) search by 3 orders of magnitude, the NSFRB search is
sensitive to the recently-discovered Galactic Long Period Radio Transients
(LPRTs). The NSFRB search operates in real-time, utilizing a custom
GPU-accelerated search code, \texttt{cerberus}, implemented in Python with JAX.
We summarize successful commissioning sensitivity tests with continuum sources
and pulsar B0329+54, estimating the $6\sigma$ flux (fluence) threshold to be
~290 mJy (~40 Jy ms). Future tests of recovery of longer timescale transients,
e.g. CHIME J1634+44, are planned to supplement injection testing and B0329+54
observations. An offline DSA-110 NSFRB Galactic Plane Survey was conducted to
search for LPRTs, covering $-3.5^\circ<b<5.7^\circ$ and $141^\circ<l<225^\circ$
(~770 square degrees) in Galactic coordinates. We estimate an upper limit
Poissonian burst rate ~1 hr$^{-1}$ per square degree (~7 hr$^{-1}$ per
$3^\circ\times3^\circ$ survey grid cell) maximized across the inner
$|b|<0.25^\circ$ of the surveyed region. By imposing the ~290 mJy flux limit on
two representative models (the magnetar plastic flow model and the White
Dwarf-M Dwarf binary model), we reject with 95% confidence the presence of
White Dwarf-M Dwarf binary LPRTs with periods between ~10-70s within ~95% of
the surveyed region. Combined with the prevalence of LPRTs in the Galactic
Plane, our results motivate further consideration of both White Dwarf-M Dwarf
binary models and isolated magnetar models. We will continue to explore novel
LPRT search strategies during real-time operations, such as triggered
periodicity searches and additional targeted surveys.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18135v1' target='_blank'>World-in-World: World Models in a Closed-Loop World</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiahan Zhang, Muqing Jiang, Nanru Dai, Taiming Lu, Arda Uzunoglu, Shunchi Zhang, Yana Wei, Jiahao Wang, Vishal M. Patel, Paul Pu Liang, Daniel Khashabi, Cheng Peng, Rama Chellappa, Tianmin Shu, Alan Yuille, Yilun Du, Jieneng Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 22:09:15</h6>
<p class='card-text'>Generative world models (WMs) can now simulate worlds with striking visual
realism, which naturally raises the question of whether they can endow embodied
agents with predictive perception for decision making. Progress on this
question has been limited by fragmented evaluation: most existing benchmarks
adopt open-loop protocols that emphasize visual quality in isolation, leaving
the core issue of embodied utility unresolved, i.e., do WMs actually help
agents succeed at embodied tasks? To address this gap, we introduce
World-in-World, the first open platform that benchmarks WMs in a closed-loop
world that mirrors real agent-environment interactions. World-in-World provides
a unified online planning strategy and a standardized action API, enabling
heterogeneous WMs for decision making. We curate four closed-loop environments
that rigorously evaluate diverse WMs, prioritize task success as the primary
metric, and move beyond the common focus on visual quality; we also present the
first data scaling law for world models in embodied settings. Our study
uncovers three surprises: (1) visual quality alone does not guarantee task
success, controllability matters more; (2) scaling post-training with
action-observation data is more effective than upgrading the pretrained video
generators; and (3) allocating more inference-time compute allows WMs to
substantially improve closed-loop performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18087v1' target='_blank'>Planned Diffusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Israel, Tian Jin, Ellie Cheng, Guy Van den Broeck, Aditya Grover, Suvinay Subramanian, Michael Carbin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 20:27:48</h6>
<p class='card-text'>A central challenge in large language model inference is the trade-off
between generation speed and output quality. Autoregressive models produce
high-quality text but generate tokens sequentially. Diffusion models can
generate tokens in parallel but often need many iterations to match the same
quality. We propose planned diffusion, a hybrid method that combines the
strengths of both paradigms. Planned diffusion works in two stages: first, the
model creates a short autoregressive plan that breaks the output into smaller,
independent spans. Second, the model generates these spans simultaneously using
diffusion. This approach expands the speed-quality Pareto frontier and provides
a practical path to faster, high-quality text generation. On AlpacaEval, a
suite of 805 instruction-following prompts, planned diffusion achieves
Pareto-optimal trade-off between quality and latency, achieving 1.27x to 1.81x
speedup over autoregressive generation with only 0.87\% to 5.4\% drop in win
rate, respectively. Our sensitivity analysis shows that the planning mechanism
of planned diffusion is minimal and reliable, and simple runtime knobs exist to
provide flexible control of the quality-latency trade-off.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18060v1' target='_blank'>SPACeR: Self-Play Anchoring with Centralized Reference Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei-Jer Chang, Akshay Rangesh, Kevin Joseph, Matthew Strong, Masayoshi Tomizuka, Yihan Hu, Wei Zhan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 19:53:02</h6>
<p class='card-text'>Developing autonomous vehicles (AVs) requires not only safety and efficiency,
but also realistic, human-like behaviors that are socially aware and
predictable. Achieving this requires sim agent policies that are human-like,
fast, and scalable in multi-agent settings. Recent progress in imitation
learning with large diffusion-based or tokenized models has shown that
behaviors can be captured directly from human driving data, producing realistic
policies. However, these models are computationally expensive, slow during
inference, and struggle to adapt in reactive, closed-loop scenarios. In
contrast, self-play reinforcement learning (RL) scales efficiently and
naturally captures multi-agent interactions, but it often relies on heuristics
and reward shaping, and the resulting policies can diverge from human norms. We
propose SPACeR, a framework that leverages a pretrained tokenized
autoregressive motion model as a centralized reference policy to guide
decentralized self-play. The reference model provides likelihood rewards and KL
divergence, anchoring policies to the human driving distribution while
preserving RL scalability. Evaluated on the Waymo Sim Agents Challenge, our
method achieves competitive performance with imitation-learned policies while
being up to 10x faster at inference and 50x smaller in parameter size than
large generative models. In addition, we demonstrate in closed-loop ego
planning evaluation tasks that our sim agents can effectively measure planner
quality with fast and scalable traffic simulation, establishing a new paradigm
for testing autonomous driving policies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.18004v1' target='_blank'>Attention-Guided Deep Adversarial Temporal Subspace Clustering (A-DATSC)
  Model for multivariate spatiotemporal data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Francis Ndikum Nji, Vandana Janeja, Jianwu Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 18:38:26</h6>
<p class='card-text'>Deep subspace clustering models are vital for applications such as snowmelt
detection, sea ice tracking, crop health monitoring, infectious disease
modeling, network load prediction, and land-use planning, where multivariate
spatiotemporal data exhibit complex temporal dependencies and reside on
multiple nonlinear manifolds beyond the capability of traditional clustering
methods. These models project data into a latent space where samples lie in
linear subspaces and exploit the self-expressiveness property to uncover
intrinsic relationships. Despite their success, existing methods face major
limitations: they use shallow autoencoders that ignore clustering errors,
emphasize global features while neglecting local structure, fail to model
long-range dependencies and positional information, and are rarely applied to
4D spatiotemporal data. To address these issues, we propose A-DATSC
(Attention-Guided Deep Adversarial Temporal Subspace Clustering), a model
combining a deep subspace clustering generator and a quality-verifying
discriminator. The generator, inspired by U-Net, preserves spatial and temporal
integrity through stacked TimeDistributed ConvLSTM2D layers, reducing
parameters and enhancing generalization. A graph attention transformer based
self-expressive network captures local spatial relationships, global
dependencies, and both short- and long-range correlations. Experiments on three
real-world multivariate spatiotemporal datasets show that A-DATSC achieves
substantially superior clustering performance compared to state-of-the-art deep
subspace clustering models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17801v1' target='_blank'>Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large
  Language Models as Embodied Brain</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yulin Luo, Chun-Kai Fan, Menghang Dong, Jiayu Shi, Mengdi Zhao, Bo-Wen Zhang, Cheng Chi, Jiaming Liu, Gaole Dai, Rongyu Zhang, Ruichuan An, Kun Wu, Zhengping Che, Shaoxuan Xie, Guocai Yao, Zhongxia Zhao, Pengwei Wang, Guang Liu, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 17:59:03</h6>
<p class='card-text'>Building robots that can perceive, reason, and act in dynamic, unstructured
environments remains a core challenge. Recent embodied systems often adopt a
dual-system paradigm, where System 2 handles high-level reasoning while System
1 executes low-level control. In this work, we refer to System 2 as the
embodied brain, emphasizing its role as the cognitive core for reasoning and
decision-making in manipulation tasks. Given this role, systematic evaluation
of the embodied brain is essential. Yet existing benchmarks emphasize execution
success, or when targeting high-level reasoning, suffer from incomplete
dimensions and limited task realism, offering only a partial picture of
cognitive capability. To bridge this gap, we introduce RoboBench, a benchmark
that systematically evaluates multimodal large language models (MLLMs) as
embodied brains. Motivated by the critical roles across the full manipulation
pipeline, RoboBench defines five dimensions-instruction comprehension,
perception reasoning, generalized planning, affordance prediction, and failure
analysis-spanning 14 capabilities, 25 tasks, and 6092 QA pairs. To ensure
realism, we curate datasets across diverse embodiments, attribute-rich objects,
and multi-view scenes, drawing from large-scale real robotic data. For
planning, RoboBench introduces an evaluation framework,
MLLM-as-world-simulator. It evaluate embodied feasibility by simulating whether
predicted plans can achieve critical object-state changes. Experiments on 14
MLLMs reveal fundamental limitations: difficulties with implicit instruction
comprehension, spatiotemporal reasoning, cross-scenario planning, fine-grained
affordance understanding, and execution failure diagnosis. RoboBench provides a
comprehensive scaffold to quantify high-level cognition, and guide the
development of next-generation embodied MLLMs. The project page is in
https://robo-bench.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17797v1' target='_blank'>Enterprise Deep Research: Steerable Multi-Agent Deep Research for
  Enterprise Analytics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Akshara Prabhakar, Roshan Ram, Zixiang Chen, Silvio Savarese, Frank Wang, Caiming Xiong, Huan Wang, Weiran Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 17:55:11</h6>
<p class='card-text'>As information grows exponentially, enterprises face increasing pressure to
transform unstructured data into coherent, actionable insights. While
autonomous agents show promise, they often struggle with domain-specific
nuances, intent alignment, and enterprise integration. We present Enterprise
Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning
Agent for adaptive query decomposition, (2) four specialized search agents
(General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool
ecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a
Visualization Agent for data-driven insights, and (5) a reflection mechanism
that detects knowledge gaps and updates research direction with optional
human-in-the-loop steering guidance. These components enable automated report
generation, real-time streaming, and seamless enterprise deployment, as
validated on internal datasets. On open-ended benchmarks including DeepResearch
Bench and DeepConsult, EDR outperforms state-of-the-art agentic systems without
any human steering. We release the EDR framework and benchmark trajectories to
advance research on multi-agent reasoning applications.
  Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and
Dataset at https://huggingface.co/datasets/Salesforce/EDR-200</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17751v1' target='_blank'>TCLK Must Stay! CAMAC Must Go! How Does Fermilab Move Forward</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:M. R. Austin, L. Carmichael, D. McArthur, E. Milton, A. Quilty</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 17:06:30</h6>
<p class='card-text'>The current Timing System at Fermilab has been around for 40 years and
currently relies on 7 CAMAC crates and over 100 CAMAC cards to produce the
Tevatron Clock (TCLK). Thanks to the ingenuity of those before us, this has
allowed Fermilab the flexibility to change the timing and Events for its
accelerator as beamlines and projects have changed over the years. With the
advent of the Proton Improvement Plan-II (PIP-II), the Timing System at
Fermilab is being reimagined into a single chassis with even greater
flexibility and functionality for decades to come while tackling the
ever-challenging task of maintaining backwards compatibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17714v1' target='_blank'>The Marked Edge Walk: A Novel MCMC Algorithm for Sampling of Graph
  Partitions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Atticus McWhorter, Daryl DeFord</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 16:28:42</h6>
<p class='card-text'>Novel Markov Chain Monte Carlo (MCMC) methods have enabled the generation of
large ensembles of redistricting plans through graph partitioning. However,
existing algorithms such as Reversible Recombination (RevReCom) and
Metropolized Forest Recombination (MFR) are constrained to sampling from
distributions related to spanning trees. We introduce the marked edge walk
(MEW), a novel MCMC algorithm for sampling from the space of graph partitions
under a tunable distribution. The walk operates on the space of spanning trees
with marked edges, allowing for calculable transition probabilities for use in
the Metropolis-Hastings algorithm. Empirical results on real-world dual graphs
show convergence under target distributions unrelated to spanning trees. For
this reason, MEW represents an advancement in flexible ensemble generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17691v1' target='_blank'>A Mimamsa Inspired Framework For Instruction Sequencing In AI Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bama Srinivasan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 16:06:53</h6>
<p class='card-text'>This paper presents a formal framework for sequencing instructions in AI
agents, inspired by the Indian philosophical system of Mimamsa. The framework
formalizes sequencing mechanisms through action object pairs in three distinct
ways: direct assertion (Srutikrama) for temporal precedence, purpose driven
sequencing (Arthakrama) for functional dependencies, and iterative procedures
(Pravrittikrama) for distinguishing between parallel and sequential execution
in repetitive tasks. It introduces the syntax and semantics of an action object
imperative logic, extending the MIRA formalism (Srinivasan and Parthasarathi,
2021) with explicit deduction rules for sequencing. The correctness of
instruction sequencing is established through a validated theorem, which is
based on object dependencies across successive instructions. This is further
supported by proofs of soundness and completeness. This formal verification
enables reliable instruction sequencing, impacting AI applications across areas
like task planning and robotics by addressing temporal reasoning and dependency
modeling.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17614v1' target='_blank'>OG-Rank: Learning to Rank Fast and Slow with Uncertainty and
  Reward-Trend Guided Adaptive Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Praphul Singh, Corey Barrett, Sumana Srivasta, Irfan Bulu, Sri Gadde, Krishnaram Kenthapadi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 15:00:02</h6>
<p class='card-text'>Clinicians need ranking systems that work in real time and still justify
their choices. Motivated by the need for a low-latency, decoder-based reranker,
we present OG-Rank, a single-decoder approach that pairs a pooled first-token
scoring signal with an uncertainty-gated explanation step. The model scores all
candidates in one pass and generates a brief, structured rationale only when
the list is genuinely ambiguous, keeping latency predictable. Trained with a
curriculum that concentrates effort on hard cases, OG-Rank delivers strong
effectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,
nDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,
nDCG@20~0.699 at a 45\% gate rate), while compact backbones show similar gains
under the same policy. Encoder baselines trail in both effectiveness and
flexibility. The result is a practical recipe: rank fast by default and explain
when it helps, a pattern that applies broadly to decision tasks where selective
generation buys accuracy at acceptable cost. The single-policy design
simplifies deployment and budget planning, and the curriculum principle (spend
more on the hard cases, less on the easy ones) readily transfers beyond
clinical order selection.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17551v1' target='_blank'>Towards Optimal Control and Algorithmic Structure of Decompression
  Schedules</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benjamin Marsh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 14:00:51</h6>
<p class='card-text'>We formalise decompression planning as an optimal control problem with gas
feasibility windows (ppO$_2$, END), affine ceilings, and convex penalties in
normalised oversaturation. We prove existence, a monotone no re-descent
structure and bang-bang ascents under a mild monotonicity assumption on inert
fraction, and establish dwell time KKT conditions. We give pseudo-polynomial DP
and label-setting algorithms with a priori error bounds, derive Lipschitz
regularity of the online value function, and discuss multi-species extensions.
The efficient frontier is continuous and generally nonconvex. We provide the
first formal existence and bang-bang structure proof under mixed gas
feasibility windows.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17541v1' target='_blank'>Distributed Spatial-Temporal Trajectory Optimization for
  Unmanned-Aerial-Vehicle Swarm</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaobo Zheng, Pan Tang, Defu Lin, Shaoming He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 13:45:50</h6>
<p class='card-text'>Swarm trajectory optimization problems are a well-recognized class of
multi-agent optimal control problems with strong nonlinearity. However, the
heuristic nature of needing to set the final time for agents beforehand and the
time-consuming limitation of the significant number of iterations prohibit the
application of existing methods to large-scale swarm of Unmanned Aerial
Vehicles (UAVs) in practice. In this paper, we propose a spatial-temporal
trajectory optimization framework that accomplishes multi-UAV consensus based
on the Alternating Direction Multiplier Method (ADMM) and uses Differential
Dynamic Programming (DDP) for fast local planning of individual UAVs. The
introduced framework is a two-level architecture that employs Parameterized DDP
(PDDP) as the trajectory optimizer for each UAV, and ADMM to satisfy the local
constraints and accomplish the spatial-temporal parameter consensus among all
UAVs. This results in a fully distributed algorithm called Distributed
Parameterized DDP (D-PDDP). In addition, an adaptive tuning criterion based on
the spectral gradient method for the penalty parameter is proposed to reduce
the number of algorithmic iterations. Several simulation examples are presented
to verify the effectiveness of the proposed algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17539v1' target='_blank'>Volumetric Non-Invasive Cardiac Mapping for Accessible Global Arrhythmia
  Characterization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jorge Vicente-Puig, Judit Chamorro-Servent, Ernesto Zacur, Inés Llorente-Lipe, Marta Martínez, Jorge Sanchez, Jana Reventós, Ivo Roca-Luque, Lluis Mont, Felipe Atienza, Andreu M. Climent, Maria S. Guillem, Ismael Hernández-Romero</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 13:42:47</h6>
<p class='card-text'>Cardiac arrhythmias are a major cause of morbidity and mortality increasing
the risk of stroke, heart failure, and sudden cardiac death. Imageless
electrocardiographic imaging (ECGI) provides a non invasive alternative to
electrical mapping from body surface potentials, but conventional ECGI is
confined to epicardial reconstructions and can miss arrhythmias originating in
deeper myocardium. We address this by reconstructing three dimensional cardiac
activity with a volumetric formulation that solves an inverse source problem
via Green's functions, enabling full volume activation mapping and improved
localization in anatomically complex regions. We evaluate the approach on
simulated premature ventricular beats and on four challenging patient cases, a
right ventricular outflow tract premature ventricular contraction, a left
bundle branch block, a ventricular tachycardia, and Wolff Parkinson White, and
additionally assess performance on an open source myocardial infarction
dataset. Results show that volumetric ECGI recovers 3D activation and sharpens
arrhythmia origin localization, achieving a 59.3% reduction in geodesic error
between estimated and simulated origins relative to surface only methods; in
patient cases, activation patterns align with clinical diagnoses. Overall,
imageless volumetric ECGI offers accessible, non invasive 3D activation mapping
that overcomes a core limitation of surface restricted techniques and may
improve preprocedural planning, ablation target guidance, and selection or
optimization of cardiac resynchronization therapy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17525v1' target='_blank'>HumanMPC - Safe and Efficient MAV Navigation among Humans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simon Schaefer, Helen Oleynikova, Sandra Hirche, Stefan Leutenegger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 13:24:36</h6>
<p class='card-text'>Safe and efficient robotic navigation among humans is essential for
integrating robots into everyday environments. Most existing approaches focus
on simplified 2D crowd navigation and fail to account for the full complexity
of human body dynamics beyond root motion. We present HumanMPC, a Model
Predictive Control (MPC) framework for 3D Micro Air Vehicle (MAV) navigation
among humans that combines theoretical safety guarantees with data-driven
models for realistic human motion forecasting. Our approach introduces a novel
twist to reachability-based safety formulation that constrains only the initial
control input for safety while modeling its effects over the entire planning
horizon, enabling safe yet efficient navigation. We validate HumanMPC in both
simulated experiments using real human trajectories and in the real-world,
demonstrating its effectiveness across tasks ranging from goal-directed
navigation to visual servoing for human tracking. While we apply our method to
MAVs in this work, it is generic and can be adapted by other platforms. Our
results show that the method ensures safety without excessive conservatism and
outperforms baseline approaches in both efficiency and reliability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17482v1' target='_blank'>SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World
  Model Powered by Sparse and Dynamic Queries</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenxu Dang, Haiyan Liu, Guangjun Bao, Pei An, Xinyue Tang, Jie Ma, Bingchuan Sun, Yan Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 12:26:25</h6>
<p class='card-text'>Semantic occupancy has emerged as a powerful representation in world models
for its ability to capture rich spatial semantics. However, most existing
occupancy world models rely on static and fixed embeddings or grids, which
inherently limit the flexibility of perception. Moreover, their ``in-place
classification" over grids exhibits a potential misalignment with the dynamic
and continuous nature of real scenarios.In this paper, we propose SparseWorld,
a novel 4D occupancy world model that is flexible, adaptive, and efficient,
powered by sparse and dynamic queries. We propose a Range-Adaptive Perception
module, in which learnable queries are modulated by the ego vehicle states and
enriched with temporal-spatial associations to enable extended-range
perception. To effectively capture the dynamics of the scene, we design a
State-Conditioned Forecasting module, which replaces classification-based
forecasting with regression-guided formulation, precisely aligning the dynamic
queries with the continuity of the 4D environment. In addition, We specifically
devise a Temporal-Aware Self-Scheduling training strategy to enable smooth and
efficient training. Extensive experiments demonstrate that SparseWorld achieves
state-of-the-art performance across perception, forecasting, and planning
tasks. Comprehensive visualizations and ablation studies further validate the
advantages of SparseWorld in terms of flexibility, adaptability, and
efficiency. The code is available at https://github.com/MSunDYY/SparseWorld.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17450v1' target='_blank'>Active Inference for an Intelligent Agent in Autonomous Reconnaissance
  Missions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Johan Schubert, Farzad Kamrani, Tove Gustavi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 11:35:46</h6>
<p class='card-text'>We develop an active inference route-planning method for the autonomous
control of intelligent agents. The aim is to reconnoiter a geographical area to
maintain a common operational picture. To achieve this, we construct an
evidence map that reflects our current understanding of the situation,
incorporating both positive and "negative" sensor observations of possible
target objects collected over time, and diffusing the evidence across the map
as time progresses. The generative model of active inference uses
Dempster-Shafer theory and a Gaussian sensor model, which provides input to the
agent. The generative process employs a Bayesian approach to update a posterior
probability distribution. We calculate the variational free energy for all
positions within the area by assessing the divergence between a pignistic
probability distribution of the evidence map and a posterior probability
distribution of a target object based on the observations, including the level
of surprise associated with receiving new observations. Using the free energy,
we direct the agents' movements in a simulation by taking an incremental step
toward a position that minimizes the free energy. This approach addresses the
challenge of exploration and exploitation, allowing agents to balance searching
extensive areas of the geographical map while tracking identified target
objects.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17418v1' target='_blank'>Diverse Planning with Simulators via Linear Temporal Logic</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mustafa F. Abdelwahed, Alice Toniolo, Joan Espasa, Ian P. Gent</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 10:59:09</h6>
<p class='card-text'>Autonomous agents rely on automated planning algorithms to achieve their
objectives. Simulation-based planning offers a significant advantage over
declarative models in modelling complex environments. However, relying solely
on a planner that produces a single plan may not be practical, as the generated
plans may not always satisfy the agent's preferences. To address this
limitation, we introduce $\texttt{FBI}_\texttt{LTL}$, a diverse planner
explicitly designed for simulation-based planning problems.
$\texttt{FBI}_\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define
semantic diversity criteria, enabling agents to specify what constitutes
meaningfully different plans. By integrating these LTL-based diversity models
directly into the search process, $\texttt{FBI}_\texttt{LTL}$ ensures the
generation of semantically diverse plans, addressing a critical limitation of
existing diverse planning approaches that may produce syntactically different
but semantically identical solutions. Extensive evaluations on various
benchmarks consistently demonstrate that $\texttt{FBI}_\texttt{LTL}$ generates
more diverse plans compared to a baseline approach. This work establishes the
feasibility of semantically-guided diverse planning in simulation-based
environments, paving the way for innovative approaches in realistic,
non-symbolic domains where traditional model-based approaches fail.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2510.17407v1' target='_blank'>Quantitative Stability in Discrete Optimal Transport</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:William Ford</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-10-20 10:49:19</h6>
<p class='card-text'>This work investigates several aspects related to quantitative stability in
optimal transport, as well as uniqueness of the dual transport problem. Our
main contributions are as follows. Chapter 1: Observations regarding the
quantitative stability of optimal transport plans with respect to Wasserstein
distance on the product space. Chapter 2: Extention of strong convexity
inequalities for the Kantorovich functional to a larger class of source
measures, using glueing arguments recently used for the quantitative stability
of optimal transport maps. Chapters 3/4: A qualitative description of the
behaviour of the fully discrete transport problem under perturbation of the
support positions, as well as quantitative stability under uniqueness
assumptions. Chapter 5: Extention of known uniqueness criteria for the dual
transport problem. We show that when one marginal measure has Lipschitz-path
connected support and the other has bounded support, the values of dual
optimisers are unique up to a constant for a large family of costs, including
$p$-costs for all $p>1$.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>