<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>planning - 2025-10-01</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>planning - 2025-10-01</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26575v1' target='_blank'>The Trajectory Bundle Method: Unifying Sequential-Convex Programming and
  Sampling-Based Trajectory Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kevin Tracy, John Z. Zhang, Jon Arrizabalaga, Stefan Schaal, Yuval Tassa, Tom Erez, Zachary Manchester</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 17:34:36</h6>
<p class='card-text'>We present a unified framework for solving trajectory optimization problems
in a derivative-free manner through the use of sequential convex programming.
Traditionally, nonconvex optimization problems are solved by forming and
solving a sequence of convex optimization problems, where the cost and
constraint functions are approximated locally through Taylor series expansions.
This presents a challenge for functions where differentiation is expensive or
unavailable. In this work, we present a derivative-free approach to form these
convex approximations by computing samples of the dynamics, cost, and
constraint functions and letting the solver interpolate between them. Our
framework includes sample-based trajectory optimization techniques like
model-predictive path integral (MPPI) control as a special case and generalizes
them to enable features like multiple shooting and general equality and
inequality constraints that are traditionally associated with derivative-based
sequential convex programming methods. The resulting framework is simple,
flexible, and capable of solving a wide variety of practical motion planning
and control problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26536v1' target='_blank'>OceanGym: A Benchmark Environment for Underwater Embodied Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yida Xue, Mingjun Mao, Xiangyuan Ru, Yuqi Zhu, Baochang Ren, Shuofei Qiao, Mengru Wang, Shumin Deng, Xinyu An, Ningyu Zhang, Ying Chen, Huajun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 17:09:32</h6>
<p class='card-text'>We introduce OceanGym, the first comprehensive benchmark for ocean underwater
embodied agents, designed to advance AI in one of the most demanding real-world
environments. Unlike terrestrial or aerial domains, underwater settings present
extreme perceptual and decision-making challenges, including low visibility,
dynamic ocean currents, making effective agent deployment exceptionally
difficult. OceanGym encompasses eight realistic task domains and a unified
agent framework driven by Multi-modal Large Language Models (MLLMs), which
integrates perception, memory, and sequential decision-making. Agents are
required to comprehend optical and sonar data, autonomously explore complex
environments, and accomplish long-horizon objectives under these harsh
conditions. Extensive experiments reveal substantial gaps between
state-of-the-art MLLM-driven agents and human experts, highlighting the
persistent difficulty of perception, planning, and adaptability in ocean
underwater environments. By providing a high-fidelity, rigorously designed
platform, OceanGym establishes a testbed for developing robust embodied AI and
transferring these capabilities to real-world autonomous ocean underwater
vehicles, marking a decisive step toward intelligent agents capable of
operating in one of Earth's last unexplored frontiers. The code and data are
available at https://github.com/OceanGPT/OceanGym.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26516v1' target='_blank'>Global Optimization Algorithm for Mixed-Integer Nonlinear Programs with
  Trigonometric Functions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christopher Montez, Sujeevraja Sanjeevi, Kaarthik Sundar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 16:54:21</h6>
<p class='card-text'>This article presents the first mixed-integer linear programming (MILP)-based
iterative algorithm to solve factorable mixed-integer nonlinear programs
(MINLPs) with bounded, differentiable periodic functions to global optimality
with an emphasis on trigonometric functions. At each iteration, the algorithm
solves a MILP relaxation of the original MINLP to obtain a bound on the optimal
objective value. The relaxations are constructed using partitions of variables
involved in each nonlinear term and across successive iterations, the solution
of the relaxations is used to refine these partitions further leading to
tighter relaxations. Also, at each iteration, a heuristic/local solve on the
MINLP is used to obtain a feasible solution to the MINLP. The iterative
algorithm terminates till the optimality gap is sufficiently small. This
article proposes novel refinement strategies that first choose a subset of
variables whose domain is refined, refinement schemes that specify the manner
in which the variable domains are refined, and MILP relaxations that exploit
the principal domain of the periodic functions. We also show how solving the
resulting MILP relaxation may be accelerated when two or more periodic
functions are related by a linking constraint. This is especially useful as any
periodic function may be approximated to arbitrary precision by a Fourier
series. Finally, we examine the effectiveness of the proposed approach by
solving a path planning problem for a single fixed-wing aerial vehicle and
present extensive numerical results comparing the various refinement schemes
and techniques.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26513v1' target='_blank'>Learning from Hallucinating Critical Points for Navigation in Dynamic
  Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saad Abdul Ghani, Kameron Lee, Xuesu Xiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 16:52:13</h6>
<p class='card-text'>Generating large and diverse obstacle datasets to learn motion planning in
environments with dynamic obstacles is challenging due to the vast space of
possible obstacle trajectories. Inspired by hallucination-based data synthesis
approaches, we propose Learning from Hallucinating Critical Points (LfH-CP), a
self-supervised framework for creating rich dynamic obstacle datasets based on
existing optimal motion plans without requiring expensive expert demonstrations
or trial-and-error exploration. LfH-CP factorizes hallucination into two
stages: first identifying when and where obstacles must appear in order to
result in an optimal motion plan, i.e., the critical points, and then
procedurally generating diverse trajectories that pass through these points
while avoiding collisions. This factorization avoids generative failures such
as mode collapse and ensures coverage of diverse dynamic behaviors. We further
introduce a diversity metric to quantify dataset richness and show that LfH-CP
produces substantially more varied training data than existing baselines.
Experiments in simulation demonstrate that planners trained on LfH-CP datasets
achieves higher success rates compared to a prior hallucination method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26510v1' target='_blank'>Ukrainian Wartime Astronomy and its Prospects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Danilo Albergaria, Kateryna Frantseva, Pedro Russo, Svitlana Babiichuk, Oksana Berezhna, Sofiia Denyshchenko, Daria Dobrycheva, Vadym Kaydash, Olena Kompaniiets, Oleksander Konovalenko, Yurii Kulinich, Igor Lukyanyk, Vladyslava Marsakova, Bohdan Novosyadlyj, Elena Panko, Volodymyr Reshetnyk, Ivan Slyusarev, Iurii Sushch, Ganna Tolstanova, Iryna Vavilova, Liubov Yankiv-Vitkovska, Yaroslav Yatskiv, Vyacheslav Zakharenko</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 16:50:51</h6>
<p class='card-text'>The Russian invasion of Ukraine damaged or compromised astronomical
facilities and has prompted the displacement of researchers. A plan to restore
Ukrainian astronomy, rooted in a deeper integration with the international
community, is now being developed.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26489v1' target='_blank'>Contrastive Diffusion Guidance for Spatial Inverse Problems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sattwik Basu, Chaitanya Amballa, Zhongweiyang Xu, Jorge Vančo Sampedro, Srihari Nelakuditi, Romit Roy Choudhury</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 16:33:25</h6>
<p class='card-text'>We consider the inverse problem of reconstructing the spatial layout of a
place, a home floorplan for example, from a user`s movements inside that
layout. Direct inversion is ill-posed since many floorplans can explain the
same movement trajectories. We adopt a diffusion-based posterior sampler to
generate layouts consistent with the measurements. While active research is in
progress on generative inverse solvers, we find that the forward operator in
our problem poses new challenges. The path-planning process inside a floorplan
is a non-invertible, non-differentiable function, and causes instability while
optimizing using the likelihood score. We break-away from existing approaches
and reformulate the likelihood score in a smoother embedding space. The
embedding space is trained with a contrastive loss which brings compatible
floorplans and trajectories close to each other, while pushing mismatched pairs
far apart. We show that a surrogate form of the likelihood score in this
embedding space is a valid approximation of the true likelihood score, making
it possible to steer the denoising process towards the posterior. Across
extensive experiments, our model CoGuide produces more consistent floorplans
from trajectories, and is more robust than differentiable-planner baselines and
guided-diffusion methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26459v1' target='_blank'>Analytic Conditions for Differentiable Collision Detection in Trajectory
  Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Akshay Jaitly, Devesh K. Jha, Kei Ota, Yuki Shirai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 16:09:52</h6>
<p class='card-text'>Optimization-based methods are widely used for computing fast, diverse
solutions for complex tasks such as collision-free movement or planning in the
presence of contacts. However, most of these methods require enforcing
non-penetration constraints between objects, resulting in a non-trivial and
computationally expensive problem. This makes the use of optimization-based
methods for planning and control challenging. In this paper, we present a
method to efficiently enforce non-penetration of sets while performing
optimization over their configuration, which is directly applicable to problems
like collision-aware trajectory optimization. We introduce novel differentiable
conditions with analytic expressions to achieve this. To enforce non-collision
between non-smooth bodies using these conditions, we introduce a method to
approximate polytopes as smooth semi-algebraic sets. We present several
numerical experiments to demonstrate the performance of the proposed method and
compare the performance with other baseline methods recently proposed in the
literature.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26458v1' target='_blank'>EQ-Robin: Generating Multiple Minimal Unique-Cause MC/DC Test Suites</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Robin Lee, Youngho Nam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 16:09:39</h6>
<p class='card-text'>Modified Condition/Decision Coverage (MC/DC), particularly its strict
Unique-Cause form, is a cornerstone of safety-critical software verification. A
recent algorithm, "Robin's Rule," introduced a deterministic method to
construct the theoretical minimum of N+1 test cases for Singular Boolean
Expressions (SBEs). However, this approach yields only a single test suite,
introducing a critical risk: if a test case forming a required 'independence
pair' is an illegal input forbidden by system constraints, the suite fails to
achieve 100% coverage. This paper proposes EQ-Robin, a lightweight pipeline
that systematically generates a family of minimal Unique-Cause MC/DC suites to
mitigate this risk. We introduce a method for systematically generating
semantically equivalent SBEs by applying algebraic rearrangements to an
Abstract Syntax Tree (AST) representation of the expression. By applying
Robin's Rule to each structural variant, a diverse set of test suites can be
produced. This provides a resilient path to discovering a valid test suite that
preserves the N+1 minimality guarantee while navigating real-world constraints.
We outline an evaluation plan on TCAS-II-derived SBEs to demonstrate how
EQ-Robin offers a practical solution for ensuring robust MC/DC coverage.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26440v1' target='_blank'>Transformer Classification of Breast Lesions: The BreastDCEDL_AMBL
  Benchmark Dataset and 0.92 AUC Baseline</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Naomi Fridman, Anat Goldstein</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 15:58:02</h6>
<p class='card-text'>The error is caused by special characters that arXiv's system doesn't
recognize. Here's the cleaned version with all problematic characters replaced:
Breast magnetic resonance imaging is a critical tool for cancer detection and
treatment planning, but its clinical utility is hindered by poor specificity,
leading to high false-positive rates and unnecessary biopsies. This study
introduces a transformer-based framework for automated classification of breast
lesions in dynamic contrast-enhanced MRI, addressing the challenge of
distinguishing benign from malignant findings. We implemented a SegFormer
architecture that achieved an AUC of 0.92 for lesion-level classification, with
100% sensitivity and 67% specificity at the patient level - potentially
eliminating one-third of unnecessary biopsies without missing malignancies. The
model quantifies malignant pixel distribution via semantic segmentation,
producing interpretable spatial predictions that support clinical
decision-making. To establish reproducible benchmarks, we curated
BreastDCEDL_AMBL by transforming The Cancer Imaging Archive's AMBL collection
into a standardized deep learning dataset with 88 patients and 133 annotated
lesions (89 benign, 44 malignant). This resource addresses a key infrastructure
gap, as existing public datasets lack benign lesion annotations, limiting
benign-malignant classification research. Training incorporated an expanded
cohort of over 1,200 patients through integration with BreastDCEDL datasets,
validating transfer learning approaches despite primary tumor-only annotations.
Public release of the dataset, models, and evaluation protocols provides the
first standardized benchmark for DCE-MRI lesion classification, enabling
methodological advancement toward clinical deployment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26428v1' target='_blank'>Real-time Velocity Profile Optimization for Time-Optimal Maneuvering
  with Generic Acceleration Constraints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mattia Piazza, Mattia Piccinini, Sebastiano Taddei, Francesco Biral, Enrico Bertolazzi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 15:48:56</h6>
<p class='card-text'>The computation of time-optimal velocity profiles along prescribed paths,
subject to generic acceleration constraints, is a crucial problem in robot
trajectory planning, with particular relevance to autonomous racing. However,
the existing methods either support arbitrary acceleration constraints at high
computational cost or use conservative box constraints for computational
efficiency. We propose FBGA, a new \underline{F}orward-\underline{B}ackward
algorithm with \underline{G}eneric \underline{A}cceleration constraints, which
achieves both high accuracy and low computation time. FBGA operates forward and
backward passes to maximize the velocity profile in short, discretized path
segments, while satisfying user-defined performance limits. Tested on five
racetracks and two vehicle classes, FBGA handles complex, non-convex
acceleration constraints with custom formulations. Its maneuvers and lap times
closely match optimal control baselines (within $0.11\%$-$0.36\%$), while being
up to three orders of magnitude faster. FBGA maintains high accuracy even with
coarse discretization, making it well-suited for online multi-query trajectory
planning. Our open-source \texttt{C++} implementation is available at:
https://anonymous.4open.science/r/FB_public_RAL.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26386v1' target='_blank'>PANDA: Towards Generalist Video Anomaly Detection via Agentic AI
  Engineer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhiwei Yang, Chen Gao, Mike Zheng Shou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 15:19:43</h6>
<p class='card-text'>Video anomaly detection (VAD) is a critical yet challenging task due to the
complex and diverse nature of real-world scenarios. Previous methods typically
rely on domain-specific training data and manual adjustments when applying to
new scenarios and unseen anomaly types, suffering from high labor costs and
limited generalization. Therefore, we aim to achieve generalist VAD, i.e.,
automatically handle any scene and any anomaly types without training data or
human involvement. In this work, we propose PANDA, an agentic AI engineer based
on MLLMs. Specifically, we achieve PANDA by comprehensively devising four key
capabilities: (1) self-adaptive scene-aware strategy planning, (2) goal-driven
heuristic reasoning, (3) tool-augmented self-reflection, and (4) self-improving
chain-of-memory. Concretely, we develop a self-adaptive scene-aware RAG
mechanism, enabling PANDA to retrieve anomaly-specific knowledge for anomaly
detection strategy planning. Next, we introduce a latent anomaly-guided
heuristic prompt strategy to enhance reasoning precision. Furthermore, PANDA
employs a progressive reflection mechanism alongside a suite of context-aware
tools to iteratively refine decision-making in complex scenarios. Finally, a
chain-of-memory mechanism enables PANDA to leverage historical experiences for
continual performance improvement. Extensive experiments demonstrate that PANDA
achieves state-of-the-art performance in multi-scenario, open-set, and complex
scenario settings without training and manual involvement, validating its
generalizable and robust anomaly detection capability. Code is released at
https://github.com/showlab/PANDA.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26339v1' target='_blank'>Kinodynamic Motion Planning for Mobile Robot Navigation across
  Inconsistent World Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eric R. Damm, Thomas M. Howard</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 14:45:30</h6>
<p class='card-text'>Mobile ground robots lacking prior knowledge of an environment must rely on
sensor data to develop a model of their surroundings. In these scenarios,
consistent identification of obstacles and terrain features can be difficult
due to noise and algorithmic shortcomings, which can make it difficult for
motion planning systems to generate safe motions. One particular difficulty to
overcome is when regions of the cost map switch between being marked as
obstacles and free space through successive planning cycles. One potential
solution to this, which we refer to as Valid in Every Hypothesis (VEH), is for
the planning system to plan motions that are guaranteed to be safe through a
history of world models. Another approach is to track a history of world
models, and adjust node costs according to the potential penalty of needing to
reroute around previously hazardous areas. This work discusses three major
iterations on this idea. The first iteration, called PEH, invokes a sub-search
for every node expansion that crosses through a divergence point in the world
models. The second and third iterations, called GEH and GEGRH respectively,
defer the sub-search until after an edge expands into the goal region. GEGRH
uses an additional step to revise the graph based on divergent nodes in each
world. Initial results showed that, although PEH and GEH find more optimistic
solutions than VEH, they are unable to generate solutions in less than
one-second, which exceeds our requirements for field deployment. Analysis of
results from a field experiment in an unstructured, off-road environment on a
Clearpath Robotics Warthog UGV indicate that GEGRH finds lower cost
trajectories and has faster average planning times than VEH. Compared to
single-hypothesis (SH) search, where only the latest world model is considered,
GEGRH generates more conservative plans with a small increase in average
planning time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26277v1' target='_blank'>Cat: Post-training quantization error reduction via cluster-based affine
  transformation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ali Zoljodi, Radu Timofte, Masoud Daneshtalab</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 14:00:28</h6>
<p class='card-text'>Post-Training Quantization (PTQ) reduces the memory footprint and
computational overhead of deep neural networks by converting full-precision
(FP) values into quantized and compressed data types. While PTQ is more
cost-efficient than Quantization-Aware Training (QAT), it is highly susceptible
to accuracy degradation under a low-bit quantization (LQ) regime (e.g., 2-bit).
Affine transformation is a classical technique used to reduce the discrepancy
between the information processed by a quantized model and that processed by
its full-precision counterpart; however, we find that using plain affine
transformation, which applies a uniform affine parameter set for all outputs,
worsens the results in low-bit PTQ. To address this, we propose Cluster-based
Affine Transformation (CAT), an error-reduction framework that employs
cluster-specific parameters to align LQ outputs with FP counterparts. CAT
refines LQ outputs with only a negligible number of additional parameters,
without requiring fine-tuning of the model or quantization parameters. We
further introduce a novel PTQ framework integrated with CAT. Experiments on
ImageNet-1K show that this framework consistently outperforms prior PTQ methods
across diverse architectures and LQ settings, achieving up to 53.18% Top-1
accuracy on W2A2 ResNet-18. Moreover, CAT enhances existing PTQ baselines by
more than 3% when used as a plug-in. We plan to release our implementation
alongside the publication of this paper.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26276v1' target='_blank'>Optimizing Speech Language Models for Acoustic Consistency</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Morteza Rohanian, Michael Krauthammer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 13:59:52</h6>
<p class='card-text'>We study speech language models that incorporate semantic initialization and
planning losses to achieve robust and consistent generation. Our approach
initializes speech tokens with self-supervised features, applies a light
alignment loss, and trains with thinning and auxiliary objectives that target
robustness and content planning. We train three models: a 0.7B speech-only
model, a 1.0B speech-only model, and a 1.0B interleaved model with both text
and speech. Acoustic studies show that the speech-only models achieve the
highest consistency across speaker, gender, sentiment, room, and background
factors, surpassing larger systems. Interleaving improves lexical and syntactic
probes and semantic--acoustic alignment but reduces consistency. Linear probes
show that our initialization biases the model toward content structure while
trading off prosody detail. These results show that LM-side design and training
mix control the balance between acoustic stability and semantic grounding
without changes to the tokenizer or runtime architecture. A demo and model
weights are available for exploration.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26216v1' target='_blank'>Comparative Analysis of Ant Colony Optimization and Google OR-Tools for
  Solving the Open Capacitated Vehicle Routing Problem in Logistics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Assem Omar, Youssef Omar, Marwa Solayman, Hesham Mansour</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 13:18:14</h6>
<p class='card-text'>In modern logistics management systems, route planning requires high
efficiency. The Open Capacitated Vehicle Routing Problem (OCVRP) deals with
finding optimal delivery routes for a fleet of vehicles serving geographically
distributed customers, without requiring the vehicles to return to the depot
after deliveries. The present study is comparative in nature and speaks of two
algorithms for OCVRP solution: Ant Colony Optimization (ACO), a nature-inspired
metaheuristic; and Google OR-Tools, an industry-standard toolkit for
optimization. Both implementations were developed in Python and using a custom
dataset. Performance appraisal was based on routing efficiency, computation
time, and scalability. The results show that ACO allows flexibility in routing
parameters while OR-Tools runs much faster with more consistency and requires
less input. This could help choose among routing strategies for scalable
real-time logistics systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26171v1' target='_blank'>Neighbor-aware informal settlement mapping with graph convolutional
  networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thomas Hallopeau, Joris Guérin, Laurent Demagistri, Christovam Barcellos, Nadine Dessay</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 12:25:25</h6>
<p class='card-text'>Mapping informal settlements is crucial for addressing challenges related to
urban planning, public health, and infrastructure in rapidly growing cities.
Geospatial machine learning has emerged as a key tool for detecting and mapping
these areas from remote sensing data. However, existing approaches often treat
spatial units independently, neglecting the relational structure of the urban
fabric. We propose a graph-based framework that explicitly incorporates local
geographical context into the classification process. Each spatial unit (cell)
is embedded in a graph structure along with its adjacent neighbors, and a
lightweight Graph Convolutional Network (GCN) is trained to classify whether
the central cell belongs to an informal settlement. Experiments are conducted
on a case study in Rio de Janeiro using spatial cross-validation across five
distinct zones, ensuring robustness and generalizability across heterogeneous
urban landscapes. Our method outperforms standard baselines, improving Kappa
coefficient by 17 points over individual cell classification. We also show that
graph-based modeling surpasses simple feature concatenation of neighboring
cells, demonstrating the benefit of encoding spatial structure for urban scene
understanding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26161v1' target='_blank'>90% Faster, 100% Code-Free: MLLM-Driven Zero-Code 3D Game Development</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Runxin Yang, Yuxuan Wan, Shuqing Li, Michael R. Lyu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 12:14:56</h6>
<p class='card-text'>Developing 3D games requires specialized expertise across multiple domains,
including programming, 3D modeling, and engine configuration, which limits
access to millions of potential creators. Recently, researchers have begun to
explore automated game development. However, existing approaches face three
primary challenges: (1) limited scope to 2D content generation or isolated code
snippets; (2) requirement for manual integration of generated components into
game engines; and (3) poor performance on handling interactive game logic and
state management. While Multimodal Large Language Models (MLLMs) demonstrate
potential capabilities to ease the game generation task, a critical gap still
remains in translating these outputs into production-ready, executable game
projects based on game engines such as Unity and Unreal Engine.
  To bridge the gap, this paper introduces UniGen, the first end-to-end
coordinated multi-agent framework that automates zero-coding development of
runnable 3D games from natural language requirements. Specifically, UniGen uses
a Planning Agent that interprets user requirements into structured blueprints
and engineered logic descriptions; after which a Generation Agent produces
executable C# scripts; then an Automation Agent handles engine-specific
component binding and scene construction; and lastly a Debugging Agent provides
real-time error correction through conversational interaction. We evaluated
UniGen on three distinct game prototypes. Results demonstrate that UniGen not
only democratizes game creation by requiring no coding from the user, but also
reduces development time by 91.4%. We release UniGen at
https://github.com/yxwan123/UniGen. A video demonstration is available at
https://www.youtube.com/watch?v=xyJjFfnxUx0.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26067v1' target='_blank'>Enhancing Connectivity for Emergency Vehicles Through UAV Trajectory and
  Resource Allocation Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:S. Fatemeh Bozorgi, S. Mohammad Razavizadeh, Mohsen Rezaee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 10:43:03</h6>
<p class='card-text'>Effective communication for emergency vehicles - such as ambulances and fire
trucks - is essential to support their operations in various traffic and
environmental conditions. In this context, this paper investigates a vehicular
communication system assisted by an Unmanned Aerial Vehicle (UAV), which
adjusts its trajectory and resource allocation according to communication
needs. The system classifies vehicles into two groups to address their varying
service requirements: emergency vehicles, which require a minimum instantaneous
data rate to access critical information timely, and normal vehicles. To
support both categories effectively, this paper proposes a joint optimization
approach that coordinates UAV trajectory planning and Dynamic Bandwidth
Allocation (DBA). The objective is to maximize the minimum average data rate
for normal vehicles while ensuring that emergency vehicles maintain an
instantaneous rate above a predefined threshold. This approach takes into
account some system constraints, including UAV propulsion power consumption,
mobility limitations, and backhaul capacity. To tackle the resulting non-convex
problem, an iterative optimization method is employed, where the original
problem is decomposed into two subproblems: bandwidth allocation and UAV
trajectory design. In each iteration, the trajectory subproblem is solved using
the Successive Convex Approximation (SCA) method. Numerical results confirm
that the proposed solution achieves superior performance in meeting service
requirements compared to baseline methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26050v1' target='_blank'>Conflict-Based Search and Prioritized Planning for Multi-Agent Path
  Finding Among Movable Obstacles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaoli Hu, Shizhe Zhao, Zhongqiang Ren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 10:27:05</h6>
<p class='card-text'>This paper investigates Multi-Agent Path Finding Among Movable Obstacles
(M-PAMO), which seeks collision-free paths for multiple agents from their start
to goal locations among static and movable obstacles. M-PAMO arises in
logistics and warehouses where mobile robots are among unexpected movable
objects. Although Multi-Agent Path Finding (MAPF) and single-agent Path
planning Among Movable Obstacles (PAMO) were both studied, M-PAMO remains
under-explored. Movable obstacles lead to new fundamental challenges as the
state space, which includes both agents and movable obstacles, grows
exponentially with respect to the number of agents and movable obstacles. In
particular, movable obstacles often closely couple agents together spatially
and temporally. This paper makes a first attempt to adapt and fuse the popular
Conflict-Based Search (CBS) and Prioritized Planning (PP) for MAPF, and a
recent single-agent PAMO planner called PAMO*, together to address M-PAMO. We
compare their performance with up to 20 agents and hundreds of movable
obstacles, and show the pros and cons of these approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.26006v1' target='_blank'>AgenticIQA: An Agentic Framework for Adaptive and Interpretable Image
  Quality Assessment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanwei Zhu, Yu Tian, Keyan Ding, Baoliang Chen, Bolin Chen, Shiqi Wang, Weisi Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 09:37:01</h6>
<p class='card-text'>Image quality assessment (IQA) is inherently complex, as it reflects both the
quantification and interpretation of perceptual quality rooted in the human
visual system. Conventional approaches typically rely on fixed models to output
scalar scores, limiting their adaptability to diverse distortions,
user-specific queries, and interpretability needs. Furthermore, scoring and
interpretation are often treated as independent processes, despite their
interdependence: interpretation identifies perceptual degradations, while
scoring abstracts them into a compact metric. To address these limitations, we
propose AgenticIQA, a modular agentic framework that integrates vision-language
models (VLMs) with traditional IQA tools in a dynamic, query-aware manner.
AgenticIQA decomposes IQA into four subtasks -- distortion detection,
distortion analysis, tool selection, and tool execution -- coordinated by a
planner, executor, and summarizer. The planner formulates task-specific
strategies, the executor collects perceptual evidence via tool invocation, and
the summarizer integrates this evidence to produce accurate scores with
human-aligned explanations. To support training and evaluation, we introduce
AgenticIQA-200K, a large-scale instruction dataset tailored for IQA agents, and
AgenticIQA-Eval, the first benchmark for assessing the planning, execution, and
summarization capabilities of VLM-based IQA agents. Extensive experiments
across diverse IQA datasets demonstrate that AgenticIQA consistently surpasses
strong baselines in both scoring accuracy and explanatory alignment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25952v1' target='_blank'>Gravitational wave experiments: achievements and plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Elista Bigongiari, Matteo Di Giovanni, Giovanni Losurdo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 08:47:01</h6>
<p class='card-text'>Gravitational wave (GW) experiments have transformed our understanding of the
Universe by enabling direct observations of compact object mergers and other
astrophysical phenomena. This chapter reviews the concepts of GW detectors,
such as LIGO, Virgo, and KAGRA, and describes their operating principles, data
acquisition and analysis techniques, and some of the methods used to extract
source properties. The scientific impact of GW observations is discussed as
well, including contributions to astrophysics, tests of general relativity, and
cosmology. We also examine the role of multimessenger astronomy and the
complementarity between different GW detectors and with other astroparticle
experiments. Finally, we outline future prospects with next-generation
detectors, like the Einstein Telescope and Cosmic Explorer, and space-based
missions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25946v1' target='_blank'>Automated Model Discovery via Multi-modal & Multi-step Pipeline</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lee Jung-Mok, Nam Hyeon-Woo, Moon Ye-Bin, Junhyun Nam, Tae-Hyun Oh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 08:40:05</h6>
<p class='card-text'>Automated model discovery is the process of automatically searching and
identifying the most appropriate model for a given dataset over a large
combinatorial search space. Existing approaches, however, often face challenges
in balancing the capture of fine-grained details with ensuring generalizability
beyond training data regimes with a reasonable model complexity. In this paper,
we present a multi-modal \& multi-step pipeline for effective automated model
discovery. Our approach leverages two vision-language-based modules (VLM),
AnalyzerVLM and EvaluatorVLM, for effective model proposal and evaluation in an
agentic way. AnalyzerVLM autonomously plans and executes multi-step analyses to
propose effective candidate models. EvaluatorVLM assesses the candidate models
both quantitatively and perceptually, regarding the fitness for local details
and the generalibility for overall trends. Our results demonstrate that our
pipeline effectively discovers models that capture fine details and ensure
strong generalizability. Additionally, extensive ablation studies show that
both multi-modality and multi-step reasoning play crucial roles in discovering
favorable models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25852v1' target='_blank'>Reinforced Embodied Planning with Verifiable Reward for Real-World
  Robotic Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zitong Bo, Yue Hu, Jinming Ma, Mingliang Zhou, Junhui Yin, Yachen Kang, Yuqi Liu, Tong Wu, Diyun Xiang, Hao Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 06:43:43</h6>
<p class='card-text'>Enabling robots to execute long-horizon manipulation tasks from free-form
language instructions remains a fundamental challenge in embodied AI. While
vision-language models (VLMs) have shown promise as high-level planners, their
deployment in the real world is hindered by two gaps: (i) the scarcity of
large-scale, sequential manipulation data that couples natural language with
multi-step action plans, and (ii) the absence of dense, interpretable rewards
for fine-tuning VLMs on planning objectives. To address these issues, we
propose REVER, a framework that empowers VLMs to generate and validate
long-horizon manipulation plans from natural language instructions in
real-world scenarios. Under REVER we train and release RoboFarseer, a VLM
incentivized to emit chain-of-thought that perform temporal and spatial
reasoning, ensuring physically plausible and logically coherent plans. To
obtain training data, we leverage the Universal Manipulation Interface
framework to capture hardware-agnostic demonstrations of atomic skills. An
automated annotation engine converts each demonstration into
vision-instruction-plan triplet. We introduce a verifiable reward that scores
the generated plan by its ordered bipartite matching overlap with the
ground-truth skill sequence. At run time, the fine-tuned VLM functions both as
a planner and as a monitor, verifying step-wise completion. RoboFarseer matches
or exceeds the performance of proprietary models that are orders of magnitude
larger, while on open-ended planning it surpasses the best baseline by more
than 40%. In real-world, long-horizon tasks, the complete system boosts overall
success by roughly 60% compared with the same low-level controller without the
planner. We will open-source both the dataset and the trained model upon
publication.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25810v1' target='_blank'>Learning to Reason as Action Abstractions with Scalable Mid-Training RL</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shenao Zhang, Donghan Yu, Yihao Feng, Bowen Jin, Zhaoran Wang, John Peebles, Zirui Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 05:34:20</h6>
<p class='card-text'>Large language models excel with reinforcement learning (RL), but fully
unlocking this potential requires a mid-training stage. An effective
mid-training phase should identify a compact set of useful actions and enable
fast selection among them through online RL. We formalize this intuition by
presenting the first theoretical result on how mid-training shapes
post-training: it characterizes an action subspace that minimizes both the
value approximation error from pruning and the RL error during subsequent
planning. Our analysis reveals two key determinants of mid-training
effectiveness: pruning efficiency, which shapes the prior of the initial RL
policy, and its impact on RL convergence, which governs the extent to which
that policy can be improved via online interactions. These results suggest that
mid-training is most effective when the decision space is compact and the
effective horizon is short, highlighting the importance of operating in the
space of action abstractions rather than primitive actions. Building on these
insights, we propose Reasoning as Action Abstractions (RA3), a scalable
mid-training algorithm. Specifically, we derive a sequential variational lower
bound and optimize it by iteratively discovering temporally-consistent latent
structures via RL, followed by fine-tuning on the bootstrapped data.
Experiments on code generation tasks demonstrate the effectiveness of our
approach. Across multiple base models, RA3 improves the average performance on
HumanEval and MBPP by 8 and 4 points over the base model and the next-token
prediction baseline. Furthermore, RA3 achieves faster convergence and higher
asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and
Codeforces.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25794v1' target='_blank'>Point-It-Out: Benchmarking Embodied Reasoning for Vision Language Models
  in Multi-Stage Visual Grounding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haotian Xue, Yunhao Ge, Yu Zeng, Zhaoshuo Li, Ming-Yu Liu, Yongxin Chen, Jiaojiao Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 05:05:54</h6>
<p class='card-text'>Vision-Language Models (VLMs) have demonstrated impressive world knowledge
across a wide range of tasks, making them promising candidates for embodied
reasoning applications. However, existing benchmarks primarily evaluate the
embodied reasoning ability of VLMs through multiple-choice questions based on
image annotations -- for example, selecting which trajectory better describes
an event in the image. In this work, we introduce the Point-It-Out (PIO)
benchmark, a novel benchmark designed to systematically assess the embodied
reasoning abilities of VLMs through precise visual grounding. We propose a
hierarchical evaluation protocol spanning three stages (S1: referred-object
localization, S2: task-driven pointing, and S3: visual trace prediction), with
data collected from critical domains for embodied intelligence, including
indoor, kitchen, driving, and robotic manipulation scenarios. Extensive
experiments with over ten state-of-the-art VLMs reveal several interesting
findings. For example, strong general-purpose models such as GPT-4o, while
excelling on many benchmarks (e.g., language, perception, and reasoning),
underperform compared to some open-source models in precise visual grounding;
models such as MoLMO perform well in S1 and S2 but struggle in S3, where
requires grounding combined with visual trace planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25733v1' target='_blank'>CATCH: A Novel Data Synthesis Framework for High Therapy Fidelity and
  Memory-Driven Planning Chain of Thought in AI Counseling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingyu Chen, Jingkai Lin, Zhaojie Chu, Xiaofen Xing, Yirong Chen, Xiangmin Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 03:44:00</h6>
<p class='card-text'>Recently, advancements in AI counseling based on large language models have
shown significant progress. However, existing studies employ a one-time
generation approach to synthesize multi-turn dialogue samples, resulting in low
therapy fidelity and failing to capture the decision-making rationale behind
each response. In this work, we propose CATCH, a novel data synthesis framework
designed to address these challenges. Specifically, to improve therapy
fidelity, we introduce the Progressive Dialogue Synthesis strategy, which
extracts goals, resources, and solutions from a client's self-report, organizes
them into structured outlines, and then incrementally generates stage-aligned
counseling dialogues. To capture decision-making rationale behind each
response, we propose the Memory-Driven Dynamic Planning thinking pattern that
integrates memory enhancement, global planning, and strategy reasoning; a
collaborative multi-agent optimizer then leverages MDP to attach explicit
chain-of-thought to each dialogue turn. Extensive experiments and human
evaluations demonstrate that CATCH significantly enhances fidelity and logical
coherence in AI counseling.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25719v1' target='_blank'>Beyond Point Estimates: Likelihood-Based Full-Posterior Wireless
  Localization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haozhe Lei, Hao Guo, Tommy Svensson, Sundeep Rangan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 03:24:21</h6>
<p class='card-text'>Modern wireless systems require not only position estimates, but also
quantified uncertainty to support planning, control, and radio resource
management. We formulate localization as posterior inference of an unknown
transmitter location from receiver measurements. We propose Monte Carlo
Candidate-Likelihood Estimation (MC-CLE), which trains a neural scoring network
using Monte Carlo sampling to compare true and candidate transmitter locations.
We show that in line-of-sight simulations with a multi-antenna receiver, MC-CLE
learns critical properties including angular ambiguity and front-to-back
antenna patterns. MC-CLE also achieves lower cross-entropy loss relative to a
uniform baseline and Gaussian posteriors. alternatives under a uniform-loss
metric.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25700v1' target='_blank'>PAST: Pilot and Adaptive Orchestration for Timely and Resilient Service
  Delivery in Edge-Assisted UAV Networks under Spatio-Temporal Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Houyi Qi, Minghui Liwang, Liqun Fu, Sai Zou, Xinlei Yi, Wei Ni, Huaiyu Dai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 02:58:58</h6>
<p class='card-text'>Incentive-driven resource trading is essential for UAV applications with
intensive, time-sensitive computing demands. Traditional spot trading suffers
from negotiation delays and high energy costs, while conventional futures
trading struggles to adapt to the dynamic, uncertain UAV-edge environment. To
address these challenges, we propose PAST (pilot-and-adaptive stable trading),
a novel framework for edge-assisted UAV networks with spatio-temporal dynamism.
PAST integrates two complementary mechanisms: PilotAO (pilot trading agreements
with overbooking), a risk-aware, overbooking-enabled early-stage
decision-making module that establishes long-term, mutually beneficial
agreements and boosts resource utilization; and AdaptAO (adaptive trading
agreements with overbooking rate update), an intelligent adaptation module that
dynamically updates agreements and overbooking rates based on UAV mobility,
supply-demand variations, and agreement performance. Together, these mechanisms
enable both stability and flexibility, guaranteeing individual rationality,
strong stability, competitive equilibrium, and weak Pareto optimality.
Extensive experiments on real-world datasets show that PAST consistently
outperforms benchmark methods in decision-making overhead, task completion
latency, resource utilization, and social welfare. By combining predictive
planning with real-time adjustments, PAST offers a valuable reference on robust
and adaptive practice for improving low-altitude mission performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25698v1' target='_blank'>Pinching-Antenna Systems (PASS)-Enabled UAV Delivery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Suyu Lv, Meng Li, Qi Li, Yuanwei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 02:56:18</h6>
<p class='card-text'>A pinching-antenna systems (PASS)-enabled unmanned aerial vehicle (UAV)
delivery framework is proposed, which exploits the capability of PASS to
establish a strong line-of-sight link and reduce free-space pathloss.Aiming at
minimizing the communication energy consumption in one cycle, a double-layer
optimization (DLO) algorithm is developed by jointly optimizing the UAV
delivery sequence and the pinching antenna (PA) activation vector. More
specifically, at the outer layer, a hierarchical alternating optimization (HAO)
scheme is proposed to tackle the NP-hard problem of delivery sequence planning,
where a genetic algorithm performs global exploration to generate candidate
solutions at the top-level, while a dynamic programming performs local
refinement to obtain elite solutions at the lower-level. With determined UAV
trajectory, at the inner layer, focus is placed on addressing the highly
coupled mixed-integer nonlinear programming problem of PA activation vector
optimization, where a pair of algorithms are proposed: 1) Branch-and-Bound
(BnB) algorithm for finding global optimum; 2) incremental search and local
refinement (ISLR) algorithm for reducing computational complexity. Simulation
results indicate that: i) The proposed HAO-based delivery sequence planning
scheme can effectively reduce the total flight distance, thereby decreasing
flight time and communication energy consumption; ii) Both the proposed BnB and
ISLR algorithms can achieve energy-efficient PA activation, with the former
exhibiting better performance and the latter having lower complexity; iii) PASS
outperforms the conventional multi-antenna systems, especially with higher
communication rate requirements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2509.25687v1' target='_blank'>OmniNav: A Unified Framework for Prospective Exploration and
  Visual-Language Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinda Xue, Junjun Hu, Minghua Luo, Xie Shichao, Jintao Chen, Zixun Xie, Quan Kuichen, Guo Wei, Mu Xu, Zedong Chu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-09-30 02:44:28</h6>
<p class='card-text'>Embodied navigation presents a core challenge for intelligent robots,
requiring the comprehension of visual environments, natural language
instructions, and autonomous exploration. Existing models often fall short in
offering a unified solution across diverse navigation paradigms, resulting in
low success rates and limited generalization. We introduce OmniNav, a unified
framework addressing instruct-goal, object-goal, point-goal navigation, and
frontier-based exploration within a single architecture. Our approach features
a lightweight, low-latency policy that accurately predicts continuous-space
waypoints (coordinates and orientations). This policy surpasses action-chunk
methods in precision and supports real-world deployment at control frequencies
up to 5 Hz. Architecturally, OmniNav employs a fast-slow system design: a fast
module generates waypoints using short-horizon visual context and subtasks,
while a slow module performs deliberative planning with long-horizon
observations and candidate frontiers to select subsequent subgoals and
subtasks. This collaboration enhances path efficiency and maintains trajectory
coherence, particularly in exploration and memory-intensive scenarios.
Crucially, we identify that the primary bottleneck isn't merely navigation
policy learning, but a robust understanding of general instructions and
objects. To boost generalization, OmniNav integrates large-scale,
general-purpose training datasets, including those for image captioning and
visual recognition, into a joint multi-task regimen. This significantly
improves success rates and robustness. Extensive experiments confirm OmniNav's
state-of-the-art performance across various navigation benchmarks, with
real-world deployment further validating its efficacy. OmniNav provides
practical insights for embodied navigation, charting a scalable path towards
versatile, highly generalizable robotic intelligence.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>